{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cpu\n",
      "1.10.2\n",
      "1.10.0\n",
      "4.11.3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import transformers\n",
    "from gpt3_onnx.generation_onnx import GPT2BeamSearchGenerator, GPT2Generator, GPT2BeamSearchSampleGenerator\n",
    "from transformers import GPT2Tokenizer\n",
    "import os\n",
    "\n",
    "\n",
    "print(torch.__version__)\n",
    "print(onnx.__version__)\n",
    "print(onnxruntime.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 4\n",
    "max_length=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50260, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50260, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_path = 'C:/Users/edbon/devproj/faiky-tails/savedir/s_kw/checkpoints/'\n",
    "\n",
    "with open(f'{chk_path}checkpoint.pt', 'rb') as f:\n",
    "    model = torch.load(f, map_location='cpu')\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('C:/Users/edbon/devproj/faiky-tails/savedir/tokenizer')\n",
    "# text_encoder.pad_token = text_encoder.eos_token\n",
    "\n",
    "PROMT = [\"старик\", \"Кощей\"]\n",
    "\n",
    "padtok =  0\n",
    "septok = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "starttok = tokenizer.convert_tokens_to_ids('<s>')\n",
    "endtok = tokenizer.convert_tokens_to_ids('</s>')\n",
    "\n",
    "\n",
    "model_config_custom = {\n",
    "    \"bos_token_id\": starttok,\n",
    "    \"eos_token_id\": endtok,\n",
    "    \"decoder_start_token_id\": septok,\n",
    "    \"pad_token_id\": padtok,\n",
    "    \"forced_bos_token_id\": None,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "    \"min_length\": 0\n",
    "}\n",
    "\n",
    "model.config.update(model_config_custom)\n",
    "\n",
    "endkeytok = tokenizer.convert_tokens_to_ids('_endkw_')\n",
    "\n",
    "context = \" _kw_ \".join(PROMT)\n",
    "context = tokenizer.encode(context)\n",
    "\n",
    "context = [starttok] + context + [endkeytok] + [septok]\n",
    "context = tokenizer.decode(context)\n",
    "\n",
    "inputs = tokenizer(context, max_length=max_length, truncation=True, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    num_beams=num_beams,\n",
    "    max_length=max_length,\n",
    "    early_stopping=True,\n",
    "    decoder_start_token_id=septok,\n",
    "    pad_token_id=padtok,\n",
    "    bos_token_id=starttok,\n",
    "    eos_token_id=endtok,\n",
    "    forced_eos_token_id=endtok,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = None\n",
    "script_model = torch.jit.script(GPT2BeamSearchGenerator(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = 'gpt3_beam.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\onnx\\utils.py:100: UserWarning: `example_outputs' is deprecated and ignored. Will be removed in next PyTorch release.\n",
      "  warnings.warn(\"`example_outputs' is deprecated and ignored. Will be removed in \"\n",
      "C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\onnx\\symbolic_helper.py:716: UserWarning: allowzero=0 by default. In order to honor zero value in shape use allowzero=1\n",
      "  warnings.warn(\"allowzero=0 by default. In order to honor zero value in shape use allowzero=1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_ids : Long(*, *, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %attention_mask : Long(1, 8, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %num_beams : Long(device=cpu),\n",
      "      %max_length : Long(device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.wte.weight : Float(50260, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.wpe.weight : Float(2048, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.ln_f.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.ln_f.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %4852 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %4853 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %4854 : Float(768, 50260, strides=[1, 768], requires_grad=0, device=cpu),\n",
      "      %4855 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %176 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %177 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3072}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "  %178 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "  %179 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={12}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "  %180 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2304}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "  %181 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={768}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "  %182 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %183 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "  %184 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %185 : Bool(device=cpu) = onnx::Constant[value={1}]() # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:385:8\n",
      "  %186 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %187 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %188 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %189 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %190 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids) # <string>:7:9\n",
      "  %191 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %192 : Long(device=cpu) = onnx::Gather[axis=0](%190, %191)\n",
      "  %193 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %194 : Long(device=cpu) = onnx::Div(%num_beams, %193)\n",
      "  %195 : Long(device=cpu) = onnx::Cast[to=7](%194)\n",
      "  %196 : Long(device=cpu) = onnx::Cast[to=7](%195)\n",
      "  %197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %198 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%192, %197)\n",
      "  %199 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%198)\n",
      "  %200 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %201 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%192, %200)\n",
      "  %202 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%201)\n",
      "  %203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%192, %203)\n",
      "  %205 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%204)\n",
      "  %206 : Bool(*, device=cpu) = onnx::ConstantOfShape[value={0}](%199)\n",
      "  %207 : Long(*, device=cpu) = onnx::ConstantOfShape[value={0}](%202)\n",
      "  %208 : Float(*, device=cpu) = onnx::ConstantOfShape[value={0}](%205) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:330:39\n",
      "  %209 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e+09}]()\n",
      "  %210 : Float(*, device=cpu) = onnx::Add(%208, %209)\n",
      "  %211 : Long(*, device=cpu)[] = onnx::SequenceEmpty[dtype=7]()\n",
      "  %212 : Float(*, device=cpu)[] = onnx::SequenceEmpty[dtype=1]()\n",
      "  %213 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids) # <string>:7:9\n",
      "  %214 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %215 : Long(device=cpu) = onnx::Gather[axis=0](%213, %214) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:25\n",
      "  %216 : Long(device=cpu) = onnx::Cast[to=7](%215)\n",
      "  %217 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %218 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %219 : Long(*, device=cpu) = onnx::Range(%217, %216, %218) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %220 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %221 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%219, %220) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %225 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %224)\n",
      "  %226 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4852, %225)\n",
      "  %229 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %230 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %229)\n",
      "  %231 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4853, %230)\n",
      "  %232 : Long(1, strides=[1], device=cpu) = onnx::Shape(%226)\n",
      "  %233 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}](%232)\n",
      "  %234 : Long(*, 1, device=cpu) = onnx::Expand(%221, %233)\n",
      "  %235 : Long(*, *, device=cpu) = onnx::Tile(%234, %231) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %237 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%235, %236) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %238 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%input_ids, %237) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:544:20\n",
      "  %239 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%attention_mask, %237) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:546:25\n",
      "  %240 : Long(2, strides=[1], device=cpu) = onnx::Shape(%238) # <string>:7:9\n",
      "  %241 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %242 : Long(device=cpu) = onnx::Gather(%240, %241)\n",
      "  %243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %244 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%192, %243)\n",
      "  %245 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %246 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %245)\n",
      "  %247 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%244, %246)\n",
      "  %248 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%247) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:586:12\n",
      "  %249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %250 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %253 : Float(*, *, device=cpu) = onnx::Slice(%248, %250, %251, %249, %252) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:586:12\n",
      "  %254 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-1e+09}]()\n",
      "  %255 : Long(2, strides=[1], device=cpu) = onnx::Shape(%253)\n",
      "  %256 : FloatTensor(device=cpu) = onnx::Expand(%254, %255) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:586:12\n",
      "  %257 : Long(2, strides=[1], device=cpu) = onnx::Shape(%248)\n",
      "  %258 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %259 : Long(device=cpu) = onnx::Gather[axis=0](%257, %258)\n",
      "  %260 : Long(device=cpu) = onnx::Cast[to=7](%259)\n",
      "  %261 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %262 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %263 : Long(*, device=cpu) = onnx::Range(%261, %260, %262)\n",
      "  %264 : Long(2, strides=[1], device=cpu) = onnx::Shape(%248)\n",
      "  %265 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %266 : Long(device=cpu) = onnx::Gather[axis=0](%264, %265)\n",
      "  %267 : Long(device=cpu) = onnx::Cast[to=7](%266)\n",
      "  %268 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %269 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %270 : Long(*, device=cpu) = onnx::Range(%268, %267, %269)\n",
      "  %271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %272 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %275 : Long(*, device=cpu) = onnx::Slice(%270, %272, %273, %271, %274)\n",
      "  %276 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %277 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%263, %276)\n",
      "  %278 : Long(*, *, device=cpu) = onnx::Add(%277, %275)\n",
      "  %279 : Long(2, strides=[1], device=cpu) = onnx::Shape(%278)\n",
      "  %280 : Long(1, strides=[1], device=cpu) = onnx::Shape(%279)\n",
      "  %281 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%280)\n",
      "  %282 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %283 : Long(2, strides=[1], device=cpu) = onnx::Mul(%281, %282)\n",
      "  %284 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%279, %283)\n",
      "  %285 : Long(2, strides=[1], device=cpu) = onnx::Where(%284, %281, %279)\n",
      "  %286 : LongTensor(device=cpu) = onnx::Expand(%277, %285)\n",
      "  %287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %288 : LongTensor(device=cpu) = onnx::Unsqueeze(%286, %287)\n",
      "  %289 : Long(1, strides=[1], device=cpu) = onnx::Shape(%279)\n",
      "  %290 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%289)\n",
      "  %291 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %292 : Long(2, strides=[1], device=cpu) = onnx::Mul(%290, %291)\n",
      "  %293 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%279, %292)\n",
      "  %294 : Long(2, strides=[1], device=cpu) = onnx::Where(%293, %290, %279)\n",
      "  %295 : LongTensor(device=cpu) = onnx::Expand(%275, %294)\n",
      "  %296 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %297 : LongTensor(device=cpu) = onnx::Unsqueeze(%295, %296)\n",
      "  %298 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%288, %297)\n",
      "  %299 : Long(2, strides=[1], device=cpu) = onnx::Shape(%248)\n",
      "  %300 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %301 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %302 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %303 : Long(0, strides=[1], device=cpu) = onnx::Slice(%299, %301, %302, %300)\n",
      "  %304 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%279, %303)\n",
      "  %305 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%256, %304)\n",
      "  %306 : Float(*, *, device=cpu) = onnx::ScatterND(%248, %298, %305) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:586:12\n",
      "  %307 : Long(device=cpu) = onnx::Mul(%192, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:587:44\n",
      "  %308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %309 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%307, %308)\n",
      "  %310 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%309)\n",
      "  %311 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%306, %310) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:587:26\n",
      "  %312 : Bool(device=cpu) = onnx::Greater(%max_length, %242) # <string>:11:9\n",
      "  %314 : Long(*, *, device=cpu), %315 : Float(*, device=cpu), %316 : Long(*, *, device=cpu), %317 : Long(device=cpu), %318 : Float(*, device=cpu)[], %319 : Long(*, device=cpu)[], %320 : Float(*, device=cpu), %321 : Long(*, device=cpu), %322 : Bool(*, device=cpu) = onnx::Loop(%182, %312, %238, %311, %239, %242, %212, %211, %210, %207, %206) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:592:12\n",
      "    block0(%323 : Long(requires_grad=0, device=cpu), %cond.5 : Bool(device=cpu), %input_ids.25 : Long(*, *, device=cpu), %beam_scores.17 : Float(*, device=cpu), %attention_mask.13 : Long(*, *, device=cpu), %cur_len.13 : Long(device=cpu), %329 : Float(*, device=cpu)[], %330 : Long(*, device=cpu)[], %331 : Float(*, device=cpu), %332 : Long(*, device=cpu), %333 : Bool(*, device=cpu)):\n",
      "      %334 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25), scope: __module.decoder/__module.decoder.transformer\n",
      "      %335 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %336 : Long(device=cpu) = onnx::Gather[axis=0](%334, %335), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:678:0\n",
      "      %337 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25), scope: __module.decoder/__module.decoder.transformer\n",
      "      %338 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %339 : Long(device=cpu) = onnx::Gather[axis=0](%337, %338), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:678:0\n",
      "      %340 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %340)\n",
      "      %342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%339, %342)\n",
      "      %344 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%341, %343)\n",
      "      %345 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %346 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %345)\n",
      "      %347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %348 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%339, %347)\n",
      "      %349 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%346, %348)\n",
      "      %350 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%input_ids.25, %344), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:679:0\n",
      "      %351 : Long(2, strides=[1], device=cpu) = onnx::Shape(%350), scope: __module.decoder/__module.decoder.transformer\n",
      "      %352 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %353 : Long(device=cpu) = onnx::Gather[axis=0](%351, %352), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:680:0\n",
      "      %354 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %355 : Long(device=cpu) = onnx::Add(%339, %354)\n",
      "      %356 : Long(device=cpu) = onnx::Cast[to=7](%189), scope: __module.decoder/__module.decoder.transformer\n",
      "      %357 : Long(device=cpu) = onnx::Cast[to=7](%355), scope: __module.decoder/__module.decoder.transformer\n",
      "      %358 : Long(device=cpu) = onnx::Cast[to=7](%187), scope: __module.decoder/__module.decoder.transformer\n",
      "      %359 : Long(*, device=cpu) = onnx::Range(%356, %357, %358), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:700:0\n",
      "      %360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %361 : Long(1, *, device=cpu) = onnx::Unsqueeze(%359, %360), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:701:0\n",
      "      %362 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%361, %349), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:701:0\n",
      "      %363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %364 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%353, %363)\n",
      "      %365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %366 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %365)\n",
      "      %367 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%364, %366)\n",
      "      %368 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%attention_mask.13, %367), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %370 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%368, %369), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %372 : Long(*, *, *, *, device=cpu) = onnx::Unsqueeze(%370, %371), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %373 : Float(*, *, *, *, device=cpu) = onnx::Cast[to=1](%372), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:720:0\n",
      "      %374 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %375 : Float(*, *, *, *, device=cpu) = onnx::Sub(%374, %373), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:548:0\n",
      "      %376 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}]()\n",
      "      %377 : Float(*, *, *, *, device=cpu) = onnx::Mul(%375, %376)\n",
      "      %378 : Float(*, *, *, device=cpu) = onnx::Gather(%decoder_no_past.decoder.transformer.wte.weight, %350), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.wte # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2044:0\n",
      "      %379 : Float(*, *, *, device=cpu) = onnx::Gather(%decoder_no_past.decoder.transformer.wpe.weight, %362), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.wpe # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2044:0\n",
      "      %380 : Float(*, *, *, device=cpu) = onnx::Add(%378, %379), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.drop # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %381 : Long(3, strides=[1], device=cpu) = onnx::Shape(%380), scope: __module.decoder/__module.decoder.transformer\n",
      "      %382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %383 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %385 : Long(1, strides=[1], device=cpu) = onnx::Slice(%381, %383, %384, %382), scope: __module.decoder/__module.decoder.transformer\n",
      "      %386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %387 : Long(device=cpu) = onnx::Squeeze(%385, %386), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:751:0\n",
      "      %388 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%380), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %389 : Float(*, *, *, device=cpu) = onnx::Sub(%380, %388), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %390 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %391 : Float(*, *, *, device=cpu) = onnx::Pow(%389, %390), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %392 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%391), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %393 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %394 : Float(*, *, device=cpu) = onnx::Add(%392, %393), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %395 : Float(*, *, device=cpu) = onnx::Sqrt(%394), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %396 : Float(*, *, *, device=cpu) = onnx::Div(%389, %395), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %397 : Float(*, *, *, device=cpu) = onnx::Mul(%396, %decoder_no_past.decoder.transformer.h.0.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %398 : Float(*, *, *, device=cpu) = onnx::Add(%397, %decoder_no_past.decoder.transformer.h.0.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %399 : Long(3, strides=[1], device=cpu) = onnx::Shape(%398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %400 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %401 : Long(device=cpu) = onnx::Gather[axis=0](%399, %400), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %402 : Long(3, strides=[1], device=cpu) = onnx::Shape(%398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %403 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %404 : Long(device=cpu) = onnx::Gather[axis=0](%402, %403), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %405 : Long(3, strides=[1], device=cpu) = onnx::Shape(%398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %406 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %408 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %409 : Long(1, strides=[1], device=cpu) = onnx::Slice(%405, %407, %408, %406), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %411 : Long(device=cpu) = onnx::Squeeze(%409, %410), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %413 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %412)\n",
      "      %414 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %415 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%411, %414)\n",
      "      %416 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%413, %415)\n",
      "      %417 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%398, %416), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %418 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%417, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %419 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %420 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%401, %419)\n",
      "      %421 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %422 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%404, %421)\n",
      "      %423 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %424 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %423)\n",
      "      %425 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%420, %422, %424)\n",
      "      %426 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%418, %425), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %427 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %428 : Float(*, *, *, device=cpu), %429 : Float(*, *, *, device=cpu), %430 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%426, %427), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %431 : Long(3, strides=[1], device=cpu) = onnx::Shape(%428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %432 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %433 : Long(device=cpu) = onnx::Gather[axis=0](%431, %432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %434 : Long(3, strides=[1], device=cpu) = onnx::Shape(%428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %435 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %436 : Long(device=cpu) = onnx::Gather[axis=0](%434, %435), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %437 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %438 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%433, %437)\n",
      "      %439 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %440 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%436, %439)\n",
      "      %441 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %442 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %441)\n",
      "      %443 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %444 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %443)\n",
      "      %445 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%438, %440, %442, %444)\n",
      "      %446 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%428, %445), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %447 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%446), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %448 : Long(3, strides=[1], device=cpu) = onnx::Shape(%429), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %449 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %450 : Long(device=cpu) = onnx::Gather[axis=0](%448, %449), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %451 : Long(3, strides=[1], device=cpu) = onnx::Shape(%429), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %452 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %453 : Long(device=cpu) = onnx::Gather[axis=0](%451, %452), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %455 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%450, %454)\n",
      "      %456 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %457 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%453, %456)\n",
      "      %458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %458)\n",
      "      %460 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %461 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %460)\n",
      "      %462 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%455, %457, %459, %461)\n",
      "      %463 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%429, %462), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %464 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%463), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %465 : Long(3, strides=[1], device=cpu) = onnx::Shape(%430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %466 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %467 : Long(device=cpu) = onnx::Gather[axis=0](%465, %466), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %468 : Long(3, strides=[1], device=cpu) = onnx::Shape(%430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %469 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %470 : Long(device=cpu) = onnx::Gather[axis=0](%468, %469), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %471 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %472 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%467, %471)\n",
      "      %473 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %474 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%470, %473)\n",
      "      %475 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %476 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %475)\n",
      "      %477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %478 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %477)\n",
      "      %479 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%472, %474, %476, %478)\n",
      "      %480 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%430, %479), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %481 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%480), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %482 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%463), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %483 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%447, %482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %484 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %485 : Float(*, *, *, *, device=cpu) = onnx::Div(%483, %484)\n",
      "      %486 : Long(4, strides=[1], device=cpu) = onnx::Shape(%447), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %489 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %490 : Long(1, strides=[1], device=cpu) = onnx::Slice(%486, %488, %489, %487), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %492 : Long(device=cpu) = onnx::Squeeze(%490, %491), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %493 : Long(4, strides=[1], device=cpu) = onnx::Shape(%464), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %495 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %496 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %497 : Long(1, strides=[1], device=cpu) = onnx::Slice(%493, %495, %496, %494), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %499 : Long(device=cpu) = onnx::Squeeze(%497, %498), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %500 : Long(device=cpu) = onnx::Sub(%499, %492), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %501 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %502 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%500, %501), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %504 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%499, %503), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %506 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %505), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %507 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %508 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.0.attn.bias, %502, %504, %506, %507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %509 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %510 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %511 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %512 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%499, %511), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %514 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %515 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %516 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%508, %510, %512, %514, %515), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %517 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%516), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %518 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.0.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %519 : Float(*, *, *, *, device=cpu) = onnx::Where(%517, %485, %518), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %520 : Float(*, *, *, *, device=cpu) = onnx::Add(%519, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %521 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%520), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %522 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%521, %481), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %523 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%522), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %524 : Long(4, strides=[1], device=cpu) = onnx::Shape(%523), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %525 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %526 : Long(device=cpu) = onnx::Gather[axis=0](%524, %525), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %527 : Long(4, strides=[1], device=cpu) = onnx::Shape(%523), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %528 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %529 : Long(device=cpu) = onnx::Gather[axis=0](%527, %528), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %531 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%526, %530)\n",
      "      %532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %533 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%529, %532)\n",
      "      %534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %535 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %534)\n",
      "      %536 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%531, %533, %535)\n",
      "      %537 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%523, %536), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %538 : Long(3, strides=[1], device=cpu) = onnx::Shape(%537), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %539 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %540 : Long(device=cpu) = onnx::Gather[axis=0](%538, %539), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %541 : Long(3, strides=[1], device=cpu) = onnx::Shape(%537), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %542 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %543 : Long(device=cpu) = onnx::Gather[axis=0](%541, %542), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %544 : Long(3, strides=[1], device=cpu) = onnx::Shape(%537), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %545 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %546 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %548 : Long(1, strides=[1], device=cpu) = onnx::Slice(%544, %546, %547, %545), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %549 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %550 : Long(device=cpu) = onnx::Squeeze(%548, %549), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %552 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %551)\n",
      "      %553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %554 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%550, %553)\n",
      "      %555 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%552, %554)\n",
      "      %556 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%537, %555), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %557 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%556, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %558 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %559 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%540, %558)\n",
      "      %560 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %561 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%543, %560)\n",
      "      %562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %563 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %562)\n",
      "      %564 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%559, %561, %563)\n",
      "      %565 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%557, %564), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %566 : Float(*, *, *, device=cpu) = onnx::Add(%565, %380), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %567 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%566), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %568 : Float(*, *, *, device=cpu) = onnx::Sub(%566, %567), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %569 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %570 : Float(*, *, *, device=cpu) = onnx::Pow(%568, %569), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %571 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%570), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %572 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %573 : Float(*, *, device=cpu) = onnx::Add(%571, %572), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %574 : Float(*, *, device=cpu) = onnx::Sqrt(%573), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %575 : Float(*, *, *, device=cpu) = onnx::Div(%568, %574), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %576 : Float(*, *, *, device=cpu) = onnx::Mul(%575, %decoder_no_past.decoder.transformer.h.0.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %577 : Float(*, *, *, device=cpu) = onnx::Add(%576, %decoder_no_past.decoder.transformer.h.0.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %578 : Long(3, strides=[1], device=cpu) = onnx::Shape(%577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %579 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %580 : Long(device=cpu) = onnx::Gather[axis=0](%578, %579), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %581 : Long(3, strides=[1], device=cpu) = onnx::Shape(%577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %582 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %583 : Long(device=cpu) = onnx::Gather[axis=0](%581, %582), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %584 : Long(3, strides=[1], device=cpu) = onnx::Shape(%577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %588 : Long(1, strides=[1], device=cpu) = onnx::Slice(%584, %586, %587, %585), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %590 : Long(device=cpu) = onnx::Squeeze(%588, %589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %592 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %591)\n",
      "      %593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %594 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%590, %593)\n",
      "      %595 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%592, %594)\n",
      "      %596 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%577, %595), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %597 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%596, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %598 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %599 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%580, %598)\n",
      "      %600 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %601 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%583, %600)\n",
      "      %602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %603 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %602)\n",
      "      %604 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%599, %601, %603)\n",
      "      %605 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%597, %604), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %606 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %607 : Float(*, *, *, device=cpu) = onnx::Mul(%605, %606)\n",
      "      %608 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %609 : Float(*, *, *, device=cpu) = onnx::Pow(%605, %608), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %611 : Float(*, *, *, device=cpu) = onnx::Mul(%609, %610)\n",
      "      %612 : Float(*, *, *, device=cpu) = onnx::Add(%605, %611), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %613 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %614 : Float(*, *, *, device=cpu) = onnx::Mul(%612, %613)\n",
      "      %615 : Float(*, *, *, device=cpu) = onnx::Tanh(%614), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %616 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %617 : Float(*, *, *, device=cpu) = onnx::Add(%615, %616)\n",
      "      %618 : Float(*, *, *, device=cpu) = onnx::Mul(%607, %617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %619 : Long(3, strides=[1], device=cpu) = onnx::Shape(%618), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %620 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %621 : Long(device=cpu) = onnx::Gather[axis=0](%619, %620), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %622 : Long(3, strides=[1], device=cpu) = onnx::Shape(%618), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %623 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %624 : Long(device=cpu) = onnx::Gather[axis=0](%622, %623), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %625 : Long(3, strides=[1], device=cpu) = onnx::Shape(%618), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %626 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %628 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %629 : Long(1, strides=[1], device=cpu) = onnx::Slice(%625, %627, %628, %626), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %631 : Long(device=cpu) = onnx::Squeeze(%629, %630), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %633 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %632)\n",
      "      %634 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %635 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%631, %634)\n",
      "      %636 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%633, %635)\n",
      "      %637 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%618, %636), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %638 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%637, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %639 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %640 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%621, %639)\n",
      "      %641 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %642 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%624, %641)\n",
      "      %643 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %644 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %643)\n",
      "      %645 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%640, %642, %644)\n",
      "      %646 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%638, %645), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %647 : Float(*, *, *, device=cpu) = onnx::Add(%566, %646), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %648 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%647), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %649 : Float(*, *, *, device=cpu) = onnx::Sub(%647, %648), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %650 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %651 : Float(*, *, *, device=cpu) = onnx::Pow(%649, %650), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %652 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%651), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %653 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %654 : Float(*, *, device=cpu) = onnx::Add(%652, %653), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %655 : Float(*, *, device=cpu) = onnx::Sqrt(%654), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %656 : Float(*, *, *, device=cpu) = onnx::Div(%649, %655), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %657 : Float(*, *, *, device=cpu) = onnx::Mul(%656, %decoder_no_past.decoder.transformer.h.1.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %658 : Float(*, *, *, device=cpu) = onnx::Add(%657, %decoder_no_past.decoder.transformer.h.1.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %659 : Long(3, strides=[1], device=cpu) = onnx::Shape(%658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %660 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %661 : Long(device=cpu) = onnx::Gather[axis=0](%659, %660), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %662 : Long(3, strides=[1], device=cpu) = onnx::Shape(%658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %663 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %664 : Long(device=cpu) = onnx::Gather[axis=0](%662, %663), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %665 : Long(3, strides=[1], device=cpu) = onnx::Shape(%658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %666 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %668 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %669 : Long(1, strides=[1], device=cpu) = onnx::Slice(%665, %667, %668, %666), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %671 : Long(device=cpu) = onnx::Squeeze(%669, %670), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %673 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %672)\n",
      "      %674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %675 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%671, %674)\n",
      "      %676 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%673, %675)\n",
      "      %677 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%658, %676), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %678 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%677, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %679 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %680 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%661, %679)\n",
      "      %681 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %682 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%664, %681)\n",
      "      %683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %683)\n",
      "      %685 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%680, %682, %684)\n",
      "      %686 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%678, %685), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %687 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %688 : Float(*, *, *, device=cpu), %689 : Float(*, *, *, device=cpu), %690 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%686, %687), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %691 : Long(3, strides=[1], device=cpu) = onnx::Shape(%688), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %692 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %693 : Long(device=cpu) = onnx::Gather[axis=0](%691, %692), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %694 : Long(3, strides=[1], device=cpu) = onnx::Shape(%688), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %695 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %696 : Long(device=cpu) = onnx::Gather[axis=0](%694, %695), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %697 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %698 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%693, %697)\n",
      "      %699 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %700 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%696, %699)\n",
      "      %701 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %702 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %701)\n",
      "      %703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %704 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %703)\n",
      "      %705 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%698, %700, %702, %704)\n",
      "      %706 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%688, %705), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %707 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%706), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %708 : Long(3, strides=[1], device=cpu) = onnx::Shape(%689), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %709 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %710 : Long(device=cpu) = onnx::Gather[axis=0](%708, %709), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %711 : Long(3, strides=[1], device=cpu) = onnx::Shape(%689), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %712 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %713 : Long(device=cpu) = onnx::Gather[axis=0](%711, %712), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %715 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%710, %714)\n",
      "      %716 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %717 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%713, %716)\n",
      "      %718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %719 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %718)\n",
      "      %720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %721 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %720)\n",
      "      %722 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%715, %717, %719, %721)\n",
      "      %723 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%689, %722), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %724 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%723), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %725 : Long(3, strides=[1], device=cpu) = onnx::Shape(%690), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %726 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %727 : Long(device=cpu) = onnx::Gather[axis=0](%725, %726), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %728 : Long(3, strides=[1], device=cpu) = onnx::Shape(%690), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %729 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %730 : Long(device=cpu) = onnx::Gather[axis=0](%728, %729), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %731 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %732 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%727, %731)\n",
      "      %733 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %734 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%730, %733)\n",
      "      %735 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %736 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %735)\n",
      "      %737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %738 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %737)\n",
      "      %739 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%732, %734, %736, %738)\n",
      "      %740 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%690, %739), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %741 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%740), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %742 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%723), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %743 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%707, %742), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %744 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %745 : Float(*, *, *, *, device=cpu) = onnx::Div(%743, %744)\n",
      "      %746 : Long(4, strides=[1], device=cpu) = onnx::Shape(%707), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %748 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %749 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %750 : Long(1, strides=[1], device=cpu) = onnx::Slice(%746, %748, %749, %747), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %751 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %752 : Long(device=cpu) = onnx::Squeeze(%750, %751), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %753 : Long(4, strides=[1], device=cpu) = onnx::Shape(%724), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %754 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %755 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %756 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %757 : Long(1, strides=[1], device=cpu) = onnx::Slice(%753, %755, %756, %754), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %758 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %759 : Long(device=cpu) = onnx::Squeeze(%757, %758), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %760 : Long(device=cpu) = onnx::Sub(%759, %752), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %761 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %762 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%760, %761), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %764 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%759, %763), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %765 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %766 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %765), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %767 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %768 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.1.attn.bias, %762, %764, %766, %767), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %769 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %770 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %771 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %772 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%759, %771), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %773 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %774 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %773), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %775 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %776 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%768, %770, %772, %774, %775), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %777 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%776), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %778 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.1.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %779 : Float(*, *, *, *, device=cpu) = onnx::Where(%777, %745, %778), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %780 : Float(*, *, *, *, device=cpu) = onnx::Add(%779, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %781 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%780), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %782 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%781, %741), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %783 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%782), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %784 : Long(4, strides=[1], device=cpu) = onnx::Shape(%783), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %785 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %786 : Long(device=cpu) = onnx::Gather[axis=0](%784, %785), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %787 : Long(4, strides=[1], device=cpu) = onnx::Shape(%783), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %788 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %789 : Long(device=cpu) = onnx::Gather[axis=0](%787, %788), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %790 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %791 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%786, %790)\n",
      "      %792 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %793 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%789, %792)\n",
      "      %794 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %795 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %794)\n",
      "      %796 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%791, %793, %795)\n",
      "      %797 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%783, %796), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %798 : Long(3, strides=[1], device=cpu) = onnx::Shape(%797), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %799 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %800 : Long(device=cpu) = onnx::Gather[axis=0](%798, %799), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %801 : Long(3, strides=[1], device=cpu) = onnx::Shape(%797), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %802 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %803 : Long(device=cpu) = onnx::Gather[axis=0](%801, %802), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %804 : Long(3, strides=[1], device=cpu) = onnx::Shape(%797), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %805 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %806 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %807 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %808 : Long(1, strides=[1], device=cpu) = onnx::Slice(%804, %806, %807, %805), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %810 : Long(device=cpu) = onnx::Squeeze(%808, %809), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %812 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %811)\n",
      "      %813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %814 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%810, %813)\n",
      "      %815 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%812, %814)\n",
      "      %816 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%797, %815), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %817 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%816, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %819 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%800, %818)\n",
      "      %820 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %821 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%803, %820)\n",
      "      %822 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %823 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %822)\n",
      "      %824 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%819, %821, %823)\n",
      "      %825 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%817, %824), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %826 : Float(*, *, *, device=cpu) = onnx::Add(%825, %647), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %827 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%826), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %828 : Float(*, *, *, device=cpu) = onnx::Sub(%826, %827), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %829 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %830 : Float(*, *, *, device=cpu) = onnx::Pow(%828, %829), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %831 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%830), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %832 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %833 : Float(*, *, device=cpu) = onnx::Add(%831, %832), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %834 : Float(*, *, device=cpu) = onnx::Sqrt(%833), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %835 : Float(*, *, *, device=cpu) = onnx::Div(%828, %834), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %836 : Float(*, *, *, device=cpu) = onnx::Mul(%835, %decoder_no_past.decoder.transformer.h.1.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %837 : Float(*, *, *, device=cpu) = onnx::Add(%836, %decoder_no_past.decoder.transformer.h.1.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %838 : Long(3, strides=[1], device=cpu) = onnx::Shape(%837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %839 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %840 : Long(device=cpu) = onnx::Gather[axis=0](%838, %839), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %841 : Long(3, strides=[1], device=cpu) = onnx::Shape(%837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %842 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %843 : Long(device=cpu) = onnx::Gather[axis=0](%841, %842), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %844 : Long(3, strides=[1], device=cpu) = onnx::Shape(%837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %847 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %848 : Long(1, strides=[1], device=cpu) = onnx::Slice(%844, %846, %847, %845), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %850 : Long(device=cpu) = onnx::Squeeze(%848, %849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %852 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %851)\n",
      "      %853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %854 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%850, %853)\n",
      "      %855 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%852, %854)\n",
      "      %856 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%837, %855), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %857 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%856, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %859 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%840, %858)\n",
      "      %860 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %861 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%843, %860)\n",
      "      %862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %863 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %862)\n",
      "      %864 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%859, %861, %863)\n",
      "      %865 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%857, %864), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %866 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %867 : Float(*, *, *, device=cpu) = onnx::Mul(%865, %866)\n",
      "      %868 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %869 : Float(*, *, *, device=cpu) = onnx::Pow(%865, %868), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %870 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %871 : Float(*, *, *, device=cpu) = onnx::Mul(%869, %870)\n",
      "      %872 : Float(*, *, *, device=cpu) = onnx::Add(%865, %871), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %873 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %874 : Float(*, *, *, device=cpu) = onnx::Mul(%872, %873)\n",
      "      %875 : Float(*, *, *, device=cpu) = onnx::Tanh(%874), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %876 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %877 : Float(*, *, *, device=cpu) = onnx::Add(%875, %876)\n",
      "      %878 : Float(*, *, *, device=cpu) = onnx::Mul(%867, %877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %879 : Long(3, strides=[1], device=cpu) = onnx::Shape(%878), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %880 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %881 : Long(device=cpu) = onnx::Gather[axis=0](%879, %880), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %882 : Long(3, strides=[1], device=cpu) = onnx::Shape(%878), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %883 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %884 : Long(device=cpu) = onnx::Gather[axis=0](%882, %883), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %885 : Long(3, strides=[1], device=cpu) = onnx::Shape(%878), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %886 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %888 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %889 : Long(1, strides=[1], device=cpu) = onnx::Slice(%885, %887, %888, %886), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %891 : Long(device=cpu) = onnx::Squeeze(%889, %890), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %892 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %893 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %892)\n",
      "      %894 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %895 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%891, %894)\n",
      "      %896 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%893, %895)\n",
      "      %897 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%878, %896), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %898 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%897, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %900 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%881, %899)\n",
      "      %901 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %902 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%884, %901)\n",
      "      %903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %904 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %903)\n",
      "      %905 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%900, %902, %904)\n",
      "      %906 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%898, %905), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %907 : Float(*, *, *, device=cpu) = onnx::Add(%826, %906), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %908 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%907), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %909 : Float(*, *, *, device=cpu) = onnx::Sub(%907, %908), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %910 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %911 : Float(*, *, *, device=cpu) = onnx::Pow(%909, %910), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %912 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%911), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %913 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %914 : Float(*, *, device=cpu) = onnx::Add(%912, %913), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %915 : Float(*, *, device=cpu) = onnx::Sqrt(%914), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %916 : Float(*, *, *, device=cpu) = onnx::Div(%909, %915), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %917 : Float(*, *, *, device=cpu) = onnx::Mul(%916, %decoder_no_past.decoder.transformer.h.2.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %918 : Float(*, *, *, device=cpu) = onnx::Add(%917, %decoder_no_past.decoder.transformer.h.2.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %919 : Long(3, strides=[1], device=cpu) = onnx::Shape(%918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %920 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %921 : Long(device=cpu) = onnx::Gather[axis=0](%919, %920), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %922 : Long(3, strides=[1], device=cpu) = onnx::Shape(%918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %923 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %924 : Long(device=cpu) = onnx::Gather[axis=0](%922, %923), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %925 : Long(3, strides=[1], device=cpu) = onnx::Shape(%918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %926 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %929 : Long(1, strides=[1], device=cpu) = onnx::Slice(%925, %927, %928, %926), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %931 : Long(device=cpu) = onnx::Squeeze(%929, %930), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %933 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %932)\n",
      "      %934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %935 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%931, %934)\n",
      "      %936 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%933, %935)\n",
      "      %937 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%918, %936), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %938 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%937, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %940 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%921, %939)\n",
      "      %941 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %942 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%924, %941)\n",
      "      %943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %943)\n",
      "      %945 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%940, %942, %944)\n",
      "      %946 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%938, %945), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %947 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %948 : Float(*, *, *, device=cpu), %949 : Float(*, *, *, device=cpu), %950 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%946, %947), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %951 : Long(3, strides=[1], device=cpu) = onnx::Shape(%948), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %952 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %953 : Long(device=cpu) = onnx::Gather[axis=0](%951, %952), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %954 : Long(3, strides=[1], device=cpu) = onnx::Shape(%948), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %955 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %956 : Long(device=cpu) = onnx::Gather[axis=0](%954, %955), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %957 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %958 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%953, %957)\n",
      "      %959 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %960 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%956, %959)\n",
      "      %961 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %962 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %961)\n",
      "      %963 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %964 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %963)\n",
      "      %965 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%958, %960, %962, %964)\n",
      "      %966 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%948, %965), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %967 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%966), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %968 : Long(3, strides=[1], device=cpu) = onnx::Shape(%949), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %969 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %970 : Long(device=cpu) = onnx::Gather[axis=0](%968, %969), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %971 : Long(3, strides=[1], device=cpu) = onnx::Shape(%949), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %972 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %973 : Long(device=cpu) = onnx::Gather[axis=0](%971, %972), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %975 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%970, %974)\n",
      "      %976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %977 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%973, %976)\n",
      "      %978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %979 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %978)\n",
      "      %980 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %981 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %980)\n",
      "      %982 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%975, %977, %979, %981)\n",
      "      %983 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%949, %982), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %984 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%983), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %985 : Long(3, strides=[1], device=cpu) = onnx::Shape(%950), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %986 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %987 : Long(device=cpu) = onnx::Gather[axis=0](%985, %986), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %988 : Long(3, strides=[1], device=cpu) = onnx::Shape(%950), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %989 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %990 : Long(device=cpu) = onnx::Gather[axis=0](%988, %989), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %991 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %992 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%987, %991)\n",
      "      %993 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %994 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%990, %993)\n",
      "      %995 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %996 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %995)\n",
      "      %997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %998 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %997)\n",
      "      %999 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%992, %994, %996, %998)\n",
      "      %1000 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%950, %999), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1001 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1000), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1002 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%983), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1003 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%967, %1002), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1004 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1005 : Float(*, *, *, *, device=cpu) = onnx::Div(%1003, %1004)\n",
      "      %1006 : Long(4, strides=[1], device=cpu) = onnx::Shape(%967), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1007 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1009 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1010 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1006, %1008, %1009, %1007), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1011 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1012 : Long(device=cpu) = onnx::Squeeze(%1010, %1011), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1013 : Long(4, strides=[1], device=cpu) = onnx::Shape(%984), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1015 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1016 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1017 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1013, %1015, %1016, %1014), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1019 : Long(device=cpu) = onnx::Squeeze(%1017, %1018), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1020 : Long(device=cpu) = onnx::Sub(%1019, %1012), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1021 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1022 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1020, %1021), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1024 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1019, %1023), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1026 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %1025), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1028 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.2.attn.bias, %1022, %1024, %1026, %1027), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1029 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1030 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %1029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1032 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1019, %1031), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1034 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1033), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1036 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1028, %1030, %1032, %1034, %1035), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1037 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1036), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1038 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.2.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1039 : Float(*, *, *, *, device=cpu) = onnx::Where(%1037, %1005, %1038), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1040 : Float(*, *, *, *, device=cpu) = onnx::Add(%1039, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1041 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1040), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1042 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1041, %1001), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1043 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1042), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1044 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1043), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1045 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1046 : Long(device=cpu) = onnx::Gather[axis=0](%1044, %1045), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1047 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1043), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1048 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1049 : Long(device=cpu) = onnx::Gather[axis=0](%1047, %1048), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1050 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1051 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1046, %1050)\n",
      "      %1052 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1053 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1049, %1052)\n",
      "      %1054 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1055 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1054)\n",
      "      %1056 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1051, %1053, %1055)\n",
      "      %1057 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1043, %1056), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1058 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1057), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1059 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1060 : Long(device=cpu) = onnx::Gather[axis=0](%1058, %1059), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1061 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1057), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1062 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1063 : Long(device=cpu) = onnx::Gather[axis=0](%1061, %1062), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1064 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1057), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1065 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1066 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1067 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1068 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1064, %1066, %1067, %1065), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1070 : Long(device=cpu) = onnx::Squeeze(%1068, %1069), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1072 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1071)\n",
      "      %1073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1074 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1070, %1073)\n",
      "      %1075 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1072, %1074)\n",
      "      %1076 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1057, %1075), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1077 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1076, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1078 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1079 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1060, %1078)\n",
      "      %1080 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1081 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1063, %1080)\n",
      "      %1082 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1083 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1082)\n",
      "      %1084 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1079, %1081, %1083)\n",
      "      %1085 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1077, %1084), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1086 : Float(*, *, *, device=cpu) = onnx::Add(%1085, %907), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1087 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1086), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1088 : Float(*, *, *, device=cpu) = onnx::Sub(%1086, %1087), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1089 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1090 : Float(*, *, *, device=cpu) = onnx::Pow(%1088, %1089), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1091 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1090), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1092 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1093 : Float(*, *, device=cpu) = onnx::Add(%1091, %1092), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1094 : Float(*, *, device=cpu) = onnx::Sqrt(%1093), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1095 : Float(*, *, *, device=cpu) = onnx::Div(%1088, %1094), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1096 : Float(*, *, *, device=cpu) = onnx::Mul(%1095, %decoder_no_past.decoder.transformer.h.2.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1097 : Float(*, *, *, device=cpu) = onnx::Add(%1096, %decoder_no_past.decoder.transformer.h.2.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1098 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1099 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1100 : Long(device=cpu) = onnx::Gather[axis=0](%1098, %1099), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1101 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1102 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1103 : Long(device=cpu) = onnx::Gather[axis=0](%1101, %1102), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1104 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1108 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1104, %1106, %1107, %1105), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1110 : Long(device=cpu) = onnx::Squeeze(%1108, %1109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1112 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1111)\n",
      "      %1113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1114 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1110, %1113)\n",
      "      %1115 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1112, %1114)\n",
      "      %1116 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1097, %1115), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1117 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1116, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1119 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1100, %1118)\n",
      "      %1120 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1121 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1103, %1120)\n",
      "      %1122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1123 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %1122)\n",
      "      %1124 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1119, %1121, %1123)\n",
      "      %1125 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1117, %1124), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1126 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1127 : Float(*, *, *, device=cpu) = onnx::Mul(%1125, %1126)\n",
      "      %1128 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1129 : Float(*, *, *, device=cpu) = onnx::Pow(%1125, %1128), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1130 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1131 : Float(*, *, *, device=cpu) = onnx::Mul(%1129, %1130)\n",
      "      %1132 : Float(*, *, *, device=cpu) = onnx::Add(%1125, %1131), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1133 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1134 : Float(*, *, *, device=cpu) = onnx::Mul(%1132, %1133)\n",
      "      %1135 : Float(*, *, *, device=cpu) = onnx::Tanh(%1134), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1136 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1137 : Float(*, *, *, device=cpu) = onnx::Add(%1135, %1136)\n",
      "      %1138 : Float(*, *, *, device=cpu) = onnx::Mul(%1127, %1137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1139 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1138), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1140 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1141 : Long(device=cpu) = onnx::Gather[axis=0](%1139, %1140), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1142 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1138), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1143 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1144 : Long(device=cpu) = onnx::Gather[axis=0](%1142, %1143), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1145 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1138), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1148 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1149 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1145, %1147, %1148, %1146), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1151 : Long(device=cpu) = onnx::Squeeze(%1149, %1150), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1153 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1152)\n",
      "      %1154 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1155 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1151, %1154)\n",
      "      %1156 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1153, %1155)\n",
      "      %1157 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1138, %1156), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1158 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1157, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1159 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1160 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1141, %1159)\n",
      "      %1161 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1162 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1144, %1161)\n",
      "      %1163 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1164 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1163)\n",
      "      %1165 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1160, %1162, %1164)\n",
      "      %1166 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1158, %1165), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1167 : Float(*, *, *, device=cpu) = onnx::Add(%1086, %1166), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1168 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1167), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1169 : Float(*, *, *, device=cpu) = onnx::Sub(%1167, %1168), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1170 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1171 : Float(*, *, *, device=cpu) = onnx::Pow(%1169, %1170), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1172 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1171), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1174 : Float(*, *, device=cpu) = onnx::Add(%1172, %1173), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1175 : Float(*, *, device=cpu) = onnx::Sqrt(%1174), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1176 : Float(*, *, *, device=cpu) = onnx::Div(%1169, %1175), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1177 : Float(*, *, *, device=cpu) = onnx::Mul(%1176, %decoder_no_past.decoder.transformer.h.3.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1178 : Float(*, *, *, device=cpu) = onnx::Add(%1177, %decoder_no_past.decoder.transformer.h.3.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1179 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1180 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1181 : Long(device=cpu) = onnx::Gather[axis=0](%1179, %1180), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1182 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1183 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1184 : Long(device=cpu) = onnx::Gather[axis=0](%1182, %1183), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1185 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1188 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1189 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1185, %1187, %1188, %1186), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1190 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1191 : Long(device=cpu) = onnx::Squeeze(%1189, %1190), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1192 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1193 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1192)\n",
      "      %1194 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1195 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1191, %1194)\n",
      "      %1196 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1193, %1195)\n",
      "      %1197 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1178, %1196), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1198 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1197, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1200 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1181, %1199)\n",
      "      %1201 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1202 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1184, %1201)\n",
      "      %1203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1203)\n",
      "      %1205 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1200, %1202, %1204)\n",
      "      %1206 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1198, %1205), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1207 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1208 : Float(*, *, *, device=cpu), %1209 : Float(*, *, *, device=cpu), %1210 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1206, %1207), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1211 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1208), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1212 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1213 : Long(device=cpu) = onnx::Gather[axis=0](%1211, %1212), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1214 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1208), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1215 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1216 : Long(device=cpu) = onnx::Gather[axis=0](%1214, %1215), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1217 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1218 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1213, %1217)\n",
      "      %1219 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1220 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1216, %1219)\n",
      "      %1221 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1222 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1221)\n",
      "      %1223 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1224 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1223)\n",
      "      %1225 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1218, %1220, %1222, %1224)\n",
      "      %1226 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1208, %1225), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1227 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1226), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1228 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1209), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1229 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1230 : Long(device=cpu) = onnx::Gather[axis=0](%1228, %1229), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1231 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1209), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1232 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1233 : Long(device=cpu) = onnx::Gather[axis=0](%1231, %1232), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1235 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1230, %1234)\n",
      "      %1236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1237 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1233, %1236)\n",
      "      %1238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1239 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1238)\n",
      "      %1240 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1241 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1240)\n",
      "      %1242 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1235, %1237, %1239, %1241)\n",
      "      %1243 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1209, %1242), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1244 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1243), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1245 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1210), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1246 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1247 : Long(device=cpu) = onnx::Gather[axis=0](%1245, %1246), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1248 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1210), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1249 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1250 : Long(device=cpu) = onnx::Gather[axis=0](%1248, %1249), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1251 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1252 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1247, %1251)\n",
      "      %1253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1254 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1250, %1253)\n",
      "      %1255 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1256 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1255)\n",
      "      %1257 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1258 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1257)\n",
      "      %1259 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1252, %1254, %1256, %1258)\n",
      "      %1260 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1210, %1259), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1261 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1260), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1262 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1243), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1263 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1227, %1262), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1264 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1265 : Float(*, *, *, *, device=cpu) = onnx::Div(%1263, %1264)\n",
      "      %1266 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1227), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1268 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1269 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1270 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1266, %1268, %1269, %1267), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1272 : Long(device=cpu) = onnx::Squeeze(%1270, %1271), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1273 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1244), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1276 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1277 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1273, %1275, %1276, %1274), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1279 : Long(device=cpu) = onnx::Squeeze(%1277, %1278), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1280 : Long(device=cpu) = onnx::Sub(%1279, %1272), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1282 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1280, %1281), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1284 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1279, %1283), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1285 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1286 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %1285), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1288 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.3.attn.bias, %1282, %1284, %1286, %1287), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1289 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1290 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %1289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1292 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1279, %1291), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1294 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1293), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1296 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1288, %1290, %1292, %1294, %1295), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1297 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1296), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1298 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.3.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1299 : Float(*, *, *, *, device=cpu) = onnx::Where(%1297, %1265, %1298), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1300 : Float(*, *, *, *, device=cpu) = onnx::Add(%1299, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1301 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1300), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1302 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1301, %1261), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1303 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1302), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1304 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1303), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1305 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1306 : Long(device=cpu) = onnx::Gather[axis=0](%1304, %1305), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1307 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1303), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1308 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1309 : Long(device=cpu) = onnx::Gather[axis=0](%1307, %1308), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1310 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1311 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1306, %1310)\n",
      "      %1312 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1313 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1309, %1312)\n",
      "      %1314 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1315 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1314)\n",
      "      %1316 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1311, %1313, %1315)\n",
      "      %1317 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1303, %1316), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1318 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1317), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1319 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1320 : Long(device=cpu) = onnx::Gather[axis=0](%1318, %1319), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1321 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1317), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1322 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1323 : Long(device=cpu) = onnx::Gather[axis=0](%1321, %1322), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1324 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1317), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1325 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1326 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1327 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1328 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1324, %1326, %1327, %1325), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1330 : Long(device=cpu) = onnx::Squeeze(%1328, %1329), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1332 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1331)\n",
      "      %1333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1334 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1330, %1333)\n",
      "      %1335 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1332, %1334)\n",
      "      %1336 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1317, %1335), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1337 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1336, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1338 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1339 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1320, %1338)\n",
      "      %1340 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1341 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1323, %1340)\n",
      "      %1342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1342)\n",
      "      %1344 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1339, %1341, %1343)\n",
      "      %1345 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1337, %1344), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1346 : Float(*, *, *, device=cpu) = onnx::Add(%1345, %1167), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1347 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1346), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1348 : Float(*, *, *, device=cpu) = onnx::Sub(%1346, %1347), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1349 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1350 : Float(*, *, *, device=cpu) = onnx::Pow(%1348, %1349), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1351 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1350), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1352 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1353 : Float(*, *, device=cpu) = onnx::Add(%1351, %1352), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1354 : Float(*, *, device=cpu) = onnx::Sqrt(%1353), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1355 : Float(*, *, *, device=cpu) = onnx::Div(%1348, %1354), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1356 : Float(*, *, *, device=cpu) = onnx::Mul(%1355, %decoder_no_past.decoder.transformer.h.3.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1357 : Float(*, *, *, device=cpu) = onnx::Add(%1356, %decoder_no_past.decoder.transformer.h.3.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1358 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1359 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1360 : Long(device=cpu) = onnx::Gather[axis=0](%1358, %1359), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1361 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1362 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1363 : Long(device=cpu) = onnx::Gather[axis=0](%1361, %1362), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1364 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1368 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1364, %1366, %1367, %1365), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1370 : Long(device=cpu) = onnx::Squeeze(%1368, %1369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1372 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1371)\n",
      "      %1373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1374 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1370, %1373)\n",
      "      %1375 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1372, %1374)\n",
      "      %1376 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1357, %1375), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1377 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1376, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1378 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1379 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1360, %1378)\n",
      "      %1380 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1381 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1363, %1380)\n",
      "      %1382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1383 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %1382)\n",
      "      %1384 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1379, %1381, %1383)\n",
      "      %1385 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1377, %1384), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1386 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1387 : Float(*, *, *, device=cpu) = onnx::Mul(%1385, %1386)\n",
      "      %1388 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1389 : Float(*, *, *, device=cpu) = onnx::Pow(%1385, %1388), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1390 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1391 : Float(*, *, *, device=cpu) = onnx::Mul(%1389, %1390)\n",
      "      %1392 : Float(*, *, *, device=cpu) = onnx::Add(%1385, %1391), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1393 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1394 : Float(*, *, *, device=cpu) = onnx::Mul(%1392, %1393)\n",
      "      %1395 : Float(*, *, *, device=cpu) = onnx::Tanh(%1394), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1396 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1397 : Float(*, *, *, device=cpu) = onnx::Add(%1395, %1396)\n",
      "      %1398 : Float(*, *, *, device=cpu) = onnx::Mul(%1387, %1397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1399 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1400 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1401 : Long(device=cpu) = onnx::Gather[axis=0](%1399, %1400), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1402 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1403 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1404 : Long(device=cpu) = onnx::Gather[axis=0](%1402, %1403), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1405 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1406 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1408 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1409 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1405, %1407, %1408, %1406), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1411 : Long(device=cpu) = onnx::Squeeze(%1409, %1410), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1413 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1412)\n",
      "      %1414 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1415 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1411, %1414)\n",
      "      %1416 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1413, %1415)\n",
      "      %1417 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1398, %1416), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1418 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1417, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1419 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1420 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1401, %1419)\n",
      "      %1421 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1422 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1404, %1421)\n",
      "      %1423 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1424 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1423)\n",
      "      %1425 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1420, %1422, %1424)\n",
      "      %1426 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1418, %1425), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1427 : Float(*, *, *, device=cpu) = onnx::Add(%1346, %1426), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1428 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1427), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1429 : Float(*, *, *, device=cpu) = onnx::Sub(%1427, %1428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1430 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1431 : Float(*, *, *, device=cpu) = onnx::Pow(%1429, %1430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1432 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1433 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1434 : Float(*, *, device=cpu) = onnx::Add(%1432, %1433), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1435 : Float(*, *, device=cpu) = onnx::Sqrt(%1434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1436 : Float(*, *, *, device=cpu) = onnx::Div(%1429, %1435), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1437 : Float(*, *, *, device=cpu) = onnx::Mul(%1436, %decoder_no_past.decoder.transformer.h.4.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1438 : Float(*, *, *, device=cpu) = onnx::Add(%1437, %decoder_no_past.decoder.transformer.h.4.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1439 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1440 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1441 : Long(device=cpu) = onnx::Gather[axis=0](%1439, %1440), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1442 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1443 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1444 : Long(device=cpu) = onnx::Gather[axis=0](%1442, %1443), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1445 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1448 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1449 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1445, %1447, %1448, %1446), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1450 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1451 : Long(device=cpu) = onnx::Squeeze(%1449, %1450), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1452 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1453 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1452)\n",
      "      %1454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1455 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1451, %1454)\n",
      "      %1456 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1453, %1455)\n",
      "      %1457 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1438, %1456), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1458 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1457, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1460 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1441, %1459)\n",
      "      %1461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1462 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1444, %1461)\n",
      "      %1463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1464 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1463)\n",
      "      %1465 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1460, %1462, %1464)\n",
      "      %1466 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1458, %1465), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1467 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1468 : Float(*, *, *, device=cpu), %1469 : Float(*, *, *, device=cpu), %1470 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1466, %1467), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1471 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1472 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1473 : Long(device=cpu) = onnx::Gather[axis=0](%1471, %1472), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1474 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1475 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1476 : Long(device=cpu) = onnx::Gather[axis=0](%1474, %1475), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1478 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1473, %1477)\n",
      "      %1479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1480 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1476, %1479)\n",
      "      %1481 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1482 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1481)\n",
      "      %1483 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1484 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1483)\n",
      "      %1485 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1478, %1480, %1482, %1484)\n",
      "      %1486 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1468, %1485), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1487 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1486), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1488 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1469), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1489 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1490 : Long(device=cpu) = onnx::Gather[axis=0](%1488, %1489), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1491 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1469), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1492 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1493 : Long(device=cpu) = onnx::Gather[axis=0](%1491, %1492), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1495 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1490, %1494)\n",
      "      %1496 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1497 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1493, %1496)\n",
      "      %1498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1499 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1498)\n",
      "      %1500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1501 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1500)\n",
      "      %1502 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1495, %1497, %1499, %1501)\n",
      "      %1503 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1469, %1502), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1504 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1503), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1505 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1470), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1506 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1507 : Long(device=cpu) = onnx::Gather[axis=0](%1505, %1506), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1508 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1470), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1509 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1510 : Long(device=cpu) = onnx::Gather[axis=0](%1508, %1509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1511 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1512 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1507, %1511)\n",
      "      %1513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1514 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1510, %1513)\n",
      "      %1515 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1516 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1515)\n",
      "      %1517 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1518 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1517)\n",
      "      %1519 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1512, %1514, %1516, %1518)\n",
      "      %1520 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1470, %1519), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1521 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1520), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1522 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1503), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1523 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1487, %1522), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1524 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1525 : Float(*, *, *, *, device=cpu) = onnx::Div(%1523, %1524)\n",
      "      %1526 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1487), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1529 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1530 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1526, %1528, %1529, %1527), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1531 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1532 : Long(device=cpu) = onnx::Squeeze(%1530, %1531), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1533 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1504), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1535 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1537 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1533, %1535, %1536, %1534), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1539 : Long(device=cpu) = onnx::Squeeze(%1537, %1538), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1540 : Long(device=cpu) = onnx::Sub(%1539, %1532), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1541 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1542 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1540, %1541), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1543 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1544 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1539, %1543), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1545 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1546 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %1545), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1548 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.4.attn.bias, %1542, %1544, %1546, %1547), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1549 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1550 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %1549), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1552 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1539, %1551), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1554 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1553), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1556 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1548, %1550, %1552, %1554, %1555), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1557 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1556), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1558 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.4.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1559 : Float(*, *, *, *, device=cpu) = onnx::Where(%1557, %1525, %1558), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1560 : Float(*, *, *, *, device=cpu) = onnx::Add(%1559, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1561 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1560), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1562 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1561, %1521), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1563 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1562), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1564 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1563), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1565 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1566 : Long(device=cpu) = onnx::Gather[axis=0](%1564, %1565), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1567 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1563), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1568 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1569 : Long(device=cpu) = onnx::Gather[axis=0](%1567, %1568), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1570 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1571 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1566, %1570)\n",
      "      %1572 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1573 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1569, %1572)\n",
      "      %1574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1575 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1574)\n",
      "      %1576 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1571, %1573, %1575)\n",
      "      %1577 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1563, %1576), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1578 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1579 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1580 : Long(device=cpu) = onnx::Gather[axis=0](%1578, %1579), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1581 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1582 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1583 : Long(device=cpu) = onnx::Gather[axis=0](%1581, %1582), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1584 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1588 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1584, %1586, %1587, %1585), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1590 : Long(device=cpu) = onnx::Squeeze(%1588, %1589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1592 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1591)\n",
      "      %1593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1594 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1590, %1593)\n",
      "      %1595 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1592, %1594)\n",
      "      %1596 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1577, %1595), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1597 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1596, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1598 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1599 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1580, %1598)\n",
      "      %1600 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1601 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1583, %1600)\n",
      "      %1602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1603 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1602)\n",
      "      %1604 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1599, %1601, %1603)\n",
      "      %1605 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1597, %1604), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1606 : Float(*, *, *, device=cpu) = onnx::Add(%1605, %1427), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1607 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1606), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1608 : Float(*, *, *, device=cpu) = onnx::Sub(%1606, %1607), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1609 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1610 : Float(*, *, *, device=cpu) = onnx::Pow(%1608, %1609), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1611 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1610), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1612 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1613 : Float(*, *, device=cpu) = onnx::Add(%1611, %1612), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1614 : Float(*, *, device=cpu) = onnx::Sqrt(%1613), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1615 : Float(*, *, *, device=cpu) = onnx::Div(%1608, %1614), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1616 : Float(*, *, *, device=cpu) = onnx::Mul(%1615, %decoder_no_past.decoder.transformer.h.4.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1617 : Float(*, *, *, device=cpu) = onnx::Add(%1616, %decoder_no_past.decoder.transformer.h.4.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1618 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1619 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1620 : Long(device=cpu) = onnx::Gather[axis=0](%1618, %1619), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1621 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1622 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1623 : Long(device=cpu) = onnx::Gather[axis=0](%1621, %1622), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1624 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1626 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1628 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1624, %1626, %1627, %1625), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1630 : Long(device=cpu) = onnx::Squeeze(%1628, %1629), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1632 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1631)\n",
      "      %1633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1634 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1630, %1633)\n",
      "      %1635 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1632, %1634)\n",
      "      %1636 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1617, %1635), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1637 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1636, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1638 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1639 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1620, %1638)\n",
      "      %1640 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1641 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1623, %1640)\n",
      "      %1642 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1643 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %1642)\n",
      "      %1644 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1639, %1641, %1643)\n",
      "      %1645 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1637, %1644), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1646 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1647 : Float(*, *, *, device=cpu) = onnx::Mul(%1645, %1646)\n",
      "      %1648 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1649 : Float(*, *, *, device=cpu) = onnx::Pow(%1645, %1648), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1650 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1651 : Float(*, *, *, device=cpu) = onnx::Mul(%1649, %1650)\n",
      "      %1652 : Float(*, *, *, device=cpu) = onnx::Add(%1645, %1651), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1653 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1654 : Float(*, *, *, device=cpu) = onnx::Mul(%1652, %1653)\n",
      "      %1655 : Float(*, *, *, device=cpu) = onnx::Tanh(%1654), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1656 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1657 : Float(*, *, *, device=cpu) = onnx::Add(%1655, %1656)\n",
      "      %1658 : Float(*, *, *, device=cpu) = onnx::Mul(%1647, %1657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1659 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1660 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1661 : Long(device=cpu) = onnx::Gather[axis=0](%1659, %1660), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1662 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1663 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1664 : Long(device=cpu) = onnx::Gather[axis=0](%1662, %1663), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1665 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1666 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1668 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1669 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1665, %1667, %1668, %1666), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1671 : Long(device=cpu) = onnx::Squeeze(%1669, %1670), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1673 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1672)\n",
      "      %1674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1675 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1671, %1674)\n",
      "      %1676 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1673, %1675)\n",
      "      %1677 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1658, %1676), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1678 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1677, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1679 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1680 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1661, %1679)\n",
      "      %1681 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1682 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1664, %1681)\n",
      "      %1683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1683)\n",
      "      %1685 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1680, %1682, %1684)\n",
      "      %1686 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1678, %1685), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1687 : Float(*, *, *, device=cpu) = onnx::Add(%1606, %1686), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1688 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1687), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1689 : Float(*, *, *, device=cpu) = onnx::Sub(%1687, %1688), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1691 : Float(*, *, *, device=cpu) = onnx::Pow(%1689, %1690), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1692 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1691), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1693 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1694 : Float(*, *, device=cpu) = onnx::Add(%1692, %1693), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1695 : Float(*, *, device=cpu) = onnx::Sqrt(%1694), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1696 : Float(*, *, *, device=cpu) = onnx::Div(%1689, %1695), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1697 : Float(*, *, *, device=cpu) = onnx::Mul(%1696, %decoder_no_past.decoder.transformer.h.5.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1698 : Float(*, *, *, device=cpu) = onnx::Add(%1697, %decoder_no_past.decoder.transformer.h.5.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1699 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1700 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1701 : Long(device=cpu) = onnx::Gather[axis=0](%1699, %1700), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1702 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1703 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1704 : Long(device=cpu) = onnx::Gather[axis=0](%1702, %1703), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1705 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1706 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1708 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1709 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1705, %1707, %1708, %1706), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1711 : Long(device=cpu) = onnx::Squeeze(%1709, %1710), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1713 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1712)\n",
      "      %1714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1715 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1711, %1714)\n",
      "      %1716 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1713, %1715)\n",
      "      %1717 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1698, %1716), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1718 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1717, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1719 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1720 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1701, %1719)\n",
      "      %1721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1722 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1704, %1721)\n",
      "      %1723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1724 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1723)\n",
      "      %1725 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1720, %1722, %1724)\n",
      "      %1726 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1718, %1725), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1727 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1728 : Float(*, *, *, device=cpu), %1729 : Float(*, *, *, device=cpu), %1730 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1726, %1727), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1731 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1728), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1732 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1733 : Long(device=cpu) = onnx::Gather[axis=0](%1731, %1732), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1734 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1728), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1735 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1736 : Long(device=cpu) = onnx::Gather[axis=0](%1734, %1735), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1738 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1733, %1737)\n",
      "      %1739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1740 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1736, %1739)\n",
      "      %1741 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1742 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1741)\n",
      "      %1743 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1744 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1743)\n",
      "      %1745 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1738, %1740, %1742, %1744)\n",
      "      %1746 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1728, %1745), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1747 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1746), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1748 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1729), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1749 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1750 : Long(device=cpu) = onnx::Gather[axis=0](%1748, %1749), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1751 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1729), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1752 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1753 : Long(device=cpu) = onnx::Gather[axis=0](%1751, %1752), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1754 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1755 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1750, %1754)\n",
      "      %1756 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1757 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1753, %1756)\n",
      "      %1758 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1759 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1758)\n",
      "      %1760 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1761 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1760)\n",
      "      %1762 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1755, %1757, %1759, %1761)\n",
      "      %1763 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1729, %1762), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1764 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1763), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1765 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1730), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1766 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1767 : Long(device=cpu) = onnx::Gather[axis=0](%1765, %1766), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1768 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1730), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1769 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1770 : Long(device=cpu) = onnx::Gather[axis=0](%1768, %1769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1771 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1772 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1767, %1771)\n",
      "      %1773 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1774 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1770, %1773)\n",
      "      %1775 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1776 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1775)\n",
      "      %1777 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1778 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %1777)\n",
      "      %1779 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1772, %1774, %1776, %1778)\n",
      "      %1780 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1730, %1779), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1781 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1780), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1782 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1763), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1783 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1747, %1782), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1784 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1785 : Float(*, *, *, *, device=cpu) = onnx::Div(%1783, %1784)\n",
      "      %1786 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1747), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1788 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1789 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1790 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1786, %1788, %1789, %1787), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1791 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1792 : Long(device=cpu) = onnx::Squeeze(%1790, %1791), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1793 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1764), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1794 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1795 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1796 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1797 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1793, %1795, %1796, %1794), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1799 : Long(device=cpu) = onnx::Squeeze(%1797, %1798), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1800 : Long(device=cpu) = onnx::Sub(%1799, %1792), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1801 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1802 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1800, %1801), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1803 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1804 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1799, %1803), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1805 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1806 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %1805), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1807 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1808 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.5.attn.bias, %1802, %1804, %1806, %1807), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1810 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %1809), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1812 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1799, %1811), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1814 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1813), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1816 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1808, %1810, %1812, %1814, %1815), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1817 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1816), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1818 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.5.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1819 : Float(*, *, *, *, device=cpu) = onnx::Where(%1817, %1785, %1818), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1820 : Float(*, *, *, *, device=cpu) = onnx::Add(%1819, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1821 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1820), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1822 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1821, %1781), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1823 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1822), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1824 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1823), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1825 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1826 : Long(device=cpu) = onnx::Gather[axis=0](%1824, %1825), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1827 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1823), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1828 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1829 : Long(device=cpu) = onnx::Gather[axis=0](%1827, %1828), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1831 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1826, %1830)\n",
      "      %1832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1833 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1829, %1832)\n",
      "      %1834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1835 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1834)\n",
      "      %1836 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1831, %1833, %1835)\n",
      "      %1837 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1823, %1836), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1838 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1839 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1840 : Long(device=cpu) = onnx::Gather[axis=0](%1838, %1839), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1841 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1842 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1843 : Long(device=cpu) = onnx::Gather[axis=0](%1841, %1842), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1844 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1846 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1847 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1848 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1844, %1846, %1847, %1845), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1850 : Long(device=cpu) = onnx::Squeeze(%1848, %1849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1852 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1851)\n",
      "      %1853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1854 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1850, %1853)\n",
      "      %1855 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1852, %1854)\n",
      "      %1856 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1837, %1855), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1857 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1856, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1859 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1840, %1858)\n",
      "      %1860 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1861 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1843, %1860)\n",
      "      %1862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1863 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1862)\n",
      "      %1864 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1859, %1861, %1863)\n",
      "      %1865 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1857, %1864), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1866 : Float(*, *, *, device=cpu) = onnx::Add(%1865, %1687), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1867 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1866), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1868 : Float(*, *, *, device=cpu) = onnx::Sub(%1866, %1867), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1869 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1870 : Float(*, *, *, device=cpu) = onnx::Pow(%1868, %1869), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1871 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1870), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1872 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1873 : Float(*, *, device=cpu) = onnx::Add(%1871, %1872), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1874 : Float(*, *, device=cpu) = onnx::Sqrt(%1873), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1875 : Float(*, *, *, device=cpu) = onnx::Div(%1868, %1874), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1876 : Float(*, *, *, device=cpu) = onnx::Mul(%1875, %decoder_no_past.decoder.transformer.h.5.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1877 : Float(*, *, *, device=cpu) = onnx::Add(%1876, %decoder_no_past.decoder.transformer.h.5.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1878 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1879 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1880 : Long(device=cpu) = onnx::Gather[axis=0](%1878, %1879), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1881 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1882 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1883 : Long(device=cpu) = onnx::Gather[axis=0](%1881, %1882), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1884 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1886 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1888 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1884, %1886, %1887, %1885), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1890 : Long(device=cpu) = onnx::Squeeze(%1888, %1889), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1892 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1891)\n",
      "      %1893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1894 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1890, %1893)\n",
      "      %1895 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1892, %1894)\n",
      "      %1896 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1877, %1895), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1897 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1896, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1899 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1880, %1898)\n",
      "      %1900 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1901 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1883, %1900)\n",
      "      %1902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1903 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %1902)\n",
      "      %1904 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1899, %1901, %1903)\n",
      "      %1905 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1897, %1904), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1906 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1907 : Float(*, *, *, device=cpu) = onnx::Mul(%1905, %1906)\n",
      "      %1908 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1909 : Float(*, *, *, device=cpu) = onnx::Pow(%1905, %1908), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1910 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1911 : Float(*, *, *, device=cpu) = onnx::Mul(%1909, %1910)\n",
      "      %1912 : Float(*, *, *, device=cpu) = onnx::Add(%1905, %1911), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1913 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1914 : Float(*, *, *, device=cpu) = onnx::Mul(%1912, %1913)\n",
      "      %1915 : Float(*, *, *, device=cpu) = onnx::Tanh(%1914), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1916 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1917 : Float(*, *, *, device=cpu) = onnx::Add(%1915, %1916)\n",
      "      %1918 : Float(*, *, *, device=cpu) = onnx::Mul(%1907, %1917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1919 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1920 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1921 : Long(device=cpu) = onnx::Gather[axis=0](%1919, %1920), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1922 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1923 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1924 : Long(device=cpu) = onnx::Gather[axis=0](%1922, %1923), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1925 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1926 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1928 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1929 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1925, %1927, %1928, %1926), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1931 : Long(device=cpu) = onnx::Squeeze(%1929, %1930), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1933 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1932)\n",
      "      %1934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1935 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1931, %1934)\n",
      "      %1936 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1933, %1935)\n",
      "      %1937 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1918, %1936), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1938 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1937, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1940 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1921, %1939)\n",
      "      %1941 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1942 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1924, %1941)\n",
      "      %1943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1943)\n",
      "      %1945 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1940, %1942, %1944)\n",
      "      %1946 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1938, %1945), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1947 : Float(*, *, *, device=cpu) = onnx::Add(%1866, %1946), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1948 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1947), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1949 : Float(*, *, *, device=cpu) = onnx::Sub(%1947, %1948), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1950 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1951 : Float(*, *, *, device=cpu) = onnx::Pow(%1949, %1950), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1952 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1951), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1953 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1954 : Float(*, *, device=cpu) = onnx::Add(%1952, %1953), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1955 : Float(*, *, device=cpu) = onnx::Sqrt(%1954), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1956 : Float(*, *, *, device=cpu) = onnx::Div(%1949, %1955), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1957 : Float(*, *, *, device=cpu) = onnx::Mul(%1956, %decoder_no_past.decoder.transformer.h.6.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1958 : Float(*, *, *, device=cpu) = onnx::Add(%1957, %decoder_no_past.decoder.transformer.h.6.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1959 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1960 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1961 : Long(device=cpu) = onnx::Gather[axis=0](%1959, %1960), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1962 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1963 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1964 : Long(device=cpu) = onnx::Gather[axis=0](%1962, %1963), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1965 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1966 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1968 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1969 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1965, %1967, %1968, %1966), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1970 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1971 : Long(device=cpu) = onnx::Squeeze(%1969, %1970), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1973 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %1972)\n",
      "      %1974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1975 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1971, %1974)\n",
      "      %1976 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1973, %1975)\n",
      "      %1977 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1958, %1976), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1978 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1977, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1979 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1980 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1961, %1979)\n",
      "      %1981 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1982 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1964, %1981)\n",
      "      %1983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1984 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1983)\n",
      "      %1985 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1980, %1982, %1984)\n",
      "      %1986 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1978, %1985), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1987 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1988 : Float(*, *, *, device=cpu), %1989 : Float(*, *, *, device=cpu), %1990 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1986, %1987), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1991 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1988), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1992 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1993 : Long(device=cpu) = onnx::Gather[axis=0](%1991, %1992), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1994 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1988), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1995 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1996 : Long(device=cpu) = onnx::Gather[axis=0](%1994, %1995), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1998 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1993, %1997)\n",
      "      %1999 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2000 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1996, %1999)\n",
      "      %2001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2002 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2001)\n",
      "      %2003 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2004 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2003)\n",
      "      %2005 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1998, %2000, %2002, %2004)\n",
      "      %2006 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1988, %2005), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2007 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2006), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2008 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1989), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2009 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2010 : Long(device=cpu) = onnx::Gather[axis=0](%2008, %2009), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2011 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1989), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2012 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2013 : Long(device=cpu) = onnx::Gather[axis=0](%2011, %2012), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2015 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2010, %2014)\n",
      "      %2016 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2017 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2013, %2016)\n",
      "      %2018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2019 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2018)\n",
      "      %2020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2021 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2020)\n",
      "      %2022 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2015, %2017, %2019, %2021)\n",
      "      %2023 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1989, %2022), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2024 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2023), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2025 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1990), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2026 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2027 : Long(device=cpu) = onnx::Gather[axis=0](%2025, %2026), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2028 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1990), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2029 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2030 : Long(device=cpu) = onnx::Gather[axis=0](%2028, %2029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2032 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2027, %2031)\n",
      "      %2033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2034 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2030, %2033)\n",
      "      %2035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2036 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2035)\n",
      "      %2037 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2038 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2037)\n",
      "      %2039 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2032, %2034, %2036, %2038)\n",
      "      %2040 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1990, %2039), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2041 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2040), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2042 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2023), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2043 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2007, %2042), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2044 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2045 : Float(*, *, *, *, device=cpu) = onnx::Div(%2043, %2044)\n",
      "      %2046 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2007), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2047 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2048 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2049 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2050 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2046, %2048, %2049, %2047), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2051 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2052 : Long(device=cpu) = onnx::Squeeze(%2050, %2051), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2053 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2024), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2054 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2055 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2057 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2053, %2055, %2056, %2054), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2059 : Long(device=cpu) = onnx::Squeeze(%2057, %2058), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2060 : Long(device=cpu) = onnx::Sub(%2059, %2052), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2061 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2062 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2060, %2061), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2063 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2064 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2059, %2063), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2065 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2066 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %2065), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2067 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2068 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.6.attn.bias, %2062, %2064, %2066, %2067), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2070 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %2069), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2072 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2059, %2071), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2074 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2073), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2076 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2068, %2070, %2072, %2074, %2075), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2077 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2076), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2078 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.6.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2079 : Float(*, *, *, *, device=cpu) = onnx::Where(%2077, %2045, %2078), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2080 : Float(*, *, *, *, device=cpu) = onnx::Add(%2079, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2081 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2080), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2082 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2081, %2041), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2083 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2082), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2084 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2083), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2085 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2086 : Long(device=cpu) = onnx::Gather[axis=0](%2084, %2085), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2087 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2083), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2088 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2089 : Long(device=cpu) = onnx::Gather[axis=0](%2087, %2088), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2090 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2091 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2086, %2090)\n",
      "      %2092 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2093 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2089, %2092)\n",
      "      %2094 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2095 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2094)\n",
      "      %2096 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2091, %2093, %2095)\n",
      "      %2097 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2083, %2096), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2098 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2099 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2100 : Long(device=cpu) = onnx::Gather[axis=0](%2098, %2099), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2101 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2102 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2103 : Long(device=cpu) = onnx::Gather[axis=0](%2101, %2102), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2104 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2106 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2108 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2104, %2106, %2107, %2105), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2110 : Long(device=cpu) = onnx::Squeeze(%2108, %2109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2112 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2111)\n",
      "      %2113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2114 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2110, %2113)\n",
      "      %2115 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2112, %2114)\n",
      "      %2116 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2097, %2115), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2117 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2116, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2118 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2119 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2100, %2118)\n",
      "      %2120 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2121 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2103, %2120)\n",
      "      %2122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2123 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2122)\n",
      "      %2124 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2119, %2121, %2123)\n",
      "      %2125 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2117, %2124), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2126 : Float(*, *, *, device=cpu) = onnx::Add(%2125, %1947), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2127 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2126), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2128 : Float(*, *, *, device=cpu) = onnx::Sub(%2126, %2127), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2129 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2130 : Float(*, *, *, device=cpu) = onnx::Pow(%2128, %2129), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2131 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2130), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2132 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2133 : Float(*, *, device=cpu) = onnx::Add(%2131, %2132), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2134 : Float(*, *, device=cpu) = onnx::Sqrt(%2133), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2135 : Float(*, *, *, device=cpu) = onnx::Div(%2128, %2134), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2136 : Float(*, *, *, device=cpu) = onnx::Mul(%2135, %decoder_no_past.decoder.transformer.h.6.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2137 : Float(*, *, *, device=cpu) = onnx::Add(%2136, %decoder_no_past.decoder.transformer.h.6.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2138 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2139 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2140 : Long(device=cpu) = onnx::Gather[axis=0](%2138, %2139), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2141 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2142 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2143 : Long(device=cpu) = onnx::Gather[axis=0](%2141, %2142), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2144 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2145 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2148 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2144, %2146, %2147, %2145), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2149 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2150 : Long(device=cpu) = onnx::Squeeze(%2148, %2149), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2152 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2151)\n",
      "      %2153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2154 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2150, %2153)\n",
      "      %2155 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2152, %2154)\n",
      "      %2156 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2137, %2155), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2157 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2156, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2158 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2159 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2140, %2158)\n",
      "      %2160 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2161 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2143, %2160)\n",
      "      %2162 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2163 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %2162)\n",
      "      %2164 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2159, %2161, %2163)\n",
      "      %2165 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2157, %2164), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2166 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2167 : Float(*, *, *, device=cpu) = onnx::Mul(%2165, %2166)\n",
      "      %2168 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2169 : Float(*, *, *, device=cpu) = onnx::Pow(%2165, %2168), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2170 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2171 : Float(*, *, *, device=cpu) = onnx::Mul(%2169, %2170)\n",
      "      %2172 : Float(*, *, *, device=cpu) = onnx::Add(%2165, %2171), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2174 : Float(*, *, *, device=cpu) = onnx::Mul(%2172, %2173)\n",
      "      %2175 : Float(*, *, *, device=cpu) = onnx::Tanh(%2174), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2176 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2177 : Float(*, *, *, device=cpu) = onnx::Add(%2175, %2176)\n",
      "      %2178 : Float(*, *, *, device=cpu) = onnx::Mul(%2167, %2177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2179 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2180 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2181 : Long(device=cpu) = onnx::Gather[axis=0](%2179, %2180), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2182 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2183 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2184 : Long(device=cpu) = onnx::Gather[axis=0](%2182, %2183), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2185 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2188 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2189 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2185, %2187, %2188, %2186), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2190 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2191 : Long(device=cpu) = onnx::Squeeze(%2189, %2190), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2192 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2193 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2192)\n",
      "      %2194 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2195 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2191, %2194)\n",
      "      %2196 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2193, %2195)\n",
      "      %2197 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2178, %2196), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2198 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2197, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2199 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2200 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2181, %2199)\n",
      "      %2201 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2202 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2184, %2201)\n",
      "      %2203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2203)\n",
      "      %2205 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2200, %2202, %2204)\n",
      "      %2206 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2198, %2205), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2207 : Float(*, *, *, device=cpu) = onnx::Add(%2126, %2206), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2208 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2207), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2209 : Float(*, *, *, device=cpu) = onnx::Sub(%2207, %2208), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2210 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2211 : Float(*, *, *, device=cpu) = onnx::Pow(%2209, %2210), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2212 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2211), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2213 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2214 : Float(*, *, device=cpu) = onnx::Add(%2212, %2213), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2215 : Float(*, *, device=cpu) = onnx::Sqrt(%2214), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2216 : Float(*, *, *, device=cpu) = onnx::Div(%2209, %2215), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2217 : Float(*, *, *, device=cpu) = onnx::Mul(%2216, %decoder_no_past.decoder.transformer.h.7.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2218 : Float(*, *, *, device=cpu) = onnx::Add(%2217, %decoder_no_past.decoder.transformer.h.7.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2219 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2220 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2221 : Long(device=cpu) = onnx::Gather[axis=0](%2219, %2220), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2222 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2223 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2224 : Long(device=cpu) = onnx::Gather[axis=0](%2222, %2223), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2225 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2227 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2229 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2225, %2227, %2228, %2226), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2231 : Long(device=cpu) = onnx::Squeeze(%2229, %2230), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2233 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2232)\n",
      "      %2234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2235 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2231, %2234)\n",
      "      %2236 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2233, %2235)\n",
      "      %2237 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2218, %2236), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2238 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2237, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2240 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2221, %2239)\n",
      "      %2241 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2242 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2224, %2241)\n",
      "      %2243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2244 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2243)\n",
      "      %2245 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2240, %2242, %2244)\n",
      "      %2246 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2238, %2245), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2247 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2248 : Float(*, *, *, device=cpu), %2249 : Float(*, *, *, device=cpu), %2250 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2246, %2247), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2251 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2248), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2252 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2253 : Long(device=cpu) = onnx::Gather[axis=0](%2251, %2252), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2254 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2248), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2255 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2256 : Long(device=cpu) = onnx::Gather[axis=0](%2254, %2255), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2257 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2258 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2253, %2257)\n",
      "      %2259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2260 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2256, %2259)\n",
      "      %2261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2262 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2261)\n",
      "      %2263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2264 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2263)\n",
      "      %2265 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2258, %2260, %2262, %2264)\n",
      "      %2266 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2248, %2265), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2267 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2266), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2268 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2249), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2269 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2270 : Long(device=cpu) = onnx::Gather[axis=0](%2268, %2269), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2271 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2249), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2272 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2273 : Long(device=cpu) = onnx::Gather[axis=0](%2271, %2272), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2275 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2270, %2274)\n",
      "      %2276 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2277 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2273, %2276)\n",
      "      %2278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2279 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2278)\n",
      "      %2280 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2281 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2280)\n",
      "      %2282 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2275, %2277, %2279, %2281)\n",
      "      %2283 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2249, %2282), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2284 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2283), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2285 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2250), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2286 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2287 : Long(device=cpu) = onnx::Gather[axis=0](%2285, %2286), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2288 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2250), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2289 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2290 : Long(device=cpu) = onnx::Gather[axis=0](%2288, %2289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2292 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2287, %2291)\n",
      "      %2293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2294 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2290, %2293)\n",
      "      %2295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2296 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2295)\n",
      "      %2297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2298 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2297)\n",
      "      %2299 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2292, %2294, %2296, %2298)\n",
      "      %2300 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2250, %2299), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2301 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2300), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2302 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2283), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2303 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2267, %2302), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2304 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2305 : Float(*, *, *, *, device=cpu) = onnx::Div(%2303, %2304)\n",
      "      %2306 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2267), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2307 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2308 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2309 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2310 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2306, %2308, %2309, %2307), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2311 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2312 : Long(device=cpu) = onnx::Squeeze(%2310, %2311), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2313 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2284), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2314 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2315 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2316 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2317 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2313, %2315, %2316, %2314), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2319 : Long(device=cpu) = onnx::Squeeze(%2317, %2318), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2320 : Long(device=cpu) = onnx::Sub(%2319, %2312), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2321 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2322 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2320, %2321), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2323 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2324 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2319, %2323), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2325 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2326 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %2325), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2327 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2328 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.7.attn.bias, %2322, %2324, %2326, %2327), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2330 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %2329), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2332 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2319, %2331), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2334 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2333), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2336 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2328, %2330, %2332, %2334, %2335), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2337 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2336), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2338 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.7.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2339 : Float(*, *, *, *, device=cpu) = onnx::Where(%2337, %2305, %2338), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2340 : Float(*, *, *, *, device=cpu) = onnx::Add(%2339, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2341 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2340), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2342 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2341, %2301), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2343 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2342), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2344 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2343), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2345 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2346 : Long(device=cpu) = onnx::Gather[axis=0](%2344, %2345), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2347 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2343), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2348 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2349 : Long(device=cpu) = onnx::Gather[axis=0](%2347, %2348), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2350 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2351 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2346, %2350)\n",
      "      %2352 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2353 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2349, %2352)\n",
      "      %2354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2355 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2354)\n",
      "      %2356 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2351, %2353, %2355)\n",
      "      %2357 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2343, %2356), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2358 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2359 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2360 : Long(device=cpu) = onnx::Gather[axis=0](%2358, %2359), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2361 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2362 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2363 : Long(device=cpu) = onnx::Gather[axis=0](%2361, %2362), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2364 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2368 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2364, %2366, %2367, %2365), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2370 : Long(device=cpu) = onnx::Squeeze(%2368, %2369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2372 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2371)\n",
      "      %2373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2374 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2370, %2373)\n",
      "      %2375 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2372, %2374)\n",
      "      %2376 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2357, %2375), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2377 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2376, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2378 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2379 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2360, %2378)\n",
      "      %2380 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2381 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2363, %2380)\n",
      "      %2382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2383 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2382)\n",
      "      %2384 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2379, %2381, %2383)\n",
      "      %2385 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2377, %2384), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2386 : Float(*, *, *, device=cpu) = onnx::Add(%2385, %2207), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2387 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2386), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2388 : Float(*, *, *, device=cpu) = onnx::Sub(%2386, %2387), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2389 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2390 : Float(*, *, *, device=cpu) = onnx::Pow(%2388, %2389), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2391 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2390), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2392 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2393 : Float(*, *, device=cpu) = onnx::Add(%2391, %2392), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2394 : Float(*, *, device=cpu) = onnx::Sqrt(%2393), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2395 : Float(*, *, *, device=cpu) = onnx::Div(%2388, %2394), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2396 : Float(*, *, *, device=cpu) = onnx::Mul(%2395, %decoder_no_past.decoder.transformer.h.7.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2397 : Float(*, *, *, device=cpu) = onnx::Add(%2396, %decoder_no_past.decoder.transformer.h.7.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2398 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2399 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2400 : Long(device=cpu) = onnx::Gather[axis=0](%2398, %2399), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2401 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2402 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2403 : Long(device=cpu) = onnx::Gather[axis=0](%2401, %2402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2404 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2405 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2406 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2408 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2404, %2406, %2407, %2405), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2410 : Long(device=cpu) = onnx::Squeeze(%2408, %2409), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2412 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2411)\n",
      "      %2413 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2414 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2410, %2413)\n",
      "      %2415 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2412, %2414)\n",
      "      %2416 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2397, %2415), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2417 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2416, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2418 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2419 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2400, %2418)\n",
      "      %2420 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2421 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2403, %2420)\n",
      "      %2422 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2423 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %2422)\n",
      "      %2424 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2419, %2421, %2423)\n",
      "      %2425 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2417, %2424), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2426 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2427 : Float(*, *, *, device=cpu) = onnx::Mul(%2425, %2426)\n",
      "      %2428 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2429 : Float(*, *, *, device=cpu) = onnx::Pow(%2425, %2428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2430 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2431 : Float(*, *, *, device=cpu) = onnx::Mul(%2429, %2430)\n",
      "      %2432 : Float(*, *, *, device=cpu) = onnx::Add(%2425, %2431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2433 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2434 : Float(*, *, *, device=cpu) = onnx::Mul(%2432, %2433)\n",
      "      %2435 : Float(*, *, *, device=cpu) = onnx::Tanh(%2434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2436 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2437 : Float(*, *, *, device=cpu) = onnx::Add(%2435, %2436)\n",
      "      %2438 : Float(*, *, *, device=cpu) = onnx::Mul(%2427, %2437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2439 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2440 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2441 : Long(device=cpu) = onnx::Gather[axis=0](%2439, %2440), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2442 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2443 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2444 : Long(device=cpu) = onnx::Gather[axis=0](%2442, %2443), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2445 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2448 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2449 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2445, %2447, %2448, %2446), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2450 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2451 : Long(device=cpu) = onnx::Squeeze(%2449, %2450), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2452 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2453 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2452)\n",
      "      %2454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2455 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2451, %2454)\n",
      "      %2456 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2453, %2455)\n",
      "      %2457 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2438, %2456), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2458 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2457, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2459 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2460 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2441, %2459)\n",
      "      %2461 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2462 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2444, %2461)\n",
      "      %2463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2464 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2463)\n",
      "      %2465 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2460, %2462, %2464)\n",
      "      %2466 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2458, %2465), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2467 : Float(*, *, *, device=cpu) = onnx::Add(%2386, %2466), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2468 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2467), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2469 : Float(*, *, *, device=cpu) = onnx::Sub(%2467, %2468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2470 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2471 : Float(*, *, *, device=cpu) = onnx::Pow(%2469, %2470), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2472 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2471), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2473 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2474 : Float(*, *, device=cpu) = onnx::Add(%2472, %2473), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2475 : Float(*, *, device=cpu) = onnx::Sqrt(%2474), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2476 : Float(*, *, *, device=cpu) = onnx::Div(%2469, %2475), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2477 : Float(*, *, *, device=cpu) = onnx::Mul(%2476, %decoder_no_past.decoder.transformer.h.8.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2478 : Float(*, *, *, device=cpu) = onnx::Add(%2477, %decoder_no_past.decoder.transformer.h.8.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2479 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2480 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2481 : Long(device=cpu) = onnx::Gather[axis=0](%2479, %2480), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2482 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2483 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2484 : Long(device=cpu) = onnx::Gather[axis=0](%2482, %2483), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2485 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2489 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2485, %2487, %2488, %2486), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2491 : Long(device=cpu) = onnx::Squeeze(%2489, %2490), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2493 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2492)\n",
      "      %2494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2495 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2491, %2494)\n",
      "      %2496 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2493, %2495)\n",
      "      %2497 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2478, %2496), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2498 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2497, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2500 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2481, %2499)\n",
      "      %2501 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2502 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2484, %2501)\n",
      "      %2503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2504 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2503)\n",
      "      %2505 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2500, %2502, %2504)\n",
      "      %2506 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2498, %2505), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2507 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2508 : Float(*, *, *, device=cpu), %2509 : Float(*, *, *, device=cpu), %2510 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2506, %2507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2511 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2508), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2512 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2513 : Long(device=cpu) = onnx::Gather[axis=0](%2511, %2512), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2514 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2508), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2515 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2516 : Long(device=cpu) = onnx::Gather[axis=0](%2514, %2515), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2517 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2518 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2513, %2517)\n",
      "      %2519 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2520 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2516, %2519)\n",
      "      %2521 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2522 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2521)\n",
      "      %2523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2524 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2523)\n",
      "      %2525 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2518, %2520, %2522, %2524)\n",
      "      %2526 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2508, %2525), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2527 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2526), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2528 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2529 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2530 : Long(device=cpu) = onnx::Gather[axis=0](%2528, %2529), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2531 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2532 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2533 : Long(device=cpu) = onnx::Gather[axis=0](%2531, %2532), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2535 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2530, %2534)\n",
      "      %2536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2537 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2533, %2536)\n",
      "      %2538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2539 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2538)\n",
      "      %2540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2541 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2540)\n",
      "      %2542 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2535, %2537, %2539, %2541)\n",
      "      %2543 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2509, %2542), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2544 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2543), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2545 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2510), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2546 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2547 : Long(device=cpu) = onnx::Gather[axis=0](%2545, %2546), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2548 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2510), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2549 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2550 : Long(device=cpu) = onnx::Gather[axis=0](%2548, %2549), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2552 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2547, %2551)\n",
      "      %2553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2554 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2550, %2553)\n",
      "      %2555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2556 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2555)\n",
      "      %2557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2558 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2557)\n",
      "      %2559 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2552, %2554, %2556, %2558)\n",
      "      %2560 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2510, %2559), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2561 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2560), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2562 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2543), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2563 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2527, %2562), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2564 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2565 : Float(*, *, *, *, device=cpu) = onnx::Div(%2563, %2564)\n",
      "      %2566 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2527), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2567 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2568 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2569 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2570 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2566, %2568, %2569, %2567), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2572 : Long(device=cpu) = onnx::Squeeze(%2570, %2571), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2573 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2544), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2576 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2577 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2573, %2575, %2576, %2574), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2578 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2579 : Long(device=cpu) = onnx::Squeeze(%2577, %2578), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2580 : Long(device=cpu) = onnx::Sub(%2579, %2572), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2581 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2582 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2580, %2581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2584 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2579, %2583), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2586 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %2585), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2588 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.8.attn.bias, %2582, %2584, %2586, %2587), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2590 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %2589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2592 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2579, %2591), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2594 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2593), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2596 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2588, %2590, %2592, %2594, %2595), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2597 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2596), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2598 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.8.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2599 : Float(*, *, *, *, device=cpu) = onnx::Where(%2597, %2565, %2598), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2600 : Float(*, *, *, *, device=cpu) = onnx::Add(%2599, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2601 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2600), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2602 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2601, %2561), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2603 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2602), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2604 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2603), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2605 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2606 : Long(device=cpu) = onnx::Gather[axis=0](%2604, %2605), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2607 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2603), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2608 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2609 : Long(device=cpu) = onnx::Gather[axis=0](%2607, %2608), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2610 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2611 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2606, %2610)\n",
      "      %2612 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2613 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2609, %2612)\n",
      "      %2614 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2615 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2614)\n",
      "      %2616 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2611, %2613, %2615)\n",
      "      %2617 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2603, %2616), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2618 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2619 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2620 : Long(device=cpu) = onnx::Gather[axis=0](%2618, %2619), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2621 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2622 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2623 : Long(device=cpu) = onnx::Gather[axis=0](%2621, %2622), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2624 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2626 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2628 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2624, %2626, %2627, %2625), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2630 : Long(device=cpu) = onnx::Squeeze(%2628, %2629), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2632 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2631)\n",
      "      %2633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2634 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2630, %2633)\n",
      "      %2635 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2632, %2634)\n",
      "      %2636 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2617, %2635), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2637 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2636, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2638 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2639 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2620, %2638)\n",
      "      %2640 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2641 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2623, %2640)\n",
      "      %2642 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2643 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2642)\n",
      "      %2644 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2639, %2641, %2643)\n",
      "      %2645 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2637, %2644), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2646 : Float(*, *, *, device=cpu) = onnx::Add(%2645, %2467), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2647 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2646), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2648 : Float(*, *, *, device=cpu) = onnx::Sub(%2646, %2647), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2649 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2650 : Float(*, *, *, device=cpu) = onnx::Pow(%2648, %2649), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2651 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2650), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2652 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2653 : Float(*, *, device=cpu) = onnx::Add(%2651, %2652), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2654 : Float(*, *, device=cpu) = onnx::Sqrt(%2653), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2655 : Float(*, *, *, device=cpu) = onnx::Div(%2648, %2654), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2656 : Float(*, *, *, device=cpu) = onnx::Mul(%2655, %decoder_no_past.decoder.transformer.h.8.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2657 : Float(*, *, *, device=cpu) = onnx::Add(%2656, %decoder_no_past.decoder.transformer.h.8.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2658 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2659 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2660 : Long(device=cpu) = onnx::Gather[axis=0](%2658, %2659), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2661 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2662 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2663 : Long(device=cpu) = onnx::Gather[axis=0](%2661, %2662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2664 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2666 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2667 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2668 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2664, %2666, %2667, %2665), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2669 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2670 : Long(device=cpu) = onnx::Squeeze(%2668, %2669), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2672 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2671)\n",
      "      %2673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2674 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2670, %2673)\n",
      "      %2675 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2672, %2674)\n",
      "      %2676 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2657, %2675), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2677 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2676, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2679 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2660, %2678)\n",
      "      %2680 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2681 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2663, %2680)\n",
      "      %2682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2683 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %2682)\n",
      "      %2684 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2679, %2681, %2683)\n",
      "      %2685 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2677, %2684), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2686 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2687 : Float(*, *, *, device=cpu) = onnx::Mul(%2685, %2686)\n",
      "      %2688 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2689 : Float(*, *, *, device=cpu) = onnx::Pow(%2685, %2688), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2691 : Float(*, *, *, device=cpu) = onnx::Mul(%2689, %2690)\n",
      "      %2692 : Float(*, *, *, device=cpu) = onnx::Add(%2685, %2691), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2693 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2694 : Float(*, *, *, device=cpu) = onnx::Mul(%2692, %2693)\n",
      "      %2695 : Float(*, *, *, device=cpu) = onnx::Tanh(%2694), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2696 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2697 : Float(*, *, *, device=cpu) = onnx::Add(%2695, %2696)\n",
      "      %2698 : Float(*, *, *, device=cpu) = onnx::Mul(%2687, %2697), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2699 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2700 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2701 : Long(device=cpu) = onnx::Gather[axis=0](%2699, %2700), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2702 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2703 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2704 : Long(device=cpu) = onnx::Gather[axis=0](%2702, %2703), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2705 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2706 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2708 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2709 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2705, %2707, %2708, %2706), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2711 : Long(device=cpu) = onnx::Squeeze(%2709, %2710), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2713 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2712)\n",
      "      %2714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2715 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2711, %2714)\n",
      "      %2716 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2713, %2715)\n",
      "      %2717 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2698, %2716), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2718 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2717, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2719 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2720 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2701, %2719)\n",
      "      %2721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2722 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2704, %2721)\n",
      "      %2723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2724 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2723)\n",
      "      %2725 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2720, %2722, %2724)\n",
      "      %2726 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2718, %2725), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2727 : Float(*, *, *, device=cpu) = onnx::Add(%2646, %2726), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2728 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2727), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2729 : Float(*, *, *, device=cpu) = onnx::Sub(%2727, %2728), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2730 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2731 : Float(*, *, *, device=cpu) = onnx::Pow(%2729, %2730), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2732 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2731), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2733 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2734 : Float(*, *, device=cpu) = onnx::Add(%2732, %2733), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2735 : Float(*, *, device=cpu) = onnx::Sqrt(%2734), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2736 : Float(*, *, *, device=cpu) = onnx::Div(%2729, %2735), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2737 : Float(*, *, *, device=cpu) = onnx::Mul(%2736, %decoder_no_past.decoder.transformer.h.9.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2738 : Float(*, *, *, device=cpu) = onnx::Add(%2737, %decoder_no_past.decoder.transformer.h.9.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2739 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2738), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2740 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2741 : Long(device=cpu) = onnx::Gather[axis=0](%2739, %2740), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2742 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2738), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2743 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2744 : Long(device=cpu) = onnx::Gather[axis=0](%2742, %2743), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2745 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2738), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2746 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2748 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2749 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2745, %2747, %2748, %2746), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2750 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2751 : Long(device=cpu) = onnx::Squeeze(%2749, %2750), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2752 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2753 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2752)\n",
      "      %2754 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2755 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2751, %2754)\n",
      "      %2756 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2753, %2755)\n",
      "      %2757 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2738, %2756), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2758 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2757, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2759 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2760 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2741, %2759)\n",
      "      %2761 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2762 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2744, %2761)\n",
      "      %2763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2764 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2763)\n",
      "      %2765 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2760, %2762, %2764)\n",
      "      %2766 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2758, %2765), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2767 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2768 : Float(*, *, *, device=cpu), %2769 : Float(*, *, *, device=cpu), %2770 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2766, %2767), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2771 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2768), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2772 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2773 : Long(device=cpu) = onnx::Gather[axis=0](%2771, %2772), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2774 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2768), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2775 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2776 : Long(device=cpu) = onnx::Gather[axis=0](%2774, %2775), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2777 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2778 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2773, %2777)\n",
      "      %2779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2780 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2776, %2779)\n",
      "      %2781 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2782 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2781)\n",
      "      %2783 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2784 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2783)\n",
      "      %2785 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2778, %2780, %2782, %2784)\n",
      "      %2786 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2768, %2785), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2787 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2786), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2788 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2789 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2790 : Long(device=cpu) = onnx::Gather[axis=0](%2788, %2789), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2791 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2792 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2793 : Long(device=cpu) = onnx::Gather[axis=0](%2791, %2792), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2794 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2795 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2790, %2794)\n",
      "      %2796 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2797 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2793, %2796)\n",
      "      %2798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2799 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2798)\n",
      "      %2800 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2801 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2800)\n",
      "      %2802 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2795, %2797, %2799, %2801)\n",
      "      %2803 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2769, %2802), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2804 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2803), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2805 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2770), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2806 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2807 : Long(device=cpu) = onnx::Gather[axis=0](%2805, %2806), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2808 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2770), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2809 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2810 : Long(device=cpu) = onnx::Gather[axis=0](%2808, %2809), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2812 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2807, %2811)\n",
      "      %2813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2814 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2810, %2813)\n",
      "      %2815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2816 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2815)\n",
      "      %2817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2818 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %2817)\n",
      "      %2819 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2812, %2814, %2816, %2818)\n",
      "      %2820 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2770, %2819), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2821 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2820), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2822 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2803), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2823 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2787, %2822), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2824 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2825 : Float(*, *, *, *, device=cpu) = onnx::Div(%2823, %2824)\n",
      "      %2826 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2787), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2827 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2829 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2830 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2826, %2828, %2829, %2827), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2831 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2832 : Long(device=cpu) = onnx::Squeeze(%2830, %2831), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2833 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2804), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2835 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2837 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2833, %2835, %2836, %2834), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2839 : Long(device=cpu) = onnx::Squeeze(%2837, %2838), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2840 : Long(device=cpu) = onnx::Sub(%2839, %2832), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2841 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2842 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2840, %2841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2843 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2844 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2839, %2843), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2846 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %2845), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2847 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2848 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.9.attn.bias, %2842, %2844, %2846, %2847), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2850 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %2849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2852 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2839, %2851), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2854 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2853), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2856 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2848, %2850, %2852, %2854, %2855), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2857 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2856), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2858 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.9.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2859 : Float(*, *, *, *, device=cpu) = onnx::Where(%2857, %2825, %2858), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2860 : Float(*, *, *, *, device=cpu) = onnx::Add(%2859, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2861 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2860), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2862 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2861, %2821), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2863 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2862), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2864 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2863), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2865 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2866 : Long(device=cpu) = onnx::Gather[axis=0](%2864, %2865), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2867 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2863), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2868 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2869 : Long(device=cpu) = onnx::Gather[axis=0](%2867, %2868), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2870 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2871 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2866, %2870)\n",
      "      %2872 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2873 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2869, %2872)\n",
      "      %2874 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2875 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2874)\n",
      "      %2876 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2871, %2873, %2875)\n",
      "      %2877 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2863, %2876), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2878 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2879 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2880 : Long(device=cpu) = onnx::Gather[axis=0](%2878, %2879), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2881 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2882 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2883 : Long(device=cpu) = onnx::Gather[axis=0](%2881, %2882), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2884 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2886 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2887 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2888 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2884, %2886, %2887, %2885), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2890 : Long(device=cpu) = onnx::Squeeze(%2888, %2889), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2892 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2891)\n",
      "      %2893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2894 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2890, %2893)\n",
      "      %2895 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2892, %2894)\n",
      "      %2896 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2877, %2895), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2897 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2896, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2899 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2880, %2898)\n",
      "      %2900 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2901 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2883, %2900)\n",
      "      %2902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2903 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2902)\n",
      "      %2904 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2899, %2901, %2903)\n",
      "      %2905 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2897, %2904), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2906 : Float(*, *, *, device=cpu) = onnx::Add(%2905, %2727), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2907 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2906), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2908 : Float(*, *, *, device=cpu) = onnx::Sub(%2906, %2907), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2909 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2910 : Float(*, *, *, device=cpu) = onnx::Pow(%2908, %2909), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2911 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2910), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2912 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2913 : Float(*, *, device=cpu) = onnx::Add(%2911, %2912), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2914 : Float(*, *, device=cpu) = onnx::Sqrt(%2913), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2915 : Float(*, *, *, device=cpu) = onnx::Div(%2908, %2914), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2916 : Float(*, *, *, device=cpu) = onnx::Mul(%2915, %decoder_no_past.decoder.transformer.h.9.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2917 : Float(*, *, *, device=cpu) = onnx::Add(%2916, %decoder_no_past.decoder.transformer.h.9.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2918 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2919 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2920 : Long(device=cpu) = onnx::Gather[axis=0](%2918, %2919), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2921 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2922 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2923 : Long(device=cpu) = onnx::Gather[axis=0](%2921, %2922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2924 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2925 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2926 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2927 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2928 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2924, %2926, %2927, %2925), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2930 : Long(device=cpu) = onnx::Squeeze(%2928, %2929), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2932 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2931)\n",
      "      %2933 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2934 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2930, %2933)\n",
      "      %2935 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2932, %2934)\n",
      "      %2936 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2917, %2935), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2937 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2936, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2939 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2920, %2938)\n",
      "      %2940 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2941 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2923, %2940)\n",
      "      %2942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2943 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %2942)\n",
      "      %2944 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2939, %2941, %2943)\n",
      "      %2945 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2937, %2944), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2946 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2947 : Float(*, *, *, device=cpu) = onnx::Mul(%2945, %2946)\n",
      "      %2948 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2949 : Float(*, *, *, device=cpu) = onnx::Pow(%2945, %2948), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2950 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2951 : Float(*, *, *, device=cpu) = onnx::Mul(%2949, %2950)\n",
      "      %2952 : Float(*, *, *, device=cpu) = onnx::Add(%2945, %2951), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2953 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2954 : Float(*, *, *, device=cpu) = onnx::Mul(%2952, %2953)\n",
      "      %2955 : Float(*, *, *, device=cpu) = onnx::Tanh(%2954), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2956 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2957 : Float(*, *, *, device=cpu) = onnx::Add(%2955, %2956)\n",
      "      %2958 : Float(*, *, *, device=cpu) = onnx::Mul(%2947, %2957), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2959 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2960 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2961 : Long(device=cpu) = onnx::Gather[axis=0](%2959, %2960), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2962 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2963 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2964 : Long(device=cpu) = onnx::Gather[axis=0](%2962, %2963), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2965 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2966 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2968 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2969 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2965, %2967, %2968, %2966), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2970 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2971 : Long(device=cpu) = onnx::Squeeze(%2969, %2970), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2973 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %2972)\n",
      "      %2974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2975 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2971, %2974)\n",
      "      %2976 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2973, %2975)\n",
      "      %2977 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2958, %2976), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2978 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2977, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2979 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2980 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2961, %2979)\n",
      "      %2981 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2982 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2964, %2981)\n",
      "      %2983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2984 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2983)\n",
      "      %2985 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2980, %2982, %2984)\n",
      "      %2986 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2978, %2985), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2987 : Float(*, *, *, device=cpu) = onnx::Add(%2906, %2986), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2988 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2987), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2989 : Float(*, *, *, device=cpu) = onnx::Sub(%2987, %2988), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2990 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2991 : Float(*, *, *, device=cpu) = onnx::Pow(%2989, %2990), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2992 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2991), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2993 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2994 : Float(*, *, device=cpu) = onnx::Add(%2992, %2993), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2995 : Float(*, *, device=cpu) = onnx::Sqrt(%2994), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2996 : Float(*, *, *, device=cpu) = onnx::Div(%2989, %2995), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2997 : Float(*, *, *, device=cpu) = onnx::Mul(%2996, %decoder_no_past.decoder.transformer.h.10.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2998 : Float(*, *, *, device=cpu) = onnx::Add(%2997, %decoder_no_past.decoder.transformer.h.10.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2999 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2998), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3000 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3001 : Long(device=cpu) = onnx::Gather[axis=0](%2999, %3000), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3002 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2998), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3003 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3004 : Long(device=cpu) = onnx::Gather[axis=0](%3002, %3003), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3005 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2998), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3006 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3007 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3008 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3009 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3005, %3007, %3008, %3006), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3010 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3011 : Long(device=cpu) = onnx::Squeeze(%3009, %3010), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3012 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3013 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3012)\n",
      "      %3014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3015 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3011, %3014)\n",
      "      %3016 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3013, %3015)\n",
      "      %3017 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2998, %3016), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3018 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3017, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3020 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3001, %3019)\n",
      "      %3021 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3022 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3004, %3021)\n",
      "      %3023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3024 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3023)\n",
      "      %3025 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3020, %3022, %3024)\n",
      "      %3026 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3018, %3025), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3027 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3028 : Float(*, *, *, device=cpu), %3029 : Float(*, *, *, device=cpu), %3030 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%3026, %3027), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %3031 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3028), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3032 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3033 : Long(device=cpu) = onnx::Gather[axis=0](%3031, %3032), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3034 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3028), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3035 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3036 : Long(device=cpu) = onnx::Gather[axis=0](%3034, %3035), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3037 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3038 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3033, %3037)\n",
      "      %3039 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3040 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3036, %3039)\n",
      "      %3041 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3042 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3041)\n",
      "      %3043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3044 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3043)\n",
      "      %3045 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3038, %3040, %3042, %3044)\n",
      "      %3046 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3028, %3045), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3047 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3046), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3048 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3049 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3050 : Long(device=cpu) = onnx::Gather[axis=0](%3048, %3049), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3051 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3052 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3053 : Long(device=cpu) = onnx::Gather[axis=0](%3051, %3052), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3054 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3055 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3050, %3054)\n",
      "      %3056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3057 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3053, %3056)\n",
      "      %3058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3059 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3058)\n",
      "      %3060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3061 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3060)\n",
      "      %3062 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3055, %3057, %3059, %3061)\n",
      "      %3063 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3029, %3062), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3064 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3063), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3065 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3030), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3066 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3067 : Long(device=cpu) = onnx::Gather[axis=0](%3065, %3066), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3068 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3030), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3069 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3070 : Long(device=cpu) = onnx::Gather[axis=0](%3068, %3069), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3072 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3067, %3071)\n",
      "      %3073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3074 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3070, %3073)\n",
      "      %3075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3076 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3075)\n",
      "      %3077 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3078 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3077)\n",
      "      %3079 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3072, %3074, %3076, %3078)\n",
      "      %3080 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3030, %3079), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3081 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3080), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3082 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%3063), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3083 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3047, %3082), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3084 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %3085 : Float(*, *, *, *, device=cpu) = onnx::Div(%3083, %3084)\n",
      "      %3086 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3047), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3087 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3088 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3089 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3090 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3086, %3088, %3089, %3087), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3091 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3092 : Long(device=cpu) = onnx::Squeeze(%3090, %3091), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3093 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3064), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3094 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3096 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3097 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3093, %3095, %3096, %3094), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3098 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3099 : Long(device=cpu) = onnx::Squeeze(%3097, %3098), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3100 : Long(device=cpu) = onnx::Sub(%3099, %3092), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3101 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3102 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3100, %3101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3103 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3104 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3099, %3103), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3106 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %3105), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3108 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.10.attn.bias, %3102, %3104, %3106, %3107), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3110 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %3109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3112 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3099, %3111), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3114 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3113), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3115 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3116 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%3108, %3110, %3112, %3114, %3115), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3117 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%3116), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3118 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.10.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3119 : Float(*, *, *, *, device=cpu) = onnx::Where(%3117, %3085, %3118), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3120 : Float(*, *, *, *, device=cpu) = onnx::Add(%3119, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %3121 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%3120), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3122 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3121, %3081), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %3123 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3122), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %3124 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3123), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3125 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3126 : Long(device=cpu) = onnx::Gather[axis=0](%3124, %3125), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3127 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3123), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3128 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3129 : Long(device=cpu) = onnx::Gather[axis=0](%3127, %3128), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3130 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3131 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3126, %3130)\n",
      "      %3132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3133 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3129, %3132)\n",
      "      %3134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3135 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3134)\n",
      "      %3136 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3131, %3133, %3135)\n",
      "      %3137 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3123, %3136), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %3138 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3139 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3140 : Long(device=cpu) = onnx::Gather[axis=0](%3138, %3139), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3141 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3142 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3143 : Long(device=cpu) = onnx::Gather[axis=0](%3141, %3142), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3144 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3145 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3146 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3148 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3144, %3146, %3147, %3145), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3149 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3150 : Long(device=cpu) = onnx::Squeeze(%3148, %3149), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3152 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3151)\n",
      "      %3153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3154 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3150, %3153)\n",
      "      %3155 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3152, %3154)\n",
      "      %3156 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3137, %3155), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3157 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3156, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3158 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3159 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3140, %3158)\n",
      "      %3160 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3161 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3143, %3160)\n",
      "      %3162 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3163 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3162)\n",
      "      %3164 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3159, %3161, %3163)\n",
      "      %3165 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3157, %3164), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3166 : Float(*, *, *, device=cpu) = onnx::Add(%3165, %2987), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %3167 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3166), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3168 : Float(*, *, *, device=cpu) = onnx::Sub(%3166, %3167), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3169 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3170 : Float(*, *, *, device=cpu) = onnx::Pow(%3168, %3169), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3171 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3170), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3172 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3173 : Float(*, *, device=cpu) = onnx::Add(%3171, %3172), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3174 : Float(*, *, device=cpu) = onnx::Sqrt(%3173), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3175 : Float(*, *, *, device=cpu) = onnx::Div(%3168, %3174), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3176 : Float(*, *, *, device=cpu) = onnx::Mul(%3175, %decoder_no_past.decoder.transformer.h.10.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3177 : Float(*, *, *, device=cpu) = onnx::Add(%3176, %decoder_no_past.decoder.transformer.h.10.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3178 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3179 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3180 : Long(device=cpu) = onnx::Gather[axis=0](%3178, %3179), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3181 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3182 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3183 : Long(device=cpu) = onnx::Gather[axis=0](%3181, %3182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3184 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3186 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3187 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3188 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3184, %3186, %3187, %3185), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3190 : Long(device=cpu) = onnx::Squeeze(%3188, %3189), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3192 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3191)\n",
      "      %3193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3194 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3190, %3193)\n",
      "      %3195 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3192, %3194)\n",
      "      %3196 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3177, %3195), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3197 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3196, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3198 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3199 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3180, %3198)\n",
      "      %3200 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3201 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3183, %3200)\n",
      "      %3202 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3203 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %3202)\n",
      "      %3204 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3199, %3201, %3203)\n",
      "      %3205 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3197, %3204), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3206 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %3207 : Float(*, *, *, device=cpu) = onnx::Mul(%3205, %3206)\n",
      "      %3208 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %3209 : Float(*, *, *, device=cpu) = onnx::Pow(%3205, %3208), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3210 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %3211 : Float(*, *, *, device=cpu) = onnx::Mul(%3209, %3210)\n",
      "      %3212 : Float(*, *, *, device=cpu) = onnx::Add(%3205, %3211), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3213 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %3214 : Float(*, *, *, device=cpu) = onnx::Mul(%3212, %3213)\n",
      "      %3215 : Float(*, *, *, device=cpu) = onnx::Tanh(%3214), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3216 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3217 : Float(*, *, *, device=cpu) = onnx::Add(%3215, %3216)\n",
      "      %3218 : Float(*, *, *, device=cpu) = onnx::Mul(%3207, %3217), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3219 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3220 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3221 : Long(device=cpu) = onnx::Gather[axis=0](%3219, %3220), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3222 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3223 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3224 : Long(device=cpu) = onnx::Gather[axis=0](%3222, %3223), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3225 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3227 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3229 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3225, %3227, %3228, %3226), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3231 : Long(device=cpu) = onnx::Squeeze(%3229, %3230), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3233 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3232)\n",
      "      %3234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3235 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3231, %3234)\n",
      "      %3236 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3233, %3235)\n",
      "      %3237 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3218, %3236), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3238 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3237, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3240 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3221, %3239)\n",
      "      %3241 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3242 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3224, %3241)\n",
      "      %3243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3244 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3243)\n",
      "      %3245 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3240, %3242, %3244)\n",
      "      %3246 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3238, %3245), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3247 : Float(*, *, *, device=cpu) = onnx::Add(%3166, %3246), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %3248 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3247), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3249 : Float(*, *, *, device=cpu) = onnx::Sub(%3247, %3248), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3250 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3251 : Float(*, *, *, device=cpu) = onnx::Pow(%3249, %3250), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3252 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3251), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3253 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3254 : Float(*, *, device=cpu) = onnx::Add(%3252, %3253), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3255 : Float(*, *, device=cpu) = onnx::Sqrt(%3254), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3256 : Float(*, *, *, device=cpu) = onnx::Div(%3249, %3255), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3257 : Float(*, *, *, device=cpu) = onnx::Mul(%3256, %decoder_no_past.decoder.transformer.h.11.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3258 : Float(*, *, *, device=cpu) = onnx::Add(%3257, %decoder_no_past.decoder.transformer.h.11.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3259 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3258), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3260 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3261 : Long(device=cpu) = onnx::Gather[axis=0](%3259, %3260), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3262 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3258), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3263 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3264 : Long(device=cpu) = onnx::Gather[axis=0](%3262, %3263), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3265 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3258), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3266 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3268 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3269 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3265, %3267, %3268, %3266), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3270 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3271 : Long(device=cpu) = onnx::Squeeze(%3269, %3270), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3272 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3273 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3272)\n",
      "      %3274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3275 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3271, %3274)\n",
      "      %3276 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3273, %3275)\n",
      "      %3277 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3258, %3276), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3278 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3277, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3279 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3280 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3261, %3279)\n",
      "      %3281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3282 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3264, %3281)\n",
      "      %3283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3284 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3283)\n",
      "      %3285 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3280, %3282, %3284)\n",
      "      %3286 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3278, %3285), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3287 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3288 : Float(*, *, *, device=cpu), %3289 : Float(*, *, *, device=cpu), %3290 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%3286, %3287), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %3291 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3288), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3292 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3293 : Long(device=cpu) = onnx::Gather[axis=0](%3291, %3292), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3294 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3288), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3295 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3296 : Long(device=cpu) = onnx::Gather[axis=0](%3294, %3295), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3298 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3293, %3297)\n",
      "      %3299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3300 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3296, %3299)\n",
      "      %3301 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3302 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3301)\n",
      "      %3303 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3304 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3303)\n",
      "      %3305 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3298, %3300, %3302, %3304)\n",
      "      %3306 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3288, %3305), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3307 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3306), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3308 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3309 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3310 : Long(device=cpu) = onnx::Gather[axis=0](%3308, %3309), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3311 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3312 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3313 : Long(device=cpu) = onnx::Gather[axis=0](%3311, %3312), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3314 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3315 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3310, %3314)\n",
      "      %3316 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3317 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3313, %3316)\n",
      "      %3318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3319 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3318)\n",
      "      %3320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3321 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3320)\n",
      "      %3322 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3315, %3317, %3319, %3321)\n",
      "      %3323 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3289, %3322), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3324 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3323), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3325 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3290), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3326 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3327 : Long(device=cpu) = onnx::Gather[axis=0](%3325, %3326), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3328 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3290), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3329 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3330 : Long(device=cpu) = onnx::Gather[axis=0](%3328, %3329), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3332 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3327, %3331)\n",
      "      %3333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3334 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3330, %3333)\n",
      "      %3335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3336 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3335)\n",
      "      %3337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%178, %3337)\n",
      "      %3339 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3332, %3334, %3336, %3338)\n",
      "      %3340 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3290, %3339), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3341 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3340), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3342 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%3323), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3343 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3307, %3342), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3344 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %3345 : Float(*, *, *, *, device=cpu) = onnx::Div(%3343, %3344)\n",
      "      %3346 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3307), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3349 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3350 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3346, %3348, %3349, %3347), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3351 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3352 : Long(device=cpu) = onnx::Squeeze(%3350, %3351), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3353 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3324), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3355 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3356 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3357 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3353, %3355, %3356, %3354), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3359 : Long(device=cpu) = onnx::Squeeze(%3357, %3358), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3360 : Long(device=cpu) = onnx::Sub(%3359, %3352), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3361 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3362 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3360, %3361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3363 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3364 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3359, %3363), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3366 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%188, %3365), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3368 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.11.attn.bias, %3362, %3364, %3366, %3367), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3370 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %3369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3372 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3359, %3371), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3374 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3373), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3376 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%3368, %3370, %3372, %3374, %3375), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3377 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%3376), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3378 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.11.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3379 : Float(*, *, *, *, device=cpu) = onnx::Where(%3377, %3345, %3378), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3380 : Float(*, *, *, *, device=cpu) = onnx::Add(%3379, %377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %3381 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%3380), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3382 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3381, %3341), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %3383 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3382), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %3384 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3383), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3385 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3386 : Long(device=cpu) = onnx::Gather[axis=0](%3384, %3385), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3387 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3383), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3388 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3389 : Long(device=cpu) = onnx::Gather[axis=0](%3387, %3388), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3390 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3391 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3386, %3390)\n",
      "      %3392 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3393 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3389, %3392)\n",
      "      %3394 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3395 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3394)\n",
      "      %3396 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3391, %3393, %3395)\n",
      "      %3397 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3383, %3396), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %3398 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3399 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3400 : Long(device=cpu) = onnx::Gather[axis=0](%3398, %3399), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3401 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3402 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3403 : Long(device=cpu) = onnx::Gather[axis=0](%3401, %3402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3404 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3405 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3406 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3407 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3408 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3404, %3406, %3407, %3405), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3410 : Long(device=cpu) = onnx::Squeeze(%3408, %3409), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3412 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3411)\n",
      "      %3413 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3414 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3410, %3413)\n",
      "      %3415 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3412, %3414)\n",
      "      %3416 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3397, %3415), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3417 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3416, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3418 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3419 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3400, %3418)\n",
      "      %3420 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3421 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3403, %3420)\n",
      "      %3422 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3423 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3422)\n",
      "      %3424 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3419, %3421, %3423)\n",
      "      %3425 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3417, %3424), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3426 : Float(*, *, *, device=cpu) = onnx::Add(%3425, %3247), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %3427 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3426), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3428 : Float(*, *, *, device=cpu) = onnx::Sub(%3426, %3427), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3429 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3430 : Float(*, *, *, device=cpu) = onnx::Pow(%3428, %3429), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3431 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3432 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3433 : Float(*, *, device=cpu) = onnx::Add(%3431, %3432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3434 : Float(*, *, device=cpu) = onnx::Sqrt(%3433), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3435 : Float(*, *, *, device=cpu) = onnx::Div(%3428, %3434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3436 : Float(*, *, *, device=cpu) = onnx::Mul(%3435, %decoder_no_past.decoder.transformer.h.11.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3437 : Float(*, *, *, device=cpu) = onnx::Add(%3436, %decoder_no_past.decoder.transformer.h.11.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3438 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3439 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3440 : Long(device=cpu) = onnx::Gather[axis=0](%3438, %3439), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3441 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3442 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3443 : Long(device=cpu) = onnx::Gather[axis=0](%3441, %3442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3444 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3445 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3446 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3448 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3444, %3446, %3447, %3445), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3449 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3450 : Long(device=cpu) = onnx::Squeeze(%3448, %3449), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3452 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3451)\n",
      "      %3453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3454 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3450, %3453)\n",
      "      %3455 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3452, %3454)\n",
      "      %3456 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3437, %3455), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3457 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3456, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3440, %3458)\n",
      "      %3460 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3461 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3443, %3460)\n",
      "      %3462 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3463 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%177, %3462)\n",
      "      %3464 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3459, %3461, %3463)\n",
      "      %3465 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3457, %3464), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3466 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %3467 : Float(*, *, *, device=cpu) = onnx::Mul(%3465, %3466)\n",
      "      %3468 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %3469 : Float(*, *, *, device=cpu) = onnx::Pow(%3465, %3468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3470 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %3471 : Float(*, *, *, device=cpu) = onnx::Mul(%3469, %3470)\n",
      "      %3472 : Float(*, *, *, device=cpu) = onnx::Add(%3465, %3471), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3473 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %3474 : Float(*, *, *, device=cpu) = onnx::Mul(%3472, %3473)\n",
      "      %3475 : Float(*, *, *, device=cpu) = onnx::Tanh(%3474), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3476 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3477 : Float(*, *, *, device=cpu) = onnx::Add(%3475, %3476)\n",
      "      %3478 : Float(*, *, *, device=cpu) = onnx::Mul(%3467, %3477), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3479 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3480 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3481 : Long(device=cpu) = onnx::Gather[axis=0](%3479, %3480), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3482 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3483 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3484 : Long(device=cpu) = onnx::Gather[axis=0](%3482, %3483), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3485 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3486 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3488 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3489 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3485, %3487, %3488, %3486), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3491 : Long(device=cpu) = onnx::Squeeze(%3489, %3490), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3493 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %3492)\n",
      "      %3494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3495 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3491, %3494)\n",
      "      %3496 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3493, %3495)\n",
      "      %3497 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3478, %3496), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3498 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3497, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3500 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3481, %3499)\n",
      "      %3501 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3502 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3484, %3501)\n",
      "      %3503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3504 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3503)\n",
      "      %3505 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3500, %3502, %3504)\n",
      "      %3506 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3498, %3505), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3507 : Float(*, *, *, device=cpu) = onnx::Add(%3426, %3506), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %3508 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3509 : Float(*, *, *, device=cpu) = onnx::Sub(%3507, %3508), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3510 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3511 : Float(*, *, *, device=cpu) = onnx::Pow(%3509, %3510), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3512 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3511), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3513 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3514 : Float(*, *, device=cpu) = onnx::Add(%3512, %3513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3515 : Float(*, *, device=cpu) = onnx::Sqrt(%3514), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3516 : Float(*, *, *, device=cpu) = onnx::Div(%3509, %3515), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3517 : Float(*, *, *, device=cpu) = onnx::Mul(%3516, %decoder_no_past.decoder.transformer.ln_f.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3518 : Float(*, *, *, device=cpu) = onnx::Add(%3517, %decoder_no_past.decoder.transformer.ln_f.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3519 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3520 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%336, %3519)\n",
      "      %3521 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3522 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%339, %3521)\n",
      "      %3523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3524 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%387, %3523)\n",
      "      %3525 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3520, %3522, %3524)\n",
      "      %3526 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3518, %3525), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:826:0\n",
      "      %3527 : Float(*, *, *, device=cpu) = onnx::MatMul(%3526, %4854) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:595:36\n",
      "      %3528 : Float(*, *, device=cpu) = onnx::Gather[axis=1](%3527, %184) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:595:36\n",
      "      %3529 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3530 : Long(device=cpu) = onnx::Sub(%max_length, %3529) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:24\n",
      "      %3531 : Bool(device=cpu) = onnx::Equal(%cur_len.13, %3530) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:13\n",
      "      %3532 : Bool(device=cpu) = onnx::Cast[to=9](%3531)\n",
      "      %3533 : Float(*, *, device=cpu) = onnx::If(%3532) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:13\n",
      "        block0():\n",
      "          %3534 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3528)\n",
      "          %3535 : Bool(*, *, device=cpu) = onnx::ConstantOfShape[value={1}](%3534) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3536 : Bool(*, device=cpu) = onnx::Gather[axis=1](%3535, %188) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3537 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3538 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3536)\n",
      "          %3539 : BoolTensor(device=cpu) = onnx::Expand(%3537, %3538) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3540 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3535)\n",
      "          %3541 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3542 : Long(device=cpu) = onnx::Gather[axis=0](%3540, %3541)\n",
      "          %3543 : Long(device=cpu) = onnx::Cast[to=7](%3542)\n",
      "          %3544 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3545 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "          %3546 : Long(*, device=cpu) = onnx::Range(%3544, %3543, %3545)\n",
      "          %3547 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3548 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %3549 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3546, %3548)\n",
      "          %3550 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3551 : Long(*, 1, device=cpu) = onnx::Add(%3549, %3550)\n",
      "          %3552 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3551)\n",
      "          %3553 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3552)\n",
      "          %3554 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3553)\n",
      "          %3555 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3556 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3554, %3555)\n",
      "          %3557 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3552, %3556)\n",
      "          %3558 : Long(2, strides=[1], device=cpu) = onnx::Where(%3557, %3554, %3552)\n",
      "          %3559 : LongTensor(device=cpu) = onnx::Expand(%3549, %3558)\n",
      "          %3560 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3561 : LongTensor(device=cpu) = onnx::Unsqueeze(%3559, %3560)\n",
      "          %3562 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3552)\n",
      "          %3563 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3562)\n",
      "          %3564 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3565 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3563, %3564)\n",
      "          %3566 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3552, %3565)\n",
      "          %3567 : Long(2, strides=[1], device=cpu) = onnx::Where(%3566, %3563, %3552)\n",
      "          %3568 : LongTensor(device=cpu) = onnx::Expand(%3547, %3567)\n",
      "          %3569 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3570 : LongTensor(device=cpu) = onnx::Unsqueeze(%3568, %3569)\n",
      "          %3571 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3561, %3570)\n",
      "          %3572 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3535)\n",
      "          %3573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %3576 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3572, %3574, %3575, %3573)\n",
      "          %3577 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3552, %3576)\n",
      "          %3578 : Bool(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3539, %3577)\n",
      "          %3579 : Bool(*, *, device=cpu) = onnx::ScatterND(%3535, %3571, %3578) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3580 : Bool(*, *, device=cpu) = onnx::Cast[to=9](%3579)\n",
      "          %3581 : Float(device=cpu) = onnx::Constant[value={-inf}]()\n",
      "          %3582 : Float(*, *, device=cpu) = onnx::Where(%3580, %3581, %3528) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:562:15\n",
      "          -> (%3582)\n",
      "        block1():\n",
      "          %3583 : Float(*, *, device=cpu) = onnx::Identity(%3528)\n",
      "          -> (%3583)\n",
      "      %3584 : Float(*, *, device=cpu) = onnx::LogSoftmax[axis=-1](%3533) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "      %3585 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25) # <string>:7:9\n",
      "      %3586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3588 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3589 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3585, %3587, %3588, %3586)\n",
      "      %3590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3591 : Long(device=cpu) = onnx::Squeeze(%3589, %3590) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:100:18\n",
      "      %3592 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3593 : Bool(device=cpu) = onnx::Less(%3591, %3592) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:101:11\n",
      "      %3594 : Bool(device=cpu) = onnx::Cast[to=9](%3593)\n",
      "      %3595 : Float(*, *, device=cpu) = onnx::If(%3594) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:101:8\n",
      "        block0():\n",
      "          %3596 : Float(*, device=cpu) = onnx::Gather[axis=1](%3584, %188) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          %3597 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}]()\n",
      "          %3598 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3596)\n",
      "          %3599 : FloatTensor(device=cpu) = onnx::Expand(%3597, %3598) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          %3600 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3584)\n",
      "          %3601 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3602 : Long(device=cpu) = onnx::Gather[axis=0](%3600, %3601)\n",
      "          %3603 : Long(device=cpu) = onnx::Cast[to=7](%3602)\n",
      "          %3604 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3605 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "          %3606 : Long(*, device=cpu) = onnx::Range(%3604, %3603, %3605)\n",
      "          %3607 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3608 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %3609 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3606, %3608)\n",
      "          %3610 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3611 : Long(*, 1, device=cpu) = onnx::Add(%3609, %3610)\n",
      "          %3612 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3611)\n",
      "          %3613 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3612)\n",
      "          %3614 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3613)\n",
      "          %3615 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3616 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3614, %3615)\n",
      "          %3617 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3612, %3616)\n",
      "          %3618 : Long(2, strides=[1], device=cpu) = onnx::Where(%3617, %3614, %3612)\n",
      "          %3619 : LongTensor(device=cpu) = onnx::Expand(%3609, %3618)\n",
      "          %3620 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3621 : LongTensor(device=cpu) = onnx::Unsqueeze(%3619, %3620)\n",
      "          %3622 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3612)\n",
      "          %3623 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3622)\n",
      "          %3624 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3625 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3623, %3624)\n",
      "          %3626 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3612, %3625)\n",
      "          %3627 : Long(2, strides=[1], device=cpu) = onnx::Where(%3626, %3623, %3612)\n",
      "          %3628 : LongTensor(device=cpu) = onnx::Expand(%3607, %3627)\n",
      "          %3629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3630 : LongTensor(device=cpu) = onnx::Unsqueeze(%3628, %3629)\n",
      "          %3631 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3621, %3630)\n",
      "          %3632 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3584)\n",
      "          %3633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3634 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %3636 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3632, %3634, %3635, %3633)\n",
      "          %3637 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3612, %3636)\n",
      "          %3638 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3599, %3637)\n",
      "          %3639 : Float(*, *, device=cpu) = onnx::ScatterND(%3584, %3631, %3638) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          -> (%3639)\n",
      "        block1():\n",
      "          %3640 : Float(*, *, device=cpu) = onnx::Identity(%3584)\n",
      "          -> (%3640)\n",
      "      %3641 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3642 : Float(*, *, device=cpu) = onnx::Unsqueeze(%beam_scores.17, %3641) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:606:56\n",
      "      %3643 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3595)\n",
      "      %3644 : FloatTensor(device=cpu) = onnx::Expand(%3642, %3643) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:606:56\n",
      "      %3645 : FloatTensor(device=cpu) = onnx::Add(%3595, %3644) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:606:36\n",
      "      %3646 : int[] = onnx::Shape(%3645) # <string>:7:9\n",
      "      %3647 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3649 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3650 : Tensor(*) = onnx::Slice(%3646, %3648, %3649, %3647)\n",
      "      %3651 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3652 : Long(device=cpu) = onnx::Squeeze(%3650, %3651) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:609:29\n",
      "      %3653 : Long(device=cpu) = onnx::Mul(%num_beams, %3652) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:610:71\n",
      "      %3654 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3655 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%192, %3654)\n",
      "      %3656 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3657 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3653, %3656)\n",
      "      %3658 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3655, %3657)\n",
      "      %3659 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3645, %3658) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:610:36\n",
      "      %3660 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3661 : Long(device=cpu) = onnx::Mul(%num_beams, %3660) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:613:39\n",
      "      %3662 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3663 : Long(1, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%3661, %3662)\n",
      "      %3664 : Float(*, *, device=cpu), %3665 : Long(*, *, device=cpu) = onnx::TopK[axis=1, largest=1, sorted=1](%3659, %3663) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:612:49\n",
      "      %3666 : Long(*, *, device=cpu) = onnx::Div(%3665, %3652)\n",
      "      %3667 : Long(*, *, device=cpu) = onnx::Cast[to=7](%3666)\n",
      "      %3668 : Long(*, *, device=cpu) = onnx::Cast[to=7](%3667) # <string>:3:9\n",
      "      %3669 : Long(*, *, device=cpu) = onnx::Div(%3665, %3652)\n",
      "      %3670 : Long(*, *, device=cpu) = onnx::Mul(%3669, %3652)\n",
      "      %3671 : Long(*, *, device=cpu) = onnx::Sub(%3665, %3670) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:617:30\n",
      "      %3672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3673 : Long(1, strides=[1], device=cpu) = onnx::Shape(%332)\n",
      "      %3674 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%3673, %3672)\n",
      "      %3675 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3676 : Long(device=cpu) = onnx::Squeeze(%3674, %3675) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:402:21\n",
      "      %3677 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3678 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3676, %3677)\n",
      "      %3679 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3680 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %3679)\n",
      "      %3681 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3678, %3680)\n",
      "      %3682 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3681) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:406:27\n",
      "      %3683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3676, %3683)\n",
      "      %3685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3686 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %3685)\n",
      "      %3687 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3684, %3686)\n",
      "      %3688 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3687) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:407:27\n",
      "      %3689 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3690 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3676, %3689)\n",
      "      %3691 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3692 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %3691)\n",
      "      %3693 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3690, %3692)\n",
      "      %3694 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3693) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:408:28\n",
      "      %3695 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3696 : Bool(device=cpu) = onnx::Greater(%3676, %3695)\n",
      "      %3697 : Long(device=cpu), %3698 : Long(device=cpu), %3699 : Long(device=cpu), %3700 : Float(*, *, device=cpu), %3701 : Long(*, *, device=cpu), %3702 : Long(*, *, device=cpu), %3703 : Float(*, device=cpu)[], %3704 : Long(*, device=cpu)[], %3705 : Float(*, device=cpu), %3706 : Long(*, device=cpu), %3707 : Bool(*, device=cpu) = onnx::Loop(%182, %3696, %188, %189, %189, %3682, %3688, %3694, %329, %330, %331, %332, %333) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:410:8\n",
      "        block0(%3708 : Long(requires_grad=0, device=cpu), %cond.3 : Bool(device=cpu), %eos_token_id.74 : Long(requires_grad=0, device=cpu), %pad_token_id.34 : Long(requires_grad=0, device=cpu), %3712 : Long(requires_grad=0, device=cpu), %3713 : Float(*, *, device=cpu), %3714 : Long(*, *, device=cpu), %3715 : Long(*, *, device=cpu), %3716 : Float(*, device=cpu)[], %3717 : Long(*, device=cpu)[], %3718 : Float(*, device=cpu), %3719 : Long(*, device=cpu), %3720 : Bool(*, device=cpu)):\n",
      "          %3721 : Bool(device=cpu) = onnx::Gather[axis=0](%3720, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:411:15\n",
      "          %3722 : Bool(device=cpu) = onnx::Cast[to=9](%3721)\n",
      "          %3723 : Long(device=cpu), %3724 : Long(device=cpu), %3725 : Float(*, *, device=cpu), %3726 : Long(*, *, device=cpu), %3727 : Long(*, *, device=cpu), %3728 : Float(*, device=cpu)[], %3729 : Long(*, device=cpu)[], %3730 : Float(*, device=cpu), %3731 : Long(*, device=cpu), %3732 : Bool(*, device=cpu) = onnx::If(%3722) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:411:12\n",
      "            block0():\n",
      "              %3733 : Float(*, device=cpu) = onnx::Gather[axis=0](%3713, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3734 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3735 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3733)\n",
      "              %3736 : FloatTensor(device=cpu) = onnx::Expand(%3734, %3735) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3738 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %3737)\n",
      "              %3739 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3713)\n",
      "              %3740 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3741 : Long(device=cpu) = onnx::Gather[axis=0](%3739, %3740)\n",
      "              %3742 : Long(device=cpu) = onnx::Cast[to=7](%3741)\n",
      "              %3743 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3744 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3745 : Long(*, device=cpu) = onnx::Range(%3743, %3742, %3744)\n",
      "              %3746 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %3747 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3738, %3746)\n",
      "              %3748 : Long(*, *, device=cpu) = onnx::Add(%3747, %3745)\n",
      "              %3749 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3748)\n",
      "              %3750 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3749)\n",
      "              %3751 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3750)\n",
      "              %3752 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3753 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3751, %3752)\n",
      "              %3754 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3749, %3753)\n",
      "              %3755 : Long(2, strides=[1], device=cpu) = onnx::Where(%3754, %3751, %3749)\n",
      "              %3756 : LongTensor(device=cpu) = onnx::Expand(%3747, %3755)\n",
      "              %3757 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3758 : LongTensor(device=cpu) = onnx::Unsqueeze(%3756, %3757)\n",
      "              %3759 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3749)\n",
      "              %3760 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3759)\n",
      "              %3761 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3762 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3760, %3761)\n",
      "              %3763 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3749, %3762)\n",
      "              %3764 : Long(2, strides=[1], device=cpu) = onnx::Where(%3763, %3760, %3749)\n",
      "              %3765 : LongTensor(device=cpu) = onnx::Expand(%3745, %3764)\n",
      "              %3766 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3767 : LongTensor(device=cpu) = onnx::Unsqueeze(%3765, %3766)\n",
      "              %3768 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3758, %3767)\n",
      "              %3769 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3713)\n",
      "              %3770 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3771 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %3772 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %3773 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3769, %3771, %3772, %3770)\n",
      "              %3774 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3749, %3773)\n",
      "              %3775 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3736, %3774)\n",
      "              %3776 : Float(*, *, device=cpu) = onnx::ScatterND(%3713, %3768, %3775) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3777 : Long(*, device=cpu) = onnx::Gather[axis=0](%3714, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %3778 : Long(device=cpu) = onnx::Cast[to=7](%pad_token_id.34)\n",
      "              %3779 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3777)\n",
      "              %3780 : LongTensor(device=cpu) = onnx::Expand(%3778, %3779) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %3781 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3782 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %3781)\n",
      "              %3783 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3714)\n",
      "              %3784 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3785 : Long(device=cpu) = onnx::Gather[axis=0](%3783, %3784)\n",
      "              %3786 : Long(device=cpu) = onnx::Cast[to=7](%3785)\n",
      "              %3787 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3788 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3789 : Long(*, device=cpu) = onnx::Range(%3787, %3786, %3788)\n",
      "              %3790 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %3791 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3782, %3790)\n",
      "              %3792 : Long(*, *, device=cpu) = onnx::Add(%3791, %3789)\n",
      "              %3793 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3792)\n",
      "              %3794 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3793)\n",
      "              %3795 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3794)\n",
      "              %3796 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3797 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3795, %3796)\n",
      "              %3798 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3793, %3797)\n",
      "              %3799 : Long(2, strides=[1], device=cpu) = onnx::Where(%3798, %3795, %3793)\n",
      "              %3800 : LongTensor(device=cpu) = onnx::Expand(%3791, %3799)\n",
      "              %3801 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3802 : LongTensor(device=cpu) = onnx::Unsqueeze(%3800, %3801)\n",
      "              %3803 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3793)\n",
      "              %3804 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3803)\n",
      "              %3805 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3806 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3804, %3805)\n",
      "              %3807 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3793, %3806)\n",
      "              %3808 : Long(2, strides=[1], device=cpu) = onnx::Where(%3807, %3804, %3793)\n",
      "              %3809 : LongTensor(device=cpu) = onnx::Expand(%3789, %3808)\n",
      "              %3810 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3811 : LongTensor(device=cpu) = onnx::Unsqueeze(%3809, %3810)\n",
      "              %3812 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3802, %3811)\n",
      "              %3813 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3714)\n",
      "              %3814 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %3816 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %3817 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3813, %3815, %3816, %3814)\n",
      "              %3818 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3793, %3817)\n",
      "              %3819 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3780, %3818)\n",
      "              %3820 : Long(*, *, device=cpu) = onnx::ScatterND(%3714, %3812, %3819) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %3821 : Long(*, device=cpu) = onnx::Gather[axis=0](%3715, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %3822 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3823 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3821)\n",
      "              %3824 : LongTensor(device=cpu) = onnx::Expand(%3822, %3823) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %3825 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3826 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %3825)\n",
      "              %3827 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3715)\n",
      "              %3828 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3829 : Long(device=cpu) = onnx::Gather[axis=0](%3827, %3828)\n",
      "              %3830 : Long(device=cpu) = onnx::Cast[to=7](%3829)\n",
      "              %3831 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3832 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3833 : Long(*, device=cpu) = onnx::Range(%3831, %3830, %3832)\n",
      "              %3834 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %3835 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3826, %3834)\n",
      "              %3836 : Long(*, *, device=cpu) = onnx::Add(%3835, %3833)\n",
      "              %3837 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3836)\n",
      "              %3838 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3837)\n",
      "              %3839 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3838)\n",
      "              %3840 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3841 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3839, %3840)\n",
      "              %3842 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3837, %3841)\n",
      "              %3843 : Long(2, strides=[1], device=cpu) = onnx::Where(%3842, %3839, %3837)\n",
      "              %3844 : LongTensor(device=cpu) = onnx::Expand(%3835, %3843)\n",
      "              %3845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3846 : LongTensor(device=cpu) = onnx::Unsqueeze(%3844, %3845)\n",
      "              %3847 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3837)\n",
      "              %3848 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3847)\n",
      "              %3849 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3850 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3848, %3849)\n",
      "              %3851 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3837, %3850)\n",
      "              %3852 : Long(2, strides=[1], device=cpu) = onnx::Where(%3851, %3848, %3837)\n",
      "              %3853 : LongTensor(device=cpu) = onnx::Expand(%3833, %3852)\n",
      "              %3854 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3855 : LongTensor(device=cpu) = onnx::Unsqueeze(%3853, %3854)\n",
      "              %3856 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3846, %3855)\n",
      "              %3857 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3715)\n",
      "              %3858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %3860 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %3861 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3857, %3859, %3860, %3858)\n",
      "              %3862 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3837, %3861)\n",
      "              %3863 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3824, %3862)\n",
      "              %3864 : Long(*, *, device=cpu) = onnx::ScatterND(%3715, %3856, %3863) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %eos_token_id.71 : Long(device=cpu) = onnx::Identity(%eos_token_id.74)\n",
      "              %pad_token_id.31 : Long(device=cpu) = onnx::Identity(%pad_token_id.34)\n",
      "              %3867 : FloatTensor(device=cpu)[] = onnx::Identity(%3716)\n",
      "              %3868 : LongTensor(device=cpu)[] = onnx::Identity(%3717)\n",
      "              %3869 : Float(*, device=cpu) = onnx::Identity(%3718)\n",
      "              %3870 : Long(*, device=cpu) = onnx::Identity(%3719)\n",
      "              %3871 : Bool(*, device=cpu) = onnx::Identity(%3720)\n",
      "              -> (%eos_token_id.71, %pad_token_id.31, %3776, %3820, %3864, %3867, %3868, %3869, %3870, %3871)\n",
      "            block1():\n",
      "              %3872 : Long(*, device=cpu) = onnx::Gather[axis=0](%3671, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:20\n",
      "              %3873 : Float(*, device=cpu) = onnx::Gather[axis=0](%3664, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:44\n",
      "              %3874 : Long(*, device=cpu) = onnx::Gather[axis=0](%3668, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:68\n",
      "              %3875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3876 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3872)\n",
      "              %3877 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%3876, %3875)\n",
      "              %3878 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3879 : Long(device=cpu) = onnx::Squeeze(%3877, %3878) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %3880 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3881 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3873)\n",
      "              %3882 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%3881, %3880)\n",
      "              %3883 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3884 : Long(device=cpu) = onnx::Squeeze(%3882, %3883) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %3885 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3886 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3874)\n",
      "              %3887 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%3886, %3885)\n",
      "              %3888 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3889 : Long(device=cpu) = onnx::Squeeze(%3887, %3888) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %3890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3891 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %3890)\n",
      "              %3892 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3893 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3879, %3892)\n",
      "              %3894 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3895 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3884, %3894)\n",
      "              %3896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3897 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3889, %3896)\n",
      "              %3898 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3891, %3893, %3895, %3897)\n",
      "              %3899 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %3900 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3901 : Bool(device=cpu) = onnx::Greater(%3899, %3900)\n",
      "              %3902 : Long(device=cpu), %3903 : Long(device=cpu), %3904 : Long(device=cpu), %3905 : Float(*, device=cpu)[], %3906 : Long(*, device=cpu)[], %3907 : Float(*, device=cpu), %3908 : Long(*, device=cpu), %3909 : Float(*, *, device=cpu), %3910 : Long(*, *, device=cpu), %3911 : Long(*, *, device=cpu) = onnx::Loop(%182, %3901, %189, %eos_token_id.74, %189, %3716, %3717, %3718, %3719, %3713, %3714, %3715) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                block0(%3912 : Long(requires_grad=0, device=cpu), %cond.1 : Bool(device=cpu), %beam_idx.36 : Long(requires_grad=0, device=cpu), %eos_token_id.72 : Long(requires_grad=0, device=cpu), %3916 : Long(requires_grad=0, device=cpu), %3917 : Float(*, device=cpu)[], %3918 : Long(*, device=cpu)[], %3919 : Float(*, device=cpu), %3920 : Long(*, device=cpu), %3921 : Float(*, *, device=cpu), %3922 : Long(*, *, device=cpu), %3923 : Long(*, *, device=cpu)):\n",
      "                  %3924 : Long(device=cpu) = onnx::Gather[axis=0](%3872, %3916) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                  %3925 : Float(device=cpu) = onnx::Gather[axis=0](%3873, %3916) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:438:24\n",
      "                  %3926 : Long(device=cpu) = onnx::Gather[axis=0](%3874, %3916) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                  %3927 : Long(device=cpu) = onnx::Mul(%3712, %196) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:429:33\n",
      "                  %3928 : Long(device=cpu) = onnx::Add(%3926, %3927) # <string>:5:9\n",
      "                  %3929 : Bool(device=cpu) = onnx::Equal(%3924, %eos_token_id.72) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:431:20\n",
      "                  %3930 : Bool(device=cpu) = onnx::Cast[to=9](%3929)\n",
      "                  %3931 : Bool(device=cpu), %3932 : Bool(device=cpu), %3933 : Long(requires_grad=0, device=cpu), %3934 : Long(device=cpu), %3935 : Long(requires_grad=0, device=cpu), %3936 : Long(requires_grad=0, device=cpu), %3937 : Float(*, device=cpu)[], %3938 : Long(*, device=cpu)[], %3939 : Float(*, device=cpu), %3940 : Long(*, device=cpu), %3941 : Float(*, *, device=cpu), %3942 : Long(*, *, device=cpu), %3943 : Long(*, *, device=cpu) = onnx::If(%3930) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:431:16\n",
      "                    block0():\n",
      "                      %3944 : Bool(device=cpu) = onnx::GreaterOrEqual(%3916, %196) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:433:61\n",
      "                      %3945 : Bool(device=cpu) = onnx::Cast[to=9](%3944)\n",
      "                      %3946 : Bool(device=cpu), %3947 : Long(requires_grad=0, device=cpu), %3948 : Long(device=cpu), %3949 : Long(requires_grad=0, device=cpu), %3950 : Long(requires_grad=0, device=cpu), %3951 : Float(*, device=cpu)[], %3952 : Long(*, device=cpu)[], %3953 : Float(*, device=cpu), %3954 : Long(*, device=cpu) = onnx::If(%3945) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:434:20\n",
      "                        block0():\n",
      "                          %3955 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                          %beam_idx.38 : Long(requires_grad=0, device=cpu) = onnx::Identity(%beam_idx.36)\n",
      "                          %eos_token_id.67 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                          %3958 : FloatTensor(device=cpu)[] = onnx::Identity(%3917)\n",
      "                          %3959 : LongTensor(device=cpu)[] = onnx::Identity(%3918)\n",
      "                          %3960 : Float(*, device=cpu) = onnx::Identity(%3919)\n",
      "                          %3961 : Long(*, device=cpu) = onnx::Identity(%3920)\n",
      "                          %beam_idx.34 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%3955, %beam_idx.38, %eos_token_id.67, %beam_idx.34, %beam_idx.34, %3958, %3959, %3960, %3961)\n",
      "                        block1():\n",
      "                          %3963 : Long(*, device=cpu) = onnx::Gather[axis=0](%input_ids.25, %3928) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:437:24\n",
      "                          %3964 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3963) # <string>:7:9\n",
      "                          %3965 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %3966 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                          %3967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                          %3968 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3964, %3966, %3967, %3965)\n",
      "                          %3969 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %3970 : Long(device=cpu) = onnx::Squeeze(%3968, %3969) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "                          %3971 : Float(device=cpu) = onnx::Cast[to=1](%3970)\n",
      "                          %3972 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                          %3973 : Float(device=cpu) = onnx::Pow(%3971, %3972) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "                          %3974 : Float(device=cpu) = onnx::Div(%3925, %3973) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:16\n",
      "                          %3975 : Long(device=cpu) = onnx::Gather[axis=0](%3920, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "                          %3976 : Bool(device=cpu) = onnx::Less(%3975, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                          %3977 : Bool(device=cpu) = onnx::Cast[to=9](%3976)\n",
      "                          %3978 : Bool(device=cpu) = onnx::If(%3977) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                            block0():\n",
      "                              %3979 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                              -> (%3979)\n",
      "                            block1():\n",
      "                              %3980 : Float(device=cpu) = onnx::Gather[axis=0](%3919, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:50\n",
      "                              %3981 : Bool(device=cpu) = onnx::Less(%3980, %3974) # <string>:15:9\n",
      "                              -> (%3981)\n",
      "                          %3982 : Bool(device=cpu) = onnx::Cast[to=9](%3978)\n",
      "                          %3983 : Float(*, device=cpu)[], %3984 : Long(*, device=cpu)[], %3985 : Float(*, device=cpu), %3986 : Long(*, device=cpu) = onnx::If(%3982) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:8\n",
      "                            block0():\n",
      "                              %3987 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                              %3988 : Bool(device=cpu) = onnx::Equal(%3712, %3987)\n",
      "                              %3989 : Bool(device=cpu) = onnx::Not(%3988) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:63\n",
      "                              %3990 : Bool(device=cpu) = onnx::Cast[to=9](%3989)\n",
      "                              %3991 : LongTensor(device=cpu) = onnx::If(%3990) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                                block0():\n",
      "                                  %3992 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %3993 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %3994 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3992, %3993)\n",
      "                                  %3995 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %3996 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %3995)\n",
      "                                  %3997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %3998 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %3997)\n",
      "                                  %3999 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4000 : LongTensor(device=cpu) = onnx::Slice(%3920, %3994, %3996, %3998, %3999) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:26\n",
      "                                  %4001 : LongTensor(device=cpu) = onnx::ReduceSum[keepdims=0](%4000) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                                  -> (%4001)\n",
      "                                block1():\n",
      "                                  %4002 : Long(requires_grad=0, device=cpu) = onnx::Identity(%176)\n",
      "                                  -> (%4002)\n",
      "                              %4003 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                              %4004 : Float(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%3974, %4003)\n",
      "                              %4005 : Float(*, device=cpu) = onnx::Cast[to=1](%4004)\n",
      "                              %4006 : Float(*, device=cpu) = onnx::Concat[axis=0](%4005) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:47\n",
      "                              %4007 : Float(*, device=cpu)[] = onnx::SequenceInsert(%3917, %4006, %3991) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:12\n",
      "                              %4008 : Long(*, device=cpu)[] = onnx::SequenceInsert(%3918, %3963, %3991) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:366:12\n",
      "                              %4009 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                              %4010 : Long(device=cpu) = onnx::Add(%3975, %4009) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                              %4011 : Bool(device=cpu) = onnx::Greater(%4010, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                              %4012 : Bool(device=cpu) = onnx::Cast[to=9](%4011)\n",
      "                              %4013 : Long(*, device=cpu)[], %4014 : Float(*, device=cpu)[], %4015 : Float(*, device=cpu), %4016 : Long(*, device=cpu) = onnx::If(%4012) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:12\n",
      "                                block0():\n",
      "                                  %4017 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4007) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                                  %4018 : LongTensor(device=cpu) = onnx::Add(%3991, %3975) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                                  %4019 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4020 : LongTensor(device=cpu) = onnx::Add(%4018, %4019) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                                  %4021 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4022 : LongTensor(device=cpu) = onnx::Unsqueeze(%3991, %4021)\n",
      "                                  %4023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4024 : LongTensor(device=cpu) = onnx::Unsqueeze(%4020, %4023)\n",
      "                                  %4025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4026 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4025)\n",
      "                                  %4027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4028 : Float(*, device=cpu) = onnx::Slice(%4017, %4022, %4024, %4026, %4027) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                                  %4029 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4030 : Long(device=cpu) = onnx::Add(%3975, %4029) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:88\n",
      "                                  %4031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4032 : Long(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4030, %4031)\n",
      "                                  %4033 : Float(*, device=cpu), %4034 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=0, sorted=1](%4028, %4032) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:368:53\n",
      "                                  %4035 : Long(device=cpu) = onnx::Gather[axis=0](%4034, %189) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                                  %4036 : LongTensor(device=cpu) = onnx::Add(%4035, %3991) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                                  %4037 : Long(*, device=cpu)[] = onnx::SequenceErase(%4008, %4036) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:20\n",
      "                                  %4038 : Float(*, device=cpu)[] = onnx::SequenceErase(%4007, %4036) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:372:20\n",
      "                                  %4039 : Float(device=cpu) = onnx::Gather[axis=0](%4033, %187) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:57\n",
      "                                  %4040 : Float(device=cpu) = onnx::Gather[axis=0](%3919, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4041 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4040)\n",
      "                                  %4042 : Float(device=cpu) = onnx::Expand(%4039, %4041) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4044 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4043)\n",
      "                                  %4045 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4044)\n",
      "                                  %4046 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4047 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4044, %4046)\n",
      "                                  %4048 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3919)\n",
      "                                  %4049 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4050 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4051 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4052 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4048, %4050, %4051, %4049)\n",
      "                                  %4053 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4045, %4052)\n",
      "                                  %4054 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4053)\n",
      "                                  %4055 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4054)\n",
      "                                  %4056 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4057 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4055, %4056)\n",
      "                                  %4058 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4053, %4057)\n",
      "                                  %4059 : Long(1, strides=[1], device=cpu) = onnx::Where(%4058, %4055, %4053)\n",
      "                                  %4060 : FloatTensor(device=cpu) = onnx::Expand(%4042, %4059)\n",
      "                                  %4061 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4060, %4053)\n",
      "                                  %4062 : Float(*, device=cpu) = onnx::ScatterND(%3919, %4047, %4061) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4063 : Long(*, device=cpu) = onnx::Identity(%3920)\n",
      "                                  -> (%4037, %4038, %4062, %4063)\n",
      "                                block1():\n",
      "                                  %4064 : Float(device=cpu) = onnx::Gather[axis=0](%3919, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:68\n",
      "                                  %4065 : Float(device=cpu) = onnx::Min(%3974, %4064) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:57\n",
      "                                  %4066 : Float(device=cpu) = onnx::Gather[axis=0](%3919, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4067 : Float(device=cpu) = onnx::Cast[to=1](%4065)\n",
      "                                  %4068 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4066)\n",
      "                                  %4069 : Float(device=cpu) = onnx::Expand(%4067, %4068) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4070 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4071 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4070)\n",
      "                                  %4072 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4071)\n",
      "                                  %4073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4074 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4071, %4073)\n",
      "                                  %4075 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3919)\n",
      "                                  %4076 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4077 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4078 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4079 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4075, %4077, %4078, %4076)\n",
      "                                  %4080 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4072, %4079)\n",
      "                                  %4081 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4080)\n",
      "                                  %4082 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4081)\n",
      "                                  %4083 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4084 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4082, %4083)\n",
      "                                  %4085 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4080, %4084)\n",
      "                                  %4086 : Long(1, strides=[1], device=cpu) = onnx::Where(%4085, %4082, %4080)\n",
      "                                  %4087 : FloatTensor(device=cpu) = onnx::Expand(%4069, %4086)\n",
      "                                  %4088 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4087, %4080)\n",
      "                                  %4089 : Float(*, device=cpu) = onnx::ScatterND(%3919, %4074, %4088) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4090 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4091 : Long(device=cpu) = onnx::Add(%3975, %4090) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:50\n",
      "                                  %4092 : Long(device=cpu) = onnx::Gather[axis=0](%3920, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4093 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4092)\n",
      "                                  %4094 : Long(device=cpu) = onnx::Expand(%4091, %4093) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4096 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4095)\n",
      "                                  %4097 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4096)\n",
      "                                  %4098 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4099 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4096, %4098)\n",
      "                                  %4100 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3920)\n",
      "                                  %4101 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4102 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4103 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4104 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4100, %4102, %4103, %4101)\n",
      "                                  %4105 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4097, %4104)\n",
      "                                  %4106 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4105)\n",
      "                                  %4107 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4106)\n",
      "                                  %4108 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4109 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4107, %4108)\n",
      "                                  %4110 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4105, %4109)\n",
      "                                  %4111 : Long(1, strides=[1], device=cpu) = onnx::Where(%4110, %4107, %4105)\n",
      "                                  %4112 : LongTensor(device=cpu) = onnx::Expand(%4094, %4111)\n",
      "                                  %4113 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4112, %4105)\n",
      "                                  %4114 : Long(*, device=cpu) = onnx::ScatterND(%3920, %4099, %4113) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4115 : Long(*, device=cpu)[] = onnx::Identity(%4008)\n",
      "                                  %4116 : Float(*, device=cpu)[] = onnx::Identity(%4007)\n",
      "                                  -> (%4115, %4116, %4089, %4114)\n",
      "                              -> (%4014, %4013, %4015, %4016)\n",
      "                            block1():\n",
      "                              %4117 : Float(*, device=cpu)[] = onnx::Identity(%3917)\n",
      "                              %4118 : Long(*, device=cpu)[] = onnx::Identity(%3918)\n",
      "                              %4119 : Float(*, device=cpu) = onnx::Identity(%3919)\n",
      "                              %4120 : Long(*, device=cpu) = onnx::Identity(%3920)\n",
      "                              -> (%4117, %4118, %4119, %4120)\n",
      "                          %beam_idx.40 : Long(requires_grad=0, device=cpu) = onnx::Identity(%beam_idx.36)\n",
      "                          %eos_token_id.68 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                          %4123 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %beam_idx.33 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%4123, %beam_idx.33, %beam_idx.33, %beam_idx.40, %eos_token_id.68, %3983, %3984, %3985, %3986)\n",
      "                      %4125 : Float(*, *, device=cpu) = onnx::Identity(%3921)\n",
      "                      %4126 : Long(*, *, device=cpu) = onnx::Identity(%3922)\n",
      "                      %4127 : Long(*, *, device=cpu) = onnx::Identity(%3923)\n",
      "                      -> (%3944, %3946, %3947, %3948, %3949, %3950, %3951, %3952, %3953, %3954, %4125, %4126, %4127)\n",
      "                    block1():\n",
      "                      %4128 : Float(*, device=cpu) = onnx::Gather[axis=0](%3921, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4129 : Float(device=cpu) = onnx::Gather[axis=0](%4128, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4130 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4129)\n",
      "                      %4131 : Float(device=cpu) = onnx::Expand(%3925, %4130) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4132 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4133 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4132)\n",
      "                      %4134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4135 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4134)\n",
      "                      %4136 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4137 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4133, %4136)\n",
      "                      %4138 : Long(*, *, device=cpu) = onnx::Add(%4137, %4135)\n",
      "                      %4139 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4138)\n",
      "                      %4140 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4139)\n",
      "                      %4141 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4140)\n",
      "                      %4142 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4143 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4141, %4142)\n",
      "                      %4144 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4139, %4143)\n",
      "                      %4145 : Long(2, strides=[1], device=cpu) = onnx::Where(%4144, %4141, %4139)\n",
      "                      %4146 : Long(*, *, device=cpu) = onnx::Expand(%4137, %4145)\n",
      "                      %4147 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4148 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4146, %4147)\n",
      "                      %4149 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4139)\n",
      "                      %4150 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4149)\n",
      "                      %4151 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4152 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4150, %4151)\n",
      "                      %4153 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4139, %4152)\n",
      "                      %4154 : Long(2, strides=[1], device=cpu) = onnx::Where(%4153, %4150, %4139)\n",
      "                      %4155 : Long(*, *, device=cpu) = onnx::Expand(%4135, %4154)\n",
      "                      %4156 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4157 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4155, %4156)\n",
      "                      %4158 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4148, %4157)\n",
      "                      %4159 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3921)\n",
      "                      %4160 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4161 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4162 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4163 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4159, %4161, %4162, %4160)\n",
      "                      %4164 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4139, %4163)\n",
      "                      %4165 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4164)\n",
      "                      %4166 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4165)\n",
      "                      %4167 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4168 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4166, %4167)\n",
      "                      %4169 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4164, %4168)\n",
      "                      %4170 : Long(2, strides=[1], device=cpu) = onnx::Where(%4169, %4166, %4164)\n",
      "                      %4171 : FloatTensor(device=cpu) = onnx::Expand(%4131, %4170)\n",
      "                      %4172 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4171, %4164)\n",
      "                      %4173 : Float(*, *, device=cpu) = onnx::ScatterND(%3921, %4158, %4172) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4174 : Long(*, device=cpu) = onnx::Gather[axis=0](%3922, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4175 : Long(device=cpu) = onnx::Gather[axis=0](%4174, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4176 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4175)\n",
      "                      %4177 : Long(device=cpu) = onnx::Expand(%3924, %4176) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4178 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4179 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4178)\n",
      "                      %4180 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4181 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4180)\n",
      "                      %4182 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4183 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4179, %4182)\n",
      "                      %4184 : Long(*, *, device=cpu) = onnx::Add(%4183, %4181)\n",
      "                      %4185 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4184)\n",
      "                      %4186 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4185)\n",
      "                      %4187 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4186)\n",
      "                      %4188 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4189 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4187, %4188)\n",
      "                      %4190 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4185, %4189)\n",
      "                      %4191 : Long(2, strides=[1], device=cpu) = onnx::Where(%4190, %4187, %4185)\n",
      "                      %4192 : Long(*, *, device=cpu) = onnx::Expand(%4183, %4191)\n",
      "                      %4193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4194 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4192, %4193)\n",
      "                      %4195 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4185)\n",
      "                      %4196 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4195)\n",
      "                      %4197 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4198 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4196, %4197)\n",
      "                      %4199 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4185, %4198)\n",
      "                      %4200 : Long(2, strides=[1], device=cpu) = onnx::Where(%4199, %4196, %4185)\n",
      "                      %4201 : Long(*, *, device=cpu) = onnx::Expand(%4181, %4200)\n",
      "                      %4202 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4203 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4201, %4202)\n",
      "                      %4204 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4194, %4203)\n",
      "                      %4205 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3922)\n",
      "                      %4206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4208 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4209 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4205, %4207, %4208, %4206)\n",
      "                      %4210 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4185, %4209)\n",
      "                      %4211 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4210)\n",
      "                      %4212 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4211)\n",
      "                      %4213 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4214 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4212, %4213)\n",
      "                      %4215 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4210, %4214)\n",
      "                      %4216 : Long(2, strides=[1], device=cpu) = onnx::Where(%4215, %4212, %4210)\n",
      "                      %4217 : LongTensor(device=cpu) = onnx::Expand(%4177, %4216)\n",
      "                      %4218 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4217, %4210)\n",
      "                      %4219 : Long(*, *, device=cpu) = onnx::ScatterND(%3922, %4204, %4218) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4220 : Long(*, device=cpu) = onnx::Gather[axis=0](%3923, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4221 : Long(device=cpu) = onnx::Gather[axis=0](%4220, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4222 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4221)\n",
      "                      %4223 : Long(device=cpu) = onnx::Expand(%3928, %4222) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4224 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4225 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4224)\n",
      "                      %4226 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4227 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4226)\n",
      "                      %4228 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4229 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4225, %4228)\n",
      "                      %4230 : Long(*, *, device=cpu) = onnx::Add(%4229, %4227)\n",
      "                      %4231 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4230)\n",
      "                      %4232 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4231)\n",
      "                      %4233 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4232)\n",
      "                      %4234 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4235 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4233, %4234)\n",
      "                      %4236 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4231, %4235)\n",
      "                      %4237 : Long(2, strides=[1], device=cpu) = onnx::Where(%4236, %4233, %4231)\n",
      "                      %4238 : Long(*, *, device=cpu) = onnx::Expand(%4229, %4237)\n",
      "                      %4239 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4240 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4238, %4239)\n",
      "                      %4241 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4231)\n",
      "                      %4242 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4241)\n",
      "                      %4243 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4244 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4242, %4243)\n",
      "                      %4245 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4231, %4244)\n",
      "                      %4246 : Long(2, strides=[1], device=cpu) = onnx::Where(%4245, %4242, %4231)\n",
      "                      %4247 : Long(*, *, device=cpu) = onnx::Expand(%4227, %4246)\n",
      "                      %4248 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4249 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4247, %4248)\n",
      "                      %4250 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4240, %4249)\n",
      "                      %4251 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3923)\n",
      "                      %4252 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4254 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4255 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4251, %4253, %4254, %4252)\n",
      "                      %4256 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4231, %4255)\n",
      "                      %4257 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4256)\n",
      "                      %4258 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4257)\n",
      "                      %4259 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4260 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4258, %4259)\n",
      "                      %4261 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4256, %4260)\n",
      "                      %4262 : Long(2, strides=[1], device=cpu) = onnx::Where(%4261, %4258, %4256)\n",
      "                      %4263 : LongTensor(device=cpu) = onnx::Expand(%4223, %4262)\n",
      "                      %4264 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4263, %4256)\n",
      "                      %4265 : Long(*, *, device=cpu) = onnx::ScatterND(%3923, %4250, %4264) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4266 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4267 : Long(device=cpu) = onnx::Add(%beam_idx.36, %4266) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:446:20\n",
      "                      %4268 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%186)\n",
      "                      %eos_token_id.70 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                      %4270 : Float(*, device=cpu)[] = onnx::Identity(%3917)\n",
      "                      %4271 : Long(*, device=cpu)[] = onnx::Identity(%3918)\n",
      "                      %4272 : Float(*, device=cpu) = onnx::Identity(%3919)\n",
      "                      %4273 : Long(*, device=cpu) = onnx::Identity(%3920)\n",
      "                      %4274 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4275 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      -> (%4268, %4274, %4275, %4275, %4267, %eos_token_id.70, %4270, %4271, %4272, %4273, %4173, %4219, %4265)\n",
      "                  %4276 : Bool(device=cpu) = onnx::Cast[to=9](%3931)\n",
      "                  %4277 : Bool(device=cpu), %4278 : Bool(device=cpu), %4279 : Long(device=cpu), %4280 : Long(device=cpu), %4281 : Bool(device=cpu), %4282 : Long(device=cpu), %4283 : Long(device=cpu) = onnx::If(%4276)\n",
      "                    block0():\n",
      "                      %4284 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                      %4285 : Bool(device=cpu) = onnx::Identity(%3932)\n",
      "                      %4286 : Long(device=cpu) = onnx::Identity(%3933)\n",
      "                      %4287 : Long(device=cpu) = onnx::Identity(%3934)\n",
      "                      %4288 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4289 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4290 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      -> (%4284, %4285, %4286, %4287, %4288, %4289, %4290)\n",
      "                    block1():\n",
      "                      %4291 : Bool(device=cpu) = onnx::Equal(%3935, %196) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:449:19\n",
      "                      %4292 : Bool(device=cpu) = onnx::Cast[to=9](%4291)\n",
      "                      %4293 : Bool(requires_grad=0, device=cpu), %4294 : Long(device=cpu), %4295 : Long(device=cpu) = onnx::If(%4292) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:449:16\n",
      "                        block0():\n",
      "                          %4296 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%186)\n",
      "                          %4297 : Long(device=cpu) = onnx::Identity(%3935)\n",
      "                          %4298 : Long(device=cpu) = onnx::Identity(%3936)\n",
      "                          -> (%4296, %4297, %4298)\n",
      "                        block1():\n",
      "                          %4299 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4300 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4301 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%4299, %4300, %4301)\n",
      "                      %4302 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                      %4303 : Long(device=cpu) = onnx::Identity(%3935)\n",
      "                      %4304 : Long(device=cpu) = onnx::Identity(%3936)\n",
      "                      -> (%4291, %4293, %4294, %4295, %4302, %4303, %4304)\n",
      "                  %4305 : Bool(device=cpu) = onnx::Cast[to=9](%4277)\n",
      "                  %4306 : Bool(device=cpu), %4307 : Long(device=cpu), %4308 : Long(device=cpu) = onnx::If(%4305)\n",
      "                    block0():\n",
      "                      %4309 : Bool(device=cpu) = onnx::Identity(%4278)\n",
      "                      %4310 : Long(device=cpu) = onnx::Identity(%4279)\n",
      "                      %4311 : Long(device=cpu) = onnx::Identity(%4280)\n",
      "                      -> (%4309, %4310, %4311)\n",
      "                    block1():\n",
      "                      %4312 : Bool(device=cpu) = onnx::Identity(%4281)\n",
      "                      %4313 : Long(device=cpu) = onnx::Identity(%4282)\n",
      "                      %4314 : Long(device=cpu) = onnx::Identity(%4283)\n",
      "                      -> (%4312, %4313, %4314)\n",
      "                  %4315 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4316 : Long(device=cpu) = onnx::Add(%3916, %4315)\n",
      "                  %4317 : Bool(device=cpu) = onnx::Less(%4316, %3899)\n",
      "                  %4318 : Bool(device=cpu) = onnx::Cast[to=9](%4317)\n",
      "                  %4319 : Bool(device=cpu) = onnx::Cast[to=9](%4306)\n",
      "                  %4320 : Bool(device=cpu) = onnx::And(%4318, %4319)\n",
      "                  %4321 : Bool(device=cpu) = onnx::Cast[to=9](%4320)\n",
      "                  -> (%4321, %4307, %4308, %4316, %3937, %3938, %3939, %3940, %3941, %3942, %3943)\n",
      "              %4322 : Bool(device=cpu) = onnx::Gather[axis=0](%3720, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:36\n",
      "              %4323 : Bool(device=cpu) = onnx::Cast[to=9](%4322)\n",
      "              %4324 : Bool(device=cpu) = onnx::If(%4323) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:36\n",
      "                block0():\n",
      "                  %4325 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                  -> (%4325)\n",
      "                block1():\n",
      "                  %4326 : Long(device=cpu) = onnx::Gather[axis=0](%3908, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "                  %4327 : Bool(device=cpu) = onnx::Less(%4326, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:383:11\n",
      "                  %4328 : Bool(device=cpu) = onnx::Cast[to=9](%4327)\n",
      "                  %4329 : Bool(requires_grad=0, device=cpu) = onnx::If(%4328) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:383:8\n",
      "                    block0():\n",
      "                      %4330 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%186)\n",
      "                      -> (%4330)\n",
      "                    block1():\n",
      "                      %4331 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                      -> (%4331)\n",
      "                  -> (%4329)\n",
      "              %4332 : Bool(device=cpu) = onnx::Gather[axis=0](%3720, %3712) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %4333 : Bool(device=cpu) = onnx::Cast[to=9](%4324)\n",
      "              %4334 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4332)\n",
      "              %4335 : Bool(device=cpu) = onnx::Expand(%4333, %4334) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %4336 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4337 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3712, %4336)\n",
      "              %4338 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4337)\n",
      "              %4339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4340 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4337, %4339)\n",
      "              %4341 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3720)\n",
      "              %4342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4343 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4344 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4345 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4341, %4343, %4344, %4342)\n",
      "              %4346 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4338, %4345)\n",
      "              %4347 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4346)\n",
      "              %4348 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4347)\n",
      "              %4349 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4350 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4348, %4349)\n",
      "              %4351 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4346, %4350)\n",
      "              %4352 : Long(1, strides=[1], device=cpu) = onnx::Where(%4351, %4348, %4346)\n",
      "              %4353 : BoolTensor(device=cpu) = onnx::Expand(%4335, %4352)\n",
      "              %4354 : Bool(*, device=cpu) = onnx::Reshape[allowzero=0](%4353, %4346)\n",
      "              %4355 : Bool(*, device=cpu) = onnx::ScatterND(%3720, %4340, %4354) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %pad_token_id.32 : Long(device=cpu) = onnx::Identity(%pad_token_id.34)\n",
      "              -> (%3903, %pad_token_id.32, %3909, %3910, %3911, %3905, %3906, %3907, %3908, %4355)\n",
      "          %4357 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4358 : Long(device=cpu) = onnx::Add(%3712, %4357)\n",
      "          %4359 : Bool(device=cpu) = onnx::Less(%4358, %3676)\n",
      "          %4360 : Bool(device=cpu) = onnx::Cast[to=9](%4359)\n",
      "          %4361 : Bool(device=cpu) = onnx::Cast[to=9](%185)\n",
      "          %4362 : Bool(device=cpu) = onnx::And(%4360, %4361)\n",
      "          %4363 : Bool(device=cpu) = onnx::Cast[to=9](%4362)\n",
      "          -> (%4363, %3723, %3724, %4358, %3725, %3726, %3727, %3728, %3729, %3730, %3731, %3732)\n",
      "      %4364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4365 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%3700, %4364) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:15\n",
      "      %4366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4367 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%3701, %4366) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:42\n",
      "      %4368 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4369 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%3702, %4368) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:69\n",
      "      %4370 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%input_ids.25, %4369) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:628:39\n",
      "      %4371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4372 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4367, %4371) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:628:63\n",
      "      %4373 : Long(*, *, device=cpu) = onnx::Concat[axis=-1](%4370, %4372) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:628:28\n",
      "      %4374 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%attention_mask.13, %4369) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:629:44\n",
      "      %4375 : Long(2, strides=[1], device=cpu) = onnx::Shape(%attention_mask.13) # <string>:7:9\n",
      "      %4376 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4377 : Long(device=cpu) = onnx::Gather[axis=0](%4375, %4376) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:629:84\n",
      "      %4378 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4379 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4377, %4378)\n",
      "      %4380 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4379)\n",
      "      %4381 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%4380) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:629:73\n",
      "      %4382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4383 : Long(*, 1, device=cpu) = onnx::Unsqueeze(%4381, %4382) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:629:73\n",
      "      %4384 : Long(*, *, device=cpu) = onnx::Concat[axis=-1](%4374, %4383) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:629:33\n",
      "      %4385 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4386 : Long(device=cpu) = onnx::Add(%cur_len.13, %4385) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:631:26\n",
      "      %4387 : Bool(*, device=cpu) = onnx::Not(%3707)\n",
      "      %4388 : Long(*, device=cpu) = onnx::Cast[to=7](%4387)\n",
      "      %4389 : Long(device=cpu) = onnx::ReduceSum[keepdims=0, noop_with_empty_axes=0](%4388)\n",
      "      %4390 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4391 : Bool(*, strides=[1], device=cpu) = onnx::Greater(%4389, %4390)\n",
      "      %4392 : Bool(*, device=cpu) = onnx::Not(%4391) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:304:15\n",
      "      %4393 : Bool(*, device=cpu) = onnx::Cast[to=9](%4392)\n",
      "      %4394 : Bool(requires_grad=0, device=cpu) = onnx::If(%4393) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:636:16\n",
      "        block0():\n",
      "          %4395 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%186)\n",
      "          -> (%4395)\n",
      "        block1():\n",
      "          %4396 : Bool(device=cpu) = onnx::Greater(%max_length, %4386) # <string>:11:9\n",
      "          -> (%4396)\n",
      "      -> (%4394, %4373, %4365, %4384, %4386, %3703, %3704, %3705, %3706, %3707)\n",
      "  %4397 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4398 : Long(1, strides=[1], device=cpu) = onnx::Shape(%321)\n",
      "  %4399 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4398, %4397)\n",
      "  %4400 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4401 : Long(device=cpu) = onnx::Squeeze(%4399, %4400) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:475:21\n",
      "  %4402 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4403 : Bool(device=cpu) = onnx::Greater(%4401, %4402)\n",
      "  %4404 : Long(device=cpu), %4405 : Float(*, device=cpu)[], %4406 : Long(*, device=cpu)[], %4407 : Float(*, device=cpu), %4408 : Long(*, device=cpu) = onnx::Loop(%182, %4403, %189, %318, %319, %320, %321) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:478:8\n",
      "    block0(%4409 : Long(requires_grad=0, device=cpu), %cond.9 : Bool(device=cpu), %4411 : Long(requires_grad=0, device=cpu), %4412 : Float(*, device=cpu)[], %4413 : Long(*, device=cpu)[], %4414 : Float(*, device=cpu), %4415 : Long(*, device=cpu)):\n",
      "      %4416 : Bool(device=cpu) = onnx::Gather[axis=0](%322, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:479:15\n",
      "      %4417 : Bool(device=cpu) = onnx::Cast[to=9](%4416)\n",
      "      %4418 : Float(*, device=cpu)[], %4419 : Long(*, device=cpu)[], %4420 : Float(*, device=cpu), %4421 : Long(*, device=cpu) = onnx::If(%4417) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:479:12\n",
      "        block0():\n",
      "          %4422 : Float(*, device=cpu)[] = onnx::Identity(%4412)\n",
      "          %4423 : Long(*, device=cpu)[] = onnx::Identity(%4413)\n",
      "          %4424 : Float(*, device=cpu) = onnx::Identity(%4414)\n",
      "          %4425 : Long(*, device=cpu) = onnx::Identity(%4415)\n",
      "          -> (%4422, %4423, %4424, %4425)\n",
      "        block1():\n",
      "          %4426 : Float(*, device=cpu)[], %4427 : Long(*, device=cpu)[], %4428 : Float(*, device=cpu), %4429 : Long(*, device=cpu) = onnx::Loop(%num_beams, %185, %4412, %4413, %4414, %4415) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:484:12\n",
      "            block0(%beam_id.1 : Long(device=cpu), %cond.7 : Bool(device=cpu), %4432 : Float(*, device=cpu)[], %4433 : Long(*, device=cpu)[], %4434 : Float(*, device=cpu), %4435 : Long(*, device=cpu)):\n",
      "              %4436 : Long(device=cpu) = onnx::Mul(%4411, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:485:33\n",
      "              %4437 : Long(device=cpu) = onnx::Add(%4436, %beam_id.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:485:33\n",
      "              %4438 : Float(device=cpu) = onnx::Gather[axis=0](%315, %4437) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:486:30\n",
      "              %4439 : Long(*, device=cpu) = onnx::Gather[axis=0](%314, %4437) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:487:31\n",
      "              %4440 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4439) # <string>:7:9\n",
      "              %4441 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4442 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4443 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4444 : Long(1, strides=[1], device=cpu) = onnx::Slice(%4440, %4442, %4443, %4441)\n",
      "              %4445 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4446 : Long(device=cpu) = onnx::Squeeze(%4444, %4445) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "              %4447 : Float(device=cpu) = onnx::Cast[to=1](%4446)\n",
      "              %4448 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4449 : Float(device=cpu) = onnx::Pow(%4447, %4448) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "              %4450 : Float(device=cpu) = onnx::Div(%4438, %4449) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:16\n",
      "              %4451 : Long(device=cpu) = onnx::Gather[axis=0](%4435, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "              %4452 : Bool(device=cpu) = onnx::Less(%4451, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "              %4453 : Bool(device=cpu) = onnx::Cast[to=9](%4452)\n",
      "              %4454 : Bool(device=cpu) = onnx::If(%4453) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                block0():\n",
      "                  %4455 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "                  -> (%4455)\n",
      "                block1():\n",
      "                  %4456 : Float(device=cpu) = onnx::Gather[axis=0](%4434, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:50\n",
      "                  %4457 : Bool(device=cpu) = onnx::Less(%4456, %4450) # <string>:15:9\n",
      "                  -> (%4457)\n",
      "              %4458 : Bool(device=cpu) = onnx::Cast[to=9](%4454)\n",
      "              %4459 : Float(*, device=cpu)[], %4460 : Long(*, device=cpu)[], %4461 : Float(*, device=cpu), %4462 : Long(*, device=cpu) = onnx::If(%4458) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:8\n",
      "                block0():\n",
      "                  %4463 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                  %4464 : Bool(device=cpu) = onnx::Equal(%4411, %4463)\n",
      "                  %4465 : Bool(device=cpu) = onnx::Not(%4464) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:63\n",
      "                  %4466 : Bool(device=cpu) = onnx::Cast[to=9](%4465)\n",
      "                  %4467 : LongTensor(device=cpu) = onnx::If(%4466) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                    block0():\n",
      "                      %4468 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4469 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4470 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4468, %4469)\n",
      "                      %4471 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4472 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4411, %4471)\n",
      "                      %4473 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4474 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4473)\n",
      "                      %4475 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4476 : LongTensor(device=cpu) = onnx::Slice(%4435, %4470, %4472, %4474, %4475) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:26\n",
      "                      %4477 : LongTensor(device=cpu) = onnx::ReduceSum[keepdims=0](%4476) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                      -> (%4477)\n",
      "                    block1():\n",
      "                      %4478 : Long(requires_grad=0, device=cpu) = onnx::Identity(%176)\n",
      "                      -> (%4478)\n",
      "                  %4479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4480 : Float(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4450, %4479)\n",
      "                  %4481 : Float(*, device=cpu) = onnx::Cast[to=1](%4480)\n",
      "                  %4482 : Float(*, device=cpu) = onnx::Concat[axis=0](%4481) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:47\n",
      "                  %4483 : Float(*, device=cpu)[] = onnx::SequenceInsert(%4432, %4482, %4467) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:12\n",
      "                  %4484 : Long(*, device=cpu)[] = onnx::SequenceInsert(%4433, %4439, %4467) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:366:12\n",
      "                  %4485 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4486 : Long(device=cpu) = onnx::Add(%4451, %4485) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                  %4487 : Bool(device=cpu) = onnx::Greater(%4486, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                  %4488 : Bool(device=cpu) = onnx::Cast[to=9](%4487)\n",
      "                  %4489 : Long(*, device=cpu)[], %4490 : Float(*, device=cpu)[], %4491 : Float(*, device=cpu), %4492 : Long(*, device=cpu) = onnx::If(%4488) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:12\n",
      "                    block0():\n",
      "                      %4493 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4483) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                      %4494 : LongTensor(device=cpu) = onnx::Add(%4467, %4451) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                      %4495 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4496 : LongTensor(device=cpu) = onnx::Add(%4494, %4495) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                      %4497 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4498 : LongTensor(device=cpu) = onnx::Unsqueeze(%4467, %4497)\n",
      "                      %4499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4500 : LongTensor(device=cpu) = onnx::Unsqueeze(%4496, %4499)\n",
      "                      %4501 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4502 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4501)\n",
      "                      %4503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4504 : Float(*, device=cpu) = onnx::Slice(%4493, %4498, %4500, %4502, %4503) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                      %4505 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4506 : Long(device=cpu) = onnx::Add(%4451, %4505) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:88\n",
      "                      %4507 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4508 : Long(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4506, %4507)\n",
      "                      %4509 : Float(*, device=cpu), %4510 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=0, sorted=1](%4504, %4508) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:368:53\n",
      "                      %4511 : Long(device=cpu) = onnx::Gather[axis=0](%4510, %189) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                      %4512 : LongTensor(device=cpu) = onnx::Add(%4511, %4467) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                      %4513 : Long(*, device=cpu)[] = onnx::SequenceErase(%4484, %4512) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:20\n",
      "                      %4514 : Float(*, device=cpu)[] = onnx::SequenceErase(%4483, %4512) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:372:20\n",
      "                      %4515 : Float(device=cpu) = onnx::Gather[axis=0](%4509, %187) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:57\n",
      "                      %4516 : Float(device=cpu) = onnx::Gather[axis=0](%4434, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4517 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4516)\n",
      "                      %4518 : Float(device=cpu) = onnx::Expand(%4515, %4517) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4519 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4520 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4411, %4519)\n",
      "                      %4521 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4520)\n",
      "                      %4522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4523 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4520, %4522)\n",
      "                      %4524 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4434)\n",
      "                      %4525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4526 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4528 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4524, %4526, %4527, %4525)\n",
      "                      %4529 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4521, %4528)\n",
      "                      %4530 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4529)\n",
      "                      %4531 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4530)\n",
      "                      %4532 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4533 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4531, %4532)\n",
      "                      %4534 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4529, %4533)\n",
      "                      %4535 : Long(1, strides=[1], device=cpu) = onnx::Where(%4534, %4531, %4529)\n",
      "                      %4536 : FloatTensor(device=cpu) = onnx::Expand(%4518, %4535)\n",
      "                      %4537 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4536, %4529)\n",
      "                      %4538 : Float(*, device=cpu) = onnx::ScatterND(%4434, %4523, %4537) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4539 : Long(*, device=cpu) = onnx::Identity(%4435)\n",
      "                      -> (%4513, %4514, %4538, %4539)\n",
      "                    block1():\n",
      "                      %4540 : Float(device=cpu) = onnx::Gather[axis=0](%4434, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:68\n",
      "                      %4541 : Float(device=cpu) = onnx::Min(%4450, %4540) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:57\n",
      "                      %4542 : Float(device=cpu) = onnx::Gather[axis=0](%4434, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4543 : Float(device=cpu) = onnx::Cast[to=1](%4541)\n",
      "                      %4544 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4542)\n",
      "                      %4545 : Float(device=cpu) = onnx::Expand(%4543, %4544) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4546 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4547 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4411, %4546)\n",
      "                      %4548 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4547)\n",
      "                      %4549 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4550 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4547, %4549)\n",
      "                      %4551 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4434)\n",
      "                      %4552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4554 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4555 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4551, %4553, %4554, %4552)\n",
      "                      %4556 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4548, %4555)\n",
      "                      %4557 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4556)\n",
      "                      %4558 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4557)\n",
      "                      %4559 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4560 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4558, %4559)\n",
      "                      %4561 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4556, %4560)\n",
      "                      %4562 : Long(1, strides=[1], device=cpu) = onnx::Where(%4561, %4558, %4556)\n",
      "                      %4563 : FloatTensor(device=cpu) = onnx::Expand(%4545, %4562)\n",
      "                      %4564 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4563, %4556)\n",
      "                      %4565 : Float(*, device=cpu) = onnx::ScatterND(%4434, %4550, %4564) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4566 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4567 : Long(device=cpu) = onnx::Add(%4451, %4566) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:50\n",
      "                      %4568 : Long(device=cpu) = onnx::Gather[axis=0](%4435, %4411) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4569 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4568)\n",
      "                      %4570 : Long(device=cpu) = onnx::Expand(%4567, %4569) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4572 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4411, %4571)\n",
      "                      %4573 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4572)\n",
      "                      %4574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4575 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4572, %4574)\n",
      "                      %4576 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4435)\n",
      "                      %4577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4578 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4580 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4576, %4578, %4579, %4577)\n",
      "                      %4581 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4573, %4580)\n",
      "                      %4582 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4581)\n",
      "                      %4583 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4582)\n",
      "                      %4584 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4585 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4583, %4584)\n",
      "                      %4586 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4581, %4585)\n",
      "                      %4587 : Long(1, strides=[1], device=cpu) = onnx::Where(%4586, %4583, %4581)\n",
      "                      %4588 : LongTensor(device=cpu) = onnx::Expand(%4570, %4587)\n",
      "                      %4589 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4588, %4581)\n",
      "                      %4590 : Long(*, device=cpu) = onnx::ScatterND(%4435, %4575, %4589) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4591 : Long(*, device=cpu)[] = onnx::Identity(%4484)\n",
      "                      %4592 : Float(*, device=cpu)[] = onnx::Identity(%4483)\n",
      "                      -> (%4591, %4592, %4565, %4590)\n",
      "                  -> (%4490, %4489, %4491, %4492)\n",
      "                block1():\n",
      "                  %4593 : Float(*, device=cpu)[] = onnx::Identity(%4432)\n",
      "                  %4594 : Long(*, device=cpu)[] = onnx::Identity(%4433)\n",
      "                  %4595 : Float(*, device=cpu) = onnx::Identity(%4434)\n",
      "                  %4596 : Long(*, device=cpu) = onnx::Identity(%4435)\n",
      "                  -> (%4593, %4594, %4595, %4596)\n",
      "              %4597 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "              -> (%4597, %4459, %4460, %4461, %4462)\n",
      "          -> (%4426, %4427, %4428, %4429)\n",
      "      %4598 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4599 : Long(device=cpu) = onnx::Add(%4411, %4598)\n",
      "      %4600 : Bool(device=cpu) = onnx::Less(%4599, %4401)\n",
      "      %4601 : Bool(device=cpu) = onnx::Cast[to=9](%4600)\n",
      "      %4602 : Bool(device=cpu) = onnx::Cast[to=9](%185)\n",
      "      %4603 : Bool(device=cpu) = onnx::And(%4601, %4602)\n",
      "      %4604 : Bool(device=cpu) = onnx::Cast[to=9](%4603)\n",
      "      -> (%4604, %4599, %4418, %4419, %4420, %4421)\n",
      "  %4605 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4606 : Long(device=cpu) = onnx::Mul(%4401, %4605) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:492:35\n",
      "  %4607 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4608 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4606, %4607)\n",
      "  %4609 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4608)\n",
      "  %4610 : Long(*, device=cpu) = onnx::ConstantOfShape[value={0}](%4609) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:492:23\n",
      "  %best.1 : Long(*, device=cpu)[] = onnx::SequenceEmpty[dtype=7]()\n",
      "  %4612 : Long(*, device=cpu), %4613 : Long(*, device=cpu)[] = onnx::Loop(%4401, %185, %4610, %best.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:498:8\n",
      "    block0(%i.1 : Long(device=cpu), %cond.13 : Bool(device=cpu), %4616 : Long(*, device=cpu), %4617 : Long(*, device=cpu)[]):\n",
      "      %4618 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4619 : Bool(device=cpu) = onnx::Greater(%i.1, %4618) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:71\n",
      "      %4620 : Bool(device=cpu) = onnx::Cast[to=9](%4619)\n",
      "      %4621 : Long(device=cpu) = onnx::If(%4620) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:31\n",
      "        block0():\n",
      "          %4622 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4623 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4624 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4622, %4623)\n",
      "          %4625 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4626 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.1, %4625)\n",
      "          %4627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4628 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4627)\n",
      "          %4629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4630 : Long(*, device=cpu) = onnx::Slice(%4408, %4624, %4626, %4628, %4629) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:41\n",
      "          %4631 : Long(device=cpu) = onnx::ReduceSum[keepdims=0](%4630) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:31\n",
      "          -> (%4631)\n",
      "        block1():\n",
      "          %4632 : Long(requires_grad=0, device=cpu) = onnx::Identity(%176)\n",
      "          -> (%4632)\n",
      "      %4633 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4634 : Long(device=cpu) = onnx::Add(%i.1, %4633) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:63\n",
      "      %4635 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4636 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4637 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4635, %4636)\n",
      "      %4638 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4639 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4634, %4638)\n",
      "      %4640 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4641 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4640)\n",
      "      %4642 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4643 : Long(*, device=cpu) = onnx::Slice(%4408, %4637, %4639, %4641, %4642) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:39\n",
      "      %4644 : Long(device=cpu) = onnx::ReduceSum[keepdims=0](%4643) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:29\n",
      "      %4645 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4405) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:502:26\n",
      "      %4646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4647 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4621, %4646)\n",
      "      %4648 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4649 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4644, %4648)\n",
      "      %4650 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4651 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4650)\n",
      "      %4652 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4653 : Float(*, device=cpu) = onnx::Slice(%4645, %4647, %4649, %4651, %4652) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:502:26\n",
      "      %4654 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4655 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4653)\n",
      "      %4656 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4655, %4654)\n",
      "      %4657 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4658 : Long(device=cpu) = onnx::Squeeze(%4656, %4657) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:503:73\n",
      "      %4659 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4660 : Long(1, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4658, %4659)\n",
      "      %4661 : Float(*, device=cpu), %4662 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1](%4653, %4660) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:503:49\n",
      "      %4663 : Long(*, device=cpu), %4664 : Long(*, device=cpu)[] = onnx::Loop(%187, %185, %4616, %4617) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:504:12\n",
      "        block0(%j.1 : Long(device=cpu), %cond.11 : Bool(device=cpu), %4667 : Long(*, device=cpu), %4668 : Long(*, device=cpu)[]):\n",
      "          %4669 : Long(device=cpu) = onnx::Gather[axis=0](%4662, %j.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:62\n",
      "          %4670 : Long(device=cpu) = onnx::Add(%4621, %4669) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:43\n",
      "          %4671 : Long(*, device=cpu) = onnx::SequenceAt(%4406, %4670) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:27\n",
      "          %4672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4673 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4671)\n",
      "          %4674 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4673, %4672)\n",
      "          %4675 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4676 : Long(device=cpu) = onnx::Squeeze(%4674, %4675) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:67\n",
      "          %4677 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4678 : Long(device=cpu) = onnx::Mul(%4677, %i.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:29\n",
      "          %4679 : Long(device=cpu) = onnx::Add(%4678, %j.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:29\n",
      "          %4680 : Long(device=cpu) = onnx::Gather[axis=0](%4667, %4679) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4681 : Long(device=cpu) = onnx::Cast[to=7](%4676)\n",
      "          %4682 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4680)\n",
      "          %4683 : Long(device=cpu) = onnx::Expand(%4681, %4682) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4684 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4685 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4679, %4684)\n",
      "          %4686 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4685)\n",
      "          %4687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4688 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4685, %4687)\n",
      "          %4689 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4667)\n",
      "          %4690 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4691 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4692 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %4693 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4689, %4691, %4692, %4690)\n",
      "          %4694 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4686, %4693)\n",
      "          %4695 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4694)\n",
      "          %4696 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4695)\n",
      "          %4697 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4698 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4696, %4697)\n",
      "          %4699 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4694, %4698)\n",
      "          %4700 : Long(1, strides=[1], device=cpu) = onnx::Where(%4699, %4696, %4694)\n",
      "          %4701 : LongTensor(device=cpu) = onnx::Expand(%4683, %4700)\n",
      "          %4702 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4701, %4694)\n",
      "          %4703 : Long(*, device=cpu) = onnx::ScatterND(%4667, %4688, %4702) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4704 : Long(*, device=cpu)[] = onnx::SequenceInsert(%4668, %4671) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:509:16\n",
      "          %4705 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "          -> (%4705, %4703, %4704)\n",
      "      %4706 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "      -> (%4706, %4663, %4664)\n",
      "  %4707 : Long(device=cpu) = onnx::ReduceMax[keepdims=0](%4612) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:27\n",
      "  %4708 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4709 : Long(device=cpu) = onnx::Add(%4707, %4708) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:27\n",
      "  %4710 : Long(device=cpu) = onnx::Min(%4709, %max_length) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:23\n",
      "  %4711 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4712 : Long(device=cpu) = onnx::Mul(%4401, %4711) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:514:30\n",
      "  %4713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4714 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4712, %4713)\n",
      "  %4715 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4716 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4710, %4715)\n",
      "  %4717 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4714, %4716)\n",
      "  %4718 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%4717) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:514:18\n",
      "  %4719 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%4612) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:11\n",
      "  %4720 : Long(device=cpu) = onnx::ReduceMax[keepdims=0](%4612) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:33\n",
      "  %4721 : Bool(device=cpu) = onnx::Equal(%4719, %4720)\n",
      "  %4722 : Bool(device=cpu) = onnx::Not(%4721) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:11\n",
      "  %4723 : Bool(device=cpu) = onnx::Cast[to=9](%4722)\n",
      "  %4724 : Long(*, *, device=cpu) = onnx::If(%4723) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:8\n",
      "    block0():\n",
      "      %4725 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4718)\n",
      "      %4726 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%4725) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:518:12\n",
      "      -> (%4726)\n",
      "    block1():\n",
      "      %4727 : Long(*, *, device=cpu) = onnx::Identity(%4718)\n",
      "      -> (%4727)\n",
      "  %4728 : Long(device=cpu) = onnx::SequenceLength(%4613) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "  %4731 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4732 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4728, %4731)\n",
      "  %4733 : Long(2, device=cpu) = onnx::Concat[axis=0](%4855, %4732)\n",
      "  %4734 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%4733) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "  %output_ids : Long(*, *, device=cpu) = onnx::Loop(%4734, %185, %4724) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "    block0(%i.17 : Long(device=cpu), %cond : Bool(device=cpu), %4738 : Long(*, *, device=cpu)):\n",
      "      %4739 : Long(*, device=cpu) = onnx::SequenceAt(%4613, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "      %4740 : Long(*, device=cpu) = onnx::Gather[axis=0](%4738, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4741 : Long(device=cpu) = onnx::Gather[axis=0](%4612, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:25\n",
      "      %4742 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4743 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4744 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4742, %4743)\n",
      "      %4745 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4746 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4741, %4745)\n",
      "      %4747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4748 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%189, %4747)\n",
      "      %4749 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4750 : Long(*, device=cpu) = onnx::Slice(%4740, %4744, %4746, %4748, %4749) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4751 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4750)\n",
      "      %4752 : LongTensor(device=cpu) = onnx::Expand(%4739, %4751) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4753 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4754 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.17, %4753)\n",
      "      %4755 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4738)\n",
      "      %4756 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4757 : Long(device=cpu) = onnx::Gather[axis=0](%4755, %4756)\n",
      "      %4758 : Long(device=cpu) = onnx::Cast[to=7](%4757)\n",
      "      %4759 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4760 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4761 : Long(*, device=cpu) = onnx::Range(%4759, %4758, %4760)\n",
      "      %4762 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4763 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4764 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4765 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4763, %4764)\n",
      "      %4766 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4767 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4741, %4766)\n",
      "      %4768 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4769 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4762, %4768)\n",
      "      %4770 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4771 : Long(*, device=cpu) = onnx::Slice(%4761, %4765, %4767, %4769, %4770)\n",
      "      %4772 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "      %4773 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4754, %4772)\n",
      "      %4774 : Long(*, *, device=cpu) = onnx::Add(%4773, %4771)\n",
      "      %4775 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4774)\n",
      "      %4776 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4775)\n",
      "      %4777 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4776)\n",
      "      %4778 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4779 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4777, %4778)\n",
      "      %4780 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4775, %4779)\n",
      "      %4781 : Long(2, strides=[1], device=cpu) = onnx::Where(%4780, %4777, %4775)\n",
      "      %4782 : LongTensor(device=cpu) = onnx::Expand(%4773, %4781)\n",
      "      %4783 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4784 : LongTensor(device=cpu) = onnx::Unsqueeze(%4782, %4783)\n",
      "      %4785 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4775)\n",
      "      %4786 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4785)\n",
      "      %4787 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4788 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4786, %4787)\n",
      "      %4789 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4775, %4788)\n",
      "      %4790 : Long(2, strides=[1], device=cpu) = onnx::Where(%4789, %4786, %4775)\n",
      "      %4791 : LongTensor(device=cpu) = onnx::Expand(%4771, %4790)\n",
      "      %4792 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4793 : LongTensor(device=cpu) = onnx::Unsqueeze(%4791, %4792)\n",
      "      %4794 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%4784, %4793)\n",
      "      %4795 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4738)\n",
      "      %4796 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4797 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "      %4798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %4799 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4795, %4797, %4798, %4796)\n",
      "      %4800 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4775, %4799)\n",
      "      %4801 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4752, %4800)\n",
      "      %4802 : Long(*, *, device=cpu) = onnx::Cast[to=7](%4801)\n",
      "      %4803 : Long(*, *, device=cpu) = onnx::ScatterND(%4738, %4794, %4802) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4804 : Long(device=cpu) = onnx::Gather[axis=0](%4612, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:15\n",
      "      %4805 : Bool(device=cpu) = onnx::Less(%4804, %max_length) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:15\n",
      "      %4806 : Bool(device=cpu) = onnx::Cast[to=9](%4805)\n",
      "      %4807 : Long(*, *, device=cpu) = onnx::If(%4806) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:12\n",
      "        block0():\n",
      "          %4808 : Long(device=cpu) = onnx::Gather[axis=0](%4612, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:524:27\n",
      "          %4809 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %4810 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4811 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.17, %4810)\n",
      "          %4812 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %4813 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4811, %4812)\n",
      "          %4814 : Long(*, *, device=cpu) = onnx::Add(%4813, %4808)\n",
      "          %4815 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4814)\n",
      "          %4816 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4815)\n",
      "          %4817 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4816)\n",
      "          %4818 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4819 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4817, %4818)\n",
      "          %4820 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4815, %4819)\n",
      "          %4821 : Long(2, strides=[1], device=cpu) = onnx::Where(%4820, %4817, %4815)\n",
      "          %4822 : Long(*, *, device=cpu) = onnx::Expand(%4813, %4821)\n",
      "          %4823 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4824 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4822, %4823)\n",
      "          %4825 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4815)\n",
      "          %4826 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4825)\n",
      "          %4827 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4828 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4826, %4827)\n",
      "          %4829 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4815, %4828)\n",
      "          %4830 : Long(2, strides=[1], device=cpu) = onnx::Where(%4829, %4826, %4815)\n",
      "          %4831 : Long(*, *, device=cpu) = onnx::Expand(%4808, %4830)\n",
      "          %4832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4833 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4831, %4832)\n",
      "          %4834 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4824, %4833)\n",
      "          %4835 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4803)\n",
      "          %4836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4837 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %4838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %4839 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4835, %4837, %4838, %4836)\n",
      "          %4840 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4815, %4839)\n",
      "          %4841 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4840)\n",
      "          %4842 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4841)\n",
      "          %4843 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4844 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4842, %4843)\n",
      "          %4845 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4840, %4844)\n",
      "          %4846 : Long(2, strides=[1], device=cpu) = onnx::Where(%4845, %4842, %4840)\n",
      "          %4847 : LongTensor(device=cpu) = onnx::Expand(%4809, %4846)\n",
      "          %4848 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4847, %4840)\n",
      "          %4849 : Long(*, *, device=cpu) = onnx::ScatterND(%4803, %4834, %4848) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:524:16\n",
      "          -> (%4849)\n",
      "        block1():\n",
      "          %4850 : Long(*, *, device=cpu) = onnx::Identity(%4803)\n",
      "          -> (%4850)\n",
      "      %4851 : Bool(device=cpu) = onnx::Identity(%185)\n",
      "      -> (%4851, %4807)\n",
      "  return (%output_ids)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        PROMT = [\"старик\", \"Кощей\"]\n",
    "\n",
    "        context = \" _kw_ \".join(PROMT)\n",
    "        context = tokenizer.encode(context)\n",
    "        endkeytok = tokenizer.convert_tokens_to_ids('_endkw_')\n",
    "\n",
    "        context = [starttok] + context + [endkeytok] + [septok]\n",
    "        context = tokenizer.decode(context)\n",
    "\n",
    "        inputs = tokenizer(context, max_length=model.config.n_ctx, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "\n",
    "        torch.onnx.export(\n",
    "            script_model,\n",
    "            (\n",
    "                inputs[\"input_ids\"],\n",
    "                inputs[\"attention_mask\"],\n",
    "                num_beams,\n",
    "                max_length,\n",
    "            ),\n",
    "            onnx_file_path,\n",
    "            opset_version=14,  # TODO for gpt maybe 12?\n",
    "            input_names=[\"input_ids\", \"attention_mask\", \"num_beams\", \"max_length\"], \n",
    "            output_names=[\"output_ids\"],\n",
    "            dynamic_axes={\n",
    "                \"input_ids\": {0: \"batch\", 1: \"seq\"},\n",
    "                \"output_ids\": {0: \"batch\", 1: \"seq_out\"},\n",
    "            },\n",
    "            example_outputs=summary_ids,\n",
    "            verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input_ids[INT64, batchxseq]\n",
      "  %attention_mask[INT64, 1x8]\n",
      "  %num_beams[INT64, scalar]\n",
      "  %max_length[INT64, scalar]\n",
      ") initializers (\n",
      "  %decoder_no_past.decoder.transformer.wte.weight[FLOAT, 50260x768]\n",
      "  %decoder_no_past.decoder.transformer.wpe.weight[FLOAT, 2048x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.ln_f.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.ln_f.weight[FLOAT, 768]\n",
      "  %4852[INT64, 1]\n",
      "  %4853[INT64, 1]\n",
      "  %4854[FLOAT, 768x50260]\n",
      "  %4855[INT64, 1]\n",
      ") {\n",
      "  %176 = Constant[value = <Scalar Tensor []>]()\n",
      "  %177 = Constant[value = <Scalar Tensor []>]()\n",
      "  %178 = Constant[value = <Scalar Tensor []>]()\n",
      "  %179 = Constant[value = <Scalar Tensor []>]()\n",
      "  %180 = Constant[value = <Scalar Tensor []>]()\n",
      "  %181 = Constant[value = <Scalar Tensor []>]()\n",
      "  %182 = Constant[value = <Scalar Tensor []>]()\n",
      "  %183 = Constant[value = <Scalar Tensor []>]()\n",
      "  %184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %185 = Constant[value = <Scalar Tensor []>]()\n",
      "  %186 = Constant[value = <Scalar Tensor []>]()\n",
      "  %187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %189 = Constant[value = <Scalar Tensor []>]()\n",
      "  %190 = Shape(%input_ids)\n",
      "  %191 = Constant[value = <Scalar Tensor []>]()\n",
      "  %192 = Gather[axis = 0](%190, %191)\n",
      "  %193 = Constant[value = <Scalar Tensor []>]()\n",
      "  %194 = Div(%num_beams, %193)\n",
      "  %195 = Cast[to = 7](%194)\n",
      "  %196 = Cast[to = 7](%195)\n",
      "  %197 = Constant[value = <Tensor>]()\n",
      "  %198 = Unsqueeze(%192, %197)\n",
      "  %199 = Concat[axis = 0](%198)\n",
      "  %200 = Constant[value = <Tensor>]()\n",
      "  %201 = Unsqueeze(%192, %200)\n",
      "  %202 = Concat[axis = 0](%201)\n",
      "  %203 = Constant[value = <Tensor>]()\n",
      "  %204 = Unsqueeze(%192, %203)\n",
      "  %205 = Concat[axis = 0](%204)\n",
      "  %206 = ConstantOfShape[value = <Tensor>](%199)\n",
      "  %207 = ConstantOfShape[value = <Tensor>](%202)\n",
      "  %208 = ConstantOfShape[value = <Tensor>](%205)\n",
      "  %209 = Constant[value = <Scalar Tensor []>]()\n",
      "  %210 = Add(%208, %209)\n",
      "  %211 = SequenceEmpty[dtype = 7]()\n",
      "  %212 = SequenceEmpty[dtype = 1]()\n",
      "  %213 = Shape(%input_ids)\n",
      "  %214 = Constant[value = <Scalar Tensor []>]()\n",
      "  %215 = Gather[axis = 0](%213, %214)\n",
      "  %216 = Cast[to = 7](%215)\n",
      "  %217 = Constant[value = <Scalar Tensor []>]()\n",
      "  %218 = Constant[value = <Scalar Tensor []>]()\n",
      "  %219 = Range(%217, %216, %218)\n",
      "  %220 = Constant[value = <Tensor>]()\n",
      "  %221 = Reshape[allowzero = 0](%219, %220)\n",
      "  %224 = Constant[value = <Tensor>]()\n",
      "  %225 = Unsqueeze(%num_beams, %224)\n",
      "  %226 = Concat[axis = 0](%4852, %225)\n",
      "  %229 = Constant[value = <Tensor>]()\n",
      "  %230 = Unsqueeze(%num_beams, %229)\n",
      "  %231 = Concat[axis = 0](%4853, %230)\n",
      "  %232 = Shape(%226)\n",
      "  %233 = ConstantOfShape[value = <Tensor>](%232)\n",
      "  %234 = Expand(%221, %233)\n",
      "  %235 = Tile(%234, %231)\n",
      "  %236 = Constant[value = <Tensor>]()\n",
      "  %237 = Reshape[allowzero = 0](%235, %236)\n",
      "  %238 = Gather[axis = 0](%input_ids, %237)\n",
      "  %239 = Gather[axis = 0](%attention_mask, %237)\n",
      "  %240 = Shape(%238)\n",
      "  %241 = Constant[value = <Scalar Tensor []>]()\n",
      "  %242 = Gather(%240, %241)\n",
      "  %243 = Constant[value = <Tensor>]()\n",
      "  %244 = Unsqueeze(%192, %243)\n",
      "  %245 = Constant[value = <Tensor>]()\n",
      "  %246 = Unsqueeze(%num_beams, %245)\n",
      "  %247 = Concat[axis = 0](%244, %246)\n",
      "  %248 = ConstantOfShape[value = <Tensor>](%247)\n",
      "  %249 = Constant[value = <Tensor>]()\n",
      "  %250 = Constant[value = <Tensor>]()\n",
      "  %251 = Constant[value = <Tensor>]()\n",
      "  %252 = Constant[value = <Tensor>]()\n",
      "  %253 = Slice(%248, %250, %251, %249, %252)\n",
      "  %254 = Constant[value = <Scalar Tensor []>]()\n",
      "  %255 = Shape(%253)\n",
      "  %256 = Expand(%254, %255)\n",
      "  %257 = Shape(%248)\n",
      "  %258 = Constant[value = <Scalar Tensor []>]()\n",
      "  %259 = Gather[axis = 0](%257, %258)\n",
      "  %260 = Cast[to = 7](%259)\n",
      "  %261 = Constant[value = <Scalar Tensor []>]()\n",
      "  %262 = Constant[value = <Scalar Tensor []>]()\n",
      "  %263 = Range(%261, %260, %262)\n",
      "  %264 = Shape(%248)\n",
      "  %265 = Constant[value = <Scalar Tensor []>]()\n",
      "  %266 = Gather[axis = 0](%264, %265)\n",
      "  %267 = Cast[to = 7](%266)\n",
      "  %268 = Constant[value = <Scalar Tensor []>]()\n",
      "  %269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %270 = Range(%268, %267, %269)\n",
      "  %271 = Constant[value = <Tensor>]()\n",
      "  %272 = Constant[value = <Tensor>]()\n",
      "  %273 = Constant[value = <Tensor>]()\n",
      "  %274 = Constant[value = <Tensor>]()\n",
      "  %275 = Slice(%270, %272, %273, %271, %274)\n",
      "  %276 = Constant[value = <Tensor>]()\n",
      "  %277 = Reshape[allowzero = 0](%263, %276)\n",
      "  %278 = Add(%277, %275)\n",
      "  %279 = Shape(%278)\n",
      "  %280 = Shape(%279)\n",
      "  %281 = ConstantOfShape[value = <Tensor>](%280)\n",
      "  %282 = Constant[value = <Scalar Tensor []>]()\n",
      "  %283 = Mul(%281, %282)\n",
      "  %284 = Equal(%279, %283)\n",
      "  %285 = Where(%284, %281, %279)\n",
      "  %286 = Expand(%277, %285)\n",
      "  %287 = Constant[value = <Tensor>]()\n",
      "  %288 = Unsqueeze(%286, %287)\n",
      "  %289 = Shape(%279)\n",
      "  %290 = ConstantOfShape[value = <Tensor>](%289)\n",
      "  %291 = Constant[value = <Scalar Tensor []>]()\n",
      "  %292 = Mul(%290, %291)\n",
      "  %293 = Equal(%279, %292)\n",
      "  %294 = Where(%293, %290, %279)\n",
      "  %295 = Expand(%275, %294)\n",
      "  %296 = Constant[value = <Tensor>]()\n",
      "  %297 = Unsqueeze(%295, %296)\n",
      "  %298 = Concat[axis = -1](%288, %297)\n",
      "  %299 = Shape(%248)\n",
      "  %300 = Constant[value = <Tensor>]()\n",
      "  %301 = Constant[value = <Tensor>]()\n",
      "  %302 = Constant[value = <Tensor>]()\n",
      "  %303 = Slice(%299, %301, %302, %300)\n",
      "  %304 = Concat[axis = 0](%279, %303)\n",
      "  %305 = Reshape[allowzero = 0](%256, %304)\n",
      "  %306 = ScatterND(%248, %298, %305)\n",
      "  %307 = Mul(%192, %num_beams)\n",
      "  %308 = Constant[value = <Tensor>]()\n",
      "  %309 = Unsqueeze(%307, %308)\n",
      "  %310 = Concat[axis = 0](%309)\n",
      "  %311 = Reshape[allowzero = 0](%306, %310)\n",
      "  %312 = Greater(%max_length, %242)\n",
      "  %314, %315, %316, %317, %318, %319, %320, %321, %322 = Loop[body = <graph torch-jit-export1>](%182, %312, %238, %311, %239, %242, %212, %211, %210, %207, %206)\n",
      "  %4397 = Constant[value = <Tensor>]()\n",
      "  %4398 = Shape(%321)\n",
      "  %4399 = Gather[axis = 0](%4398, %4397)\n",
      "  %4400 = Constant[value = <Tensor>]()\n",
      "  %4401 = Squeeze(%4399, %4400)\n",
      "  %4402 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4403 = Greater(%4401, %4402)\n",
      "  %4404, %4405, %4406, %4407, %4408 = Loop[body = <graph torch-jit-export34>](%182, %4403, %189, %318, %319, %320, %321)\n",
      "  %4605 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4606 = Mul(%4401, %4605)\n",
      "  %4607 = Constant[value = <Tensor>]()\n",
      "  %4608 = Unsqueeze(%4606, %4607)\n",
      "  %4609 = Concat[axis = 0](%4608)\n",
      "  %4610 = ConstantOfShape[value = <Tensor>](%4609)\n",
      "  %best.1 = SequenceEmpty[dtype = 7]()\n",
      "  %4612, %4613 = Loop[body = <graph torch-jit-export46>](%4401, %185, %4610, %best.1)\n",
      "  %4707 = ReduceMax[keepdims = 0](%4612)\n",
      "  %4708 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4709 = Add(%4707, %4708)\n",
      "  %4710 = Min(%4709, %max_length)\n",
      "  %4711 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4712 = Mul(%4401, %4711)\n",
      "  %4713 = Constant[value = <Tensor>]()\n",
      "  %4714 = Unsqueeze(%4712, %4713)\n",
      "  %4715 = Constant[value = <Tensor>]()\n",
      "  %4716 = Unsqueeze(%4710, %4715)\n",
      "  %4717 = Concat[axis = 0](%4714, %4716)\n",
      "  %4718 = ConstantOfShape[value = <Tensor>](%4717)\n",
      "  %4719 = ReduceMin[keepdims = 0](%4612)\n",
      "  %4720 = ReduceMax[keepdims = 0](%4612)\n",
      "  %4721 = Equal(%4719, %4720)\n",
      "  %4722 = Not(%4721)\n",
      "  %4723 = Cast[to = 9](%4722)\n",
      "  %4724 = If[else_branch = <graph torch-jit-export51>, then_branch = <graph torch-jit-export50>](%4723)\n",
      "  %4728 = SequenceLength(%4613)\n",
      "  %4731 = Constant[value = <Tensor>]()\n",
      "  %4732 = Unsqueeze(%4728, %4731)\n",
      "  %4733 = Concat[axis = 0](%4855, %4732)\n",
      "  %4734 = ReduceMin[keepdims = 0](%4733)\n",
      "  %output_ids = Loop[body = <graph torch-jit-export52>](%4734, %185, %4724)\n",
      "  return %output_ids\n",
      "}\n",
      "\n",
      "graph torch-jit-export1 (\n",
      "  %323[INT64, scalar]\n",
      "  %cond.5[BOOL, scalar]\n",
      "  %input_ids.25[INT64, input_ids.25_dim_0xinput_ids.25_dim_1]\n",
      "  %beam_scores.17[FLOAT, beam_scores.17_dim_0]\n",
      "  %attention_mask.13[INT64, attention_mask.13_dim_0xattention_mask.13_dim_1]\n",
      "  %cur_len.13[INT64, scalar]\n",
      "  %329[Unknown type sequence_type]\n",
      "  %330[Unknown type sequence_type]\n",
      "  %331[FLOAT, 331_dim_0]\n",
      "  %332[INT64, 332_dim_0]\n",
      "  %333[BOOL, 333_dim_0]\n",
      ") {\n",
      "  %334 = Shape(%input_ids.25)\n",
      "  %335 = Constant[value = <Scalar Tensor []>]()\n",
      "  %336 = Gather[axis = 0](%334, %335)\n",
      "  %337 = Shape(%input_ids.25)\n",
      "  %338 = Constant[value = <Scalar Tensor []>]()\n",
      "  %339 = Gather[axis = 0](%337, %338)\n",
      "  %340 = Constant[value = <Tensor>]()\n",
      "  %341 = Unsqueeze(%184, %340)\n",
      "  %342 = Constant[value = <Tensor>]()\n",
      "  %343 = Unsqueeze(%339, %342)\n",
      "  %344 = Concat[axis = 0](%341, %343)\n",
      "  %345 = Constant[value = <Tensor>]()\n",
      "  %346 = Unsqueeze(%184, %345)\n",
      "  %347 = Constant[value = <Tensor>]()\n",
      "  %348 = Unsqueeze(%339, %347)\n",
      "  %349 = Concat[axis = 0](%346, %348)\n",
      "  %350 = Reshape[allowzero = 0](%input_ids.25, %344)\n",
      "  %351 = Shape(%350)\n",
      "  %352 = Constant[value = <Scalar Tensor []>]()\n",
      "  %353 = Gather[axis = 0](%351, %352)\n",
      "  %354 = Constant[value = <Scalar Tensor []>]()\n",
      "  %355 = Add(%339, %354)\n",
      "  %356 = Cast[to = 7](%189)\n",
      "  %357 = Cast[to = 7](%355)\n",
      "  %358 = Cast[to = 7](%187)\n",
      "  %359 = Range(%356, %357, %358)\n",
      "  %360 = Constant[value = <Tensor>]()\n",
      "  %361 = Unsqueeze(%359, %360)\n",
      "  %362 = Reshape[allowzero = 0](%361, %349)\n",
      "  %363 = Constant[value = <Tensor>]()\n",
      "  %364 = Unsqueeze(%353, %363)\n",
      "  %365 = Constant[value = <Tensor>]()\n",
      "  %366 = Unsqueeze(%184, %365)\n",
      "  %367 = Concat[axis = 0](%364, %366)\n",
      "  %368 = Reshape[allowzero = 0](%attention_mask.13, %367)\n",
      "  %369 = Constant[value = <Tensor>]()\n",
      "  %370 = Unsqueeze(%368, %369)\n",
      "  %371 = Constant[value = <Tensor>]()\n",
      "  %372 = Unsqueeze(%370, %371)\n",
      "  %373 = Cast[to = 1](%372)\n",
      "  %374 = Constant[value = <Scalar Tensor []>]()\n",
      "  %375 = Sub(%374, %373)\n",
      "  %376 = Constant[value = <Scalar Tensor []>]()\n",
      "  %377 = Mul(%375, %376)\n",
      "  %378 = Gather(%decoder_no_past.decoder.transformer.wte.weight, %350)\n",
      "  %379 = Gather(%decoder_no_past.decoder.transformer.wpe.weight, %362)\n",
      "  %380 = Add(%378, %379)\n",
      "  %381 = Shape(%380)\n",
      "  %382 = Constant[value = <Tensor>]()\n",
      "  %383 = Constant[value = <Tensor>]()\n",
      "  %384 = Constant[value = <Tensor>]()\n",
      "  %385 = Slice(%381, %383, %384, %382)\n",
      "  %386 = Constant[value = <Tensor>]()\n",
      "  %387 = Squeeze(%385, %386)\n",
      "  %388 = ReduceMean[axes = [-1]](%380)\n",
      "  %389 = Sub(%380, %388)\n",
      "  %390 = Constant[value = <Scalar Tensor []>]()\n",
      "  %391 = Pow(%389, %390)\n",
      "  %392 = ReduceMean[axes = [-1]](%391)\n",
      "  %393 = Constant[value = <Scalar Tensor []>]()\n",
      "  %394 = Add(%392, %393)\n",
      "  %395 = Sqrt(%394)\n",
      "  %396 = Div(%389, %395)\n",
      "  %397 = Mul(%396, %decoder_no_past.decoder.transformer.h.0.ln_1.weight)\n",
      "  %398 = Add(%397, %decoder_no_past.decoder.transformer.h.0.ln_1.bias)\n",
      "  %399 = Shape(%398)\n",
      "  %400 = Constant[value = <Scalar Tensor []>]()\n",
      "  %401 = Gather[axis = 0](%399, %400)\n",
      "  %402 = Shape(%398)\n",
      "  %403 = Constant[value = <Scalar Tensor []>]()\n",
      "  %404 = Gather[axis = 0](%402, %403)\n",
      "  %405 = Shape(%398)\n",
      "  %406 = Constant[value = <Tensor>]()\n",
      "  %407 = Constant[value = <Tensor>]()\n",
      "  %408 = Constant[value = <Tensor>]()\n",
      "  %409 = Slice(%405, %407, %408, %406)\n",
      "  %410 = Constant[value = <Tensor>]()\n",
      "  %411 = Squeeze(%409, %410)\n",
      "  %412 = Constant[value = <Tensor>]()\n",
      "  %413 = Unsqueeze(%184, %412)\n",
      "  %414 = Constant[value = <Tensor>]()\n",
      "  %415 = Unsqueeze(%411, %414)\n",
      "  %416 = Concat[axis = 0](%413, %415)\n",
      "  %417 = Reshape[allowzero = 0](%398, %416)\n",
      "  %418 = Gemm[alpha = 1, beta = 1](%417, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias)\n",
      "  %419 = Constant[value = <Tensor>]()\n",
      "  %420 = Unsqueeze(%401, %419)\n",
      "  %421 = Constant[value = <Tensor>]()\n",
      "  %422 = Unsqueeze(%404, %421)\n",
      "  %423 = Constant[value = <Tensor>]()\n",
      "  %424 = Unsqueeze(%180, %423)\n",
      "  %425 = Concat[axis = 0](%420, %422, %424)\n",
      "  %426 = Reshape[allowzero = 0](%418, %425)\n",
      "  %427 = Constant[value = <Tensor>]()\n",
      "  %428, %429, %430 = Split[axis = 2](%426, %427)\n",
      "  %431 = Shape(%428)\n",
      "  %432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %433 = Gather[axis = 0](%431, %432)\n",
      "  %434 = Shape(%428)\n",
      "  %435 = Constant[value = <Scalar Tensor []>]()\n",
      "  %436 = Gather[axis = 0](%434, %435)\n",
      "  %437 = Constant[value = <Tensor>]()\n",
      "  %438 = Unsqueeze(%433, %437)\n",
      "  %439 = Constant[value = <Tensor>]()\n",
      "  %440 = Unsqueeze(%436, %439)\n",
      "  %441 = Constant[value = <Tensor>]()\n",
      "  %442 = Unsqueeze(%179, %441)\n",
      "  %443 = Constant[value = <Tensor>]()\n",
      "  %444 = Unsqueeze(%178, %443)\n",
      "  %445 = Concat[axis = 0](%438, %440, %442, %444)\n",
      "  %446 = Reshape[allowzero = 0](%428, %445)\n",
      "  %447 = Transpose[perm = [0, 2, 1, 3]](%446)\n",
      "  %448 = Shape(%429)\n",
      "  %449 = Constant[value = <Scalar Tensor []>]()\n",
      "  %450 = Gather[axis = 0](%448, %449)\n",
      "  %451 = Shape(%429)\n",
      "  %452 = Constant[value = <Scalar Tensor []>]()\n",
      "  %453 = Gather[axis = 0](%451, %452)\n",
      "  %454 = Constant[value = <Tensor>]()\n",
      "  %455 = Unsqueeze(%450, %454)\n",
      "  %456 = Constant[value = <Tensor>]()\n",
      "  %457 = Unsqueeze(%453, %456)\n",
      "  %458 = Constant[value = <Tensor>]()\n",
      "  %459 = Unsqueeze(%179, %458)\n",
      "  %460 = Constant[value = <Tensor>]()\n",
      "  %461 = Unsqueeze(%178, %460)\n",
      "  %462 = Concat[axis = 0](%455, %457, %459, %461)\n",
      "  %463 = Reshape[allowzero = 0](%429, %462)\n",
      "  %464 = Transpose[perm = [0, 2, 1, 3]](%463)\n",
      "  %465 = Shape(%430)\n",
      "  %466 = Constant[value = <Scalar Tensor []>]()\n",
      "  %467 = Gather[axis = 0](%465, %466)\n",
      "  %468 = Shape(%430)\n",
      "  %469 = Constant[value = <Scalar Tensor []>]()\n",
      "  %470 = Gather[axis = 0](%468, %469)\n",
      "  %471 = Constant[value = <Tensor>]()\n",
      "  %472 = Unsqueeze(%467, %471)\n",
      "  %473 = Constant[value = <Tensor>]()\n",
      "  %474 = Unsqueeze(%470, %473)\n",
      "  %475 = Constant[value = <Tensor>]()\n",
      "  %476 = Unsqueeze(%179, %475)\n",
      "  %477 = Constant[value = <Tensor>]()\n",
      "  %478 = Unsqueeze(%178, %477)\n",
      "  %479 = Concat[axis = 0](%472, %474, %476, %478)\n",
      "  %480 = Reshape[allowzero = 0](%430, %479)\n",
      "  %481 = Transpose[perm = [0, 2, 1, 3]](%480)\n",
      "  %482 = Transpose[perm = [0, 2, 3, 1]](%463)\n",
      "  %483 = MatMul(%447, %482)\n",
      "  %484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %485 = Div(%483, %484)\n",
      "  %486 = Shape(%447)\n",
      "  %487 = Constant[value = <Tensor>]()\n",
      "  %488 = Constant[value = <Tensor>]()\n",
      "  %489 = Constant[value = <Tensor>]()\n",
      "  %490 = Slice(%486, %488, %489, %487)\n",
      "  %491 = Constant[value = <Tensor>]()\n",
      "  %492 = Squeeze(%490, %491)\n",
      "  %493 = Shape(%464)\n",
      "  %494 = Constant[value = <Tensor>]()\n",
      "  %495 = Constant[value = <Tensor>]()\n",
      "  %496 = Constant[value = <Tensor>]()\n",
      "  %497 = Slice(%493, %495, %496, %494)\n",
      "  %498 = Constant[value = <Tensor>]()\n",
      "  %499 = Squeeze(%497, %498)\n",
      "  %500 = Sub(%499, %492)\n",
      "  %501 = Constant[value = <Tensor>]()\n",
      "  %502 = Unsqueeze(%500, %501)\n",
      "  %503 = Constant[value = <Tensor>]()\n",
      "  %504 = Unsqueeze(%499, %503)\n",
      "  %505 = Constant[value = <Tensor>]()\n",
      "  %506 = Unsqueeze(%188, %505)\n",
      "  %507 = Constant[value = <Tensor>]()\n",
      "  %508 = Slice(%decoder_no_past.decoder.transformer.h.0.attn.bias, %502, %504, %506, %507)\n",
      "  %509 = Constant[value = <Tensor>]()\n",
      "  %510 = Unsqueeze(%189, %509)\n",
      "  %511 = Constant[value = <Tensor>]()\n",
      "  %512 = Unsqueeze(%499, %511)\n",
      "  %513 = Constant[value = <Tensor>]()\n",
      "  %514 = Unsqueeze(%183, %513)\n",
      "  %515 = Constant[value = <Tensor>]()\n",
      "  %516 = Slice(%508, %510, %512, %514, %515)\n",
      "  %517 = Cast[to = 9](%516)\n",
      "  %518 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.0.attn.masked_bias)\n",
      "  %519 = Where(%517, %485, %518)\n",
      "  %520 = Add(%519, %377)\n",
      "  %521 = Softmax[axis = -1](%520)\n",
      "  %522 = MatMul(%521, %481)\n",
      "  %523 = Transpose[perm = [0, 2, 1, 3]](%522)\n",
      "  %524 = Shape(%523)\n",
      "  %525 = Constant[value = <Scalar Tensor []>]()\n",
      "  %526 = Gather[axis = 0](%524, %525)\n",
      "  %527 = Shape(%523)\n",
      "  %528 = Constant[value = <Scalar Tensor []>]()\n",
      "  %529 = Gather[axis = 0](%527, %528)\n",
      "  %530 = Constant[value = <Tensor>]()\n",
      "  %531 = Unsqueeze(%526, %530)\n",
      "  %532 = Constant[value = <Tensor>]()\n",
      "  %533 = Unsqueeze(%529, %532)\n",
      "  %534 = Constant[value = <Tensor>]()\n",
      "  %535 = Unsqueeze(%181, %534)\n",
      "  %536 = Concat[axis = 0](%531, %533, %535)\n",
      "  %537 = Reshape[allowzero = 0](%523, %536)\n",
      "  %538 = Shape(%537)\n",
      "  %539 = Constant[value = <Scalar Tensor []>]()\n",
      "  %540 = Gather[axis = 0](%538, %539)\n",
      "  %541 = Shape(%537)\n",
      "  %542 = Constant[value = <Scalar Tensor []>]()\n",
      "  %543 = Gather[axis = 0](%541, %542)\n",
      "  %544 = Shape(%537)\n",
      "  %545 = Constant[value = <Tensor>]()\n",
      "  %546 = Constant[value = <Tensor>]()\n",
      "  %547 = Constant[value = <Tensor>]()\n",
      "  %548 = Slice(%544, %546, %547, %545)\n",
      "  %549 = Constant[value = <Tensor>]()\n",
      "  %550 = Squeeze(%548, %549)\n",
      "  %551 = Constant[value = <Tensor>]()\n",
      "  %552 = Unsqueeze(%184, %551)\n",
      "  %553 = Constant[value = <Tensor>]()\n",
      "  %554 = Unsqueeze(%550, %553)\n",
      "  %555 = Concat[axis = 0](%552, %554)\n",
      "  %556 = Reshape[allowzero = 0](%537, %555)\n",
      "  %557 = Gemm[alpha = 1, beta = 1](%556, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias)\n",
      "  %558 = Constant[value = <Tensor>]()\n",
      "  %559 = Unsqueeze(%540, %558)\n",
      "  %560 = Constant[value = <Tensor>]()\n",
      "  %561 = Unsqueeze(%543, %560)\n",
      "  %562 = Constant[value = <Tensor>]()\n",
      "  %563 = Unsqueeze(%181, %562)\n",
      "  %564 = Concat[axis = 0](%559, %561, %563)\n",
      "  %565 = Reshape[allowzero = 0](%557, %564)\n",
      "  %566 = Add(%565, %380)\n",
      "  %567 = ReduceMean[axes = [-1]](%566)\n",
      "  %568 = Sub(%566, %567)\n",
      "  %569 = Constant[value = <Scalar Tensor []>]()\n",
      "  %570 = Pow(%568, %569)\n",
      "  %571 = ReduceMean[axes = [-1]](%570)\n",
      "  %572 = Constant[value = <Scalar Tensor []>]()\n",
      "  %573 = Add(%571, %572)\n",
      "  %574 = Sqrt(%573)\n",
      "  %575 = Div(%568, %574)\n",
      "  %576 = Mul(%575, %decoder_no_past.decoder.transformer.h.0.ln_2.weight)\n",
      "  %577 = Add(%576, %decoder_no_past.decoder.transformer.h.0.ln_2.bias)\n",
      "  %578 = Shape(%577)\n",
      "  %579 = Constant[value = <Scalar Tensor []>]()\n",
      "  %580 = Gather[axis = 0](%578, %579)\n",
      "  %581 = Shape(%577)\n",
      "  %582 = Constant[value = <Scalar Tensor []>]()\n",
      "  %583 = Gather[axis = 0](%581, %582)\n",
      "  %584 = Shape(%577)\n",
      "  %585 = Constant[value = <Tensor>]()\n",
      "  %586 = Constant[value = <Tensor>]()\n",
      "  %587 = Constant[value = <Tensor>]()\n",
      "  %588 = Slice(%584, %586, %587, %585)\n",
      "  %589 = Constant[value = <Tensor>]()\n",
      "  %590 = Squeeze(%588, %589)\n",
      "  %591 = Constant[value = <Tensor>]()\n",
      "  %592 = Unsqueeze(%184, %591)\n",
      "  %593 = Constant[value = <Tensor>]()\n",
      "  %594 = Unsqueeze(%590, %593)\n",
      "  %595 = Concat[axis = 0](%592, %594)\n",
      "  %596 = Reshape[allowzero = 0](%577, %595)\n",
      "  %597 = Gemm[alpha = 1, beta = 1](%596, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias)\n",
      "  %598 = Constant[value = <Tensor>]()\n",
      "  %599 = Unsqueeze(%580, %598)\n",
      "  %600 = Constant[value = <Tensor>]()\n",
      "  %601 = Unsqueeze(%583, %600)\n",
      "  %602 = Constant[value = <Tensor>]()\n",
      "  %603 = Unsqueeze(%177, %602)\n",
      "  %604 = Concat[axis = 0](%599, %601, %603)\n",
      "  %605 = Reshape[allowzero = 0](%597, %604)\n",
      "  %606 = Constant[value = <Scalar Tensor []>]()\n",
      "  %607 = Mul(%605, %606)\n",
      "  %608 = Constant[value = <Scalar Tensor []>]()\n",
      "  %609 = Pow(%605, %608)\n",
      "  %610 = Constant[value = <Scalar Tensor []>]()\n",
      "  %611 = Mul(%609, %610)\n",
      "  %612 = Add(%605, %611)\n",
      "  %613 = Constant[value = <Scalar Tensor []>]()\n",
      "  %614 = Mul(%612, %613)\n",
      "  %615 = Tanh(%614)\n",
      "  %616 = Constant[value = <Scalar Tensor []>]()\n",
      "  %617 = Add(%615, %616)\n",
      "  %618 = Mul(%607, %617)\n",
      "  %619 = Shape(%618)\n",
      "  %620 = Constant[value = <Scalar Tensor []>]()\n",
      "  %621 = Gather[axis = 0](%619, %620)\n",
      "  %622 = Shape(%618)\n",
      "  %623 = Constant[value = <Scalar Tensor []>]()\n",
      "  %624 = Gather[axis = 0](%622, %623)\n",
      "  %625 = Shape(%618)\n",
      "  %626 = Constant[value = <Tensor>]()\n",
      "  %627 = Constant[value = <Tensor>]()\n",
      "  %628 = Constant[value = <Tensor>]()\n",
      "  %629 = Slice(%625, %627, %628, %626)\n",
      "  %630 = Constant[value = <Tensor>]()\n",
      "  %631 = Squeeze(%629, %630)\n",
      "  %632 = Constant[value = <Tensor>]()\n",
      "  %633 = Unsqueeze(%184, %632)\n",
      "  %634 = Constant[value = <Tensor>]()\n",
      "  %635 = Unsqueeze(%631, %634)\n",
      "  %636 = Concat[axis = 0](%633, %635)\n",
      "  %637 = Reshape[allowzero = 0](%618, %636)\n",
      "  %638 = Gemm[alpha = 1, beta = 1](%637, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias)\n",
      "  %639 = Constant[value = <Tensor>]()\n",
      "  %640 = Unsqueeze(%621, %639)\n",
      "  %641 = Constant[value = <Tensor>]()\n",
      "  %642 = Unsqueeze(%624, %641)\n",
      "  %643 = Constant[value = <Tensor>]()\n",
      "  %644 = Unsqueeze(%181, %643)\n",
      "  %645 = Concat[axis = 0](%640, %642, %644)\n",
      "  %646 = Reshape[allowzero = 0](%638, %645)\n",
      "  %647 = Add(%566, %646)\n",
      "  %648 = ReduceMean[axes = [-1]](%647)\n",
      "  %649 = Sub(%647, %648)\n",
      "  %650 = Constant[value = <Scalar Tensor []>]()\n",
      "  %651 = Pow(%649, %650)\n",
      "  %652 = ReduceMean[axes = [-1]](%651)\n",
      "  %653 = Constant[value = <Scalar Tensor []>]()\n",
      "  %654 = Add(%652, %653)\n",
      "  %655 = Sqrt(%654)\n",
      "  %656 = Div(%649, %655)\n",
      "  %657 = Mul(%656, %decoder_no_past.decoder.transformer.h.1.ln_1.weight)\n",
      "  %658 = Add(%657, %decoder_no_past.decoder.transformer.h.1.ln_1.bias)\n",
      "  %659 = Shape(%658)\n",
      "  %660 = Constant[value = <Scalar Tensor []>]()\n",
      "  %661 = Gather[axis = 0](%659, %660)\n",
      "  %662 = Shape(%658)\n",
      "  %663 = Constant[value = <Scalar Tensor []>]()\n",
      "  %664 = Gather[axis = 0](%662, %663)\n",
      "  %665 = Shape(%658)\n",
      "  %666 = Constant[value = <Tensor>]()\n",
      "  %667 = Constant[value = <Tensor>]()\n",
      "  %668 = Constant[value = <Tensor>]()\n",
      "  %669 = Slice(%665, %667, %668, %666)\n",
      "  %670 = Constant[value = <Tensor>]()\n",
      "  %671 = Squeeze(%669, %670)\n",
      "  %672 = Constant[value = <Tensor>]()\n",
      "  %673 = Unsqueeze(%184, %672)\n",
      "  %674 = Constant[value = <Tensor>]()\n",
      "  %675 = Unsqueeze(%671, %674)\n",
      "  %676 = Concat[axis = 0](%673, %675)\n",
      "  %677 = Reshape[allowzero = 0](%658, %676)\n",
      "  %678 = Gemm[alpha = 1, beta = 1](%677, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias)\n",
      "  %679 = Constant[value = <Tensor>]()\n",
      "  %680 = Unsqueeze(%661, %679)\n",
      "  %681 = Constant[value = <Tensor>]()\n",
      "  %682 = Unsqueeze(%664, %681)\n",
      "  %683 = Constant[value = <Tensor>]()\n",
      "  %684 = Unsqueeze(%180, %683)\n",
      "  %685 = Concat[axis = 0](%680, %682, %684)\n",
      "  %686 = Reshape[allowzero = 0](%678, %685)\n",
      "  %687 = Constant[value = <Tensor>]()\n",
      "  %688, %689, %690 = Split[axis = 2](%686, %687)\n",
      "  %691 = Shape(%688)\n",
      "  %692 = Constant[value = <Scalar Tensor []>]()\n",
      "  %693 = Gather[axis = 0](%691, %692)\n",
      "  %694 = Shape(%688)\n",
      "  %695 = Constant[value = <Scalar Tensor []>]()\n",
      "  %696 = Gather[axis = 0](%694, %695)\n",
      "  %697 = Constant[value = <Tensor>]()\n",
      "  %698 = Unsqueeze(%693, %697)\n",
      "  %699 = Constant[value = <Tensor>]()\n",
      "  %700 = Unsqueeze(%696, %699)\n",
      "  %701 = Constant[value = <Tensor>]()\n",
      "  %702 = Unsqueeze(%179, %701)\n",
      "  %703 = Constant[value = <Tensor>]()\n",
      "  %704 = Unsqueeze(%178, %703)\n",
      "  %705 = Concat[axis = 0](%698, %700, %702, %704)\n",
      "  %706 = Reshape[allowzero = 0](%688, %705)\n",
      "  %707 = Transpose[perm = [0, 2, 1, 3]](%706)\n",
      "  %708 = Shape(%689)\n",
      "  %709 = Constant[value = <Scalar Tensor []>]()\n",
      "  %710 = Gather[axis = 0](%708, %709)\n",
      "  %711 = Shape(%689)\n",
      "  %712 = Constant[value = <Scalar Tensor []>]()\n",
      "  %713 = Gather[axis = 0](%711, %712)\n",
      "  %714 = Constant[value = <Tensor>]()\n",
      "  %715 = Unsqueeze(%710, %714)\n",
      "  %716 = Constant[value = <Tensor>]()\n",
      "  %717 = Unsqueeze(%713, %716)\n",
      "  %718 = Constant[value = <Tensor>]()\n",
      "  %719 = Unsqueeze(%179, %718)\n",
      "  %720 = Constant[value = <Tensor>]()\n",
      "  %721 = Unsqueeze(%178, %720)\n",
      "  %722 = Concat[axis = 0](%715, %717, %719, %721)\n",
      "  %723 = Reshape[allowzero = 0](%689, %722)\n",
      "  %724 = Transpose[perm = [0, 2, 1, 3]](%723)\n",
      "  %725 = Shape(%690)\n",
      "  %726 = Constant[value = <Scalar Tensor []>]()\n",
      "  %727 = Gather[axis = 0](%725, %726)\n",
      "  %728 = Shape(%690)\n",
      "  %729 = Constant[value = <Scalar Tensor []>]()\n",
      "  %730 = Gather[axis = 0](%728, %729)\n",
      "  %731 = Constant[value = <Tensor>]()\n",
      "  %732 = Unsqueeze(%727, %731)\n",
      "  %733 = Constant[value = <Tensor>]()\n",
      "  %734 = Unsqueeze(%730, %733)\n",
      "  %735 = Constant[value = <Tensor>]()\n",
      "  %736 = Unsqueeze(%179, %735)\n",
      "  %737 = Constant[value = <Tensor>]()\n",
      "  %738 = Unsqueeze(%178, %737)\n",
      "  %739 = Concat[axis = 0](%732, %734, %736, %738)\n",
      "  %740 = Reshape[allowzero = 0](%690, %739)\n",
      "  %741 = Transpose[perm = [0, 2, 1, 3]](%740)\n",
      "  %742 = Transpose[perm = [0, 2, 3, 1]](%723)\n",
      "  %743 = MatMul(%707, %742)\n",
      "  %744 = Constant[value = <Scalar Tensor []>]()\n",
      "  %745 = Div(%743, %744)\n",
      "  %746 = Shape(%707)\n",
      "  %747 = Constant[value = <Tensor>]()\n",
      "  %748 = Constant[value = <Tensor>]()\n",
      "  %749 = Constant[value = <Tensor>]()\n",
      "  %750 = Slice(%746, %748, %749, %747)\n",
      "  %751 = Constant[value = <Tensor>]()\n",
      "  %752 = Squeeze(%750, %751)\n",
      "  %753 = Shape(%724)\n",
      "  %754 = Constant[value = <Tensor>]()\n",
      "  %755 = Constant[value = <Tensor>]()\n",
      "  %756 = Constant[value = <Tensor>]()\n",
      "  %757 = Slice(%753, %755, %756, %754)\n",
      "  %758 = Constant[value = <Tensor>]()\n",
      "  %759 = Squeeze(%757, %758)\n",
      "  %760 = Sub(%759, %752)\n",
      "  %761 = Constant[value = <Tensor>]()\n",
      "  %762 = Unsqueeze(%760, %761)\n",
      "  %763 = Constant[value = <Tensor>]()\n",
      "  %764 = Unsqueeze(%759, %763)\n",
      "  %765 = Constant[value = <Tensor>]()\n",
      "  %766 = Unsqueeze(%188, %765)\n",
      "  %767 = Constant[value = <Tensor>]()\n",
      "  %768 = Slice(%decoder_no_past.decoder.transformer.h.1.attn.bias, %762, %764, %766, %767)\n",
      "  %769 = Constant[value = <Tensor>]()\n",
      "  %770 = Unsqueeze(%189, %769)\n",
      "  %771 = Constant[value = <Tensor>]()\n",
      "  %772 = Unsqueeze(%759, %771)\n",
      "  %773 = Constant[value = <Tensor>]()\n",
      "  %774 = Unsqueeze(%183, %773)\n",
      "  %775 = Constant[value = <Tensor>]()\n",
      "  %776 = Slice(%768, %770, %772, %774, %775)\n",
      "  %777 = Cast[to = 9](%776)\n",
      "  %778 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.1.attn.masked_bias)\n",
      "  %779 = Where(%777, %745, %778)\n",
      "  %780 = Add(%779, %377)\n",
      "  %781 = Softmax[axis = -1](%780)\n",
      "  %782 = MatMul(%781, %741)\n",
      "  %783 = Transpose[perm = [0, 2, 1, 3]](%782)\n",
      "  %784 = Shape(%783)\n",
      "  %785 = Constant[value = <Scalar Tensor []>]()\n",
      "  %786 = Gather[axis = 0](%784, %785)\n",
      "  %787 = Shape(%783)\n",
      "  %788 = Constant[value = <Scalar Tensor []>]()\n",
      "  %789 = Gather[axis = 0](%787, %788)\n",
      "  %790 = Constant[value = <Tensor>]()\n",
      "  %791 = Unsqueeze(%786, %790)\n",
      "  %792 = Constant[value = <Tensor>]()\n",
      "  %793 = Unsqueeze(%789, %792)\n",
      "  %794 = Constant[value = <Tensor>]()\n",
      "  %795 = Unsqueeze(%181, %794)\n",
      "  %796 = Concat[axis = 0](%791, %793, %795)\n",
      "  %797 = Reshape[allowzero = 0](%783, %796)\n",
      "  %798 = Shape(%797)\n",
      "  %799 = Constant[value = <Scalar Tensor []>]()\n",
      "  %800 = Gather[axis = 0](%798, %799)\n",
      "  %801 = Shape(%797)\n",
      "  %802 = Constant[value = <Scalar Tensor []>]()\n",
      "  %803 = Gather[axis = 0](%801, %802)\n",
      "  %804 = Shape(%797)\n",
      "  %805 = Constant[value = <Tensor>]()\n",
      "  %806 = Constant[value = <Tensor>]()\n",
      "  %807 = Constant[value = <Tensor>]()\n",
      "  %808 = Slice(%804, %806, %807, %805)\n",
      "  %809 = Constant[value = <Tensor>]()\n",
      "  %810 = Squeeze(%808, %809)\n",
      "  %811 = Constant[value = <Tensor>]()\n",
      "  %812 = Unsqueeze(%184, %811)\n",
      "  %813 = Constant[value = <Tensor>]()\n",
      "  %814 = Unsqueeze(%810, %813)\n",
      "  %815 = Concat[axis = 0](%812, %814)\n",
      "  %816 = Reshape[allowzero = 0](%797, %815)\n",
      "  %817 = Gemm[alpha = 1, beta = 1](%816, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias)\n",
      "  %818 = Constant[value = <Tensor>]()\n",
      "  %819 = Unsqueeze(%800, %818)\n",
      "  %820 = Constant[value = <Tensor>]()\n",
      "  %821 = Unsqueeze(%803, %820)\n",
      "  %822 = Constant[value = <Tensor>]()\n",
      "  %823 = Unsqueeze(%181, %822)\n",
      "  %824 = Concat[axis = 0](%819, %821, %823)\n",
      "  %825 = Reshape[allowzero = 0](%817, %824)\n",
      "  %826 = Add(%825, %647)\n",
      "  %827 = ReduceMean[axes = [-1]](%826)\n",
      "  %828 = Sub(%826, %827)\n",
      "  %829 = Constant[value = <Scalar Tensor []>]()\n",
      "  %830 = Pow(%828, %829)\n",
      "  %831 = ReduceMean[axes = [-1]](%830)\n",
      "  %832 = Constant[value = <Scalar Tensor []>]()\n",
      "  %833 = Add(%831, %832)\n",
      "  %834 = Sqrt(%833)\n",
      "  %835 = Div(%828, %834)\n",
      "  %836 = Mul(%835, %decoder_no_past.decoder.transformer.h.1.ln_2.weight)\n",
      "  %837 = Add(%836, %decoder_no_past.decoder.transformer.h.1.ln_2.bias)\n",
      "  %838 = Shape(%837)\n",
      "  %839 = Constant[value = <Scalar Tensor []>]()\n",
      "  %840 = Gather[axis = 0](%838, %839)\n",
      "  %841 = Shape(%837)\n",
      "  %842 = Constant[value = <Scalar Tensor []>]()\n",
      "  %843 = Gather[axis = 0](%841, %842)\n",
      "  %844 = Shape(%837)\n",
      "  %845 = Constant[value = <Tensor>]()\n",
      "  %846 = Constant[value = <Tensor>]()\n",
      "  %847 = Constant[value = <Tensor>]()\n",
      "  %848 = Slice(%844, %846, %847, %845)\n",
      "  %849 = Constant[value = <Tensor>]()\n",
      "  %850 = Squeeze(%848, %849)\n",
      "  %851 = Constant[value = <Tensor>]()\n",
      "  %852 = Unsqueeze(%184, %851)\n",
      "  %853 = Constant[value = <Tensor>]()\n",
      "  %854 = Unsqueeze(%850, %853)\n",
      "  %855 = Concat[axis = 0](%852, %854)\n",
      "  %856 = Reshape[allowzero = 0](%837, %855)\n",
      "  %857 = Gemm[alpha = 1, beta = 1](%856, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias)\n",
      "  %858 = Constant[value = <Tensor>]()\n",
      "  %859 = Unsqueeze(%840, %858)\n",
      "  %860 = Constant[value = <Tensor>]()\n",
      "  %861 = Unsqueeze(%843, %860)\n",
      "  %862 = Constant[value = <Tensor>]()\n",
      "  %863 = Unsqueeze(%177, %862)\n",
      "  %864 = Concat[axis = 0](%859, %861, %863)\n",
      "  %865 = Reshape[allowzero = 0](%857, %864)\n",
      "  %866 = Constant[value = <Scalar Tensor []>]()\n",
      "  %867 = Mul(%865, %866)\n",
      "  %868 = Constant[value = <Scalar Tensor []>]()\n",
      "  %869 = Pow(%865, %868)\n",
      "  %870 = Constant[value = <Scalar Tensor []>]()\n",
      "  %871 = Mul(%869, %870)\n",
      "  %872 = Add(%865, %871)\n",
      "  %873 = Constant[value = <Scalar Tensor []>]()\n",
      "  %874 = Mul(%872, %873)\n",
      "  %875 = Tanh(%874)\n",
      "  %876 = Constant[value = <Scalar Tensor []>]()\n",
      "  %877 = Add(%875, %876)\n",
      "  %878 = Mul(%867, %877)\n",
      "  %879 = Shape(%878)\n",
      "  %880 = Constant[value = <Scalar Tensor []>]()\n",
      "  %881 = Gather[axis = 0](%879, %880)\n",
      "  %882 = Shape(%878)\n",
      "  %883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %884 = Gather[axis = 0](%882, %883)\n",
      "  %885 = Shape(%878)\n",
      "  %886 = Constant[value = <Tensor>]()\n",
      "  %887 = Constant[value = <Tensor>]()\n",
      "  %888 = Constant[value = <Tensor>]()\n",
      "  %889 = Slice(%885, %887, %888, %886)\n",
      "  %890 = Constant[value = <Tensor>]()\n",
      "  %891 = Squeeze(%889, %890)\n",
      "  %892 = Constant[value = <Tensor>]()\n",
      "  %893 = Unsqueeze(%184, %892)\n",
      "  %894 = Constant[value = <Tensor>]()\n",
      "  %895 = Unsqueeze(%891, %894)\n",
      "  %896 = Concat[axis = 0](%893, %895)\n",
      "  %897 = Reshape[allowzero = 0](%878, %896)\n",
      "  %898 = Gemm[alpha = 1, beta = 1](%897, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias)\n",
      "  %899 = Constant[value = <Tensor>]()\n",
      "  %900 = Unsqueeze(%881, %899)\n",
      "  %901 = Constant[value = <Tensor>]()\n",
      "  %902 = Unsqueeze(%884, %901)\n",
      "  %903 = Constant[value = <Tensor>]()\n",
      "  %904 = Unsqueeze(%181, %903)\n",
      "  %905 = Concat[axis = 0](%900, %902, %904)\n",
      "  %906 = Reshape[allowzero = 0](%898, %905)\n",
      "  %907 = Add(%826, %906)\n",
      "  %908 = ReduceMean[axes = [-1]](%907)\n",
      "  %909 = Sub(%907, %908)\n",
      "  %910 = Constant[value = <Scalar Tensor []>]()\n",
      "  %911 = Pow(%909, %910)\n",
      "  %912 = ReduceMean[axes = [-1]](%911)\n",
      "  %913 = Constant[value = <Scalar Tensor []>]()\n",
      "  %914 = Add(%912, %913)\n",
      "  %915 = Sqrt(%914)\n",
      "  %916 = Div(%909, %915)\n",
      "  %917 = Mul(%916, %decoder_no_past.decoder.transformer.h.2.ln_1.weight)\n",
      "  %918 = Add(%917, %decoder_no_past.decoder.transformer.h.2.ln_1.bias)\n",
      "  %919 = Shape(%918)\n",
      "  %920 = Constant[value = <Scalar Tensor []>]()\n",
      "  %921 = Gather[axis = 0](%919, %920)\n",
      "  %922 = Shape(%918)\n",
      "  %923 = Constant[value = <Scalar Tensor []>]()\n",
      "  %924 = Gather[axis = 0](%922, %923)\n",
      "  %925 = Shape(%918)\n",
      "  %926 = Constant[value = <Tensor>]()\n",
      "  %927 = Constant[value = <Tensor>]()\n",
      "  %928 = Constant[value = <Tensor>]()\n",
      "  %929 = Slice(%925, %927, %928, %926)\n",
      "  %930 = Constant[value = <Tensor>]()\n",
      "  %931 = Squeeze(%929, %930)\n",
      "  %932 = Constant[value = <Tensor>]()\n",
      "  %933 = Unsqueeze(%184, %932)\n",
      "  %934 = Constant[value = <Tensor>]()\n",
      "  %935 = Unsqueeze(%931, %934)\n",
      "  %936 = Concat[axis = 0](%933, %935)\n",
      "  %937 = Reshape[allowzero = 0](%918, %936)\n",
      "  %938 = Gemm[alpha = 1, beta = 1](%937, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias)\n",
      "  %939 = Constant[value = <Tensor>]()\n",
      "  %940 = Unsqueeze(%921, %939)\n",
      "  %941 = Constant[value = <Tensor>]()\n",
      "  %942 = Unsqueeze(%924, %941)\n",
      "  %943 = Constant[value = <Tensor>]()\n",
      "  %944 = Unsqueeze(%180, %943)\n",
      "  %945 = Concat[axis = 0](%940, %942, %944)\n",
      "  %946 = Reshape[allowzero = 0](%938, %945)\n",
      "  %947 = Constant[value = <Tensor>]()\n",
      "  %948, %949, %950 = Split[axis = 2](%946, %947)\n",
      "  %951 = Shape(%948)\n",
      "  %952 = Constant[value = <Scalar Tensor []>]()\n",
      "  %953 = Gather[axis = 0](%951, %952)\n",
      "  %954 = Shape(%948)\n",
      "  %955 = Constant[value = <Scalar Tensor []>]()\n",
      "  %956 = Gather[axis = 0](%954, %955)\n",
      "  %957 = Constant[value = <Tensor>]()\n",
      "  %958 = Unsqueeze(%953, %957)\n",
      "  %959 = Constant[value = <Tensor>]()\n",
      "  %960 = Unsqueeze(%956, %959)\n",
      "  %961 = Constant[value = <Tensor>]()\n",
      "  %962 = Unsqueeze(%179, %961)\n",
      "  %963 = Constant[value = <Tensor>]()\n",
      "  %964 = Unsqueeze(%178, %963)\n",
      "  %965 = Concat[axis = 0](%958, %960, %962, %964)\n",
      "  %966 = Reshape[allowzero = 0](%948, %965)\n",
      "  %967 = Transpose[perm = [0, 2, 1, 3]](%966)\n",
      "  %968 = Shape(%949)\n",
      "  %969 = Constant[value = <Scalar Tensor []>]()\n",
      "  %970 = Gather[axis = 0](%968, %969)\n",
      "  %971 = Shape(%949)\n",
      "  %972 = Constant[value = <Scalar Tensor []>]()\n",
      "  %973 = Gather[axis = 0](%971, %972)\n",
      "  %974 = Constant[value = <Tensor>]()\n",
      "  %975 = Unsqueeze(%970, %974)\n",
      "  %976 = Constant[value = <Tensor>]()\n",
      "  %977 = Unsqueeze(%973, %976)\n",
      "  %978 = Constant[value = <Tensor>]()\n",
      "  %979 = Unsqueeze(%179, %978)\n",
      "  %980 = Constant[value = <Tensor>]()\n",
      "  %981 = Unsqueeze(%178, %980)\n",
      "  %982 = Concat[axis = 0](%975, %977, %979, %981)\n",
      "  %983 = Reshape[allowzero = 0](%949, %982)\n",
      "  %984 = Transpose[perm = [0, 2, 1, 3]](%983)\n",
      "  %985 = Shape(%950)\n",
      "  %986 = Constant[value = <Scalar Tensor []>]()\n",
      "  %987 = Gather[axis = 0](%985, %986)\n",
      "  %988 = Shape(%950)\n",
      "  %989 = Constant[value = <Scalar Tensor []>]()\n",
      "  %990 = Gather[axis = 0](%988, %989)\n",
      "  %991 = Constant[value = <Tensor>]()\n",
      "  %992 = Unsqueeze(%987, %991)\n",
      "  %993 = Constant[value = <Tensor>]()\n",
      "  %994 = Unsqueeze(%990, %993)\n",
      "  %995 = Constant[value = <Tensor>]()\n",
      "  %996 = Unsqueeze(%179, %995)\n",
      "  %997 = Constant[value = <Tensor>]()\n",
      "  %998 = Unsqueeze(%178, %997)\n",
      "  %999 = Concat[axis = 0](%992, %994, %996, %998)\n",
      "  %1000 = Reshape[allowzero = 0](%950, %999)\n",
      "  %1001 = Transpose[perm = [0, 2, 1, 3]](%1000)\n",
      "  %1002 = Transpose[perm = [0, 2, 3, 1]](%983)\n",
      "  %1003 = MatMul(%967, %1002)\n",
      "  %1004 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1005 = Div(%1003, %1004)\n",
      "  %1006 = Shape(%967)\n",
      "  %1007 = Constant[value = <Tensor>]()\n",
      "  %1008 = Constant[value = <Tensor>]()\n",
      "  %1009 = Constant[value = <Tensor>]()\n",
      "  %1010 = Slice(%1006, %1008, %1009, %1007)\n",
      "  %1011 = Constant[value = <Tensor>]()\n",
      "  %1012 = Squeeze(%1010, %1011)\n",
      "  %1013 = Shape(%984)\n",
      "  %1014 = Constant[value = <Tensor>]()\n",
      "  %1015 = Constant[value = <Tensor>]()\n",
      "  %1016 = Constant[value = <Tensor>]()\n",
      "  %1017 = Slice(%1013, %1015, %1016, %1014)\n",
      "  %1018 = Constant[value = <Tensor>]()\n",
      "  %1019 = Squeeze(%1017, %1018)\n",
      "  %1020 = Sub(%1019, %1012)\n",
      "  %1021 = Constant[value = <Tensor>]()\n",
      "  %1022 = Unsqueeze(%1020, %1021)\n",
      "  %1023 = Constant[value = <Tensor>]()\n",
      "  %1024 = Unsqueeze(%1019, %1023)\n",
      "  %1025 = Constant[value = <Tensor>]()\n",
      "  %1026 = Unsqueeze(%188, %1025)\n",
      "  %1027 = Constant[value = <Tensor>]()\n",
      "  %1028 = Slice(%decoder_no_past.decoder.transformer.h.2.attn.bias, %1022, %1024, %1026, %1027)\n",
      "  %1029 = Constant[value = <Tensor>]()\n",
      "  %1030 = Unsqueeze(%189, %1029)\n",
      "  %1031 = Constant[value = <Tensor>]()\n",
      "  %1032 = Unsqueeze(%1019, %1031)\n",
      "  %1033 = Constant[value = <Tensor>]()\n",
      "  %1034 = Unsqueeze(%183, %1033)\n",
      "  %1035 = Constant[value = <Tensor>]()\n",
      "  %1036 = Slice(%1028, %1030, %1032, %1034, %1035)\n",
      "  %1037 = Cast[to = 9](%1036)\n",
      "  %1038 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.2.attn.masked_bias)\n",
      "  %1039 = Where(%1037, %1005, %1038)\n",
      "  %1040 = Add(%1039, %377)\n",
      "  %1041 = Softmax[axis = -1](%1040)\n",
      "  %1042 = MatMul(%1041, %1001)\n",
      "  %1043 = Transpose[perm = [0, 2, 1, 3]](%1042)\n",
      "  %1044 = Shape(%1043)\n",
      "  %1045 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1046 = Gather[axis = 0](%1044, %1045)\n",
      "  %1047 = Shape(%1043)\n",
      "  %1048 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1049 = Gather[axis = 0](%1047, %1048)\n",
      "  %1050 = Constant[value = <Tensor>]()\n",
      "  %1051 = Unsqueeze(%1046, %1050)\n",
      "  %1052 = Constant[value = <Tensor>]()\n",
      "  %1053 = Unsqueeze(%1049, %1052)\n",
      "  %1054 = Constant[value = <Tensor>]()\n",
      "  %1055 = Unsqueeze(%181, %1054)\n",
      "  %1056 = Concat[axis = 0](%1051, %1053, %1055)\n",
      "  %1057 = Reshape[allowzero = 0](%1043, %1056)\n",
      "  %1058 = Shape(%1057)\n",
      "  %1059 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1060 = Gather[axis = 0](%1058, %1059)\n",
      "  %1061 = Shape(%1057)\n",
      "  %1062 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1063 = Gather[axis = 0](%1061, %1062)\n",
      "  %1064 = Shape(%1057)\n",
      "  %1065 = Constant[value = <Tensor>]()\n",
      "  %1066 = Constant[value = <Tensor>]()\n",
      "  %1067 = Constant[value = <Tensor>]()\n",
      "  %1068 = Slice(%1064, %1066, %1067, %1065)\n",
      "  %1069 = Constant[value = <Tensor>]()\n",
      "  %1070 = Squeeze(%1068, %1069)\n",
      "  %1071 = Constant[value = <Tensor>]()\n",
      "  %1072 = Unsqueeze(%184, %1071)\n",
      "  %1073 = Constant[value = <Tensor>]()\n",
      "  %1074 = Unsqueeze(%1070, %1073)\n",
      "  %1075 = Concat[axis = 0](%1072, %1074)\n",
      "  %1076 = Reshape[allowzero = 0](%1057, %1075)\n",
      "  %1077 = Gemm[alpha = 1, beta = 1](%1076, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias)\n",
      "  %1078 = Constant[value = <Tensor>]()\n",
      "  %1079 = Unsqueeze(%1060, %1078)\n",
      "  %1080 = Constant[value = <Tensor>]()\n",
      "  %1081 = Unsqueeze(%1063, %1080)\n",
      "  %1082 = Constant[value = <Tensor>]()\n",
      "  %1083 = Unsqueeze(%181, %1082)\n",
      "  %1084 = Concat[axis = 0](%1079, %1081, %1083)\n",
      "  %1085 = Reshape[allowzero = 0](%1077, %1084)\n",
      "  %1086 = Add(%1085, %907)\n",
      "  %1087 = ReduceMean[axes = [-1]](%1086)\n",
      "  %1088 = Sub(%1086, %1087)\n",
      "  %1089 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1090 = Pow(%1088, %1089)\n",
      "  %1091 = ReduceMean[axes = [-1]](%1090)\n",
      "  %1092 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1093 = Add(%1091, %1092)\n",
      "  %1094 = Sqrt(%1093)\n",
      "  %1095 = Div(%1088, %1094)\n",
      "  %1096 = Mul(%1095, %decoder_no_past.decoder.transformer.h.2.ln_2.weight)\n",
      "  %1097 = Add(%1096, %decoder_no_past.decoder.transformer.h.2.ln_2.bias)\n",
      "  %1098 = Shape(%1097)\n",
      "  %1099 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1100 = Gather[axis = 0](%1098, %1099)\n",
      "  %1101 = Shape(%1097)\n",
      "  %1102 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1103 = Gather[axis = 0](%1101, %1102)\n",
      "  %1104 = Shape(%1097)\n",
      "  %1105 = Constant[value = <Tensor>]()\n",
      "  %1106 = Constant[value = <Tensor>]()\n",
      "  %1107 = Constant[value = <Tensor>]()\n",
      "  %1108 = Slice(%1104, %1106, %1107, %1105)\n",
      "  %1109 = Constant[value = <Tensor>]()\n",
      "  %1110 = Squeeze(%1108, %1109)\n",
      "  %1111 = Constant[value = <Tensor>]()\n",
      "  %1112 = Unsqueeze(%184, %1111)\n",
      "  %1113 = Constant[value = <Tensor>]()\n",
      "  %1114 = Unsqueeze(%1110, %1113)\n",
      "  %1115 = Concat[axis = 0](%1112, %1114)\n",
      "  %1116 = Reshape[allowzero = 0](%1097, %1115)\n",
      "  %1117 = Gemm[alpha = 1, beta = 1](%1116, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias)\n",
      "  %1118 = Constant[value = <Tensor>]()\n",
      "  %1119 = Unsqueeze(%1100, %1118)\n",
      "  %1120 = Constant[value = <Tensor>]()\n",
      "  %1121 = Unsqueeze(%1103, %1120)\n",
      "  %1122 = Constant[value = <Tensor>]()\n",
      "  %1123 = Unsqueeze(%177, %1122)\n",
      "  %1124 = Concat[axis = 0](%1119, %1121, %1123)\n",
      "  %1125 = Reshape[allowzero = 0](%1117, %1124)\n",
      "  %1126 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1127 = Mul(%1125, %1126)\n",
      "  %1128 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1129 = Pow(%1125, %1128)\n",
      "  %1130 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1131 = Mul(%1129, %1130)\n",
      "  %1132 = Add(%1125, %1131)\n",
      "  %1133 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1134 = Mul(%1132, %1133)\n",
      "  %1135 = Tanh(%1134)\n",
      "  %1136 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1137 = Add(%1135, %1136)\n",
      "  %1138 = Mul(%1127, %1137)\n",
      "  %1139 = Shape(%1138)\n",
      "  %1140 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1141 = Gather[axis = 0](%1139, %1140)\n",
      "  %1142 = Shape(%1138)\n",
      "  %1143 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1144 = Gather[axis = 0](%1142, %1143)\n",
      "  %1145 = Shape(%1138)\n",
      "  %1146 = Constant[value = <Tensor>]()\n",
      "  %1147 = Constant[value = <Tensor>]()\n",
      "  %1148 = Constant[value = <Tensor>]()\n",
      "  %1149 = Slice(%1145, %1147, %1148, %1146)\n",
      "  %1150 = Constant[value = <Tensor>]()\n",
      "  %1151 = Squeeze(%1149, %1150)\n",
      "  %1152 = Constant[value = <Tensor>]()\n",
      "  %1153 = Unsqueeze(%184, %1152)\n",
      "  %1154 = Constant[value = <Tensor>]()\n",
      "  %1155 = Unsqueeze(%1151, %1154)\n",
      "  %1156 = Concat[axis = 0](%1153, %1155)\n",
      "  %1157 = Reshape[allowzero = 0](%1138, %1156)\n",
      "  %1158 = Gemm[alpha = 1, beta = 1](%1157, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias)\n",
      "  %1159 = Constant[value = <Tensor>]()\n",
      "  %1160 = Unsqueeze(%1141, %1159)\n",
      "  %1161 = Constant[value = <Tensor>]()\n",
      "  %1162 = Unsqueeze(%1144, %1161)\n",
      "  %1163 = Constant[value = <Tensor>]()\n",
      "  %1164 = Unsqueeze(%181, %1163)\n",
      "  %1165 = Concat[axis = 0](%1160, %1162, %1164)\n",
      "  %1166 = Reshape[allowzero = 0](%1158, %1165)\n",
      "  %1167 = Add(%1086, %1166)\n",
      "  %1168 = ReduceMean[axes = [-1]](%1167)\n",
      "  %1169 = Sub(%1167, %1168)\n",
      "  %1170 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1171 = Pow(%1169, %1170)\n",
      "  %1172 = ReduceMean[axes = [-1]](%1171)\n",
      "  %1173 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1174 = Add(%1172, %1173)\n",
      "  %1175 = Sqrt(%1174)\n",
      "  %1176 = Div(%1169, %1175)\n",
      "  %1177 = Mul(%1176, %decoder_no_past.decoder.transformer.h.3.ln_1.weight)\n",
      "  %1178 = Add(%1177, %decoder_no_past.decoder.transformer.h.3.ln_1.bias)\n",
      "  %1179 = Shape(%1178)\n",
      "  %1180 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1181 = Gather[axis = 0](%1179, %1180)\n",
      "  %1182 = Shape(%1178)\n",
      "  %1183 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1184 = Gather[axis = 0](%1182, %1183)\n",
      "  %1185 = Shape(%1178)\n",
      "  %1186 = Constant[value = <Tensor>]()\n",
      "  %1187 = Constant[value = <Tensor>]()\n",
      "  %1188 = Constant[value = <Tensor>]()\n",
      "  %1189 = Slice(%1185, %1187, %1188, %1186)\n",
      "  %1190 = Constant[value = <Tensor>]()\n",
      "  %1191 = Squeeze(%1189, %1190)\n",
      "  %1192 = Constant[value = <Tensor>]()\n",
      "  %1193 = Unsqueeze(%184, %1192)\n",
      "  %1194 = Constant[value = <Tensor>]()\n",
      "  %1195 = Unsqueeze(%1191, %1194)\n",
      "  %1196 = Concat[axis = 0](%1193, %1195)\n",
      "  %1197 = Reshape[allowzero = 0](%1178, %1196)\n",
      "  %1198 = Gemm[alpha = 1, beta = 1](%1197, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias)\n",
      "  %1199 = Constant[value = <Tensor>]()\n",
      "  %1200 = Unsqueeze(%1181, %1199)\n",
      "  %1201 = Constant[value = <Tensor>]()\n",
      "  %1202 = Unsqueeze(%1184, %1201)\n",
      "  %1203 = Constant[value = <Tensor>]()\n",
      "  %1204 = Unsqueeze(%180, %1203)\n",
      "  %1205 = Concat[axis = 0](%1200, %1202, %1204)\n",
      "  %1206 = Reshape[allowzero = 0](%1198, %1205)\n",
      "  %1207 = Constant[value = <Tensor>]()\n",
      "  %1208, %1209, %1210 = Split[axis = 2](%1206, %1207)\n",
      "  %1211 = Shape(%1208)\n",
      "  %1212 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1213 = Gather[axis = 0](%1211, %1212)\n",
      "  %1214 = Shape(%1208)\n",
      "  %1215 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1216 = Gather[axis = 0](%1214, %1215)\n",
      "  %1217 = Constant[value = <Tensor>]()\n",
      "  %1218 = Unsqueeze(%1213, %1217)\n",
      "  %1219 = Constant[value = <Tensor>]()\n",
      "  %1220 = Unsqueeze(%1216, %1219)\n",
      "  %1221 = Constant[value = <Tensor>]()\n",
      "  %1222 = Unsqueeze(%179, %1221)\n",
      "  %1223 = Constant[value = <Tensor>]()\n",
      "  %1224 = Unsqueeze(%178, %1223)\n",
      "  %1225 = Concat[axis = 0](%1218, %1220, %1222, %1224)\n",
      "  %1226 = Reshape[allowzero = 0](%1208, %1225)\n",
      "  %1227 = Transpose[perm = [0, 2, 1, 3]](%1226)\n",
      "  %1228 = Shape(%1209)\n",
      "  %1229 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1230 = Gather[axis = 0](%1228, %1229)\n",
      "  %1231 = Shape(%1209)\n",
      "  %1232 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1233 = Gather[axis = 0](%1231, %1232)\n",
      "  %1234 = Constant[value = <Tensor>]()\n",
      "  %1235 = Unsqueeze(%1230, %1234)\n",
      "  %1236 = Constant[value = <Tensor>]()\n",
      "  %1237 = Unsqueeze(%1233, %1236)\n",
      "  %1238 = Constant[value = <Tensor>]()\n",
      "  %1239 = Unsqueeze(%179, %1238)\n",
      "  %1240 = Constant[value = <Tensor>]()\n",
      "  %1241 = Unsqueeze(%178, %1240)\n",
      "  %1242 = Concat[axis = 0](%1235, %1237, %1239, %1241)\n",
      "  %1243 = Reshape[allowzero = 0](%1209, %1242)\n",
      "  %1244 = Transpose[perm = [0, 2, 1, 3]](%1243)\n",
      "  %1245 = Shape(%1210)\n",
      "  %1246 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1247 = Gather[axis = 0](%1245, %1246)\n",
      "  %1248 = Shape(%1210)\n",
      "  %1249 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1250 = Gather[axis = 0](%1248, %1249)\n",
      "  %1251 = Constant[value = <Tensor>]()\n",
      "  %1252 = Unsqueeze(%1247, %1251)\n",
      "  %1253 = Constant[value = <Tensor>]()\n",
      "  %1254 = Unsqueeze(%1250, %1253)\n",
      "  %1255 = Constant[value = <Tensor>]()\n",
      "  %1256 = Unsqueeze(%179, %1255)\n",
      "  %1257 = Constant[value = <Tensor>]()\n",
      "  %1258 = Unsqueeze(%178, %1257)\n",
      "  %1259 = Concat[axis = 0](%1252, %1254, %1256, %1258)\n",
      "  %1260 = Reshape[allowzero = 0](%1210, %1259)\n",
      "  %1261 = Transpose[perm = [0, 2, 1, 3]](%1260)\n",
      "  %1262 = Transpose[perm = [0, 2, 3, 1]](%1243)\n",
      "  %1263 = MatMul(%1227, %1262)\n",
      "  %1264 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1265 = Div(%1263, %1264)\n",
      "  %1266 = Shape(%1227)\n",
      "  %1267 = Constant[value = <Tensor>]()\n",
      "  %1268 = Constant[value = <Tensor>]()\n",
      "  %1269 = Constant[value = <Tensor>]()\n",
      "  %1270 = Slice(%1266, %1268, %1269, %1267)\n",
      "  %1271 = Constant[value = <Tensor>]()\n",
      "  %1272 = Squeeze(%1270, %1271)\n",
      "  %1273 = Shape(%1244)\n",
      "  %1274 = Constant[value = <Tensor>]()\n",
      "  %1275 = Constant[value = <Tensor>]()\n",
      "  %1276 = Constant[value = <Tensor>]()\n",
      "  %1277 = Slice(%1273, %1275, %1276, %1274)\n",
      "  %1278 = Constant[value = <Tensor>]()\n",
      "  %1279 = Squeeze(%1277, %1278)\n",
      "  %1280 = Sub(%1279, %1272)\n",
      "  %1281 = Constant[value = <Tensor>]()\n",
      "  %1282 = Unsqueeze(%1280, %1281)\n",
      "  %1283 = Constant[value = <Tensor>]()\n",
      "  %1284 = Unsqueeze(%1279, %1283)\n",
      "  %1285 = Constant[value = <Tensor>]()\n",
      "  %1286 = Unsqueeze(%188, %1285)\n",
      "  %1287 = Constant[value = <Tensor>]()\n",
      "  %1288 = Slice(%decoder_no_past.decoder.transformer.h.3.attn.bias, %1282, %1284, %1286, %1287)\n",
      "  %1289 = Constant[value = <Tensor>]()\n",
      "  %1290 = Unsqueeze(%189, %1289)\n",
      "  %1291 = Constant[value = <Tensor>]()\n",
      "  %1292 = Unsqueeze(%1279, %1291)\n",
      "  %1293 = Constant[value = <Tensor>]()\n",
      "  %1294 = Unsqueeze(%183, %1293)\n",
      "  %1295 = Constant[value = <Tensor>]()\n",
      "  %1296 = Slice(%1288, %1290, %1292, %1294, %1295)\n",
      "  %1297 = Cast[to = 9](%1296)\n",
      "  %1298 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.3.attn.masked_bias)\n",
      "  %1299 = Where(%1297, %1265, %1298)\n",
      "  %1300 = Add(%1299, %377)\n",
      "  %1301 = Softmax[axis = -1](%1300)\n",
      "  %1302 = MatMul(%1301, %1261)\n",
      "  %1303 = Transpose[perm = [0, 2, 1, 3]](%1302)\n",
      "  %1304 = Shape(%1303)\n",
      "  %1305 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1306 = Gather[axis = 0](%1304, %1305)\n",
      "  %1307 = Shape(%1303)\n",
      "  %1308 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1309 = Gather[axis = 0](%1307, %1308)\n",
      "  %1310 = Constant[value = <Tensor>]()\n",
      "  %1311 = Unsqueeze(%1306, %1310)\n",
      "  %1312 = Constant[value = <Tensor>]()\n",
      "  %1313 = Unsqueeze(%1309, %1312)\n",
      "  %1314 = Constant[value = <Tensor>]()\n",
      "  %1315 = Unsqueeze(%181, %1314)\n",
      "  %1316 = Concat[axis = 0](%1311, %1313, %1315)\n",
      "  %1317 = Reshape[allowzero = 0](%1303, %1316)\n",
      "  %1318 = Shape(%1317)\n",
      "  %1319 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1320 = Gather[axis = 0](%1318, %1319)\n",
      "  %1321 = Shape(%1317)\n",
      "  %1322 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1323 = Gather[axis = 0](%1321, %1322)\n",
      "  %1324 = Shape(%1317)\n",
      "  %1325 = Constant[value = <Tensor>]()\n",
      "  %1326 = Constant[value = <Tensor>]()\n",
      "  %1327 = Constant[value = <Tensor>]()\n",
      "  %1328 = Slice(%1324, %1326, %1327, %1325)\n",
      "  %1329 = Constant[value = <Tensor>]()\n",
      "  %1330 = Squeeze(%1328, %1329)\n",
      "  %1331 = Constant[value = <Tensor>]()\n",
      "  %1332 = Unsqueeze(%184, %1331)\n",
      "  %1333 = Constant[value = <Tensor>]()\n",
      "  %1334 = Unsqueeze(%1330, %1333)\n",
      "  %1335 = Concat[axis = 0](%1332, %1334)\n",
      "  %1336 = Reshape[allowzero = 0](%1317, %1335)\n",
      "  %1337 = Gemm[alpha = 1, beta = 1](%1336, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias)\n",
      "  %1338 = Constant[value = <Tensor>]()\n",
      "  %1339 = Unsqueeze(%1320, %1338)\n",
      "  %1340 = Constant[value = <Tensor>]()\n",
      "  %1341 = Unsqueeze(%1323, %1340)\n",
      "  %1342 = Constant[value = <Tensor>]()\n",
      "  %1343 = Unsqueeze(%181, %1342)\n",
      "  %1344 = Concat[axis = 0](%1339, %1341, %1343)\n",
      "  %1345 = Reshape[allowzero = 0](%1337, %1344)\n",
      "  %1346 = Add(%1345, %1167)\n",
      "  %1347 = ReduceMean[axes = [-1]](%1346)\n",
      "  %1348 = Sub(%1346, %1347)\n",
      "  %1349 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1350 = Pow(%1348, %1349)\n",
      "  %1351 = ReduceMean[axes = [-1]](%1350)\n",
      "  %1352 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1353 = Add(%1351, %1352)\n",
      "  %1354 = Sqrt(%1353)\n",
      "  %1355 = Div(%1348, %1354)\n",
      "  %1356 = Mul(%1355, %decoder_no_past.decoder.transformer.h.3.ln_2.weight)\n",
      "  %1357 = Add(%1356, %decoder_no_past.decoder.transformer.h.3.ln_2.bias)\n",
      "  %1358 = Shape(%1357)\n",
      "  %1359 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1360 = Gather[axis = 0](%1358, %1359)\n",
      "  %1361 = Shape(%1357)\n",
      "  %1362 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1363 = Gather[axis = 0](%1361, %1362)\n",
      "  %1364 = Shape(%1357)\n",
      "  %1365 = Constant[value = <Tensor>]()\n",
      "  %1366 = Constant[value = <Tensor>]()\n",
      "  %1367 = Constant[value = <Tensor>]()\n",
      "  %1368 = Slice(%1364, %1366, %1367, %1365)\n",
      "  %1369 = Constant[value = <Tensor>]()\n",
      "  %1370 = Squeeze(%1368, %1369)\n",
      "  %1371 = Constant[value = <Tensor>]()\n",
      "  %1372 = Unsqueeze(%184, %1371)\n",
      "  %1373 = Constant[value = <Tensor>]()\n",
      "  %1374 = Unsqueeze(%1370, %1373)\n",
      "  %1375 = Concat[axis = 0](%1372, %1374)\n",
      "  %1376 = Reshape[allowzero = 0](%1357, %1375)\n",
      "  %1377 = Gemm[alpha = 1, beta = 1](%1376, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias)\n",
      "  %1378 = Constant[value = <Tensor>]()\n",
      "  %1379 = Unsqueeze(%1360, %1378)\n",
      "  %1380 = Constant[value = <Tensor>]()\n",
      "  %1381 = Unsqueeze(%1363, %1380)\n",
      "  %1382 = Constant[value = <Tensor>]()\n",
      "  %1383 = Unsqueeze(%177, %1382)\n",
      "  %1384 = Concat[axis = 0](%1379, %1381, %1383)\n",
      "  %1385 = Reshape[allowzero = 0](%1377, %1384)\n",
      "  %1386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1387 = Mul(%1385, %1386)\n",
      "  %1388 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1389 = Pow(%1385, %1388)\n",
      "  %1390 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1391 = Mul(%1389, %1390)\n",
      "  %1392 = Add(%1385, %1391)\n",
      "  %1393 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1394 = Mul(%1392, %1393)\n",
      "  %1395 = Tanh(%1394)\n",
      "  %1396 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1397 = Add(%1395, %1396)\n",
      "  %1398 = Mul(%1387, %1397)\n",
      "  %1399 = Shape(%1398)\n",
      "  %1400 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1401 = Gather[axis = 0](%1399, %1400)\n",
      "  %1402 = Shape(%1398)\n",
      "  %1403 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1404 = Gather[axis = 0](%1402, %1403)\n",
      "  %1405 = Shape(%1398)\n",
      "  %1406 = Constant[value = <Tensor>]()\n",
      "  %1407 = Constant[value = <Tensor>]()\n",
      "  %1408 = Constant[value = <Tensor>]()\n",
      "  %1409 = Slice(%1405, %1407, %1408, %1406)\n",
      "  %1410 = Constant[value = <Tensor>]()\n",
      "  %1411 = Squeeze(%1409, %1410)\n",
      "  %1412 = Constant[value = <Tensor>]()\n",
      "  %1413 = Unsqueeze(%184, %1412)\n",
      "  %1414 = Constant[value = <Tensor>]()\n",
      "  %1415 = Unsqueeze(%1411, %1414)\n",
      "  %1416 = Concat[axis = 0](%1413, %1415)\n",
      "  %1417 = Reshape[allowzero = 0](%1398, %1416)\n",
      "  %1418 = Gemm[alpha = 1, beta = 1](%1417, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias)\n",
      "  %1419 = Constant[value = <Tensor>]()\n",
      "  %1420 = Unsqueeze(%1401, %1419)\n",
      "  %1421 = Constant[value = <Tensor>]()\n",
      "  %1422 = Unsqueeze(%1404, %1421)\n",
      "  %1423 = Constant[value = <Tensor>]()\n",
      "  %1424 = Unsqueeze(%181, %1423)\n",
      "  %1425 = Concat[axis = 0](%1420, %1422, %1424)\n",
      "  %1426 = Reshape[allowzero = 0](%1418, %1425)\n",
      "  %1427 = Add(%1346, %1426)\n",
      "  %1428 = ReduceMean[axes = [-1]](%1427)\n",
      "  %1429 = Sub(%1427, %1428)\n",
      "  %1430 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1431 = Pow(%1429, %1430)\n",
      "  %1432 = ReduceMean[axes = [-1]](%1431)\n",
      "  %1433 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1434 = Add(%1432, %1433)\n",
      "  %1435 = Sqrt(%1434)\n",
      "  %1436 = Div(%1429, %1435)\n",
      "  %1437 = Mul(%1436, %decoder_no_past.decoder.transformer.h.4.ln_1.weight)\n",
      "  %1438 = Add(%1437, %decoder_no_past.decoder.transformer.h.4.ln_1.bias)\n",
      "  %1439 = Shape(%1438)\n",
      "  %1440 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1441 = Gather[axis = 0](%1439, %1440)\n",
      "  %1442 = Shape(%1438)\n",
      "  %1443 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1444 = Gather[axis = 0](%1442, %1443)\n",
      "  %1445 = Shape(%1438)\n",
      "  %1446 = Constant[value = <Tensor>]()\n",
      "  %1447 = Constant[value = <Tensor>]()\n",
      "  %1448 = Constant[value = <Tensor>]()\n",
      "  %1449 = Slice(%1445, %1447, %1448, %1446)\n",
      "  %1450 = Constant[value = <Tensor>]()\n",
      "  %1451 = Squeeze(%1449, %1450)\n",
      "  %1452 = Constant[value = <Tensor>]()\n",
      "  %1453 = Unsqueeze(%184, %1452)\n",
      "  %1454 = Constant[value = <Tensor>]()\n",
      "  %1455 = Unsqueeze(%1451, %1454)\n",
      "  %1456 = Concat[axis = 0](%1453, %1455)\n",
      "  %1457 = Reshape[allowzero = 0](%1438, %1456)\n",
      "  %1458 = Gemm[alpha = 1, beta = 1](%1457, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias)\n",
      "  %1459 = Constant[value = <Tensor>]()\n",
      "  %1460 = Unsqueeze(%1441, %1459)\n",
      "  %1461 = Constant[value = <Tensor>]()\n",
      "  %1462 = Unsqueeze(%1444, %1461)\n",
      "  %1463 = Constant[value = <Tensor>]()\n",
      "  %1464 = Unsqueeze(%180, %1463)\n",
      "  %1465 = Concat[axis = 0](%1460, %1462, %1464)\n",
      "  %1466 = Reshape[allowzero = 0](%1458, %1465)\n",
      "  %1467 = Constant[value = <Tensor>]()\n",
      "  %1468, %1469, %1470 = Split[axis = 2](%1466, %1467)\n",
      "  %1471 = Shape(%1468)\n",
      "  %1472 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1473 = Gather[axis = 0](%1471, %1472)\n",
      "  %1474 = Shape(%1468)\n",
      "  %1475 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1476 = Gather[axis = 0](%1474, %1475)\n",
      "  %1477 = Constant[value = <Tensor>]()\n",
      "  %1478 = Unsqueeze(%1473, %1477)\n",
      "  %1479 = Constant[value = <Tensor>]()\n",
      "  %1480 = Unsqueeze(%1476, %1479)\n",
      "  %1481 = Constant[value = <Tensor>]()\n",
      "  %1482 = Unsqueeze(%179, %1481)\n",
      "  %1483 = Constant[value = <Tensor>]()\n",
      "  %1484 = Unsqueeze(%178, %1483)\n",
      "  %1485 = Concat[axis = 0](%1478, %1480, %1482, %1484)\n",
      "  %1486 = Reshape[allowzero = 0](%1468, %1485)\n",
      "  %1487 = Transpose[perm = [0, 2, 1, 3]](%1486)\n",
      "  %1488 = Shape(%1469)\n",
      "  %1489 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1490 = Gather[axis = 0](%1488, %1489)\n",
      "  %1491 = Shape(%1469)\n",
      "  %1492 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1493 = Gather[axis = 0](%1491, %1492)\n",
      "  %1494 = Constant[value = <Tensor>]()\n",
      "  %1495 = Unsqueeze(%1490, %1494)\n",
      "  %1496 = Constant[value = <Tensor>]()\n",
      "  %1497 = Unsqueeze(%1493, %1496)\n",
      "  %1498 = Constant[value = <Tensor>]()\n",
      "  %1499 = Unsqueeze(%179, %1498)\n",
      "  %1500 = Constant[value = <Tensor>]()\n",
      "  %1501 = Unsqueeze(%178, %1500)\n",
      "  %1502 = Concat[axis = 0](%1495, %1497, %1499, %1501)\n",
      "  %1503 = Reshape[allowzero = 0](%1469, %1502)\n",
      "  %1504 = Transpose[perm = [0, 2, 1, 3]](%1503)\n",
      "  %1505 = Shape(%1470)\n",
      "  %1506 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1507 = Gather[axis = 0](%1505, %1506)\n",
      "  %1508 = Shape(%1470)\n",
      "  %1509 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1510 = Gather[axis = 0](%1508, %1509)\n",
      "  %1511 = Constant[value = <Tensor>]()\n",
      "  %1512 = Unsqueeze(%1507, %1511)\n",
      "  %1513 = Constant[value = <Tensor>]()\n",
      "  %1514 = Unsqueeze(%1510, %1513)\n",
      "  %1515 = Constant[value = <Tensor>]()\n",
      "  %1516 = Unsqueeze(%179, %1515)\n",
      "  %1517 = Constant[value = <Tensor>]()\n",
      "  %1518 = Unsqueeze(%178, %1517)\n",
      "  %1519 = Concat[axis = 0](%1512, %1514, %1516, %1518)\n",
      "  %1520 = Reshape[allowzero = 0](%1470, %1519)\n",
      "  %1521 = Transpose[perm = [0, 2, 1, 3]](%1520)\n",
      "  %1522 = Transpose[perm = [0, 2, 3, 1]](%1503)\n",
      "  %1523 = MatMul(%1487, %1522)\n",
      "  %1524 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1525 = Div(%1523, %1524)\n",
      "  %1526 = Shape(%1487)\n",
      "  %1527 = Constant[value = <Tensor>]()\n",
      "  %1528 = Constant[value = <Tensor>]()\n",
      "  %1529 = Constant[value = <Tensor>]()\n",
      "  %1530 = Slice(%1526, %1528, %1529, %1527)\n",
      "  %1531 = Constant[value = <Tensor>]()\n",
      "  %1532 = Squeeze(%1530, %1531)\n",
      "  %1533 = Shape(%1504)\n",
      "  %1534 = Constant[value = <Tensor>]()\n",
      "  %1535 = Constant[value = <Tensor>]()\n",
      "  %1536 = Constant[value = <Tensor>]()\n",
      "  %1537 = Slice(%1533, %1535, %1536, %1534)\n",
      "  %1538 = Constant[value = <Tensor>]()\n",
      "  %1539 = Squeeze(%1537, %1538)\n",
      "  %1540 = Sub(%1539, %1532)\n",
      "  %1541 = Constant[value = <Tensor>]()\n",
      "  %1542 = Unsqueeze(%1540, %1541)\n",
      "  %1543 = Constant[value = <Tensor>]()\n",
      "  %1544 = Unsqueeze(%1539, %1543)\n",
      "  %1545 = Constant[value = <Tensor>]()\n",
      "  %1546 = Unsqueeze(%188, %1545)\n",
      "  %1547 = Constant[value = <Tensor>]()\n",
      "  %1548 = Slice(%decoder_no_past.decoder.transformer.h.4.attn.bias, %1542, %1544, %1546, %1547)\n",
      "  %1549 = Constant[value = <Tensor>]()\n",
      "  %1550 = Unsqueeze(%189, %1549)\n",
      "  %1551 = Constant[value = <Tensor>]()\n",
      "  %1552 = Unsqueeze(%1539, %1551)\n",
      "  %1553 = Constant[value = <Tensor>]()\n",
      "  %1554 = Unsqueeze(%183, %1553)\n",
      "  %1555 = Constant[value = <Tensor>]()\n",
      "  %1556 = Slice(%1548, %1550, %1552, %1554, %1555)\n",
      "  %1557 = Cast[to = 9](%1556)\n",
      "  %1558 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.4.attn.masked_bias)\n",
      "  %1559 = Where(%1557, %1525, %1558)\n",
      "  %1560 = Add(%1559, %377)\n",
      "  %1561 = Softmax[axis = -1](%1560)\n",
      "  %1562 = MatMul(%1561, %1521)\n",
      "  %1563 = Transpose[perm = [0, 2, 1, 3]](%1562)\n",
      "  %1564 = Shape(%1563)\n",
      "  %1565 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1566 = Gather[axis = 0](%1564, %1565)\n",
      "  %1567 = Shape(%1563)\n",
      "  %1568 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1569 = Gather[axis = 0](%1567, %1568)\n",
      "  %1570 = Constant[value = <Tensor>]()\n",
      "  %1571 = Unsqueeze(%1566, %1570)\n",
      "  %1572 = Constant[value = <Tensor>]()\n",
      "  %1573 = Unsqueeze(%1569, %1572)\n",
      "  %1574 = Constant[value = <Tensor>]()\n",
      "  %1575 = Unsqueeze(%181, %1574)\n",
      "  %1576 = Concat[axis = 0](%1571, %1573, %1575)\n",
      "  %1577 = Reshape[allowzero = 0](%1563, %1576)\n",
      "  %1578 = Shape(%1577)\n",
      "  %1579 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1580 = Gather[axis = 0](%1578, %1579)\n",
      "  %1581 = Shape(%1577)\n",
      "  %1582 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1583 = Gather[axis = 0](%1581, %1582)\n",
      "  %1584 = Shape(%1577)\n",
      "  %1585 = Constant[value = <Tensor>]()\n",
      "  %1586 = Constant[value = <Tensor>]()\n",
      "  %1587 = Constant[value = <Tensor>]()\n",
      "  %1588 = Slice(%1584, %1586, %1587, %1585)\n",
      "  %1589 = Constant[value = <Tensor>]()\n",
      "  %1590 = Squeeze(%1588, %1589)\n",
      "  %1591 = Constant[value = <Tensor>]()\n",
      "  %1592 = Unsqueeze(%184, %1591)\n",
      "  %1593 = Constant[value = <Tensor>]()\n",
      "  %1594 = Unsqueeze(%1590, %1593)\n",
      "  %1595 = Concat[axis = 0](%1592, %1594)\n",
      "  %1596 = Reshape[allowzero = 0](%1577, %1595)\n",
      "  %1597 = Gemm[alpha = 1, beta = 1](%1596, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias)\n",
      "  %1598 = Constant[value = <Tensor>]()\n",
      "  %1599 = Unsqueeze(%1580, %1598)\n",
      "  %1600 = Constant[value = <Tensor>]()\n",
      "  %1601 = Unsqueeze(%1583, %1600)\n",
      "  %1602 = Constant[value = <Tensor>]()\n",
      "  %1603 = Unsqueeze(%181, %1602)\n",
      "  %1604 = Concat[axis = 0](%1599, %1601, %1603)\n",
      "  %1605 = Reshape[allowzero = 0](%1597, %1604)\n",
      "  %1606 = Add(%1605, %1427)\n",
      "  %1607 = ReduceMean[axes = [-1]](%1606)\n",
      "  %1608 = Sub(%1606, %1607)\n",
      "  %1609 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1610 = Pow(%1608, %1609)\n",
      "  %1611 = ReduceMean[axes = [-1]](%1610)\n",
      "  %1612 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1613 = Add(%1611, %1612)\n",
      "  %1614 = Sqrt(%1613)\n",
      "  %1615 = Div(%1608, %1614)\n",
      "  %1616 = Mul(%1615, %decoder_no_past.decoder.transformer.h.4.ln_2.weight)\n",
      "  %1617 = Add(%1616, %decoder_no_past.decoder.transformer.h.4.ln_2.bias)\n",
      "  %1618 = Shape(%1617)\n",
      "  %1619 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1620 = Gather[axis = 0](%1618, %1619)\n",
      "  %1621 = Shape(%1617)\n",
      "  %1622 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1623 = Gather[axis = 0](%1621, %1622)\n",
      "  %1624 = Shape(%1617)\n",
      "  %1625 = Constant[value = <Tensor>]()\n",
      "  %1626 = Constant[value = <Tensor>]()\n",
      "  %1627 = Constant[value = <Tensor>]()\n",
      "  %1628 = Slice(%1624, %1626, %1627, %1625)\n",
      "  %1629 = Constant[value = <Tensor>]()\n",
      "  %1630 = Squeeze(%1628, %1629)\n",
      "  %1631 = Constant[value = <Tensor>]()\n",
      "  %1632 = Unsqueeze(%184, %1631)\n",
      "  %1633 = Constant[value = <Tensor>]()\n",
      "  %1634 = Unsqueeze(%1630, %1633)\n",
      "  %1635 = Concat[axis = 0](%1632, %1634)\n",
      "  %1636 = Reshape[allowzero = 0](%1617, %1635)\n",
      "  %1637 = Gemm[alpha = 1, beta = 1](%1636, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias)\n",
      "  %1638 = Constant[value = <Tensor>]()\n",
      "  %1639 = Unsqueeze(%1620, %1638)\n",
      "  %1640 = Constant[value = <Tensor>]()\n",
      "  %1641 = Unsqueeze(%1623, %1640)\n",
      "  %1642 = Constant[value = <Tensor>]()\n",
      "  %1643 = Unsqueeze(%177, %1642)\n",
      "  %1644 = Concat[axis = 0](%1639, %1641, %1643)\n",
      "  %1645 = Reshape[allowzero = 0](%1637, %1644)\n",
      "  %1646 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1647 = Mul(%1645, %1646)\n",
      "  %1648 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1649 = Pow(%1645, %1648)\n",
      "  %1650 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1651 = Mul(%1649, %1650)\n",
      "  %1652 = Add(%1645, %1651)\n",
      "  %1653 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1654 = Mul(%1652, %1653)\n",
      "  %1655 = Tanh(%1654)\n",
      "  %1656 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1657 = Add(%1655, %1656)\n",
      "  %1658 = Mul(%1647, %1657)\n",
      "  %1659 = Shape(%1658)\n",
      "  %1660 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1661 = Gather[axis = 0](%1659, %1660)\n",
      "  %1662 = Shape(%1658)\n",
      "  %1663 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1664 = Gather[axis = 0](%1662, %1663)\n",
      "  %1665 = Shape(%1658)\n",
      "  %1666 = Constant[value = <Tensor>]()\n",
      "  %1667 = Constant[value = <Tensor>]()\n",
      "  %1668 = Constant[value = <Tensor>]()\n",
      "  %1669 = Slice(%1665, %1667, %1668, %1666)\n",
      "  %1670 = Constant[value = <Tensor>]()\n",
      "  %1671 = Squeeze(%1669, %1670)\n",
      "  %1672 = Constant[value = <Tensor>]()\n",
      "  %1673 = Unsqueeze(%184, %1672)\n",
      "  %1674 = Constant[value = <Tensor>]()\n",
      "  %1675 = Unsqueeze(%1671, %1674)\n",
      "  %1676 = Concat[axis = 0](%1673, %1675)\n",
      "  %1677 = Reshape[allowzero = 0](%1658, %1676)\n",
      "  %1678 = Gemm[alpha = 1, beta = 1](%1677, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias)\n",
      "  %1679 = Constant[value = <Tensor>]()\n",
      "  %1680 = Unsqueeze(%1661, %1679)\n",
      "  %1681 = Constant[value = <Tensor>]()\n",
      "  %1682 = Unsqueeze(%1664, %1681)\n",
      "  %1683 = Constant[value = <Tensor>]()\n",
      "  %1684 = Unsqueeze(%181, %1683)\n",
      "  %1685 = Concat[axis = 0](%1680, %1682, %1684)\n",
      "  %1686 = Reshape[allowzero = 0](%1678, %1685)\n",
      "  %1687 = Add(%1606, %1686)\n",
      "  %1688 = ReduceMean[axes = [-1]](%1687)\n",
      "  %1689 = Sub(%1687, %1688)\n",
      "  %1690 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1691 = Pow(%1689, %1690)\n",
      "  %1692 = ReduceMean[axes = [-1]](%1691)\n",
      "  %1693 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1694 = Add(%1692, %1693)\n",
      "  %1695 = Sqrt(%1694)\n",
      "  %1696 = Div(%1689, %1695)\n",
      "  %1697 = Mul(%1696, %decoder_no_past.decoder.transformer.h.5.ln_1.weight)\n",
      "  %1698 = Add(%1697, %decoder_no_past.decoder.transformer.h.5.ln_1.bias)\n",
      "  %1699 = Shape(%1698)\n",
      "  %1700 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1701 = Gather[axis = 0](%1699, %1700)\n",
      "  %1702 = Shape(%1698)\n",
      "  %1703 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1704 = Gather[axis = 0](%1702, %1703)\n",
      "  %1705 = Shape(%1698)\n",
      "  %1706 = Constant[value = <Tensor>]()\n",
      "  %1707 = Constant[value = <Tensor>]()\n",
      "  %1708 = Constant[value = <Tensor>]()\n",
      "  %1709 = Slice(%1705, %1707, %1708, %1706)\n",
      "  %1710 = Constant[value = <Tensor>]()\n",
      "  %1711 = Squeeze(%1709, %1710)\n",
      "  %1712 = Constant[value = <Tensor>]()\n",
      "  %1713 = Unsqueeze(%184, %1712)\n",
      "  %1714 = Constant[value = <Tensor>]()\n",
      "  %1715 = Unsqueeze(%1711, %1714)\n",
      "  %1716 = Concat[axis = 0](%1713, %1715)\n",
      "  %1717 = Reshape[allowzero = 0](%1698, %1716)\n",
      "  %1718 = Gemm[alpha = 1, beta = 1](%1717, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias)\n",
      "  %1719 = Constant[value = <Tensor>]()\n",
      "  %1720 = Unsqueeze(%1701, %1719)\n",
      "  %1721 = Constant[value = <Tensor>]()\n",
      "  %1722 = Unsqueeze(%1704, %1721)\n",
      "  %1723 = Constant[value = <Tensor>]()\n",
      "  %1724 = Unsqueeze(%180, %1723)\n",
      "  %1725 = Concat[axis = 0](%1720, %1722, %1724)\n",
      "  %1726 = Reshape[allowzero = 0](%1718, %1725)\n",
      "  %1727 = Constant[value = <Tensor>]()\n",
      "  %1728, %1729, %1730 = Split[axis = 2](%1726, %1727)\n",
      "  %1731 = Shape(%1728)\n",
      "  %1732 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1733 = Gather[axis = 0](%1731, %1732)\n",
      "  %1734 = Shape(%1728)\n",
      "  %1735 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1736 = Gather[axis = 0](%1734, %1735)\n",
      "  %1737 = Constant[value = <Tensor>]()\n",
      "  %1738 = Unsqueeze(%1733, %1737)\n",
      "  %1739 = Constant[value = <Tensor>]()\n",
      "  %1740 = Unsqueeze(%1736, %1739)\n",
      "  %1741 = Constant[value = <Tensor>]()\n",
      "  %1742 = Unsqueeze(%179, %1741)\n",
      "  %1743 = Constant[value = <Tensor>]()\n",
      "  %1744 = Unsqueeze(%178, %1743)\n",
      "  %1745 = Concat[axis = 0](%1738, %1740, %1742, %1744)\n",
      "  %1746 = Reshape[allowzero = 0](%1728, %1745)\n",
      "  %1747 = Transpose[perm = [0, 2, 1, 3]](%1746)\n",
      "  %1748 = Shape(%1729)\n",
      "  %1749 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1750 = Gather[axis = 0](%1748, %1749)\n",
      "  %1751 = Shape(%1729)\n",
      "  %1752 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1753 = Gather[axis = 0](%1751, %1752)\n",
      "  %1754 = Constant[value = <Tensor>]()\n",
      "  %1755 = Unsqueeze(%1750, %1754)\n",
      "  %1756 = Constant[value = <Tensor>]()\n",
      "  %1757 = Unsqueeze(%1753, %1756)\n",
      "  %1758 = Constant[value = <Tensor>]()\n",
      "  %1759 = Unsqueeze(%179, %1758)\n",
      "  %1760 = Constant[value = <Tensor>]()\n",
      "  %1761 = Unsqueeze(%178, %1760)\n",
      "  %1762 = Concat[axis = 0](%1755, %1757, %1759, %1761)\n",
      "  %1763 = Reshape[allowzero = 0](%1729, %1762)\n",
      "  %1764 = Transpose[perm = [0, 2, 1, 3]](%1763)\n",
      "  %1765 = Shape(%1730)\n",
      "  %1766 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1767 = Gather[axis = 0](%1765, %1766)\n",
      "  %1768 = Shape(%1730)\n",
      "  %1769 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1770 = Gather[axis = 0](%1768, %1769)\n",
      "  %1771 = Constant[value = <Tensor>]()\n",
      "  %1772 = Unsqueeze(%1767, %1771)\n",
      "  %1773 = Constant[value = <Tensor>]()\n",
      "  %1774 = Unsqueeze(%1770, %1773)\n",
      "  %1775 = Constant[value = <Tensor>]()\n",
      "  %1776 = Unsqueeze(%179, %1775)\n",
      "  %1777 = Constant[value = <Tensor>]()\n",
      "  %1778 = Unsqueeze(%178, %1777)\n",
      "  %1779 = Concat[axis = 0](%1772, %1774, %1776, %1778)\n",
      "  %1780 = Reshape[allowzero = 0](%1730, %1779)\n",
      "  %1781 = Transpose[perm = [0, 2, 1, 3]](%1780)\n",
      "  %1782 = Transpose[perm = [0, 2, 3, 1]](%1763)\n",
      "  %1783 = MatMul(%1747, %1782)\n",
      "  %1784 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1785 = Div(%1783, %1784)\n",
      "  %1786 = Shape(%1747)\n",
      "  %1787 = Constant[value = <Tensor>]()\n",
      "  %1788 = Constant[value = <Tensor>]()\n",
      "  %1789 = Constant[value = <Tensor>]()\n",
      "  %1790 = Slice(%1786, %1788, %1789, %1787)\n",
      "  %1791 = Constant[value = <Tensor>]()\n",
      "  %1792 = Squeeze(%1790, %1791)\n",
      "  %1793 = Shape(%1764)\n",
      "  %1794 = Constant[value = <Tensor>]()\n",
      "  %1795 = Constant[value = <Tensor>]()\n",
      "  %1796 = Constant[value = <Tensor>]()\n",
      "  %1797 = Slice(%1793, %1795, %1796, %1794)\n",
      "  %1798 = Constant[value = <Tensor>]()\n",
      "  %1799 = Squeeze(%1797, %1798)\n",
      "  %1800 = Sub(%1799, %1792)\n",
      "  %1801 = Constant[value = <Tensor>]()\n",
      "  %1802 = Unsqueeze(%1800, %1801)\n",
      "  %1803 = Constant[value = <Tensor>]()\n",
      "  %1804 = Unsqueeze(%1799, %1803)\n",
      "  %1805 = Constant[value = <Tensor>]()\n",
      "  %1806 = Unsqueeze(%188, %1805)\n",
      "  %1807 = Constant[value = <Tensor>]()\n",
      "  %1808 = Slice(%decoder_no_past.decoder.transformer.h.5.attn.bias, %1802, %1804, %1806, %1807)\n",
      "  %1809 = Constant[value = <Tensor>]()\n",
      "  %1810 = Unsqueeze(%189, %1809)\n",
      "  %1811 = Constant[value = <Tensor>]()\n",
      "  %1812 = Unsqueeze(%1799, %1811)\n",
      "  %1813 = Constant[value = <Tensor>]()\n",
      "  %1814 = Unsqueeze(%183, %1813)\n",
      "  %1815 = Constant[value = <Tensor>]()\n",
      "  %1816 = Slice(%1808, %1810, %1812, %1814, %1815)\n",
      "  %1817 = Cast[to = 9](%1816)\n",
      "  %1818 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.5.attn.masked_bias)\n",
      "  %1819 = Where(%1817, %1785, %1818)\n",
      "  %1820 = Add(%1819, %377)\n",
      "  %1821 = Softmax[axis = -1](%1820)\n",
      "  %1822 = MatMul(%1821, %1781)\n",
      "  %1823 = Transpose[perm = [0, 2, 1, 3]](%1822)\n",
      "  %1824 = Shape(%1823)\n",
      "  %1825 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1826 = Gather[axis = 0](%1824, %1825)\n",
      "  %1827 = Shape(%1823)\n",
      "  %1828 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1829 = Gather[axis = 0](%1827, %1828)\n",
      "  %1830 = Constant[value = <Tensor>]()\n",
      "  %1831 = Unsqueeze(%1826, %1830)\n",
      "  %1832 = Constant[value = <Tensor>]()\n",
      "  %1833 = Unsqueeze(%1829, %1832)\n",
      "  %1834 = Constant[value = <Tensor>]()\n",
      "  %1835 = Unsqueeze(%181, %1834)\n",
      "  %1836 = Concat[axis = 0](%1831, %1833, %1835)\n",
      "  %1837 = Reshape[allowzero = 0](%1823, %1836)\n",
      "  %1838 = Shape(%1837)\n",
      "  %1839 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1840 = Gather[axis = 0](%1838, %1839)\n",
      "  %1841 = Shape(%1837)\n",
      "  %1842 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1843 = Gather[axis = 0](%1841, %1842)\n",
      "  %1844 = Shape(%1837)\n",
      "  %1845 = Constant[value = <Tensor>]()\n",
      "  %1846 = Constant[value = <Tensor>]()\n",
      "  %1847 = Constant[value = <Tensor>]()\n",
      "  %1848 = Slice(%1844, %1846, %1847, %1845)\n",
      "  %1849 = Constant[value = <Tensor>]()\n",
      "  %1850 = Squeeze(%1848, %1849)\n",
      "  %1851 = Constant[value = <Tensor>]()\n",
      "  %1852 = Unsqueeze(%184, %1851)\n",
      "  %1853 = Constant[value = <Tensor>]()\n",
      "  %1854 = Unsqueeze(%1850, %1853)\n",
      "  %1855 = Concat[axis = 0](%1852, %1854)\n",
      "  %1856 = Reshape[allowzero = 0](%1837, %1855)\n",
      "  %1857 = Gemm[alpha = 1, beta = 1](%1856, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias)\n",
      "  %1858 = Constant[value = <Tensor>]()\n",
      "  %1859 = Unsqueeze(%1840, %1858)\n",
      "  %1860 = Constant[value = <Tensor>]()\n",
      "  %1861 = Unsqueeze(%1843, %1860)\n",
      "  %1862 = Constant[value = <Tensor>]()\n",
      "  %1863 = Unsqueeze(%181, %1862)\n",
      "  %1864 = Concat[axis = 0](%1859, %1861, %1863)\n",
      "  %1865 = Reshape[allowzero = 0](%1857, %1864)\n",
      "  %1866 = Add(%1865, %1687)\n",
      "  %1867 = ReduceMean[axes = [-1]](%1866)\n",
      "  %1868 = Sub(%1866, %1867)\n",
      "  %1869 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1870 = Pow(%1868, %1869)\n",
      "  %1871 = ReduceMean[axes = [-1]](%1870)\n",
      "  %1872 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1873 = Add(%1871, %1872)\n",
      "  %1874 = Sqrt(%1873)\n",
      "  %1875 = Div(%1868, %1874)\n",
      "  %1876 = Mul(%1875, %decoder_no_past.decoder.transformer.h.5.ln_2.weight)\n",
      "  %1877 = Add(%1876, %decoder_no_past.decoder.transformer.h.5.ln_2.bias)\n",
      "  %1878 = Shape(%1877)\n",
      "  %1879 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1880 = Gather[axis = 0](%1878, %1879)\n",
      "  %1881 = Shape(%1877)\n",
      "  %1882 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1883 = Gather[axis = 0](%1881, %1882)\n",
      "  %1884 = Shape(%1877)\n",
      "  %1885 = Constant[value = <Tensor>]()\n",
      "  %1886 = Constant[value = <Tensor>]()\n",
      "  %1887 = Constant[value = <Tensor>]()\n",
      "  %1888 = Slice(%1884, %1886, %1887, %1885)\n",
      "  %1889 = Constant[value = <Tensor>]()\n",
      "  %1890 = Squeeze(%1888, %1889)\n",
      "  %1891 = Constant[value = <Tensor>]()\n",
      "  %1892 = Unsqueeze(%184, %1891)\n",
      "  %1893 = Constant[value = <Tensor>]()\n",
      "  %1894 = Unsqueeze(%1890, %1893)\n",
      "  %1895 = Concat[axis = 0](%1892, %1894)\n",
      "  %1896 = Reshape[allowzero = 0](%1877, %1895)\n",
      "  %1897 = Gemm[alpha = 1, beta = 1](%1896, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias)\n",
      "  %1898 = Constant[value = <Tensor>]()\n",
      "  %1899 = Unsqueeze(%1880, %1898)\n",
      "  %1900 = Constant[value = <Tensor>]()\n",
      "  %1901 = Unsqueeze(%1883, %1900)\n",
      "  %1902 = Constant[value = <Tensor>]()\n",
      "  %1903 = Unsqueeze(%177, %1902)\n",
      "  %1904 = Concat[axis = 0](%1899, %1901, %1903)\n",
      "  %1905 = Reshape[allowzero = 0](%1897, %1904)\n",
      "  %1906 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1907 = Mul(%1905, %1906)\n",
      "  %1908 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1909 = Pow(%1905, %1908)\n",
      "  %1910 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1911 = Mul(%1909, %1910)\n",
      "  %1912 = Add(%1905, %1911)\n",
      "  %1913 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1914 = Mul(%1912, %1913)\n",
      "  %1915 = Tanh(%1914)\n",
      "  %1916 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1917 = Add(%1915, %1916)\n",
      "  %1918 = Mul(%1907, %1917)\n",
      "  %1919 = Shape(%1918)\n",
      "  %1920 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1921 = Gather[axis = 0](%1919, %1920)\n",
      "  %1922 = Shape(%1918)\n",
      "  %1923 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1924 = Gather[axis = 0](%1922, %1923)\n",
      "  %1925 = Shape(%1918)\n",
      "  %1926 = Constant[value = <Tensor>]()\n",
      "  %1927 = Constant[value = <Tensor>]()\n",
      "  %1928 = Constant[value = <Tensor>]()\n",
      "  %1929 = Slice(%1925, %1927, %1928, %1926)\n",
      "  %1930 = Constant[value = <Tensor>]()\n",
      "  %1931 = Squeeze(%1929, %1930)\n",
      "  %1932 = Constant[value = <Tensor>]()\n",
      "  %1933 = Unsqueeze(%184, %1932)\n",
      "  %1934 = Constant[value = <Tensor>]()\n",
      "  %1935 = Unsqueeze(%1931, %1934)\n",
      "  %1936 = Concat[axis = 0](%1933, %1935)\n",
      "  %1937 = Reshape[allowzero = 0](%1918, %1936)\n",
      "  %1938 = Gemm[alpha = 1, beta = 1](%1937, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias)\n",
      "  %1939 = Constant[value = <Tensor>]()\n",
      "  %1940 = Unsqueeze(%1921, %1939)\n",
      "  %1941 = Constant[value = <Tensor>]()\n",
      "  %1942 = Unsqueeze(%1924, %1941)\n",
      "  %1943 = Constant[value = <Tensor>]()\n",
      "  %1944 = Unsqueeze(%181, %1943)\n",
      "  %1945 = Concat[axis = 0](%1940, %1942, %1944)\n",
      "  %1946 = Reshape[allowzero = 0](%1938, %1945)\n",
      "  %1947 = Add(%1866, %1946)\n",
      "  %1948 = ReduceMean[axes = [-1]](%1947)\n",
      "  %1949 = Sub(%1947, %1948)\n",
      "  %1950 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1951 = Pow(%1949, %1950)\n",
      "  %1952 = ReduceMean[axes = [-1]](%1951)\n",
      "  %1953 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1954 = Add(%1952, %1953)\n",
      "  %1955 = Sqrt(%1954)\n",
      "  %1956 = Div(%1949, %1955)\n",
      "  %1957 = Mul(%1956, %decoder_no_past.decoder.transformer.h.6.ln_1.weight)\n",
      "  %1958 = Add(%1957, %decoder_no_past.decoder.transformer.h.6.ln_1.bias)\n",
      "  %1959 = Shape(%1958)\n",
      "  %1960 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1961 = Gather[axis = 0](%1959, %1960)\n",
      "  %1962 = Shape(%1958)\n",
      "  %1963 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1964 = Gather[axis = 0](%1962, %1963)\n",
      "  %1965 = Shape(%1958)\n",
      "  %1966 = Constant[value = <Tensor>]()\n",
      "  %1967 = Constant[value = <Tensor>]()\n",
      "  %1968 = Constant[value = <Tensor>]()\n",
      "  %1969 = Slice(%1965, %1967, %1968, %1966)\n",
      "  %1970 = Constant[value = <Tensor>]()\n",
      "  %1971 = Squeeze(%1969, %1970)\n",
      "  %1972 = Constant[value = <Tensor>]()\n",
      "  %1973 = Unsqueeze(%184, %1972)\n",
      "  %1974 = Constant[value = <Tensor>]()\n",
      "  %1975 = Unsqueeze(%1971, %1974)\n",
      "  %1976 = Concat[axis = 0](%1973, %1975)\n",
      "  %1977 = Reshape[allowzero = 0](%1958, %1976)\n",
      "  %1978 = Gemm[alpha = 1, beta = 1](%1977, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias)\n",
      "  %1979 = Constant[value = <Tensor>]()\n",
      "  %1980 = Unsqueeze(%1961, %1979)\n",
      "  %1981 = Constant[value = <Tensor>]()\n",
      "  %1982 = Unsqueeze(%1964, %1981)\n",
      "  %1983 = Constant[value = <Tensor>]()\n",
      "  %1984 = Unsqueeze(%180, %1983)\n",
      "  %1985 = Concat[axis = 0](%1980, %1982, %1984)\n",
      "  %1986 = Reshape[allowzero = 0](%1978, %1985)\n",
      "  %1987 = Constant[value = <Tensor>]()\n",
      "  %1988, %1989, %1990 = Split[axis = 2](%1986, %1987)\n",
      "  %1991 = Shape(%1988)\n",
      "  %1992 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1993 = Gather[axis = 0](%1991, %1992)\n",
      "  %1994 = Shape(%1988)\n",
      "  %1995 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1996 = Gather[axis = 0](%1994, %1995)\n",
      "  %1997 = Constant[value = <Tensor>]()\n",
      "  %1998 = Unsqueeze(%1993, %1997)\n",
      "  %1999 = Constant[value = <Tensor>]()\n",
      "  %2000 = Unsqueeze(%1996, %1999)\n",
      "  %2001 = Constant[value = <Tensor>]()\n",
      "  %2002 = Unsqueeze(%179, %2001)\n",
      "  %2003 = Constant[value = <Tensor>]()\n",
      "  %2004 = Unsqueeze(%178, %2003)\n",
      "  %2005 = Concat[axis = 0](%1998, %2000, %2002, %2004)\n",
      "  %2006 = Reshape[allowzero = 0](%1988, %2005)\n",
      "  %2007 = Transpose[perm = [0, 2, 1, 3]](%2006)\n",
      "  %2008 = Shape(%1989)\n",
      "  %2009 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2010 = Gather[axis = 0](%2008, %2009)\n",
      "  %2011 = Shape(%1989)\n",
      "  %2012 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2013 = Gather[axis = 0](%2011, %2012)\n",
      "  %2014 = Constant[value = <Tensor>]()\n",
      "  %2015 = Unsqueeze(%2010, %2014)\n",
      "  %2016 = Constant[value = <Tensor>]()\n",
      "  %2017 = Unsqueeze(%2013, %2016)\n",
      "  %2018 = Constant[value = <Tensor>]()\n",
      "  %2019 = Unsqueeze(%179, %2018)\n",
      "  %2020 = Constant[value = <Tensor>]()\n",
      "  %2021 = Unsqueeze(%178, %2020)\n",
      "  %2022 = Concat[axis = 0](%2015, %2017, %2019, %2021)\n",
      "  %2023 = Reshape[allowzero = 0](%1989, %2022)\n",
      "  %2024 = Transpose[perm = [0, 2, 1, 3]](%2023)\n",
      "  %2025 = Shape(%1990)\n",
      "  %2026 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2027 = Gather[axis = 0](%2025, %2026)\n",
      "  %2028 = Shape(%1990)\n",
      "  %2029 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2030 = Gather[axis = 0](%2028, %2029)\n",
      "  %2031 = Constant[value = <Tensor>]()\n",
      "  %2032 = Unsqueeze(%2027, %2031)\n",
      "  %2033 = Constant[value = <Tensor>]()\n",
      "  %2034 = Unsqueeze(%2030, %2033)\n",
      "  %2035 = Constant[value = <Tensor>]()\n",
      "  %2036 = Unsqueeze(%179, %2035)\n",
      "  %2037 = Constant[value = <Tensor>]()\n",
      "  %2038 = Unsqueeze(%178, %2037)\n",
      "  %2039 = Concat[axis = 0](%2032, %2034, %2036, %2038)\n",
      "  %2040 = Reshape[allowzero = 0](%1990, %2039)\n",
      "  %2041 = Transpose[perm = [0, 2, 1, 3]](%2040)\n",
      "  %2042 = Transpose[perm = [0, 2, 3, 1]](%2023)\n",
      "  %2043 = MatMul(%2007, %2042)\n",
      "  %2044 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2045 = Div(%2043, %2044)\n",
      "  %2046 = Shape(%2007)\n",
      "  %2047 = Constant[value = <Tensor>]()\n",
      "  %2048 = Constant[value = <Tensor>]()\n",
      "  %2049 = Constant[value = <Tensor>]()\n",
      "  %2050 = Slice(%2046, %2048, %2049, %2047)\n",
      "  %2051 = Constant[value = <Tensor>]()\n",
      "  %2052 = Squeeze(%2050, %2051)\n",
      "  %2053 = Shape(%2024)\n",
      "  %2054 = Constant[value = <Tensor>]()\n",
      "  %2055 = Constant[value = <Tensor>]()\n",
      "  %2056 = Constant[value = <Tensor>]()\n",
      "  %2057 = Slice(%2053, %2055, %2056, %2054)\n",
      "  %2058 = Constant[value = <Tensor>]()\n",
      "  %2059 = Squeeze(%2057, %2058)\n",
      "  %2060 = Sub(%2059, %2052)\n",
      "  %2061 = Constant[value = <Tensor>]()\n",
      "  %2062 = Unsqueeze(%2060, %2061)\n",
      "  %2063 = Constant[value = <Tensor>]()\n",
      "  %2064 = Unsqueeze(%2059, %2063)\n",
      "  %2065 = Constant[value = <Tensor>]()\n",
      "  %2066 = Unsqueeze(%188, %2065)\n",
      "  %2067 = Constant[value = <Tensor>]()\n",
      "  %2068 = Slice(%decoder_no_past.decoder.transformer.h.6.attn.bias, %2062, %2064, %2066, %2067)\n",
      "  %2069 = Constant[value = <Tensor>]()\n",
      "  %2070 = Unsqueeze(%189, %2069)\n",
      "  %2071 = Constant[value = <Tensor>]()\n",
      "  %2072 = Unsqueeze(%2059, %2071)\n",
      "  %2073 = Constant[value = <Tensor>]()\n",
      "  %2074 = Unsqueeze(%183, %2073)\n",
      "  %2075 = Constant[value = <Tensor>]()\n",
      "  %2076 = Slice(%2068, %2070, %2072, %2074, %2075)\n",
      "  %2077 = Cast[to = 9](%2076)\n",
      "  %2078 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.6.attn.masked_bias)\n",
      "  %2079 = Where(%2077, %2045, %2078)\n",
      "  %2080 = Add(%2079, %377)\n",
      "  %2081 = Softmax[axis = -1](%2080)\n",
      "  %2082 = MatMul(%2081, %2041)\n",
      "  %2083 = Transpose[perm = [0, 2, 1, 3]](%2082)\n",
      "  %2084 = Shape(%2083)\n",
      "  %2085 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2086 = Gather[axis = 0](%2084, %2085)\n",
      "  %2087 = Shape(%2083)\n",
      "  %2088 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2089 = Gather[axis = 0](%2087, %2088)\n",
      "  %2090 = Constant[value = <Tensor>]()\n",
      "  %2091 = Unsqueeze(%2086, %2090)\n",
      "  %2092 = Constant[value = <Tensor>]()\n",
      "  %2093 = Unsqueeze(%2089, %2092)\n",
      "  %2094 = Constant[value = <Tensor>]()\n",
      "  %2095 = Unsqueeze(%181, %2094)\n",
      "  %2096 = Concat[axis = 0](%2091, %2093, %2095)\n",
      "  %2097 = Reshape[allowzero = 0](%2083, %2096)\n",
      "  %2098 = Shape(%2097)\n",
      "  %2099 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2100 = Gather[axis = 0](%2098, %2099)\n",
      "  %2101 = Shape(%2097)\n",
      "  %2102 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2103 = Gather[axis = 0](%2101, %2102)\n",
      "  %2104 = Shape(%2097)\n",
      "  %2105 = Constant[value = <Tensor>]()\n",
      "  %2106 = Constant[value = <Tensor>]()\n",
      "  %2107 = Constant[value = <Tensor>]()\n",
      "  %2108 = Slice(%2104, %2106, %2107, %2105)\n",
      "  %2109 = Constant[value = <Tensor>]()\n",
      "  %2110 = Squeeze(%2108, %2109)\n",
      "  %2111 = Constant[value = <Tensor>]()\n",
      "  %2112 = Unsqueeze(%184, %2111)\n",
      "  %2113 = Constant[value = <Tensor>]()\n",
      "  %2114 = Unsqueeze(%2110, %2113)\n",
      "  %2115 = Concat[axis = 0](%2112, %2114)\n",
      "  %2116 = Reshape[allowzero = 0](%2097, %2115)\n",
      "  %2117 = Gemm[alpha = 1, beta = 1](%2116, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias)\n",
      "  %2118 = Constant[value = <Tensor>]()\n",
      "  %2119 = Unsqueeze(%2100, %2118)\n",
      "  %2120 = Constant[value = <Tensor>]()\n",
      "  %2121 = Unsqueeze(%2103, %2120)\n",
      "  %2122 = Constant[value = <Tensor>]()\n",
      "  %2123 = Unsqueeze(%181, %2122)\n",
      "  %2124 = Concat[axis = 0](%2119, %2121, %2123)\n",
      "  %2125 = Reshape[allowzero = 0](%2117, %2124)\n",
      "  %2126 = Add(%2125, %1947)\n",
      "  %2127 = ReduceMean[axes = [-1]](%2126)\n",
      "  %2128 = Sub(%2126, %2127)\n",
      "  %2129 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2130 = Pow(%2128, %2129)\n",
      "  %2131 = ReduceMean[axes = [-1]](%2130)\n",
      "  %2132 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2133 = Add(%2131, %2132)\n",
      "  %2134 = Sqrt(%2133)\n",
      "  %2135 = Div(%2128, %2134)\n",
      "  %2136 = Mul(%2135, %decoder_no_past.decoder.transformer.h.6.ln_2.weight)\n",
      "  %2137 = Add(%2136, %decoder_no_past.decoder.transformer.h.6.ln_2.bias)\n",
      "  %2138 = Shape(%2137)\n",
      "  %2139 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2140 = Gather[axis = 0](%2138, %2139)\n",
      "  %2141 = Shape(%2137)\n",
      "  %2142 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2143 = Gather[axis = 0](%2141, %2142)\n",
      "  %2144 = Shape(%2137)\n",
      "  %2145 = Constant[value = <Tensor>]()\n",
      "  %2146 = Constant[value = <Tensor>]()\n",
      "  %2147 = Constant[value = <Tensor>]()\n",
      "  %2148 = Slice(%2144, %2146, %2147, %2145)\n",
      "  %2149 = Constant[value = <Tensor>]()\n",
      "  %2150 = Squeeze(%2148, %2149)\n",
      "  %2151 = Constant[value = <Tensor>]()\n",
      "  %2152 = Unsqueeze(%184, %2151)\n",
      "  %2153 = Constant[value = <Tensor>]()\n",
      "  %2154 = Unsqueeze(%2150, %2153)\n",
      "  %2155 = Concat[axis = 0](%2152, %2154)\n",
      "  %2156 = Reshape[allowzero = 0](%2137, %2155)\n",
      "  %2157 = Gemm[alpha = 1, beta = 1](%2156, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias)\n",
      "  %2158 = Constant[value = <Tensor>]()\n",
      "  %2159 = Unsqueeze(%2140, %2158)\n",
      "  %2160 = Constant[value = <Tensor>]()\n",
      "  %2161 = Unsqueeze(%2143, %2160)\n",
      "  %2162 = Constant[value = <Tensor>]()\n",
      "  %2163 = Unsqueeze(%177, %2162)\n",
      "  %2164 = Concat[axis = 0](%2159, %2161, %2163)\n",
      "  %2165 = Reshape[allowzero = 0](%2157, %2164)\n",
      "  %2166 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2167 = Mul(%2165, %2166)\n",
      "  %2168 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2169 = Pow(%2165, %2168)\n",
      "  %2170 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2171 = Mul(%2169, %2170)\n",
      "  %2172 = Add(%2165, %2171)\n",
      "  %2173 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2174 = Mul(%2172, %2173)\n",
      "  %2175 = Tanh(%2174)\n",
      "  %2176 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2177 = Add(%2175, %2176)\n",
      "  %2178 = Mul(%2167, %2177)\n",
      "  %2179 = Shape(%2178)\n",
      "  %2180 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2181 = Gather[axis = 0](%2179, %2180)\n",
      "  %2182 = Shape(%2178)\n",
      "  %2183 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2184 = Gather[axis = 0](%2182, %2183)\n",
      "  %2185 = Shape(%2178)\n",
      "  %2186 = Constant[value = <Tensor>]()\n",
      "  %2187 = Constant[value = <Tensor>]()\n",
      "  %2188 = Constant[value = <Tensor>]()\n",
      "  %2189 = Slice(%2185, %2187, %2188, %2186)\n",
      "  %2190 = Constant[value = <Tensor>]()\n",
      "  %2191 = Squeeze(%2189, %2190)\n",
      "  %2192 = Constant[value = <Tensor>]()\n",
      "  %2193 = Unsqueeze(%184, %2192)\n",
      "  %2194 = Constant[value = <Tensor>]()\n",
      "  %2195 = Unsqueeze(%2191, %2194)\n",
      "  %2196 = Concat[axis = 0](%2193, %2195)\n",
      "  %2197 = Reshape[allowzero = 0](%2178, %2196)\n",
      "  %2198 = Gemm[alpha = 1, beta = 1](%2197, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias)\n",
      "  %2199 = Constant[value = <Tensor>]()\n",
      "  %2200 = Unsqueeze(%2181, %2199)\n",
      "  %2201 = Constant[value = <Tensor>]()\n",
      "  %2202 = Unsqueeze(%2184, %2201)\n",
      "  %2203 = Constant[value = <Tensor>]()\n",
      "  %2204 = Unsqueeze(%181, %2203)\n",
      "  %2205 = Concat[axis = 0](%2200, %2202, %2204)\n",
      "  %2206 = Reshape[allowzero = 0](%2198, %2205)\n",
      "  %2207 = Add(%2126, %2206)\n",
      "  %2208 = ReduceMean[axes = [-1]](%2207)\n",
      "  %2209 = Sub(%2207, %2208)\n",
      "  %2210 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2211 = Pow(%2209, %2210)\n",
      "  %2212 = ReduceMean[axes = [-1]](%2211)\n",
      "  %2213 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2214 = Add(%2212, %2213)\n",
      "  %2215 = Sqrt(%2214)\n",
      "  %2216 = Div(%2209, %2215)\n",
      "  %2217 = Mul(%2216, %decoder_no_past.decoder.transformer.h.7.ln_1.weight)\n",
      "  %2218 = Add(%2217, %decoder_no_past.decoder.transformer.h.7.ln_1.bias)\n",
      "  %2219 = Shape(%2218)\n",
      "  %2220 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2221 = Gather[axis = 0](%2219, %2220)\n",
      "  %2222 = Shape(%2218)\n",
      "  %2223 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2224 = Gather[axis = 0](%2222, %2223)\n",
      "  %2225 = Shape(%2218)\n",
      "  %2226 = Constant[value = <Tensor>]()\n",
      "  %2227 = Constant[value = <Tensor>]()\n",
      "  %2228 = Constant[value = <Tensor>]()\n",
      "  %2229 = Slice(%2225, %2227, %2228, %2226)\n",
      "  %2230 = Constant[value = <Tensor>]()\n",
      "  %2231 = Squeeze(%2229, %2230)\n",
      "  %2232 = Constant[value = <Tensor>]()\n",
      "  %2233 = Unsqueeze(%184, %2232)\n",
      "  %2234 = Constant[value = <Tensor>]()\n",
      "  %2235 = Unsqueeze(%2231, %2234)\n",
      "  %2236 = Concat[axis = 0](%2233, %2235)\n",
      "  %2237 = Reshape[allowzero = 0](%2218, %2236)\n",
      "  %2238 = Gemm[alpha = 1, beta = 1](%2237, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias)\n",
      "  %2239 = Constant[value = <Tensor>]()\n",
      "  %2240 = Unsqueeze(%2221, %2239)\n",
      "  %2241 = Constant[value = <Tensor>]()\n",
      "  %2242 = Unsqueeze(%2224, %2241)\n",
      "  %2243 = Constant[value = <Tensor>]()\n",
      "  %2244 = Unsqueeze(%180, %2243)\n",
      "  %2245 = Concat[axis = 0](%2240, %2242, %2244)\n",
      "  %2246 = Reshape[allowzero = 0](%2238, %2245)\n",
      "  %2247 = Constant[value = <Tensor>]()\n",
      "  %2248, %2249, %2250 = Split[axis = 2](%2246, %2247)\n",
      "  %2251 = Shape(%2248)\n",
      "  %2252 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2253 = Gather[axis = 0](%2251, %2252)\n",
      "  %2254 = Shape(%2248)\n",
      "  %2255 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2256 = Gather[axis = 0](%2254, %2255)\n",
      "  %2257 = Constant[value = <Tensor>]()\n",
      "  %2258 = Unsqueeze(%2253, %2257)\n",
      "  %2259 = Constant[value = <Tensor>]()\n",
      "  %2260 = Unsqueeze(%2256, %2259)\n",
      "  %2261 = Constant[value = <Tensor>]()\n",
      "  %2262 = Unsqueeze(%179, %2261)\n",
      "  %2263 = Constant[value = <Tensor>]()\n",
      "  %2264 = Unsqueeze(%178, %2263)\n",
      "  %2265 = Concat[axis = 0](%2258, %2260, %2262, %2264)\n",
      "  %2266 = Reshape[allowzero = 0](%2248, %2265)\n",
      "  %2267 = Transpose[perm = [0, 2, 1, 3]](%2266)\n",
      "  %2268 = Shape(%2249)\n",
      "  %2269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2270 = Gather[axis = 0](%2268, %2269)\n",
      "  %2271 = Shape(%2249)\n",
      "  %2272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2273 = Gather[axis = 0](%2271, %2272)\n",
      "  %2274 = Constant[value = <Tensor>]()\n",
      "  %2275 = Unsqueeze(%2270, %2274)\n",
      "  %2276 = Constant[value = <Tensor>]()\n",
      "  %2277 = Unsqueeze(%2273, %2276)\n",
      "  %2278 = Constant[value = <Tensor>]()\n",
      "  %2279 = Unsqueeze(%179, %2278)\n",
      "  %2280 = Constant[value = <Tensor>]()\n",
      "  %2281 = Unsqueeze(%178, %2280)\n",
      "  %2282 = Concat[axis = 0](%2275, %2277, %2279, %2281)\n",
      "  %2283 = Reshape[allowzero = 0](%2249, %2282)\n",
      "  %2284 = Transpose[perm = [0, 2, 1, 3]](%2283)\n",
      "  %2285 = Shape(%2250)\n",
      "  %2286 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2287 = Gather[axis = 0](%2285, %2286)\n",
      "  %2288 = Shape(%2250)\n",
      "  %2289 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2290 = Gather[axis = 0](%2288, %2289)\n",
      "  %2291 = Constant[value = <Tensor>]()\n",
      "  %2292 = Unsqueeze(%2287, %2291)\n",
      "  %2293 = Constant[value = <Tensor>]()\n",
      "  %2294 = Unsqueeze(%2290, %2293)\n",
      "  %2295 = Constant[value = <Tensor>]()\n",
      "  %2296 = Unsqueeze(%179, %2295)\n",
      "  %2297 = Constant[value = <Tensor>]()\n",
      "  %2298 = Unsqueeze(%178, %2297)\n",
      "  %2299 = Concat[axis = 0](%2292, %2294, %2296, %2298)\n",
      "  %2300 = Reshape[allowzero = 0](%2250, %2299)\n",
      "  %2301 = Transpose[perm = [0, 2, 1, 3]](%2300)\n",
      "  %2302 = Transpose[perm = [0, 2, 3, 1]](%2283)\n",
      "  %2303 = MatMul(%2267, %2302)\n",
      "  %2304 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2305 = Div(%2303, %2304)\n",
      "  %2306 = Shape(%2267)\n",
      "  %2307 = Constant[value = <Tensor>]()\n",
      "  %2308 = Constant[value = <Tensor>]()\n",
      "  %2309 = Constant[value = <Tensor>]()\n",
      "  %2310 = Slice(%2306, %2308, %2309, %2307)\n",
      "  %2311 = Constant[value = <Tensor>]()\n",
      "  %2312 = Squeeze(%2310, %2311)\n",
      "  %2313 = Shape(%2284)\n",
      "  %2314 = Constant[value = <Tensor>]()\n",
      "  %2315 = Constant[value = <Tensor>]()\n",
      "  %2316 = Constant[value = <Tensor>]()\n",
      "  %2317 = Slice(%2313, %2315, %2316, %2314)\n",
      "  %2318 = Constant[value = <Tensor>]()\n",
      "  %2319 = Squeeze(%2317, %2318)\n",
      "  %2320 = Sub(%2319, %2312)\n",
      "  %2321 = Constant[value = <Tensor>]()\n",
      "  %2322 = Unsqueeze(%2320, %2321)\n",
      "  %2323 = Constant[value = <Tensor>]()\n",
      "  %2324 = Unsqueeze(%2319, %2323)\n",
      "  %2325 = Constant[value = <Tensor>]()\n",
      "  %2326 = Unsqueeze(%188, %2325)\n",
      "  %2327 = Constant[value = <Tensor>]()\n",
      "  %2328 = Slice(%decoder_no_past.decoder.transformer.h.7.attn.bias, %2322, %2324, %2326, %2327)\n",
      "  %2329 = Constant[value = <Tensor>]()\n",
      "  %2330 = Unsqueeze(%189, %2329)\n",
      "  %2331 = Constant[value = <Tensor>]()\n",
      "  %2332 = Unsqueeze(%2319, %2331)\n",
      "  %2333 = Constant[value = <Tensor>]()\n",
      "  %2334 = Unsqueeze(%183, %2333)\n",
      "  %2335 = Constant[value = <Tensor>]()\n",
      "  %2336 = Slice(%2328, %2330, %2332, %2334, %2335)\n",
      "  %2337 = Cast[to = 9](%2336)\n",
      "  %2338 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.7.attn.masked_bias)\n",
      "  %2339 = Where(%2337, %2305, %2338)\n",
      "  %2340 = Add(%2339, %377)\n",
      "  %2341 = Softmax[axis = -1](%2340)\n",
      "  %2342 = MatMul(%2341, %2301)\n",
      "  %2343 = Transpose[perm = [0, 2, 1, 3]](%2342)\n",
      "  %2344 = Shape(%2343)\n",
      "  %2345 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2346 = Gather[axis = 0](%2344, %2345)\n",
      "  %2347 = Shape(%2343)\n",
      "  %2348 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2349 = Gather[axis = 0](%2347, %2348)\n",
      "  %2350 = Constant[value = <Tensor>]()\n",
      "  %2351 = Unsqueeze(%2346, %2350)\n",
      "  %2352 = Constant[value = <Tensor>]()\n",
      "  %2353 = Unsqueeze(%2349, %2352)\n",
      "  %2354 = Constant[value = <Tensor>]()\n",
      "  %2355 = Unsqueeze(%181, %2354)\n",
      "  %2356 = Concat[axis = 0](%2351, %2353, %2355)\n",
      "  %2357 = Reshape[allowzero = 0](%2343, %2356)\n",
      "  %2358 = Shape(%2357)\n",
      "  %2359 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2360 = Gather[axis = 0](%2358, %2359)\n",
      "  %2361 = Shape(%2357)\n",
      "  %2362 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2363 = Gather[axis = 0](%2361, %2362)\n",
      "  %2364 = Shape(%2357)\n",
      "  %2365 = Constant[value = <Tensor>]()\n",
      "  %2366 = Constant[value = <Tensor>]()\n",
      "  %2367 = Constant[value = <Tensor>]()\n",
      "  %2368 = Slice(%2364, %2366, %2367, %2365)\n",
      "  %2369 = Constant[value = <Tensor>]()\n",
      "  %2370 = Squeeze(%2368, %2369)\n",
      "  %2371 = Constant[value = <Tensor>]()\n",
      "  %2372 = Unsqueeze(%184, %2371)\n",
      "  %2373 = Constant[value = <Tensor>]()\n",
      "  %2374 = Unsqueeze(%2370, %2373)\n",
      "  %2375 = Concat[axis = 0](%2372, %2374)\n",
      "  %2376 = Reshape[allowzero = 0](%2357, %2375)\n",
      "  %2377 = Gemm[alpha = 1, beta = 1](%2376, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias)\n",
      "  %2378 = Constant[value = <Tensor>]()\n",
      "  %2379 = Unsqueeze(%2360, %2378)\n",
      "  %2380 = Constant[value = <Tensor>]()\n",
      "  %2381 = Unsqueeze(%2363, %2380)\n",
      "  %2382 = Constant[value = <Tensor>]()\n",
      "  %2383 = Unsqueeze(%181, %2382)\n",
      "  %2384 = Concat[axis = 0](%2379, %2381, %2383)\n",
      "  %2385 = Reshape[allowzero = 0](%2377, %2384)\n",
      "  %2386 = Add(%2385, %2207)\n",
      "  %2387 = ReduceMean[axes = [-1]](%2386)\n",
      "  %2388 = Sub(%2386, %2387)\n",
      "  %2389 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2390 = Pow(%2388, %2389)\n",
      "  %2391 = ReduceMean[axes = [-1]](%2390)\n",
      "  %2392 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2393 = Add(%2391, %2392)\n",
      "  %2394 = Sqrt(%2393)\n",
      "  %2395 = Div(%2388, %2394)\n",
      "  %2396 = Mul(%2395, %decoder_no_past.decoder.transformer.h.7.ln_2.weight)\n",
      "  %2397 = Add(%2396, %decoder_no_past.decoder.transformer.h.7.ln_2.bias)\n",
      "  %2398 = Shape(%2397)\n",
      "  %2399 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2400 = Gather[axis = 0](%2398, %2399)\n",
      "  %2401 = Shape(%2397)\n",
      "  %2402 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2403 = Gather[axis = 0](%2401, %2402)\n",
      "  %2404 = Shape(%2397)\n",
      "  %2405 = Constant[value = <Tensor>]()\n",
      "  %2406 = Constant[value = <Tensor>]()\n",
      "  %2407 = Constant[value = <Tensor>]()\n",
      "  %2408 = Slice(%2404, %2406, %2407, %2405)\n",
      "  %2409 = Constant[value = <Tensor>]()\n",
      "  %2410 = Squeeze(%2408, %2409)\n",
      "  %2411 = Constant[value = <Tensor>]()\n",
      "  %2412 = Unsqueeze(%184, %2411)\n",
      "  %2413 = Constant[value = <Tensor>]()\n",
      "  %2414 = Unsqueeze(%2410, %2413)\n",
      "  %2415 = Concat[axis = 0](%2412, %2414)\n",
      "  %2416 = Reshape[allowzero = 0](%2397, %2415)\n",
      "  %2417 = Gemm[alpha = 1, beta = 1](%2416, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias)\n",
      "  %2418 = Constant[value = <Tensor>]()\n",
      "  %2419 = Unsqueeze(%2400, %2418)\n",
      "  %2420 = Constant[value = <Tensor>]()\n",
      "  %2421 = Unsqueeze(%2403, %2420)\n",
      "  %2422 = Constant[value = <Tensor>]()\n",
      "  %2423 = Unsqueeze(%177, %2422)\n",
      "  %2424 = Concat[axis = 0](%2419, %2421, %2423)\n",
      "  %2425 = Reshape[allowzero = 0](%2417, %2424)\n",
      "  %2426 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2427 = Mul(%2425, %2426)\n",
      "  %2428 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2429 = Pow(%2425, %2428)\n",
      "  %2430 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2431 = Mul(%2429, %2430)\n",
      "  %2432 = Add(%2425, %2431)\n",
      "  %2433 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2434 = Mul(%2432, %2433)\n",
      "  %2435 = Tanh(%2434)\n",
      "  %2436 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2437 = Add(%2435, %2436)\n",
      "  %2438 = Mul(%2427, %2437)\n",
      "  %2439 = Shape(%2438)\n",
      "  %2440 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2441 = Gather[axis = 0](%2439, %2440)\n",
      "  %2442 = Shape(%2438)\n",
      "  %2443 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2444 = Gather[axis = 0](%2442, %2443)\n",
      "  %2445 = Shape(%2438)\n",
      "  %2446 = Constant[value = <Tensor>]()\n",
      "  %2447 = Constant[value = <Tensor>]()\n",
      "  %2448 = Constant[value = <Tensor>]()\n",
      "  %2449 = Slice(%2445, %2447, %2448, %2446)\n",
      "  %2450 = Constant[value = <Tensor>]()\n",
      "  %2451 = Squeeze(%2449, %2450)\n",
      "  %2452 = Constant[value = <Tensor>]()\n",
      "  %2453 = Unsqueeze(%184, %2452)\n",
      "  %2454 = Constant[value = <Tensor>]()\n",
      "  %2455 = Unsqueeze(%2451, %2454)\n",
      "  %2456 = Concat[axis = 0](%2453, %2455)\n",
      "  %2457 = Reshape[allowzero = 0](%2438, %2456)\n",
      "  %2458 = Gemm[alpha = 1, beta = 1](%2457, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias)\n",
      "  %2459 = Constant[value = <Tensor>]()\n",
      "  %2460 = Unsqueeze(%2441, %2459)\n",
      "  %2461 = Constant[value = <Tensor>]()\n",
      "  %2462 = Unsqueeze(%2444, %2461)\n",
      "  %2463 = Constant[value = <Tensor>]()\n",
      "  %2464 = Unsqueeze(%181, %2463)\n",
      "  %2465 = Concat[axis = 0](%2460, %2462, %2464)\n",
      "  %2466 = Reshape[allowzero = 0](%2458, %2465)\n",
      "  %2467 = Add(%2386, %2466)\n",
      "  %2468 = ReduceMean[axes = [-1]](%2467)\n",
      "  %2469 = Sub(%2467, %2468)\n",
      "  %2470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2471 = Pow(%2469, %2470)\n",
      "  %2472 = ReduceMean[axes = [-1]](%2471)\n",
      "  %2473 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2474 = Add(%2472, %2473)\n",
      "  %2475 = Sqrt(%2474)\n",
      "  %2476 = Div(%2469, %2475)\n",
      "  %2477 = Mul(%2476, %decoder_no_past.decoder.transformer.h.8.ln_1.weight)\n",
      "  %2478 = Add(%2477, %decoder_no_past.decoder.transformer.h.8.ln_1.bias)\n",
      "  %2479 = Shape(%2478)\n",
      "  %2480 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2481 = Gather[axis = 0](%2479, %2480)\n",
      "  %2482 = Shape(%2478)\n",
      "  %2483 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2484 = Gather[axis = 0](%2482, %2483)\n",
      "  %2485 = Shape(%2478)\n",
      "  %2486 = Constant[value = <Tensor>]()\n",
      "  %2487 = Constant[value = <Tensor>]()\n",
      "  %2488 = Constant[value = <Tensor>]()\n",
      "  %2489 = Slice(%2485, %2487, %2488, %2486)\n",
      "  %2490 = Constant[value = <Tensor>]()\n",
      "  %2491 = Squeeze(%2489, %2490)\n",
      "  %2492 = Constant[value = <Tensor>]()\n",
      "  %2493 = Unsqueeze(%184, %2492)\n",
      "  %2494 = Constant[value = <Tensor>]()\n",
      "  %2495 = Unsqueeze(%2491, %2494)\n",
      "  %2496 = Concat[axis = 0](%2493, %2495)\n",
      "  %2497 = Reshape[allowzero = 0](%2478, %2496)\n",
      "  %2498 = Gemm[alpha = 1, beta = 1](%2497, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias)\n",
      "  %2499 = Constant[value = <Tensor>]()\n",
      "  %2500 = Unsqueeze(%2481, %2499)\n",
      "  %2501 = Constant[value = <Tensor>]()\n",
      "  %2502 = Unsqueeze(%2484, %2501)\n",
      "  %2503 = Constant[value = <Tensor>]()\n",
      "  %2504 = Unsqueeze(%180, %2503)\n",
      "  %2505 = Concat[axis = 0](%2500, %2502, %2504)\n",
      "  %2506 = Reshape[allowzero = 0](%2498, %2505)\n",
      "  %2507 = Constant[value = <Tensor>]()\n",
      "  %2508, %2509, %2510 = Split[axis = 2](%2506, %2507)\n",
      "  %2511 = Shape(%2508)\n",
      "  %2512 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2513 = Gather[axis = 0](%2511, %2512)\n",
      "  %2514 = Shape(%2508)\n",
      "  %2515 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2516 = Gather[axis = 0](%2514, %2515)\n",
      "  %2517 = Constant[value = <Tensor>]()\n",
      "  %2518 = Unsqueeze(%2513, %2517)\n",
      "  %2519 = Constant[value = <Tensor>]()\n",
      "  %2520 = Unsqueeze(%2516, %2519)\n",
      "  %2521 = Constant[value = <Tensor>]()\n",
      "  %2522 = Unsqueeze(%179, %2521)\n",
      "  %2523 = Constant[value = <Tensor>]()\n",
      "  %2524 = Unsqueeze(%178, %2523)\n",
      "  %2525 = Concat[axis = 0](%2518, %2520, %2522, %2524)\n",
      "  %2526 = Reshape[allowzero = 0](%2508, %2525)\n",
      "  %2527 = Transpose[perm = [0, 2, 1, 3]](%2526)\n",
      "  %2528 = Shape(%2509)\n",
      "  %2529 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2530 = Gather[axis = 0](%2528, %2529)\n",
      "  %2531 = Shape(%2509)\n",
      "  %2532 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2533 = Gather[axis = 0](%2531, %2532)\n",
      "  %2534 = Constant[value = <Tensor>]()\n",
      "  %2535 = Unsqueeze(%2530, %2534)\n",
      "  %2536 = Constant[value = <Tensor>]()\n",
      "  %2537 = Unsqueeze(%2533, %2536)\n",
      "  %2538 = Constant[value = <Tensor>]()\n",
      "  %2539 = Unsqueeze(%179, %2538)\n",
      "  %2540 = Constant[value = <Tensor>]()\n",
      "  %2541 = Unsqueeze(%178, %2540)\n",
      "  %2542 = Concat[axis = 0](%2535, %2537, %2539, %2541)\n",
      "  %2543 = Reshape[allowzero = 0](%2509, %2542)\n",
      "  %2544 = Transpose[perm = [0, 2, 1, 3]](%2543)\n",
      "  %2545 = Shape(%2510)\n",
      "  %2546 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2547 = Gather[axis = 0](%2545, %2546)\n",
      "  %2548 = Shape(%2510)\n",
      "  %2549 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2550 = Gather[axis = 0](%2548, %2549)\n",
      "  %2551 = Constant[value = <Tensor>]()\n",
      "  %2552 = Unsqueeze(%2547, %2551)\n",
      "  %2553 = Constant[value = <Tensor>]()\n",
      "  %2554 = Unsqueeze(%2550, %2553)\n",
      "  %2555 = Constant[value = <Tensor>]()\n",
      "  %2556 = Unsqueeze(%179, %2555)\n",
      "  %2557 = Constant[value = <Tensor>]()\n",
      "  %2558 = Unsqueeze(%178, %2557)\n",
      "  %2559 = Concat[axis = 0](%2552, %2554, %2556, %2558)\n",
      "  %2560 = Reshape[allowzero = 0](%2510, %2559)\n",
      "  %2561 = Transpose[perm = [0, 2, 1, 3]](%2560)\n",
      "  %2562 = Transpose[perm = [0, 2, 3, 1]](%2543)\n",
      "  %2563 = MatMul(%2527, %2562)\n",
      "  %2564 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2565 = Div(%2563, %2564)\n",
      "  %2566 = Shape(%2527)\n",
      "  %2567 = Constant[value = <Tensor>]()\n",
      "  %2568 = Constant[value = <Tensor>]()\n",
      "  %2569 = Constant[value = <Tensor>]()\n",
      "  %2570 = Slice(%2566, %2568, %2569, %2567)\n",
      "  %2571 = Constant[value = <Tensor>]()\n",
      "  %2572 = Squeeze(%2570, %2571)\n",
      "  %2573 = Shape(%2544)\n",
      "  %2574 = Constant[value = <Tensor>]()\n",
      "  %2575 = Constant[value = <Tensor>]()\n",
      "  %2576 = Constant[value = <Tensor>]()\n",
      "  %2577 = Slice(%2573, %2575, %2576, %2574)\n",
      "  %2578 = Constant[value = <Tensor>]()\n",
      "  %2579 = Squeeze(%2577, %2578)\n",
      "  %2580 = Sub(%2579, %2572)\n",
      "  %2581 = Constant[value = <Tensor>]()\n",
      "  %2582 = Unsqueeze(%2580, %2581)\n",
      "  %2583 = Constant[value = <Tensor>]()\n",
      "  %2584 = Unsqueeze(%2579, %2583)\n",
      "  %2585 = Constant[value = <Tensor>]()\n",
      "  %2586 = Unsqueeze(%188, %2585)\n",
      "  %2587 = Constant[value = <Tensor>]()\n",
      "  %2588 = Slice(%decoder_no_past.decoder.transformer.h.8.attn.bias, %2582, %2584, %2586, %2587)\n",
      "  %2589 = Constant[value = <Tensor>]()\n",
      "  %2590 = Unsqueeze(%189, %2589)\n",
      "  %2591 = Constant[value = <Tensor>]()\n",
      "  %2592 = Unsqueeze(%2579, %2591)\n",
      "  %2593 = Constant[value = <Tensor>]()\n",
      "  %2594 = Unsqueeze(%183, %2593)\n",
      "  %2595 = Constant[value = <Tensor>]()\n",
      "  %2596 = Slice(%2588, %2590, %2592, %2594, %2595)\n",
      "  %2597 = Cast[to = 9](%2596)\n",
      "  %2598 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.8.attn.masked_bias)\n",
      "  %2599 = Where(%2597, %2565, %2598)\n",
      "  %2600 = Add(%2599, %377)\n",
      "  %2601 = Softmax[axis = -1](%2600)\n",
      "  %2602 = MatMul(%2601, %2561)\n",
      "  %2603 = Transpose[perm = [0, 2, 1, 3]](%2602)\n",
      "  %2604 = Shape(%2603)\n",
      "  %2605 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2606 = Gather[axis = 0](%2604, %2605)\n",
      "  %2607 = Shape(%2603)\n",
      "  %2608 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2609 = Gather[axis = 0](%2607, %2608)\n",
      "  %2610 = Constant[value = <Tensor>]()\n",
      "  %2611 = Unsqueeze(%2606, %2610)\n",
      "  %2612 = Constant[value = <Tensor>]()\n",
      "  %2613 = Unsqueeze(%2609, %2612)\n",
      "  %2614 = Constant[value = <Tensor>]()\n",
      "  %2615 = Unsqueeze(%181, %2614)\n",
      "  %2616 = Concat[axis = 0](%2611, %2613, %2615)\n",
      "  %2617 = Reshape[allowzero = 0](%2603, %2616)\n",
      "  %2618 = Shape(%2617)\n",
      "  %2619 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2620 = Gather[axis = 0](%2618, %2619)\n",
      "  %2621 = Shape(%2617)\n",
      "  %2622 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2623 = Gather[axis = 0](%2621, %2622)\n",
      "  %2624 = Shape(%2617)\n",
      "  %2625 = Constant[value = <Tensor>]()\n",
      "  %2626 = Constant[value = <Tensor>]()\n",
      "  %2627 = Constant[value = <Tensor>]()\n",
      "  %2628 = Slice(%2624, %2626, %2627, %2625)\n",
      "  %2629 = Constant[value = <Tensor>]()\n",
      "  %2630 = Squeeze(%2628, %2629)\n",
      "  %2631 = Constant[value = <Tensor>]()\n",
      "  %2632 = Unsqueeze(%184, %2631)\n",
      "  %2633 = Constant[value = <Tensor>]()\n",
      "  %2634 = Unsqueeze(%2630, %2633)\n",
      "  %2635 = Concat[axis = 0](%2632, %2634)\n",
      "  %2636 = Reshape[allowzero = 0](%2617, %2635)\n",
      "  %2637 = Gemm[alpha = 1, beta = 1](%2636, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias)\n",
      "  %2638 = Constant[value = <Tensor>]()\n",
      "  %2639 = Unsqueeze(%2620, %2638)\n",
      "  %2640 = Constant[value = <Tensor>]()\n",
      "  %2641 = Unsqueeze(%2623, %2640)\n",
      "  %2642 = Constant[value = <Tensor>]()\n",
      "  %2643 = Unsqueeze(%181, %2642)\n",
      "  %2644 = Concat[axis = 0](%2639, %2641, %2643)\n",
      "  %2645 = Reshape[allowzero = 0](%2637, %2644)\n",
      "  %2646 = Add(%2645, %2467)\n",
      "  %2647 = ReduceMean[axes = [-1]](%2646)\n",
      "  %2648 = Sub(%2646, %2647)\n",
      "  %2649 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2650 = Pow(%2648, %2649)\n",
      "  %2651 = ReduceMean[axes = [-1]](%2650)\n",
      "  %2652 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2653 = Add(%2651, %2652)\n",
      "  %2654 = Sqrt(%2653)\n",
      "  %2655 = Div(%2648, %2654)\n",
      "  %2656 = Mul(%2655, %decoder_no_past.decoder.transformer.h.8.ln_2.weight)\n",
      "  %2657 = Add(%2656, %decoder_no_past.decoder.transformer.h.8.ln_2.bias)\n",
      "  %2658 = Shape(%2657)\n",
      "  %2659 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2660 = Gather[axis = 0](%2658, %2659)\n",
      "  %2661 = Shape(%2657)\n",
      "  %2662 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2663 = Gather[axis = 0](%2661, %2662)\n",
      "  %2664 = Shape(%2657)\n",
      "  %2665 = Constant[value = <Tensor>]()\n",
      "  %2666 = Constant[value = <Tensor>]()\n",
      "  %2667 = Constant[value = <Tensor>]()\n",
      "  %2668 = Slice(%2664, %2666, %2667, %2665)\n",
      "  %2669 = Constant[value = <Tensor>]()\n",
      "  %2670 = Squeeze(%2668, %2669)\n",
      "  %2671 = Constant[value = <Tensor>]()\n",
      "  %2672 = Unsqueeze(%184, %2671)\n",
      "  %2673 = Constant[value = <Tensor>]()\n",
      "  %2674 = Unsqueeze(%2670, %2673)\n",
      "  %2675 = Concat[axis = 0](%2672, %2674)\n",
      "  %2676 = Reshape[allowzero = 0](%2657, %2675)\n",
      "  %2677 = Gemm[alpha = 1, beta = 1](%2676, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias)\n",
      "  %2678 = Constant[value = <Tensor>]()\n",
      "  %2679 = Unsqueeze(%2660, %2678)\n",
      "  %2680 = Constant[value = <Tensor>]()\n",
      "  %2681 = Unsqueeze(%2663, %2680)\n",
      "  %2682 = Constant[value = <Tensor>]()\n",
      "  %2683 = Unsqueeze(%177, %2682)\n",
      "  %2684 = Concat[axis = 0](%2679, %2681, %2683)\n",
      "  %2685 = Reshape[allowzero = 0](%2677, %2684)\n",
      "  %2686 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2687 = Mul(%2685, %2686)\n",
      "  %2688 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2689 = Pow(%2685, %2688)\n",
      "  %2690 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2691 = Mul(%2689, %2690)\n",
      "  %2692 = Add(%2685, %2691)\n",
      "  %2693 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2694 = Mul(%2692, %2693)\n",
      "  %2695 = Tanh(%2694)\n",
      "  %2696 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2697 = Add(%2695, %2696)\n",
      "  %2698 = Mul(%2687, %2697)\n",
      "  %2699 = Shape(%2698)\n",
      "  %2700 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2701 = Gather[axis = 0](%2699, %2700)\n",
      "  %2702 = Shape(%2698)\n",
      "  %2703 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2704 = Gather[axis = 0](%2702, %2703)\n",
      "  %2705 = Shape(%2698)\n",
      "  %2706 = Constant[value = <Tensor>]()\n",
      "  %2707 = Constant[value = <Tensor>]()\n",
      "  %2708 = Constant[value = <Tensor>]()\n",
      "  %2709 = Slice(%2705, %2707, %2708, %2706)\n",
      "  %2710 = Constant[value = <Tensor>]()\n",
      "  %2711 = Squeeze(%2709, %2710)\n",
      "  %2712 = Constant[value = <Tensor>]()\n",
      "  %2713 = Unsqueeze(%184, %2712)\n",
      "  %2714 = Constant[value = <Tensor>]()\n",
      "  %2715 = Unsqueeze(%2711, %2714)\n",
      "  %2716 = Concat[axis = 0](%2713, %2715)\n",
      "  %2717 = Reshape[allowzero = 0](%2698, %2716)\n",
      "  %2718 = Gemm[alpha = 1, beta = 1](%2717, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias)\n",
      "  %2719 = Constant[value = <Tensor>]()\n",
      "  %2720 = Unsqueeze(%2701, %2719)\n",
      "  %2721 = Constant[value = <Tensor>]()\n",
      "  %2722 = Unsqueeze(%2704, %2721)\n",
      "  %2723 = Constant[value = <Tensor>]()\n",
      "  %2724 = Unsqueeze(%181, %2723)\n",
      "  %2725 = Concat[axis = 0](%2720, %2722, %2724)\n",
      "  %2726 = Reshape[allowzero = 0](%2718, %2725)\n",
      "  %2727 = Add(%2646, %2726)\n",
      "  %2728 = ReduceMean[axes = [-1]](%2727)\n",
      "  %2729 = Sub(%2727, %2728)\n",
      "  %2730 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2731 = Pow(%2729, %2730)\n",
      "  %2732 = ReduceMean[axes = [-1]](%2731)\n",
      "  %2733 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2734 = Add(%2732, %2733)\n",
      "  %2735 = Sqrt(%2734)\n",
      "  %2736 = Div(%2729, %2735)\n",
      "  %2737 = Mul(%2736, %decoder_no_past.decoder.transformer.h.9.ln_1.weight)\n",
      "  %2738 = Add(%2737, %decoder_no_past.decoder.transformer.h.9.ln_1.bias)\n",
      "  %2739 = Shape(%2738)\n",
      "  %2740 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2741 = Gather[axis = 0](%2739, %2740)\n",
      "  %2742 = Shape(%2738)\n",
      "  %2743 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2744 = Gather[axis = 0](%2742, %2743)\n",
      "  %2745 = Shape(%2738)\n",
      "  %2746 = Constant[value = <Tensor>]()\n",
      "  %2747 = Constant[value = <Tensor>]()\n",
      "  %2748 = Constant[value = <Tensor>]()\n",
      "  %2749 = Slice(%2745, %2747, %2748, %2746)\n",
      "  %2750 = Constant[value = <Tensor>]()\n",
      "  %2751 = Squeeze(%2749, %2750)\n",
      "  %2752 = Constant[value = <Tensor>]()\n",
      "  %2753 = Unsqueeze(%184, %2752)\n",
      "  %2754 = Constant[value = <Tensor>]()\n",
      "  %2755 = Unsqueeze(%2751, %2754)\n",
      "  %2756 = Concat[axis = 0](%2753, %2755)\n",
      "  %2757 = Reshape[allowzero = 0](%2738, %2756)\n",
      "  %2758 = Gemm[alpha = 1, beta = 1](%2757, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias)\n",
      "  %2759 = Constant[value = <Tensor>]()\n",
      "  %2760 = Unsqueeze(%2741, %2759)\n",
      "  %2761 = Constant[value = <Tensor>]()\n",
      "  %2762 = Unsqueeze(%2744, %2761)\n",
      "  %2763 = Constant[value = <Tensor>]()\n",
      "  %2764 = Unsqueeze(%180, %2763)\n",
      "  %2765 = Concat[axis = 0](%2760, %2762, %2764)\n",
      "  %2766 = Reshape[allowzero = 0](%2758, %2765)\n",
      "  %2767 = Constant[value = <Tensor>]()\n",
      "  %2768, %2769, %2770 = Split[axis = 2](%2766, %2767)\n",
      "  %2771 = Shape(%2768)\n",
      "  %2772 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2773 = Gather[axis = 0](%2771, %2772)\n",
      "  %2774 = Shape(%2768)\n",
      "  %2775 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2776 = Gather[axis = 0](%2774, %2775)\n",
      "  %2777 = Constant[value = <Tensor>]()\n",
      "  %2778 = Unsqueeze(%2773, %2777)\n",
      "  %2779 = Constant[value = <Tensor>]()\n",
      "  %2780 = Unsqueeze(%2776, %2779)\n",
      "  %2781 = Constant[value = <Tensor>]()\n",
      "  %2782 = Unsqueeze(%179, %2781)\n",
      "  %2783 = Constant[value = <Tensor>]()\n",
      "  %2784 = Unsqueeze(%178, %2783)\n",
      "  %2785 = Concat[axis = 0](%2778, %2780, %2782, %2784)\n",
      "  %2786 = Reshape[allowzero = 0](%2768, %2785)\n",
      "  %2787 = Transpose[perm = [0, 2, 1, 3]](%2786)\n",
      "  %2788 = Shape(%2769)\n",
      "  %2789 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2790 = Gather[axis = 0](%2788, %2789)\n",
      "  %2791 = Shape(%2769)\n",
      "  %2792 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2793 = Gather[axis = 0](%2791, %2792)\n",
      "  %2794 = Constant[value = <Tensor>]()\n",
      "  %2795 = Unsqueeze(%2790, %2794)\n",
      "  %2796 = Constant[value = <Tensor>]()\n",
      "  %2797 = Unsqueeze(%2793, %2796)\n",
      "  %2798 = Constant[value = <Tensor>]()\n",
      "  %2799 = Unsqueeze(%179, %2798)\n",
      "  %2800 = Constant[value = <Tensor>]()\n",
      "  %2801 = Unsqueeze(%178, %2800)\n",
      "  %2802 = Concat[axis = 0](%2795, %2797, %2799, %2801)\n",
      "  %2803 = Reshape[allowzero = 0](%2769, %2802)\n",
      "  %2804 = Transpose[perm = [0, 2, 1, 3]](%2803)\n",
      "  %2805 = Shape(%2770)\n",
      "  %2806 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2807 = Gather[axis = 0](%2805, %2806)\n",
      "  %2808 = Shape(%2770)\n",
      "  %2809 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2810 = Gather[axis = 0](%2808, %2809)\n",
      "  %2811 = Constant[value = <Tensor>]()\n",
      "  %2812 = Unsqueeze(%2807, %2811)\n",
      "  %2813 = Constant[value = <Tensor>]()\n",
      "  %2814 = Unsqueeze(%2810, %2813)\n",
      "  %2815 = Constant[value = <Tensor>]()\n",
      "  %2816 = Unsqueeze(%179, %2815)\n",
      "  %2817 = Constant[value = <Tensor>]()\n",
      "  %2818 = Unsqueeze(%178, %2817)\n",
      "  %2819 = Concat[axis = 0](%2812, %2814, %2816, %2818)\n",
      "  %2820 = Reshape[allowzero = 0](%2770, %2819)\n",
      "  %2821 = Transpose[perm = [0, 2, 1, 3]](%2820)\n",
      "  %2822 = Transpose[perm = [0, 2, 3, 1]](%2803)\n",
      "  %2823 = MatMul(%2787, %2822)\n",
      "  %2824 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2825 = Div(%2823, %2824)\n",
      "  %2826 = Shape(%2787)\n",
      "  %2827 = Constant[value = <Tensor>]()\n",
      "  %2828 = Constant[value = <Tensor>]()\n",
      "  %2829 = Constant[value = <Tensor>]()\n",
      "  %2830 = Slice(%2826, %2828, %2829, %2827)\n",
      "  %2831 = Constant[value = <Tensor>]()\n",
      "  %2832 = Squeeze(%2830, %2831)\n",
      "  %2833 = Shape(%2804)\n",
      "  %2834 = Constant[value = <Tensor>]()\n",
      "  %2835 = Constant[value = <Tensor>]()\n",
      "  %2836 = Constant[value = <Tensor>]()\n",
      "  %2837 = Slice(%2833, %2835, %2836, %2834)\n",
      "  %2838 = Constant[value = <Tensor>]()\n",
      "  %2839 = Squeeze(%2837, %2838)\n",
      "  %2840 = Sub(%2839, %2832)\n",
      "  %2841 = Constant[value = <Tensor>]()\n",
      "  %2842 = Unsqueeze(%2840, %2841)\n",
      "  %2843 = Constant[value = <Tensor>]()\n",
      "  %2844 = Unsqueeze(%2839, %2843)\n",
      "  %2845 = Constant[value = <Tensor>]()\n",
      "  %2846 = Unsqueeze(%188, %2845)\n",
      "  %2847 = Constant[value = <Tensor>]()\n",
      "  %2848 = Slice(%decoder_no_past.decoder.transformer.h.9.attn.bias, %2842, %2844, %2846, %2847)\n",
      "  %2849 = Constant[value = <Tensor>]()\n",
      "  %2850 = Unsqueeze(%189, %2849)\n",
      "  %2851 = Constant[value = <Tensor>]()\n",
      "  %2852 = Unsqueeze(%2839, %2851)\n",
      "  %2853 = Constant[value = <Tensor>]()\n",
      "  %2854 = Unsqueeze(%183, %2853)\n",
      "  %2855 = Constant[value = <Tensor>]()\n",
      "  %2856 = Slice(%2848, %2850, %2852, %2854, %2855)\n",
      "  %2857 = Cast[to = 9](%2856)\n",
      "  %2858 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.9.attn.masked_bias)\n",
      "  %2859 = Where(%2857, %2825, %2858)\n",
      "  %2860 = Add(%2859, %377)\n",
      "  %2861 = Softmax[axis = -1](%2860)\n",
      "  %2862 = MatMul(%2861, %2821)\n",
      "  %2863 = Transpose[perm = [0, 2, 1, 3]](%2862)\n",
      "  %2864 = Shape(%2863)\n",
      "  %2865 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2866 = Gather[axis = 0](%2864, %2865)\n",
      "  %2867 = Shape(%2863)\n",
      "  %2868 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2869 = Gather[axis = 0](%2867, %2868)\n",
      "  %2870 = Constant[value = <Tensor>]()\n",
      "  %2871 = Unsqueeze(%2866, %2870)\n",
      "  %2872 = Constant[value = <Tensor>]()\n",
      "  %2873 = Unsqueeze(%2869, %2872)\n",
      "  %2874 = Constant[value = <Tensor>]()\n",
      "  %2875 = Unsqueeze(%181, %2874)\n",
      "  %2876 = Concat[axis = 0](%2871, %2873, %2875)\n",
      "  %2877 = Reshape[allowzero = 0](%2863, %2876)\n",
      "  %2878 = Shape(%2877)\n",
      "  %2879 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2880 = Gather[axis = 0](%2878, %2879)\n",
      "  %2881 = Shape(%2877)\n",
      "  %2882 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2883 = Gather[axis = 0](%2881, %2882)\n",
      "  %2884 = Shape(%2877)\n",
      "  %2885 = Constant[value = <Tensor>]()\n",
      "  %2886 = Constant[value = <Tensor>]()\n",
      "  %2887 = Constant[value = <Tensor>]()\n",
      "  %2888 = Slice(%2884, %2886, %2887, %2885)\n",
      "  %2889 = Constant[value = <Tensor>]()\n",
      "  %2890 = Squeeze(%2888, %2889)\n",
      "  %2891 = Constant[value = <Tensor>]()\n",
      "  %2892 = Unsqueeze(%184, %2891)\n",
      "  %2893 = Constant[value = <Tensor>]()\n",
      "  %2894 = Unsqueeze(%2890, %2893)\n",
      "  %2895 = Concat[axis = 0](%2892, %2894)\n",
      "  %2896 = Reshape[allowzero = 0](%2877, %2895)\n",
      "  %2897 = Gemm[alpha = 1, beta = 1](%2896, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias)\n",
      "  %2898 = Constant[value = <Tensor>]()\n",
      "  %2899 = Unsqueeze(%2880, %2898)\n",
      "  %2900 = Constant[value = <Tensor>]()\n",
      "  %2901 = Unsqueeze(%2883, %2900)\n",
      "  %2902 = Constant[value = <Tensor>]()\n",
      "  %2903 = Unsqueeze(%181, %2902)\n",
      "  %2904 = Concat[axis = 0](%2899, %2901, %2903)\n",
      "  %2905 = Reshape[allowzero = 0](%2897, %2904)\n",
      "  %2906 = Add(%2905, %2727)\n",
      "  %2907 = ReduceMean[axes = [-1]](%2906)\n",
      "  %2908 = Sub(%2906, %2907)\n",
      "  %2909 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2910 = Pow(%2908, %2909)\n",
      "  %2911 = ReduceMean[axes = [-1]](%2910)\n",
      "  %2912 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2913 = Add(%2911, %2912)\n",
      "  %2914 = Sqrt(%2913)\n",
      "  %2915 = Div(%2908, %2914)\n",
      "  %2916 = Mul(%2915, %decoder_no_past.decoder.transformer.h.9.ln_2.weight)\n",
      "  %2917 = Add(%2916, %decoder_no_past.decoder.transformer.h.9.ln_2.bias)\n",
      "  %2918 = Shape(%2917)\n",
      "  %2919 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2920 = Gather[axis = 0](%2918, %2919)\n",
      "  %2921 = Shape(%2917)\n",
      "  %2922 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2923 = Gather[axis = 0](%2921, %2922)\n",
      "  %2924 = Shape(%2917)\n",
      "  %2925 = Constant[value = <Tensor>]()\n",
      "  %2926 = Constant[value = <Tensor>]()\n",
      "  %2927 = Constant[value = <Tensor>]()\n",
      "  %2928 = Slice(%2924, %2926, %2927, %2925)\n",
      "  %2929 = Constant[value = <Tensor>]()\n",
      "  %2930 = Squeeze(%2928, %2929)\n",
      "  %2931 = Constant[value = <Tensor>]()\n",
      "  %2932 = Unsqueeze(%184, %2931)\n",
      "  %2933 = Constant[value = <Tensor>]()\n",
      "  %2934 = Unsqueeze(%2930, %2933)\n",
      "  %2935 = Concat[axis = 0](%2932, %2934)\n",
      "  %2936 = Reshape[allowzero = 0](%2917, %2935)\n",
      "  %2937 = Gemm[alpha = 1, beta = 1](%2936, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias)\n",
      "  %2938 = Constant[value = <Tensor>]()\n",
      "  %2939 = Unsqueeze(%2920, %2938)\n",
      "  %2940 = Constant[value = <Tensor>]()\n",
      "  %2941 = Unsqueeze(%2923, %2940)\n",
      "  %2942 = Constant[value = <Tensor>]()\n",
      "  %2943 = Unsqueeze(%177, %2942)\n",
      "  %2944 = Concat[axis = 0](%2939, %2941, %2943)\n",
      "  %2945 = Reshape[allowzero = 0](%2937, %2944)\n",
      "  %2946 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2947 = Mul(%2945, %2946)\n",
      "  %2948 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2949 = Pow(%2945, %2948)\n",
      "  %2950 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2951 = Mul(%2949, %2950)\n",
      "  %2952 = Add(%2945, %2951)\n",
      "  %2953 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2954 = Mul(%2952, %2953)\n",
      "  %2955 = Tanh(%2954)\n",
      "  %2956 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2957 = Add(%2955, %2956)\n",
      "  %2958 = Mul(%2947, %2957)\n",
      "  %2959 = Shape(%2958)\n",
      "  %2960 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2961 = Gather[axis = 0](%2959, %2960)\n",
      "  %2962 = Shape(%2958)\n",
      "  %2963 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2964 = Gather[axis = 0](%2962, %2963)\n",
      "  %2965 = Shape(%2958)\n",
      "  %2966 = Constant[value = <Tensor>]()\n",
      "  %2967 = Constant[value = <Tensor>]()\n",
      "  %2968 = Constant[value = <Tensor>]()\n",
      "  %2969 = Slice(%2965, %2967, %2968, %2966)\n",
      "  %2970 = Constant[value = <Tensor>]()\n",
      "  %2971 = Squeeze(%2969, %2970)\n",
      "  %2972 = Constant[value = <Tensor>]()\n",
      "  %2973 = Unsqueeze(%184, %2972)\n",
      "  %2974 = Constant[value = <Tensor>]()\n",
      "  %2975 = Unsqueeze(%2971, %2974)\n",
      "  %2976 = Concat[axis = 0](%2973, %2975)\n",
      "  %2977 = Reshape[allowzero = 0](%2958, %2976)\n",
      "  %2978 = Gemm[alpha = 1, beta = 1](%2977, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias)\n",
      "  %2979 = Constant[value = <Tensor>]()\n",
      "  %2980 = Unsqueeze(%2961, %2979)\n",
      "  %2981 = Constant[value = <Tensor>]()\n",
      "  %2982 = Unsqueeze(%2964, %2981)\n",
      "  %2983 = Constant[value = <Tensor>]()\n",
      "  %2984 = Unsqueeze(%181, %2983)\n",
      "  %2985 = Concat[axis = 0](%2980, %2982, %2984)\n",
      "  %2986 = Reshape[allowzero = 0](%2978, %2985)\n",
      "  %2987 = Add(%2906, %2986)\n",
      "  %2988 = ReduceMean[axes = [-1]](%2987)\n",
      "  %2989 = Sub(%2987, %2988)\n",
      "  %2990 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2991 = Pow(%2989, %2990)\n",
      "  %2992 = ReduceMean[axes = [-1]](%2991)\n",
      "  %2993 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2994 = Add(%2992, %2993)\n",
      "  %2995 = Sqrt(%2994)\n",
      "  %2996 = Div(%2989, %2995)\n",
      "  %2997 = Mul(%2996, %decoder_no_past.decoder.transformer.h.10.ln_1.weight)\n",
      "  %2998 = Add(%2997, %decoder_no_past.decoder.transformer.h.10.ln_1.bias)\n",
      "  %2999 = Shape(%2998)\n",
      "  %3000 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3001 = Gather[axis = 0](%2999, %3000)\n",
      "  %3002 = Shape(%2998)\n",
      "  %3003 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3004 = Gather[axis = 0](%3002, %3003)\n",
      "  %3005 = Shape(%2998)\n",
      "  %3006 = Constant[value = <Tensor>]()\n",
      "  %3007 = Constant[value = <Tensor>]()\n",
      "  %3008 = Constant[value = <Tensor>]()\n",
      "  %3009 = Slice(%3005, %3007, %3008, %3006)\n",
      "  %3010 = Constant[value = <Tensor>]()\n",
      "  %3011 = Squeeze(%3009, %3010)\n",
      "  %3012 = Constant[value = <Tensor>]()\n",
      "  %3013 = Unsqueeze(%184, %3012)\n",
      "  %3014 = Constant[value = <Tensor>]()\n",
      "  %3015 = Unsqueeze(%3011, %3014)\n",
      "  %3016 = Concat[axis = 0](%3013, %3015)\n",
      "  %3017 = Reshape[allowzero = 0](%2998, %3016)\n",
      "  %3018 = Gemm[alpha = 1, beta = 1](%3017, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias)\n",
      "  %3019 = Constant[value = <Tensor>]()\n",
      "  %3020 = Unsqueeze(%3001, %3019)\n",
      "  %3021 = Constant[value = <Tensor>]()\n",
      "  %3022 = Unsqueeze(%3004, %3021)\n",
      "  %3023 = Constant[value = <Tensor>]()\n",
      "  %3024 = Unsqueeze(%180, %3023)\n",
      "  %3025 = Concat[axis = 0](%3020, %3022, %3024)\n",
      "  %3026 = Reshape[allowzero = 0](%3018, %3025)\n",
      "  %3027 = Constant[value = <Tensor>]()\n",
      "  %3028, %3029, %3030 = Split[axis = 2](%3026, %3027)\n",
      "  %3031 = Shape(%3028)\n",
      "  %3032 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3033 = Gather[axis = 0](%3031, %3032)\n",
      "  %3034 = Shape(%3028)\n",
      "  %3035 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3036 = Gather[axis = 0](%3034, %3035)\n",
      "  %3037 = Constant[value = <Tensor>]()\n",
      "  %3038 = Unsqueeze(%3033, %3037)\n",
      "  %3039 = Constant[value = <Tensor>]()\n",
      "  %3040 = Unsqueeze(%3036, %3039)\n",
      "  %3041 = Constant[value = <Tensor>]()\n",
      "  %3042 = Unsqueeze(%179, %3041)\n",
      "  %3043 = Constant[value = <Tensor>]()\n",
      "  %3044 = Unsqueeze(%178, %3043)\n",
      "  %3045 = Concat[axis = 0](%3038, %3040, %3042, %3044)\n",
      "  %3046 = Reshape[allowzero = 0](%3028, %3045)\n",
      "  %3047 = Transpose[perm = [0, 2, 1, 3]](%3046)\n",
      "  %3048 = Shape(%3029)\n",
      "  %3049 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3050 = Gather[axis = 0](%3048, %3049)\n",
      "  %3051 = Shape(%3029)\n",
      "  %3052 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3053 = Gather[axis = 0](%3051, %3052)\n",
      "  %3054 = Constant[value = <Tensor>]()\n",
      "  %3055 = Unsqueeze(%3050, %3054)\n",
      "  %3056 = Constant[value = <Tensor>]()\n",
      "  %3057 = Unsqueeze(%3053, %3056)\n",
      "  %3058 = Constant[value = <Tensor>]()\n",
      "  %3059 = Unsqueeze(%179, %3058)\n",
      "  %3060 = Constant[value = <Tensor>]()\n",
      "  %3061 = Unsqueeze(%178, %3060)\n",
      "  %3062 = Concat[axis = 0](%3055, %3057, %3059, %3061)\n",
      "  %3063 = Reshape[allowzero = 0](%3029, %3062)\n",
      "  %3064 = Transpose[perm = [0, 2, 1, 3]](%3063)\n",
      "  %3065 = Shape(%3030)\n",
      "  %3066 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3067 = Gather[axis = 0](%3065, %3066)\n",
      "  %3068 = Shape(%3030)\n",
      "  %3069 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3070 = Gather[axis = 0](%3068, %3069)\n",
      "  %3071 = Constant[value = <Tensor>]()\n",
      "  %3072 = Unsqueeze(%3067, %3071)\n",
      "  %3073 = Constant[value = <Tensor>]()\n",
      "  %3074 = Unsqueeze(%3070, %3073)\n",
      "  %3075 = Constant[value = <Tensor>]()\n",
      "  %3076 = Unsqueeze(%179, %3075)\n",
      "  %3077 = Constant[value = <Tensor>]()\n",
      "  %3078 = Unsqueeze(%178, %3077)\n",
      "  %3079 = Concat[axis = 0](%3072, %3074, %3076, %3078)\n",
      "  %3080 = Reshape[allowzero = 0](%3030, %3079)\n",
      "  %3081 = Transpose[perm = [0, 2, 1, 3]](%3080)\n",
      "  %3082 = Transpose[perm = [0, 2, 3, 1]](%3063)\n",
      "  %3083 = MatMul(%3047, %3082)\n",
      "  %3084 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3085 = Div(%3083, %3084)\n",
      "  %3086 = Shape(%3047)\n",
      "  %3087 = Constant[value = <Tensor>]()\n",
      "  %3088 = Constant[value = <Tensor>]()\n",
      "  %3089 = Constant[value = <Tensor>]()\n",
      "  %3090 = Slice(%3086, %3088, %3089, %3087)\n",
      "  %3091 = Constant[value = <Tensor>]()\n",
      "  %3092 = Squeeze(%3090, %3091)\n",
      "  %3093 = Shape(%3064)\n",
      "  %3094 = Constant[value = <Tensor>]()\n",
      "  %3095 = Constant[value = <Tensor>]()\n",
      "  %3096 = Constant[value = <Tensor>]()\n",
      "  %3097 = Slice(%3093, %3095, %3096, %3094)\n",
      "  %3098 = Constant[value = <Tensor>]()\n",
      "  %3099 = Squeeze(%3097, %3098)\n",
      "  %3100 = Sub(%3099, %3092)\n",
      "  %3101 = Constant[value = <Tensor>]()\n",
      "  %3102 = Unsqueeze(%3100, %3101)\n",
      "  %3103 = Constant[value = <Tensor>]()\n",
      "  %3104 = Unsqueeze(%3099, %3103)\n",
      "  %3105 = Constant[value = <Tensor>]()\n",
      "  %3106 = Unsqueeze(%188, %3105)\n",
      "  %3107 = Constant[value = <Tensor>]()\n",
      "  %3108 = Slice(%decoder_no_past.decoder.transformer.h.10.attn.bias, %3102, %3104, %3106, %3107)\n",
      "  %3109 = Constant[value = <Tensor>]()\n",
      "  %3110 = Unsqueeze(%189, %3109)\n",
      "  %3111 = Constant[value = <Tensor>]()\n",
      "  %3112 = Unsqueeze(%3099, %3111)\n",
      "  %3113 = Constant[value = <Tensor>]()\n",
      "  %3114 = Unsqueeze(%183, %3113)\n",
      "  %3115 = Constant[value = <Tensor>]()\n",
      "  %3116 = Slice(%3108, %3110, %3112, %3114, %3115)\n",
      "  %3117 = Cast[to = 9](%3116)\n",
      "  %3118 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.10.attn.masked_bias)\n",
      "  %3119 = Where(%3117, %3085, %3118)\n",
      "  %3120 = Add(%3119, %377)\n",
      "  %3121 = Softmax[axis = -1](%3120)\n",
      "  %3122 = MatMul(%3121, %3081)\n",
      "  %3123 = Transpose[perm = [0, 2, 1, 3]](%3122)\n",
      "  %3124 = Shape(%3123)\n",
      "  %3125 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3126 = Gather[axis = 0](%3124, %3125)\n",
      "  %3127 = Shape(%3123)\n",
      "  %3128 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3129 = Gather[axis = 0](%3127, %3128)\n",
      "  %3130 = Constant[value = <Tensor>]()\n",
      "  %3131 = Unsqueeze(%3126, %3130)\n",
      "  %3132 = Constant[value = <Tensor>]()\n",
      "  %3133 = Unsqueeze(%3129, %3132)\n",
      "  %3134 = Constant[value = <Tensor>]()\n",
      "  %3135 = Unsqueeze(%181, %3134)\n",
      "  %3136 = Concat[axis = 0](%3131, %3133, %3135)\n",
      "  %3137 = Reshape[allowzero = 0](%3123, %3136)\n",
      "  %3138 = Shape(%3137)\n",
      "  %3139 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3140 = Gather[axis = 0](%3138, %3139)\n",
      "  %3141 = Shape(%3137)\n",
      "  %3142 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3143 = Gather[axis = 0](%3141, %3142)\n",
      "  %3144 = Shape(%3137)\n",
      "  %3145 = Constant[value = <Tensor>]()\n",
      "  %3146 = Constant[value = <Tensor>]()\n",
      "  %3147 = Constant[value = <Tensor>]()\n",
      "  %3148 = Slice(%3144, %3146, %3147, %3145)\n",
      "  %3149 = Constant[value = <Tensor>]()\n",
      "  %3150 = Squeeze(%3148, %3149)\n",
      "  %3151 = Constant[value = <Tensor>]()\n",
      "  %3152 = Unsqueeze(%184, %3151)\n",
      "  %3153 = Constant[value = <Tensor>]()\n",
      "  %3154 = Unsqueeze(%3150, %3153)\n",
      "  %3155 = Concat[axis = 0](%3152, %3154)\n",
      "  %3156 = Reshape[allowzero = 0](%3137, %3155)\n",
      "  %3157 = Gemm[alpha = 1, beta = 1](%3156, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias)\n",
      "  %3158 = Constant[value = <Tensor>]()\n",
      "  %3159 = Unsqueeze(%3140, %3158)\n",
      "  %3160 = Constant[value = <Tensor>]()\n",
      "  %3161 = Unsqueeze(%3143, %3160)\n",
      "  %3162 = Constant[value = <Tensor>]()\n",
      "  %3163 = Unsqueeze(%181, %3162)\n",
      "  %3164 = Concat[axis = 0](%3159, %3161, %3163)\n",
      "  %3165 = Reshape[allowzero = 0](%3157, %3164)\n",
      "  %3166 = Add(%3165, %2987)\n",
      "  %3167 = ReduceMean[axes = [-1]](%3166)\n",
      "  %3168 = Sub(%3166, %3167)\n",
      "  %3169 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3170 = Pow(%3168, %3169)\n",
      "  %3171 = ReduceMean[axes = [-1]](%3170)\n",
      "  %3172 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3173 = Add(%3171, %3172)\n",
      "  %3174 = Sqrt(%3173)\n",
      "  %3175 = Div(%3168, %3174)\n",
      "  %3176 = Mul(%3175, %decoder_no_past.decoder.transformer.h.10.ln_2.weight)\n",
      "  %3177 = Add(%3176, %decoder_no_past.decoder.transformer.h.10.ln_2.bias)\n",
      "  %3178 = Shape(%3177)\n",
      "  %3179 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3180 = Gather[axis = 0](%3178, %3179)\n",
      "  %3181 = Shape(%3177)\n",
      "  %3182 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3183 = Gather[axis = 0](%3181, %3182)\n",
      "  %3184 = Shape(%3177)\n",
      "  %3185 = Constant[value = <Tensor>]()\n",
      "  %3186 = Constant[value = <Tensor>]()\n",
      "  %3187 = Constant[value = <Tensor>]()\n",
      "  %3188 = Slice(%3184, %3186, %3187, %3185)\n",
      "  %3189 = Constant[value = <Tensor>]()\n",
      "  %3190 = Squeeze(%3188, %3189)\n",
      "  %3191 = Constant[value = <Tensor>]()\n",
      "  %3192 = Unsqueeze(%184, %3191)\n",
      "  %3193 = Constant[value = <Tensor>]()\n",
      "  %3194 = Unsqueeze(%3190, %3193)\n",
      "  %3195 = Concat[axis = 0](%3192, %3194)\n",
      "  %3196 = Reshape[allowzero = 0](%3177, %3195)\n",
      "  %3197 = Gemm[alpha = 1, beta = 1](%3196, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias)\n",
      "  %3198 = Constant[value = <Tensor>]()\n",
      "  %3199 = Unsqueeze(%3180, %3198)\n",
      "  %3200 = Constant[value = <Tensor>]()\n",
      "  %3201 = Unsqueeze(%3183, %3200)\n",
      "  %3202 = Constant[value = <Tensor>]()\n",
      "  %3203 = Unsqueeze(%177, %3202)\n",
      "  %3204 = Concat[axis = 0](%3199, %3201, %3203)\n",
      "  %3205 = Reshape[allowzero = 0](%3197, %3204)\n",
      "  %3206 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3207 = Mul(%3205, %3206)\n",
      "  %3208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3209 = Pow(%3205, %3208)\n",
      "  %3210 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3211 = Mul(%3209, %3210)\n",
      "  %3212 = Add(%3205, %3211)\n",
      "  %3213 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3214 = Mul(%3212, %3213)\n",
      "  %3215 = Tanh(%3214)\n",
      "  %3216 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3217 = Add(%3215, %3216)\n",
      "  %3218 = Mul(%3207, %3217)\n",
      "  %3219 = Shape(%3218)\n",
      "  %3220 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3221 = Gather[axis = 0](%3219, %3220)\n",
      "  %3222 = Shape(%3218)\n",
      "  %3223 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3224 = Gather[axis = 0](%3222, %3223)\n",
      "  %3225 = Shape(%3218)\n",
      "  %3226 = Constant[value = <Tensor>]()\n",
      "  %3227 = Constant[value = <Tensor>]()\n",
      "  %3228 = Constant[value = <Tensor>]()\n",
      "  %3229 = Slice(%3225, %3227, %3228, %3226)\n",
      "  %3230 = Constant[value = <Tensor>]()\n",
      "  %3231 = Squeeze(%3229, %3230)\n",
      "  %3232 = Constant[value = <Tensor>]()\n",
      "  %3233 = Unsqueeze(%184, %3232)\n",
      "  %3234 = Constant[value = <Tensor>]()\n",
      "  %3235 = Unsqueeze(%3231, %3234)\n",
      "  %3236 = Concat[axis = 0](%3233, %3235)\n",
      "  %3237 = Reshape[allowzero = 0](%3218, %3236)\n",
      "  %3238 = Gemm[alpha = 1, beta = 1](%3237, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias)\n",
      "  %3239 = Constant[value = <Tensor>]()\n",
      "  %3240 = Unsqueeze(%3221, %3239)\n",
      "  %3241 = Constant[value = <Tensor>]()\n",
      "  %3242 = Unsqueeze(%3224, %3241)\n",
      "  %3243 = Constant[value = <Tensor>]()\n",
      "  %3244 = Unsqueeze(%181, %3243)\n",
      "  %3245 = Concat[axis = 0](%3240, %3242, %3244)\n",
      "  %3246 = Reshape[allowzero = 0](%3238, %3245)\n",
      "  %3247 = Add(%3166, %3246)\n",
      "  %3248 = ReduceMean[axes = [-1]](%3247)\n",
      "  %3249 = Sub(%3247, %3248)\n",
      "  %3250 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3251 = Pow(%3249, %3250)\n",
      "  %3252 = ReduceMean[axes = [-1]](%3251)\n",
      "  %3253 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3254 = Add(%3252, %3253)\n",
      "  %3255 = Sqrt(%3254)\n",
      "  %3256 = Div(%3249, %3255)\n",
      "  %3257 = Mul(%3256, %decoder_no_past.decoder.transformer.h.11.ln_1.weight)\n",
      "  %3258 = Add(%3257, %decoder_no_past.decoder.transformer.h.11.ln_1.bias)\n",
      "  %3259 = Shape(%3258)\n",
      "  %3260 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3261 = Gather[axis = 0](%3259, %3260)\n",
      "  %3262 = Shape(%3258)\n",
      "  %3263 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3264 = Gather[axis = 0](%3262, %3263)\n",
      "  %3265 = Shape(%3258)\n",
      "  %3266 = Constant[value = <Tensor>]()\n",
      "  %3267 = Constant[value = <Tensor>]()\n",
      "  %3268 = Constant[value = <Tensor>]()\n",
      "  %3269 = Slice(%3265, %3267, %3268, %3266)\n",
      "  %3270 = Constant[value = <Tensor>]()\n",
      "  %3271 = Squeeze(%3269, %3270)\n",
      "  %3272 = Constant[value = <Tensor>]()\n",
      "  %3273 = Unsqueeze(%184, %3272)\n",
      "  %3274 = Constant[value = <Tensor>]()\n",
      "  %3275 = Unsqueeze(%3271, %3274)\n",
      "  %3276 = Concat[axis = 0](%3273, %3275)\n",
      "  %3277 = Reshape[allowzero = 0](%3258, %3276)\n",
      "  %3278 = Gemm[alpha = 1, beta = 1](%3277, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias)\n",
      "  %3279 = Constant[value = <Tensor>]()\n",
      "  %3280 = Unsqueeze(%3261, %3279)\n",
      "  %3281 = Constant[value = <Tensor>]()\n",
      "  %3282 = Unsqueeze(%3264, %3281)\n",
      "  %3283 = Constant[value = <Tensor>]()\n",
      "  %3284 = Unsqueeze(%180, %3283)\n",
      "  %3285 = Concat[axis = 0](%3280, %3282, %3284)\n",
      "  %3286 = Reshape[allowzero = 0](%3278, %3285)\n",
      "  %3287 = Constant[value = <Tensor>]()\n",
      "  %3288, %3289, %3290 = Split[axis = 2](%3286, %3287)\n",
      "  %3291 = Shape(%3288)\n",
      "  %3292 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3293 = Gather[axis = 0](%3291, %3292)\n",
      "  %3294 = Shape(%3288)\n",
      "  %3295 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3296 = Gather[axis = 0](%3294, %3295)\n",
      "  %3297 = Constant[value = <Tensor>]()\n",
      "  %3298 = Unsqueeze(%3293, %3297)\n",
      "  %3299 = Constant[value = <Tensor>]()\n",
      "  %3300 = Unsqueeze(%3296, %3299)\n",
      "  %3301 = Constant[value = <Tensor>]()\n",
      "  %3302 = Unsqueeze(%179, %3301)\n",
      "  %3303 = Constant[value = <Tensor>]()\n",
      "  %3304 = Unsqueeze(%178, %3303)\n",
      "  %3305 = Concat[axis = 0](%3298, %3300, %3302, %3304)\n",
      "  %3306 = Reshape[allowzero = 0](%3288, %3305)\n",
      "  %3307 = Transpose[perm = [0, 2, 1, 3]](%3306)\n",
      "  %3308 = Shape(%3289)\n",
      "  %3309 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3310 = Gather[axis = 0](%3308, %3309)\n",
      "  %3311 = Shape(%3289)\n",
      "  %3312 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3313 = Gather[axis = 0](%3311, %3312)\n",
      "  %3314 = Constant[value = <Tensor>]()\n",
      "  %3315 = Unsqueeze(%3310, %3314)\n",
      "  %3316 = Constant[value = <Tensor>]()\n",
      "  %3317 = Unsqueeze(%3313, %3316)\n",
      "  %3318 = Constant[value = <Tensor>]()\n",
      "  %3319 = Unsqueeze(%179, %3318)\n",
      "  %3320 = Constant[value = <Tensor>]()\n",
      "  %3321 = Unsqueeze(%178, %3320)\n",
      "  %3322 = Concat[axis = 0](%3315, %3317, %3319, %3321)\n",
      "  %3323 = Reshape[allowzero = 0](%3289, %3322)\n",
      "  %3324 = Transpose[perm = [0, 2, 1, 3]](%3323)\n",
      "  %3325 = Shape(%3290)\n",
      "  %3326 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3327 = Gather[axis = 0](%3325, %3326)\n",
      "  %3328 = Shape(%3290)\n",
      "  %3329 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3330 = Gather[axis = 0](%3328, %3329)\n",
      "  %3331 = Constant[value = <Tensor>]()\n",
      "  %3332 = Unsqueeze(%3327, %3331)\n",
      "  %3333 = Constant[value = <Tensor>]()\n",
      "  %3334 = Unsqueeze(%3330, %3333)\n",
      "  %3335 = Constant[value = <Tensor>]()\n",
      "  %3336 = Unsqueeze(%179, %3335)\n",
      "  %3337 = Constant[value = <Tensor>]()\n",
      "  %3338 = Unsqueeze(%178, %3337)\n",
      "  %3339 = Concat[axis = 0](%3332, %3334, %3336, %3338)\n",
      "  %3340 = Reshape[allowzero = 0](%3290, %3339)\n",
      "  %3341 = Transpose[perm = [0, 2, 1, 3]](%3340)\n",
      "  %3342 = Transpose[perm = [0, 2, 3, 1]](%3323)\n",
      "  %3343 = MatMul(%3307, %3342)\n",
      "  %3344 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3345 = Div(%3343, %3344)\n",
      "  %3346 = Shape(%3307)\n",
      "  %3347 = Constant[value = <Tensor>]()\n",
      "  %3348 = Constant[value = <Tensor>]()\n",
      "  %3349 = Constant[value = <Tensor>]()\n",
      "  %3350 = Slice(%3346, %3348, %3349, %3347)\n",
      "  %3351 = Constant[value = <Tensor>]()\n",
      "  %3352 = Squeeze(%3350, %3351)\n",
      "  %3353 = Shape(%3324)\n",
      "  %3354 = Constant[value = <Tensor>]()\n",
      "  %3355 = Constant[value = <Tensor>]()\n",
      "  %3356 = Constant[value = <Tensor>]()\n",
      "  %3357 = Slice(%3353, %3355, %3356, %3354)\n",
      "  %3358 = Constant[value = <Tensor>]()\n",
      "  %3359 = Squeeze(%3357, %3358)\n",
      "  %3360 = Sub(%3359, %3352)\n",
      "  %3361 = Constant[value = <Tensor>]()\n",
      "  %3362 = Unsqueeze(%3360, %3361)\n",
      "  %3363 = Constant[value = <Tensor>]()\n",
      "  %3364 = Unsqueeze(%3359, %3363)\n",
      "  %3365 = Constant[value = <Tensor>]()\n",
      "  %3366 = Unsqueeze(%188, %3365)\n",
      "  %3367 = Constant[value = <Tensor>]()\n",
      "  %3368 = Slice(%decoder_no_past.decoder.transformer.h.11.attn.bias, %3362, %3364, %3366, %3367)\n",
      "  %3369 = Constant[value = <Tensor>]()\n",
      "  %3370 = Unsqueeze(%189, %3369)\n",
      "  %3371 = Constant[value = <Tensor>]()\n",
      "  %3372 = Unsqueeze(%3359, %3371)\n",
      "  %3373 = Constant[value = <Tensor>]()\n",
      "  %3374 = Unsqueeze(%183, %3373)\n",
      "  %3375 = Constant[value = <Tensor>]()\n",
      "  %3376 = Slice(%3368, %3370, %3372, %3374, %3375)\n",
      "  %3377 = Cast[to = 9](%3376)\n",
      "  %3378 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.11.attn.masked_bias)\n",
      "  %3379 = Where(%3377, %3345, %3378)\n",
      "  %3380 = Add(%3379, %377)\n",
      "  %3381 = Softmax[axis = -1](%3380)\n",
      "  %3382 = MatMul(%3381, %3341)\n",
      "  %3383 = Transpose[perm = [0, 2, 1, 3]](%3382)\n",
      "  %3384 = Shape(%3383)\n",
      "  %3385 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3386 = Gather[axis = 0](%3384, %3385)\n",
      "  %3387 = Shape(%3383)\n",
      "  %3388 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3389 = Gather[axis = 0](%3387, %3388)\n",
      "  %3390 = Constant[value = <Tensor>]()\n",
      "  %3391 = Unsqueeze(%3386, %3390)\n",
      "  %3392 = Constant[value = <Tensor>]()\n",
      "  %3393 = Unsqueeze(%3389, %3392)\n",
      "  %3394 = Constant[value = <Tensor>]()\n",
      "  %3395 = Unsqueeze(%181, %3394)\n",
      "  %3396 = Concat[axis = 0](%3391, %3393, %3395)\n",
      "  %3397 = Reshape[allowzero = 0](%3383, %3396)\n",
      "  %3398 = Shape(%3397)\n",
      "  %3399 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3400 = Gather[axis = 0](%3398, %3399)\n",
      "  %3401 = Shape(%3397)\n",
      "  %3402 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3403 = Gather[axis = 0](%3401, %3402)\n",
      "  %3404 = Shape(%3397)\n",
      "  %3405 = Constant[value = <Tensor>]()\n",
      "  %3406 = Constant[value = <Tensor>]()\n",
      "  %3407 = Constant[value = <Tensor>]()\n",
      "  %3408 = Slice(%3404, %3406, %3407, %3405)\n",
      "  %3409 = Constant[value = <Tensor>]()\n",
      "  %3410 = Squeeze(%3408, %3409)\n",
      "  %3411 = Constant[value = <Tensor>]()\n",
      "  %3412 = Unsqueeze(%184, %3411)\n",
      "  %3413 = Constant[value = <Tensor>]()\n",
      "  %3414 = Unsqueeze(%3410, %3413)\n",
      "  %3415 = Concat[axis = 0](%3412, %3414)\n",
      "  %3416 = Reshape[allowzero = 0](%3397, %3415)\n",
      "  %3417 = Gemm[alpha = 1, beta = 1](%3416, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias)\n",
      "  %3418 = Constant[value = <Tensor>]()\n",
      "  %3419 = Unsqueeze(%3400, %3418)\n",
      "  %3420 = Constant[value = <Tensor>]()\n",
      "  %3421 = Unsqueeze(%3403, %3420)\n",
      "  %3422 = Constant[value = <Tensor>]()\n",
      "  %3423 = Unsqueeze(%181, %3422)\n",
      "  %3424 = Concat[axis = 0](%3419, %3421, %3423)\n",
      "  %3425 = Reshape[allowzero = 0](%3417, %3424)\n",
      "  %3426 = Add(%3425, %3247)\n",
      "  %3427 = ReduceMean[axes = [-1]](%3426)\n",
      "  %3428 = Sub(%3426, %3427)\n",
      "  %3429 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3430 = Pow(%3428, %3429)\n",
      "  %3431 = ReduceMean[axes = [-1]](%3430)\n",
      "  %3432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3433 = Add(%3431, %3432)\n",
      "  %3434 = Sqrt(%3433)\n",
      "  %3435 = Div(%3428, %3434)\n",
      "  %3436 = Mul(%3435, %decoder_no_past.decoder.transformer.h.11.ln_2.weight)\n",
      "  %3437 = Add(%3436, %decoder_no_past.decoder.transformer.h.11.ln_2.bias)\n",
      "  %3438 = Shape(%3437)\n",
      "  %3439 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3440 = Gather[axis = 0](%3438, %3439)\n",
      "  %3441 = Shape(%3437)\n",
      "  %3442 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3443 = Gather[axis = 0](%3441, %3442)\n",
      "  %3444 = Shape(%3437)\n",
      "  %3445 = Constant[value = <Tensor>]()\n",
      "  %3446 = Constant[value = <Tensor>]()\n",
      "  %3447 = Constant[value = <Tensor>]()\n",
      "  %3448 = Slice(%3444, %3446, %3447, %3445)\n",
      "  %3449 = Constant[value = <Tensor>]()\n",
      "  %3450 = Squeeze(%3448, %3449)\n",
      "  %3451 = Constant[value = <Tensor>]()\n",
      "  %3452 = Unsqueeze(%184, %3451)\n",
      "  %3453 = Constant[value = <Tensor>]()\n",
      "  %3454 = Unsqueeze(%3450, %3453)\n",
      "  %3455 = Concat[axis = 0](%3452, %3454)\n",
      "  %3456 = Reshape[allowzero = 0](%3437, %3455)\n",
      "  %3457 = Gemm[alpha = 1, beta = 1](%3456, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias)\n",
      "  %3458 = Constant[value = <Tensor>]()\n",
      "  %3459 = Unsqueeze(%3440, %3458)\n",
      "  %3460 = Constant[value = <Tensor>]()\n",
      "  %3461 = Unsqueeze(%3443, %3460)\n",
      "  %3462 = Constant[value = <Tensor>]()\n",
      "  %3463 = Unsqueeze(%177, %3462)\n",
      "  %3464 = Concat[axis = 0](%3459, %3461, %3463)\n",
      "  %3465 = Reshape[allowzero = 0](%3457, %3464)\n",
      "  %3466 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3467 = Mul(%3465, %3466)\n",
      "  %3468 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3469 = Pow(%3465, %3468)\n",
      "  %3470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3471 = Mul(%3469, %3470)\n",
      "  %3472 = Add(%3465, %3471)\n",
      "  %3473 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3474 = Mul(%3472, %3473)\n",
      "  %3475 = Tanh(%3474)\n",
      "  %3476 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3477 = Add(%3475, %3476)\n",
      "  %3478 = Mul(%3467, %3477)\n",
      "  %3479 = Shape(%3478)\n",
      "  %3480 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3481 = Gather[axis = 0](%3479, %3480)\n",
      "  %3482 = Shape(%3478)\n",
      "  %3483 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3484 = Gather[axis = 0](%3482, %3483)\n",
      "  %3485 = Shape(%3478)\n",
      "  %3486 = Constant[value = <Tensor>]()\n",
      "  %3487 = Constant[value = <Tensor>]()\n",
      "  %3488 = Constant[value = <Tensor>]()\n",
      "  %3489 = Slice(%3485, %3487, %3488, %3486)\n",
      "  %3490 = Constant[value = <Tensor>]()\n",
      "  %3491 = Squeeze(%3489, %3490)\n",
      "  %3492 = Constant[value = <Tensor>]()\n",
      "  %3493 = Unsqueeze(%184, %3492)\n",
      "  %3494 = Constant[value = <Tensor>]()\n",
      "  %3495 = Unsqueeze(%3491, %3494)\n",
      "  %3496 = Concat[axis = 0](%3493, %3495)\n",
      "  %3497 = Reshape[allowzero = 0](%3478, %3496)\n",
      "  %3498 = Gemm[alpha = 1, beta = 1](%3497, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias)\n",
      "  %3499 = Constant[value = <Tensor>]()\n",
      "  %3500 = Unsqueeze(%3481, %3499)\n",
      "  %3501 = Constant[value = <Tensor>]()\n",
      "  %3502 = Unsqueeze(%3484, %3501)\n",
      "  %3503 = Constant[value = <Tensor>]()\n",
      "  %3504 = Unsqueeze(%181, %3503)\n",
      "  %3505 = Concat[axis = 0](%3500, %3502, %3504)\n",
      "  %3506 = Reshape[allowzero = 0](%3498, %3505)\n",
      "  %3507 = Add(%3426, %3506)\n",
      "  %3508 = ReduceMean[axes = [-1]](%3507)\n",
      "  %3509 = Sub(%3507, %3508)\n",
      "  %3510 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3511 = Pow(%3509, %3510)\n",
      "  %3512 = ReduceMean[axes = [-1]](%3511)\n",
      "  %3513 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3514 = Add(%3512, %3513)\n",
      "  %3515 = Sqrt(%3514)\n",
      "  %3516 = Div(%3509, %3515)\n",
      "  %3517 = Mul(%3516, %decoder_no_past.decoder.transformer.ln_f.weight)\n",
      "  %3518 = Add(%3517, %decoder_no_past.decoder.transformer.ln_f.bias)\n",
      "  %3519 = Constant[value = <Tensor>]()\n",
      "  %3520 = Unsqueeze(%336, %3519)\n",
      "  %3521 = Constant[value = <Tensor>]()\n",
      "  %3522 = Unsqueeze(%339, %3521)\n",
      "  %3523 = Constant[value = <Tensor>]()\n",
      "  %3524 = Unsqueeze(%387, %3523)\n",
      "  %3525 = Concat[axis = 0](%3520, %3522, %3524)\n",
      "  %3526 = Reshape[allowzero = 0](%3518, %3525)\n",
      "  %3527 = MatMul(%3526, %4854)\n",
      "  %3528 = Gather[axis = 1](%3527, %184)\n",
      "  %3529 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3530 = Sub(%max_length, %3529)\n",
      "  %3531 = Equal(%cur_len.13, %3530)\n",
      "  %3532 = Cast[to = 9](%3531)\n",
      "  %3533 = If[else_branch = <graph torch-jit-export3>, then_branch = <graph torch-jit-export2>](%3532)\n",
      "  %3584 = LogSoftmax[axis = -1](%3533)\n",
      "  %3585 = Shape(%input_ids.25)\n",
      "  %3586 = Constant[value = <Tensor>]()\n",
      "  %3587 = Constant[value = <Tensor>]()\n",
      "  %3588 = Constant[value = <Tensor>]()\n",
      "  %3589 = Slice(%3585, %3587, %3588, %3586)\n",
      "  %3590 = Constant[value = <Tensor>]()\n",
      "  %3591 = Squeeze(%3589, %3590)\n",
      "  %3592 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3593 = Less(%3591, %3592)\n",
      "  %3594 = Cast[to = 9](%3593)\n",
      "  %3595 = If[else_branch = <graph torch-jit-export5>, then_branch = <graph torch-jit-export4>](%3594)\n",
      "  %3641 = Constant[value = <Tensor>]()\n",
      "  %3642 = Unsqueeze(%beam_scores.17, %3641)\n",
      "  %3643 = Shape(%3595)\n",
      "  %3644 = Expand(%3642, %3643)\n",
      "  %3645 = Add(%3595, %3644)\n",
      "  %3646 = Shape(%3645)\n",
      "  %3647 = Constant[value = <Tensor>]()\n",
      "  %3648 = Constant[value = <Tensor>]()\n",
      "  %3649 = Constant[value = <Tensor>]()\n",
      "  %3650 = Slice(%3646, %3648, %3649, %3647)\n",
      "  %3651 = Constant[value = <Tensor>]()\n",
      "  %3652 = Squeeze(%3650, %3651)\n",
      "  %3653 = Mul(%num_beams, %3652)\n",
      "  %3654 = Constant[value = <Tensor>]()\n",
      "  %3655 = Unsqueeze(%192, %3654)\n",
      "  %3656 = Constant[value = <Tensor>]()\n",
      "  %3657 = Unsqueeze(%3653, %3656)\n",
      "  %3658 = Concat[axis = 0](%3655, %3657)\n",
      "  %3659 = Reshape[allowzero = 0](%3645, %3658)\n",
      "  %3660 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3661 = Mul(%num_beams, %3660)\n",
      "  %3662 = Constant[value = <Tensor>]()\n",
      "  %3663 = Reshape[allowzero = 0](%3661, %3662)\n",
      "  %3664, %3665 = TopK[axis = 1, largest = 1, sorted = 1](%3659, %3663)\n",
      "  %3666 = Div(%3665, %3652)\n",
      "  %3667 = Cast[to = 7](%3666)\n",
      "  %3668 = Cast[to = 7](%3667)\n",
      "  %3669 = Div(%3665, %3652)\n",
      "  %3670 = Mul(%3669, %3652)\n",
      "  %3671 = Sub(%3665, %3670)\n",
      "  %3672 = Constant[value = <Tensor>]()\n",
      "  %3673 = Shape(%332)\n",
      "  %3674 = Gather[axis = 0](%3673, %3672)\n",
      "  %3675 = Constant[value = <Tensor>]()\n",
      "  %3676 = Squeeze(%3674, %3675)\n",
      "  %3677 = Constant[value = <Tensor>]()\n",
      "  %3678 = Unsqueeze(%3676, %3677)\n",
      "  %3679 = Constant[value = <Tensor>]()\n",
      "  %3680 = Unsqueeze(%196, %3679)\n",
      "  %3681 = Concat[axis = 0](%3678, %3680)\n",
      "  %3682 = ConstantOfShape[value = <Tensor>](%3681)\n",
      "  %3683 = Constant[value = <Tensor>]()\n",
      "  %3684 = Unsqueeze(%3676, %3683)\n",
      "  %3685 = Constant[value = <Tensor>]()\n",
      "  %3686 = Unsqueeze(%196, %3685)\n",
      "  %3687 = Concat[axis = 0](%3684, %3686)\n",
      "  %3688 = ConstantOfShape[value = <Tensor>](%3687)\n",
      "  %3689 = Constant[value = <Tensor>]()\n",
      "  %3690 = Unsqueeze(%3676, %3689)\n",
      "  %3691 = Constant[value = <Tensor>]()\n",
      "  %3692 = Unsqueeze(%196, %3691)\n",
      "  %3693 = Concat[axis = 0](%3690, %3692)\n",
      "  %3694 = ConstantOfShape[value = <Tensor>](%3693)\n",
      "  %3695 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3696 = Greater(%3676, %3695)\n",
      "  %3697, %3698, %3699, %3700, %3701, %3702, %3703, %3704, %3705, %3706, %3707 = Loop[body = <graph torch-jit-export6>](%182, %3696, %188, %189, %189, %3682, %3688, %3694, %329, %330, %331, %332, %333)\n",
      "  %4364 = Constant[value = <Tensor>]()\n",
      "  %4365 = Reshape[allowzero = 0](%3700, %4364)\n",
      "  %4366 = Constant[value = <Tensor>]()\n",
      "  %4367 = Reshape[allowzero = 0](%3701, %4366)\n",
      "  %4368 = Constant[value = <Tensor>]()\n",
      "  %4369 = Reshape[allowzero = 0](%3702, %4368)\n",
      "  %4370 = Gather[axis = 0](%input_ids.25, %4369)\n",
      "  %4371 = Constant[value = <Tensor>]()\n",
      "  %4372 = Unsqueeze(%4367, %4371)\n",
      "  %4373 = Concat[axis = -1](%4370, %4372)\n",
      "  %4374 = Gather[axis = 0](%attention_mask.13, %4369)\n",
      "  %4375 = Shape(%attention_mask.13)\n",
      "  %4376 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4377 = Gather[axis = 0](%4375, %4376)\n",
      "  %4378 = Constant[value = <Tensor>]()\n",
      "  %4379 = Unsqueeze(%4377, %4378)\n",
      "  %4380 = Concat[axis = 0](%4379)\n",
      "  %4381 = ConstantOfShape[value = <Tensor>](%4380)\n",
      "  %4382 = Constant[value = <Tensor>]()\n",
      "  %4383 = Unsqueeze(%4381, %4382)\n",
      "  %4384 = Concat[axis = -1](%4374, %4383)\n",
      "  %4385 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4386 = Add(%cur_len.13, %4385)\n",
      "  %4387 = Not(%3707)\n",
      "  %4388 = Cast[to = 7](%4387)\n",
      "  %4389 = ReduceSum[keepdims = 0, noop_with_empty_axes = 0](%4388)\n",
      "  %4390 = Constant[value = <Tensor>]()\n",
      "  %4391 = Greater(%4389, %4390)\n",
      "  %4392 = Not(%4391)\n",
      "  %4393 = Cast[to = 9](%4392)\n",
      "  %4394 = If[else_branch = <graph torch-jit-export33>, then_branch = <graph torch-jit-export32>](%4393)\n",
      "  return %4394, %4373, %4365, %4384, %4386, %3703, %3704, %3705, %3706, %3707\n",
      "}\n",
      "\n",
      "graph torch-jit-export2 {\n",
      "  %3534 = Shape(%3528)\n",
      "  %3535 = ConstantOfShape[value = <Tensor>](%3534)\n",
      "  %3536 = Gather[axis = 1](%3535, %188)\n",
      "  %3537 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3538 = Shape(%3536)\n",
      "  %3539 = Expand(%3537, %3538)\n",
      "  %3540 = Shape(%3535)\n",
      "  %3541 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3542 = Gather[axis = 0](%3540, %3541)\n",
      "  %3543 = Cast[to = 7](%3542)\n",
      "  %3544 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3545 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3546 = Range(%3544, %3543, %3545)\n",
      "  %3547 = Constant[value = <Tensor>]()\n",
      "  %3548 = Constant[value = <Tensor>]()\n",
      "  %3549 = Reshape[allowzero = 0](%3546, %3548)\n",
      "  %3550 = Constant[value = <Tensor>]()\n",
      "  %3551 = Add(%3549, %3550)\n",
      "  %3552 = Shape(%3551)\n",
      "  %3553 = Shape(%3552)\n",
      "  %3554 = ConstantOfShape[value = <Tensor>](%3553)\n",
      "  %3555 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3556 = Mul(%3554, %3555)\n",
      "  %3557 = Equal(%3552, %3556)\n",
      "  %3558 = Where(%3557, %3554, %3552)\n",
      "  %3559 = Expand(%3549, %3558)\n",
      "  %3560 = Constant[value = <Tensor>]()\n",
      "  %3561 = Unsqueeze(%3559, %3560)\n",
      "  %3562 = Shape(%3552)\n",
      "  %3563 = ConstantOfShape[value = <Tensor>](%3562)\n",
      "  %3564 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3565 = Mul(%3563, %3564)\n",
      "  %3566 = Equal(%3552, %3565)\n",
      "  %3567 = Where(%3566, %3563, %3552)\n",
      "  %3568 = Expand(%3547, %3567)\n",
      "  %3569 = Constant[value = <Tensor>]()\n",
      "  %3570 = Unsqueeze(%3568, %3569)\n",
      "  %3571 = Concat[axis = -1](%3561, %3570)\n",
      "  %3572 = Shape(%3535)\n",
      "  %3573 = Constant[value = <Tensor>]()\n",
      "  %3574 = Constant[value = <Tensor>]()\n",
      "  %3575 = Constant[value = <Tensor>]()\n",
      "  %3576 = Slice(%3572, %3574, %3575, %3573)\n",
      "  %3577 = Concat[axis = 0](%3552, %3576)\n",
      "  %3578 = Reshape[allowzero = 0](%3539, %3577)\n",
      "  %3579 = ScatterND(%3535, %3571, %3578)\n",
      "  %3580 = Cast[to = 9](%3579)\n",
      "  %3581 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3582 = Where(%3580, %3581, %3528)\n",
      "  return %3582\n",
      "}\n",
      "\n",
      "graph torch-jit-export3 {\n",
      "  %3583 = Identity(%3528)\n",
      "  return %3583\n",
      "}\n",
      "\n",
      "graph torch-jit-export4 {\n",
      "  %3596 = Gather[axis = 1](%3584, %188)\n",
      "  %3597 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3598 = Shape(%3596)\n",
      "  %3599 = Expand(%3597, %3598)\n",
      "  %3600 = Shape(%3584)\n",
      "  %3601 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3602 = Gather[axis = 0](%3600, %3601)\n",
      "  %3603 = Cast[to = 7](%3602)\n",
      "  %3604 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3605 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3606 = Range(%3604, %3603, %3605)\n",
      "  %3607 = Constant[value = <Tensor>]()\n",
      "  %3608 = Constant[value = <Tensor>]()\n",
      "  %3609 = Reshape[allowzero = 0](%3606, %3608)\n",
      "  %3610 = Constant[value = <Tensor>]()\n",
      "  %3611 = Add(%3609, %3610)\n",
      "  %3612 = Shape(%3611)\n",
      "  %3613 = Shape(%3612)\n",
      "  %3614 = ConstantOfShape[value = <Tensor>](%3613)\n",
      "  %3615 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3616 = Mul(%3614, %3615)\n",
      "  %3617 = Equal(%3612, %3616)\n",
      "  %3618 = Where(%3617, %3614, %3612)\n",
      "  %3619 = Expand(%3609, %3618)\n",
      "  %3620 = Constant[value = <Tensor>]()\n",
      "  %3621 = Unsqueeze(%3619, %3620)\n",
      "  %3622 = Shape(%3612)\n",
      "  %3623 = ConstantOfShape[value = <Tensor>](%3622)\n",
      "  %3624 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3625 = Mul(%3623, %3624)\n",
      "  %3626 = Equal(%3612, %3625)\n",
      "  %3627 = Where(%3626, %3623, %3612)\n",
      "  %3628 = Expand(%3607, %3627)\n",
      "  %3629 = Constant[value = <Tensor>]()\n",
      "  %3630 = Unsqueeze(%3628, %3629)\n",
      "  %3631 = Concat[axis = -1](%3621, %3630)\n",
      "  %3632 = Shape(%3584)\n",
      "  %3633 = Constant[value = <Tensor>]()\n",
      "  %3634 = Constant[value = <Tensor>]()\n",
      "  %3635 = Constant[value = <Tensor>]()\n",
      "  %3636 = Slice(%3632, %3634, %3635, %3633)\n",
      "  %3637 = Concat[axis = 0](%3612, %3636)\n",
      "  %3638 = Reshape[allowzero = 0](%3599, %3637)\n",
      "  %3639 = ScatterND(%3584, %3631, %3638)\n",
      "  return %3639\n",
      "}\n",
      "\n",
      "graph torch-jit-export5 {\n",
      "  %3640 = Identity(%3584)\n",
      "  return %3640\n",
      "}\n",
      "\n",
      "graph torch-jit-export6 (\n",
      "  %3708[INT64, scalar]\n",
      "  %cond.3[BOOL, scalar]\n",
      "  %eos_token_id.74[INT64, scalar]\n",
      "  %pad_token_id.34[INT64, scalar]\n",
      "  %3712[INT64, scalar]\n",
      "  %3713[FLOAT, 3713_dim_0x3713_dim_1]\n",
      "  %3714[INT64, 3714_dim_0x3714_dim_1]\n",
      "  %3715[INT64, 3715_dim_0x3715_dim_1]\n",
      "  %3716[Unknown type sequence_type]\n",
      "  %3717[Unknown type sequence_type]\n",
      "  %3718[FLOAT, 331_dim_0]\n",
      "  %3719[INT64, 332_dim_0]\n",
      "  %3720[BOOL, 333_dim_0]\n",
      ") {\n",
      "  %3721 = Gather[axis = 0](%3720, %3712)\n",
      "  %3722 = Cast[to = 9](%3721)\n",
      "  %3723, %3724, %3725, %3726, %3727, %3728, %3729, %3730, %3731, %3732 = If[else_branch = <graph torch-jit-export8>, then_branch = <graph torch-jit-export7>](%3722)\n",
      "  %4357 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4358 = Add(%3712, %4357)\n",
      "  %4359 = Less(%4358, %3676)\n",
      "  %4360 = Cast[to = 9](%4359)\n",
      "  %4361 = Cast[to = 9](%185)\n",
      "  %4362 = And(%4360, %4361)\n",
      "  %4363 = Cast[to = 9](%4362)\n",
      "  return %4363, %3723, %3724, %4358, %3725, %3726, %3727, %3728, %3729, %3730, %3731, %3732\n",
      "}\n",
      "\n",
      "graph torch-jit-export7 {\n",
      "  %3733 = Gather[axis = 0](%3713, %3712)\n",
      "  %3734 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3735 = Shape(%3733)\n",
      "  %3736 = Expand(%3734, %3735)\n",
      "  %3737 = Constant[value = <Tensor>]()\n",
      "  %3738 = Unsqueeze(%3712, %3737)\n",
      "  %3739 = Shape(%3713)\n",
      "  %3740 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3741 = Gather[axis = 0](%3739, %3740)\n",
      "  %3742 = Cast[to = 7](%3741)\n",
      "  %3743 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3744 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3745 = Range(%3743, %3742, %3744)\n",
      "  %3746 = Constant[value = <Tensor>]()\n",
      "  %3747 = Reshape[allowzero = 0](%3738, %3746)\n",
      "  %3748 = Add(%3747, %3745)\n",
      "  %3749 = Shape(%3748)\n",
      "  %3750 = Shape(%3749)\n",
      "  %3751 = ConstantOfShape[value = <Tensor>](%3750)\n",
      "  %3752 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3753 = Mul(%3751, %3752)\n",
      "  %3754 = Equal(%3749, %3753)\n",
      "  %3755 = Where(%3754, %3751, %3749)\n",
      "  %3756 = Expand(%3747, %3755)\n",
      "  %3757 = Constant[value = <Tensor>]()\n",
      "  %3758 = Unsqueeze(%3756, %3757)\n",
      "  %3759 = Shape(%3749)\n",
      "  %3760 = ConstantOfShape[value = <Tensor>](%3759)\n",
      "  %3761 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3762 = Mul(%3760, %3761)\n",
      "  %3763 = Equal(%3749, %3762)\n",
      "  %3764 = Where(%3763, %3760, %3749)\n",
      "  %3765 = Expand(%3745, %3764)\n",
      "  %3766 = Constant[value = <Tensor>]()\n",
      "  %3767 = Unsqueeze(%3765, %3766)\n",
      "  %3768 = Concat[axis = -1](%3758, %3767)\n",
      "  %3769 = Shape(%3713)\n",
      "  %3770 = Constant[value = <Tensor>]()\n",
      "  %3771 = Constant[value = <Tensor>]()\n",
      "  %3772 = Constant[value = <Tensor>]()\n",
      "  %3773 = Slice(%3769, %3771, %3772, %3770)\n",
      "  %3774 = Concat[axis = 0](%3749, %3773)\n",
      "  %3775 = Reshape[allowzero = 0](%3736, %3774)\n",
      "  %3776 = ScatterND(%3713, %3768, %3775)\n",
      "  %3777 = Gather[axis = 0](%3714, %3712)\n",
      "  %3778 = Cast[to = 7](%pad_token_id.34)\n",
      "  %3779 = Shape(%3777)\n",
      "  %3780 = Expand(%3778, %3779)\n",
      "  %3781 = Constant[value = <Tensor>]()\n",
      "  %3782 = Unsqueeze(%3712, %3781)\n",
      "  %3783 = Shape(%3714)\n",
      "  %3784 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3785 = Gather[axis = 0](%3783, %3784)\n",
      "  %3786 = Cast[to = 7](%3785)\n",
      "  %3787 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3788 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3789 = Range(%3787, %3786, %3788)\n",
      "  %3790 = Constant[value = <Tensor>]()\n",
      "  %3791 = Reshape[allowzero = 0](%3782, %3790)\n",
      "  %3792 = Add(%3791, %3789)\n",
      "  %3793 = Shape(%3792)\n",
      "  %3794 = Shape(%3793)\n",
      "  %3795 = ConstantOfShape[value = <Tensor>](%3794)\n",
      "  %3796 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3797 = Mul(%3795, %3796)\n",
      "  %3798 = Equal(%3793, %3797)\n",
      "  %3799 = Where(%3798, %3795, %3793)\n",
      "  %3800 = Expand(%3791, %3799)\n",
      "  %3801 = Constant[value = <Tensor>]()\n",
      "  %3802 = Unsqueeze(%3800, %3801)\n",
      "  %3803 = Shape(%3793)\n",
      "  %3804 = ConstantOfShape[value = <Tensor>](%3803)\n",
      "  %3805 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3806 = Mul(%3804, %3805)\n",
      "  %3807 = Equal(%3793, %3806)\n",
      "  %3808 = Where(%3807, %3804, %3793)\n",
      "  %3809 = Expand(%3789, %3808)\n",
      "  %3810 = Constant[value = <Tensor>]()\n",
      "  %3811 = Unsqueeze(%3809, %3810)\n",
      "  %3812 = Concat[axis = -1](%3802, %3811)\n",
      "  %3813 = Shape(%3714)\n",
      "  %3814 = Constant[value = <Tensor>]()\n",
      "  %3815 = Constant[value = <Tensor>]()\n",
      "  %3816 = Constant[value = <Tensor>]()\n",
      "  %3817 = Slice(%3813, %3815, %3816, %3814)\n",
      "  %3818 = Concat[axis = 0](%3793, %3817)\n",
      "  %3819 = Reshape[allowzero = 0](%3780, %3818)\n",
      "  %3820 = ScatterND(%3714, %3812, %3819)\n",
      "  %3821 = Gather[axis = 0](%3715, %3712)\n",
      "  %3822 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3823 = Shape(%3821)\n",
      "  %3824 = Expand(%3822, %3823)\n",
      "  %3825 = Constant[value = <Tensor>]()\n",
      "  %3826 = Unsqueeze(%3712, %3825)\n",
      "  %3827 = Shape(%3715)\n",
      "  %3828 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3829 = Gather[axis = 0](%3827, %3828)\n",
      "  %3830 = Cast[to = 7](%3829)\n",
      "  %3831 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3832 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3833 = Range(%3831, %3830, %3832)\n",
      "  %3834 = Constant[value = <Tensor>]()\n",
      "  %3835 = Reshape[allowzero = 0](%3826, %3834)\n",
      "  %3836 = Add(%3835, %3833)\n",
      "  %3837 = Shape(%3836)\n",
      "  %3838 = Shape(%3837)\n",
      "  %3839 = ConstantOfShape[value = <Tensor>](%3838)\n",
      "  %3840 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3841 = Mul(%3839, %3840)\n",
      "  %3842 = Equal(%3837, %3841)\n",
      "  %3843 = Where(%3842, %3839, %3837)\n",
      "  %3844 = Expand(%3835, %3843)\n",
      "  %3845 = Constant[value = <Tensor>]()\n",
      "  %3846 = Unsqueeze(%3844, %3845)\n",
      "  %3847 = Shape(%3837)\n",
      "  %3848 = ConstantOfShape[value = <Tensor>](%3847)\n",
      "  %3849 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3850 = Mul(%3848, %3849)\n",
      "  %3851 = Equal(%3837, %3850)\n",
      "  %3852 = Where(%3851, %3848, %3837)\n",
      "  %3853 = Expand(%3833, %3852)\n",
      "  %3854 = Constant[value = <Tensor>]()\n",
      "  %3855 = Unsqueeze(%3853, %3854)\n",
      "  %3856 = Concat[axis = -1](%3846, %3855)\n",
      "  %3857 = Shape(%3715)\n",
      "  %3858 = Constant[value = <Tensor>]()\n",
      "  %3859 = Constant[value = <Tensor>]()\n",
      "  %3860 = Constant[value = <Tensor>]()\n",
      "  %3861 = Slice(%3857, %3859, %3860, %3858)\n",
      "  %3862 = Concat[axis = 0](%3837, %3861)\n",
      "  %3863 = Reshape[allowzero = 0](%3824, %3862)\n",
      "  %3864 = ScatterND(%3715, %3856, %3863)\n",
      "  %eos_token_id.71 = Identity(%eos_token_id.74)\n",
      "  %pad_token_id.31 = Identity(%pad_token_id.34)\n",
      "  %3867 = Identity(%3716)\n",
      "  %3868 = Identity(%3717)\n",
      "  %3869 = Identity(%3718)\n",
      "  %3870 = Identity(%3719)\n",
      "  %3871 = Identity(%3720)\n",
      "  return %eos_token_id.71, %pad_token_id.31, %3776, %3820, %3864, %3867, %3868, %3869, %3870, %3871\n",
      "}\n",
      "\n",
      "graph torch-jit-export8 {\n",
      "  %3872 = Gather[axis = 0](%3671, %3712)\n",
      "  %3873 = Gather[axis = 0](%3664, %3712)\n",
      "  %3874 = Gather[axis = 0](%3668, %3712)\n",
      "  %3875 = Constant[value = <Tensor>]()\n",
      "  %3876 = Shape(%3872)\n",
      "  %3877 = Gather[axis = 0](%3876, %3875)\n",
      "  %3878 = Constant[value = <Tensor>]()\n",
      "  %3879 = Squeeze(%3877, %3878)\n",
      "  %3880 = Constant[value = <Tensor>]()\n",
      "  %3881 = Shape(%3873)\n",
      "  %3882 = Gather[axis = 0](%3881, %3880)\n",
      "  %3883 = Constant[value = <Tensor>]()\n",
      "  %3884 = Squeeze(%3882, %3883)\n",
      "  %3885 = Constant[value = <Tensor>]()\n",
      "  %3886 = Shape(%3874)\n",
      "  %3887 = Gather[axis = 0](%3886, %3885)\n",
      "  %3888 = Constant[value = <Tensor>]()\n",
      "  %3889 = Squeeze(%3887, %3888)\n",
      "  %3890 = Constant[value = <Tensor>]()\n",
      "  %3891 = Unsqueeze(%182, %3890)\n",
      "  %3892 = Constant[value = <Tensor>]()\n",
      "  %3893 = Unsqueeze(%3879, %3892)\n",
      "  %3894 = Constant[value = <Tensor>]()\n",
      "  %3895 = Unsqueeze(%3884, %3894)\n",
      "  %3896 = Constant[value = <Tensor>]()\n",
      "  %3897 = Unsqueeze(%3889, %3896)\n",
      "  %3898 = Concat[axis = 0](%3891, %3893, %3895, %3897)\n",
      "  %3899 = ReduceMin[keepdims = 0](%3898)\n",
      "  %3900 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3901 = Greater(%3899, %3900)\n",
      "  %3902, %3903, %3904, %3905, %3906, %3907, %3908, %3909, %3910, %3911 = Loop[body = <graph torch-jit-export9>](%182, %3901, %189, %eos_token_id.74, %189, %3716, %3717, %3718, %3719, %3713, %3714, %3715)\n",
      "  %4322 = Gather[axis = 0](%3720, %3712)\n",
      "  %4323 = Cast[to = 9](%4322)\n",
      "  %4324 = If[else_branch = <graph torch-jit-export29>, then_branch = <graph torch-jit-export28>](%4323)\n",
      "  %4332 = Gather[axis = 0](%3720, %3712)\n",
      "  %4333 = Cast[to = 9](%4324)\n",
      "  %4334 = Shape(%4332)\n",
      "  %4335 = Expand(%4333, %4334)\n",
      "  %4336 = Constant[value = <Tensor>]()\n",
      "  %4337 = Unsqueeze(%3712, %4336)\n",
      "  %4338 = Shape(%4337)\n",
      "  %4339 = Constant[value = <Tensor>]()\n",
      "  %4340 = Unsqueeze(%4337, %4339)\n",
      "  %4341 = Shape(%3720)\n",
      "  %4342 = Constant[value = <Tensor>]()\n",
      "  %4343 = Constant[value = <Tensor>]()\n",
      "  %4344 = Constant[value = <Tensor>]()\n",
      "  %4345 = Slice(%4341, %4343, %4344, %4342)\n",
      "  %4346 = Concat[axis = 0](%4338, %4345)\n",
      "  %4347 = Shape(%4346)\n",
      "  %4348 = ConstantOfShape[value = <Tensor>](%4347)\n",
      "  %4349 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4350 = Mul(%4348, %4349)\n",
      "  %4351 = Equal(%4346, %4350)\n",
      "  %4352 = Where(%4351, %4348, %4346)\n",
      "  %4353 = Expand(%4335, %4352)\n",
      "  %4354 = Reshape[allowzero = 0](%4353, %4346)\n",
      "  %4355 = ScatterND(%3720, %4340, %4354)\n",
      "  %pad_token_id.32 = Identity(%pad_token_id.34)\n",
      "  return %3903, %pad_token_id.32, %3909, %3910, %3911, %3905, %3906, %3907, %3908, %4355\n",
      "}\n",
      "\n",
      "graph torch-jit-export9 (\n",
      "  %3912[INT64, scalar]\n",
      "  %cond.1[BOOL, scalar]\n",
      "  %beam_idx.36[INT64, scalar]\n",
      "  %eos_token_id.72[INT64, scalar]\n",
      "  %3916[INT64, scalar]\n",
      "  %3917[Unknown type sequence_type]\n",
      "  %3918[Unknown type sequence_type]\n",
      "  %3919[FLOAT, 331_dim_0]\n",
      "  %3920[INT64, 332_dim_0]\n",
      "  %3921[FLOAT, 3713_dim_0x3713_dim_1]\n",
      "  %3922[INT64, 3714_dim_0x3714_dim_1]\n",
      "  %3923[INT64, 3715_dim_0x3715_dim_1]\n",
      ") {\n",
      "  %3924 = Gather[axis = 0](%3872, %3916)\n",
      "  %3925 = Gather[axis = 0](%3873, %3916)\n",
      "  %3926 = Gather[axis = 0](%3874, %3916)\n",
      "  %3927 = Mul(%3712, %196)\n",
      "  %3928 = Add(%3926, %3927)\n",
      "  %3929 = Equal(%3924, %eos_token_id.72)\n",
      "  %3930 = Cast[to = 9](%3929)\n",
      "  %3931, %3932, %3933, %3934, %3935, %3936, %3937, %3938, %3939, %3940, %3941, %3942, %3943 = If[else_branch = <graph torch-jit-export21>, then_branch = <graph torch-jit-export10>](%3930)\n",
      "  %4276 = Cast[to = 9](%3931)\n",
      "  %4277, %4278, %4279, %4280, %4281, %4282, %4283 = If[else_branch = <graph torch-jit-export23>, then_branch = <graph torch-jit-export22>](%4276)\n",
      "  %4305 = Cast[to = 9](%4277)\n",
      "  %4306, %4307, %4308 = If[else_branch = <graph torch-jit-export27>, then_branch = <graph torch-jit-export26>](%4305)\n",
      "  %4315 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4316 = Add(%3916, %4315)\n",
      "  %4317 = Less(%4316, %3899)\n",
      "  %4318 = Cast[to = 9](%4317)\n",
      "  %4319 = Cast[to = 9](%4306)\n",
      "  %4320 = And(%4318, %4319)\n",
      "  %4321 = Cast[to = 9](%4320)\n",
      "  return %4321, %4307, %4308, %4316, %3937, %3938, %3939, %3940, %3941, %3942, %3943\n",
      "}\n",
      "\n",
      "graph torch-jit-export10 {\n",
      "  %3944 = GreaterOrEqual(%3916, %196)\n",
      "  %3945 = Cast[to = 9](%3944)\n",
      "  %3946, %3947, %3948, %3949, %3950, %3951, %3952, %3953, %3954 = If[else_branch = <graph torch-jit-export12>, then_branch = <graph torch-jit-export11>](%3945)\n",
      "  %4125 = Identity(%3921)\n",
      "  %4126 = Identity(%3922)\n",
      "  %4127 = Identity(%3923)\n",
      "  return %3944, %3946, %3947, %3948, %3949, %3950, %3951, %3952, %3953, %3954, %4125, %4126, %4127\n",
      "}\n",
      "\n",
      "graph torch-jit-export11 {\n",
      "  %3955 = Identity(%185)\n",
      "  %beam_idx.38 = Identity(%beam_idx.36)\n",
      "  %eos_token_id.67 = Identity(%eos_token_id.72)\n",
      "  %3958 = Identity(%3917)\n",
      "  %3959 = Identity(%3918)\n",
      "  %3960 = Identity(%3919)\n",
      "  %3961 = Identity(%3920)\n",
      "  %beam_idx.34 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %3955, %beam_idx.38, %eos_token_id.67, %beam_idx.34, %beam_idx.34, %3958, %3959, %3960, %3961\n",
      "}\n",
      "\n",
      "graph torch-jit-export12 {\n",
      "  %3963 = Gather[axis = 0](%input_ids.25, %3928)\n",
      "  %3964 = Shape(%3963)\n",
      "  %3965 = Constant[value = <Tensor>]()\n",
      "  %3966 = Constant[value = <Tensor>]()\n",
      "  %3967 = Constant[value = <Tensor>]()\n",
      "  %3968 = Slice(%3964, %3966, %3967, %3965)\n",
      "  %3969 = Constant[value = <Tensor>]()\n",
      "  %3970 = Squeeze(%3968, %3969)\n",
      "  %3971 = Cast[to = 1](%3970)\n",
      "  %3972 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3973 = Pow(%3971, %3972)\n",
      "  %3974 = Div(%3925, %3973)\n",
      "  %3975 = Gather[axis = 0](%3920, %3712)\n",
      "  %3976 = Less(%3975, %num_beams)\n",
      "  %3977 = Cast[to = 9](%3976)\n",
      "  %3978 = If[else_branch = <graph torch-jit-export14>, then_branch = <graph torch-jit-export13>](%3977)\n",
      "  %3982 = Cast[to = 9](%3978)\n",
      "  %3983, %3984, %3985, %3986 = If[else_branch = <graph torch-jit-export20>, then_branch = <graph torch-jit-export15>](%3982)\n",
      "  %beam_idx.40 = Identity(%beam_idx.36)\n",
      "  %eos_token_id.68 = Identity(%eos_token_id.72)\n",
      "  %4123 = Constant[value = <Scalar Tensor []>]()\n",
      "  %beam_idx.33 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4123, %beam_idx.33, %beam_idx.33, %beam_idx.40, %eos_token_id.68, %3983, %3984, %3985, %3986\n",
      "}\n",
      "\n",
      "graph torch-jit-export13 {\n",
      "  %3979 = Identity(%185)\n",
      "  return %3979\n",
      "}\n",
      "\n",
      "graph torch-jit-export14 {\n",
      "  %3980 = Gather[axis = 0](%3919, %3712)\n",
      "  %3981 = Less(%3980, %3974)\n",
      "  return %3981\n",
      "}\n",
      "\n",
      "graph torch-jit-export15 {\n",
      "  %3987 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3988 = Equal(%3712, %3987)\n",
      "  %3989 = Not(%3988)\n",
      "  %3990 = Cast[to = 9](%3989)\n",
      "  %3991 = If[else_branch = <graph torch-jit-export17>, then_branch = <graph torch-jit-export16>](%3990)\n",
      "  %4003 = Constant[value = <Tensor>]()\n",
      "  %4004 = Reshape[allowzero = 0](%3974, %4003)\n",
      "  %4005 = Cast[to = 1](%4004)\n",
      "  %4006 = Concat[axis = 0](%4005)\n",
      "  %4007 = SequenceInsert(%3917, %4006, %3991)\n",
      "  %4008 = SequenceInsert(%3918, %3963, %3991)\n",
      "  %4009 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4010 = Add(%3975, %4009)\n",
      "  %4011 = Greater(%4010, %num_beams)\n",
      "  %4012 = Cast[to = 9](%4011)\n",
      "  %4013, %4014, %4015, %4016 = If[else_branch = <graph torch-jit-export19>, then_branch = <graph torch-jit-export18>](%4012)\n",
      "  return %4014, %4013, %4015, %4016\n",
      "}\n",
      "\n",
      "graph torch-jit-export16 {\n",
      "  %3992 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3993 = Constant[value = <Tensor>]()\n",
      "  %3994 = Unsqueeze(%3992, %3993)\n",
      "  %3995 = Constant[value = <Tensor>]()\n",
      "  %3996 = Unsqueeze(%3712, %3995)\n",
      "  %3997 = Constant[value = <Tensor>]()\n",
      "  %3998 = Unsqueeze(%189, %3997)\n",
      "  %3999 = Constant[value = <Tensor>]()\n",
      "  %4000 = Slice(%3920, %3994, %3996, %3998, %3999)\n",
      "  %4001 = ReduceSum[keepdims = 0](%4000)\n",
      "  return %4001\n",
      "}\n",
      "\n",
      "graph torch-jit-export17 {\n",
      "  %4002 = Identity(%176)\n",
      "  return %4002\n",
      "}\n",
      "\n",
      "graph torch-jit-export18 {\n",
      "  %4017 = ConcatFromSequence[axis = 0](%4007)\n",
      "  %4018 = Add(%3991, %3975)\n",
      "  %4019 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4020 = Add(%4018, %4019)\n",
      "  %4021 = Constant[value = <Tensor>]()\n",
      "  %4022 = Unsqueeze(%3991, %4021)\n",
      "  %4023 = Constant[value = <Tensor>]()\n",
      "  %4024 = Unsqueeze(%4020, %4023)\n",
      "  %4025 = Constant[value = <Tensor>]()\n",
      "  %4026 = Unsqueeze(%189, %4025)\n",
      "  %4027 = Constant[value = <Tensor>]()\n",
      "  %4028 = Slice(%4017, %4022, %4024, %4026, %4027)\n",
      "  %4029 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4030 = Add(%3975, %4029)\n",
      "  %4031 = Constant[value = <Tensor>]()\n",
      "  %4032 = Reshape[allowzero = 0](%4030, %4031)\n",
      "  %4033, %4034 = TopK[axis = -1, largest = 0, sorted = 1](%4028, %4032)\n",
      "  %4035 = Gather[axis = 0](%4034, %189)\n",
      "  %4036 = Add(%4035, %3991)\n",
      "  %4037 = SequenceErase(%4008, %4036)\n",
      "  %4038 = SequenceErase(%4007, %4036)\n",
      "  %4039 = Gather[axis = 0](%4033, %187)\n",
      "  %4040 = Gather[axis = 0](%3919, %3712)\n",
      "  %4041 = Shape(%4040)\n",
      "  %4042 = Expand(%4039, %4041)\n",
      "  %4043 = Constant[value = <Tensor>]()\n",
      "  %4044 = Unsqueeze(%3712, %4043)\n",
      "  %4045 = Shape(%4044)\n",
      "  %4046 = Constant[value = <Tensor>]()\n",
      "  %4047 = Unsqueeze(%4044, %4046)\n",
      "  %4048 = Shape(%3919)\n",
      "  %4049 = Constant[value = <Tensor>]()\n",
      "  %4050 = Constant[value = <Tensor>]()\n",
      "  %4051 = Constant[value = <Tensor>]()\n",
      "  %4052 = Slice(%4048, %4050, %4051, %4049)\n",
      "  %4053 = Concat[axis = 0](%4045, %4052)\n",
      "  %4054 = Shape(%4053)\n",
      "  %4055 = ConstantOfShape[value = <Tensor>](%4054)\n",
      "  %4056 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4057 = Mul(%4055, %4056)\n",
      "  %4058 = Equal(%4053, %4057)\n",
      "  %4059 = Where(%4058, %4055, %4053)\n",
      "  %4060 = Expand(%4042, %4059)\n",
      "  %4061 = Reshape[allowzero = 0](%4060, %4053)\n",
      "  %4062 = ScatterND(%3919, %4047, %4061)\n",
      "  %4063 = Identity(%3920)\n",
      "  return %4037, %4038, %4062, %4063\n",
      "}\n",
      "\n",
      "graph torch-jit-export19 {\n",
      "  %4064 = Gather[axis = 0](%3919, %3712)\n",
      "  %4065 = Min(%3974, %4064)\n",
      "  %4066 = Gather[axis = 0](%3919, %3712)\n",
      "  %4067 = Cast[to = 1](%4065)\n",
      "  %4068 = Shape(%4066)\n",
      "  %4069 = Expand(%4067, %4068)\n",
      "  %4070 = Constant[value = <Tensor>]()\n",
      "  %4071 = Unsqueeze(%3712, %4070)\n",
      "  %4072 = Shape(%4071)\n",
      "  %4073 = Constant[value = <Tensor>]()\n",
      "  %4074 = Unsqueeze(%4071, %4073)\n",
      "  %4075 = Shape(%3919)\n",
      "  %4076 = Constant[value = <Tensor>]()\n",
      "  %4077 = Constant[value = <Tensor>]()\n",
      "  %4078 = Constant[value = <Tensor>]()\n",
      "  %4079 = Slice(%4075, %4077, %4078, %4076)\n",
      "  %4080 = Concat[axis = 0](%4072, %4079)\n",
      "  %4081 = Shape(%4080)\n",
      "  %4082 = ConstantOfShape[value = <Tensor>](%4081)\n",
      "  %4083 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4084 = Mul(%4082, %4083)\n",
      "  %4085 = Equal(%4080, %4084)\n",
      "  %4086 = Where(%4085, %4082, %4080)\n",
      "  %4087 = Expand(%4069, %4086)\n",
      "  %4088 = Reshape[allowzero = 0](%4087, %4080)\n",
      "  %4089 = ScatterND(%3919, %4074, %4088)\n",
      "  %4090 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4091 = Add(%3975, %4090)\n",
      "  %4092 = Gather[axis = 0](%3920, %3712)\n",
      "  %4093 = Shape(%4092)\n",
      "  %4094 = Expand(%4091, %4093)\n",
      "  %4095 = Constant[value = <Tensor>]()\n",
      "  %4096 = Unsqueeze(%3712, %4095)\n",
      "  %4097 = Shape(%4096)\n",
      "  %4098 = Constant[value = <Tensor>]()\n",
      "  %4099 = Unsqueeze(%4096, %4098)\n",
      "  %4100 = Shape(%3920)\n",
      "  %4101 = Constant[value = <Tensor>]()\n",
      "  %4102 = Constant[value = <Tensor>]()\n",
      "  %4103 = Constant[value = <Tensor>]()\n",
      "  %4104 = Slice(%4100, %4102, %4103, %4101)\n",
      "  %4105 = Concat[axis = 0](%4097, %4104)\n",
      "  %4106 = Shape(%4105)\n",
      "  %4107 = ConstantOfShape[value = <Tensor>](%4106)\n",
      "  %4108 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4109 = Mul(%4107, %4108)\n",
      "  %4110 = Equal(%4105, %4109)\n",
      "  %4111 = Where(%4110, %4107, %4105)\n",
      "  %4112 = Expand(%4094, %4111)\n",
      "  %4113 = Reshape[allowzero = 0](%4112, %4105)\n",
      "  %4114 = ScatterND(%3920, %4099, %4113)\n",
      "  %4115 = Identity(%4008)\n",
      "  %4116 = Identity(%4007)\n",
      "  return %4115, %4116, %4089, %4114\n",
      "}\n",
      "\n",
      "graph torch-jit-export20 {\n",
      "  %4117 = Identity(%3917)\n",
      "  %4118 = Identity(%3918)\n",
      "  %4119 = Identity(%3919)\n",
      "  %4120 = Identity(%3920)\n",
      "  return %4117, %4118, %4119, %4120\n",
      "}\n",
      "\n",
      "graph torch-jit-export21 {\n",
      "  %4128 = Gather[axis = 0](%3921, %3712)\n",
      "  %4129 = Gather[axis = 0](%4128, %beam_idx.36)\n",
      "  %4130 = Shape(%4129)\n",
      "  %4131 = Expand(%3925, %4130)\n",
      "  %4132 = Constant[value = <Tensor>]()\n",
      "  %4133 = Unsqueeze(%3712, %4132)\n",
      "  %4134 = Constant[value = <Tensor>]()\n",
      "  %4135 = Unsqueeze(%beam_idx.36, %4134)\n",
      "  %4136 = Constant[value = <Tensor>]()\n",
      "  %4137 = Reshape[allowzero = 0](%4133, %4136)\n",
      "  %4138 = Add(%4137, %4135)\n",
      "  %4139 = Shape(%4138)\n",
      "  %4140 = Shape(%4139)\n",
      "  %4141 = ConstantOfShape[value = <Tensor>](%4140)\n",
      "  %4142 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4143 = Mul(%4141, %4142)\n",
      "  %4144 = Equal(%4139, %4143)\n",
      "  %4145 = Where(%4144, %4141, %4139)\n",
      "  %4146 = Expand(%4137, %4145)\n",
      "  %4147 = Constant[value = <Tensor>]()\n",
      "  %4148 = Unsqueeze(%4146, %4147)\n",
      "  %4149 = Shape(%4139)\n",
      "  %4150 = ConstantOfShape[value = <Tensor>](%4149)\n",
      "  %4151 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4152 = Mul(%4150, %4151)\n",
      "  %4153 = Equal(%4139, %4152)\n",
      "  %4154 = Where(%4153, %4150, %4139)\n",
      "  %4155 = Expand(%4135, %4154)\n",
      "  %4156 = Constant[value = <Tensor>]()\n",
      "  %4157 = Unsqueeze(%4155, %4156)\n",
      "  %4158 = Concat[axis = -1](%4148, %4157)\n",
      "  %4159 = Shape(%3921)\n",
      "  %4160 = Constant[value = <Tensor>]()\n",
      "  %4161 = Constant[value = <Tensor>]()\n",
      "  %4162 = Constant[value = <Tensor>]()\n",
      "  %4163 = Slice(%4159, %4161, %4162, %4160)\n",
      "  %4164 = Concat[axis = 0](%4139, %4163)\n",
      "  %4165 = Shape(%4164)\n",
      "  %4166 = ConstantOfShape[value = <Tensor>](%4165)\n",
      "  %4167 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4168 = Mul(%4166, %4167)\n",
      "  %4169 = Equal(%4164, %4168)\n",
      "  %4170 = Where(%4169, %4166, %4164)\n",
      "  %4171 = Expand(%4131, %4170)\n",
      "  %4172 = Reshape[allowzero = 0](%4171, %4164)\n",
      "  %4173 = ScatterND(%3921, %4158, %4172)\n",
      "  %4174 = Gather[axis = 0](%3922, %3712)\n",
      "  %4175 = Gather[axis = 0](%4174, %beam_idx.36)\n",
      "  %4176 = Shape(%4175)\n",
      "  %4177 = Expand(%3924, %4176)\n",
      "  %4178 = Constant[value = <Tensor>]()\n",
      "  %4179 = Unsqueeze(%3712, %4178)\n",
      "  %4180 = Constant[value = <Tensor>]()\n",
      "  %4181 = Unsqueeze(%beam_idx.36, %4180)\n",
      "  %4182 = Constant[value = <Tensor>]()\n",
      "  %4183 = Reshape[allowzero = 0](%4179, %4182)\n",
      "  %4184 = Add(%4183, %4181)\n",
      "  %4185 = Shape(%4184)\n",
      "  %4186 = Shape(%4185)\n",
      "  %4187 = ConstantOfShape[value = <Tensor>](%4186)\n",
      "  %4188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4189 = Mul(%4187, %4188)\n",
      "  %4190 = Equal(%4185, %4189)\n",
      "  %4191 = Where(%4190, %4187, %4185)\n",
      "  %4192 = Expand(%4183, %4191)\n",
      "  %4193 = Constant[value = <Tensor>]()\n",
      "  %4194 = Unsqueeze(%4192, %4193)\n",
      "  %4195 = Shape(%4185)\n",
      "  %4196 = ConstantOfShape[value = <Tensor>](%4195)\n",
      "  %4197 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4198 = Mul(%4196, %4197)\n",
      "  %4199 = Equal(%4185, %4198)\n",
      "  %4200 = Where(%4199, %4196, %4185)\n",
      "  %4201 = Expand(%4181, %4200)\n",
      "  %4202 = Constant[value = <Tensor>]()\n",
      "  %4203 = Unsqueeze(%4201, %4202)\n",
      "  %4204 = Concat[axis = -1](%4194, %4203)\n",
      "  %4205 = Shape(%3922)\n",
      "  %4206 = Constant[value = <Tensor>]()\n",
      "  %4207 = Constant[value = <Tensor>]()\n",
      "  %4208 = Constant[value = <Tensor>]()\n",
      "  %4209 = Slice(%4205, %4207, %4208, %4206)\n",
      "  %4210 = Concat[axis = 0](%4185, %4209)\n",
      "  %4211 = Shape(%4210)\n",
      "  %4212 = ConstantOfShape[value = <Tensor>](%4211)\n",
      "  %4213 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4214 = Mul(%4212, %4213)\n",
      "  %4215 = Equal(%4210, %4214)\n",
      "  %4216 = Where(%4215, %4212, %4210)\n",
      "  %4217 = Expand(%4177, %4216)\n",
      "  %4218 = Reshape[allowzero = 0](%4217, %4210)\n",
      "  %4219 = ScatterND(%3922, %4204, %4218)\n",
      "  %4220 = Gather[axis = 0](%3923, %3712)\n",
      "  %4221 = Gather[axis = 0](%4220, %beam_idx.36)\n",
      "  %4222 = Shape(%4221)\n",
      "  %4223 = Expand(%3928, %4222)\n",
      "  %4224 = Constant[value = <Tensor>]()\n",
      "  %4225 = Unsqueeze(%3712, %4224)\n",
      "  %4226 = Constant[value = <Tensor>]()\n",
      "  %4227 = Unsqueeze(%beam_idx.36, %4226)\n",
      "  %4228 = Constant[value = <Tensor>]()\n",
      "  %4229 = Reshape[allowzero = 0](%4225, %4228)\n",
      "  %4230 = Add(%4229, %4227)\n",
      "  %4231 = Shape(%4230)\n",
      "  %4232 = Shape(%4231)\n",
      "  %4233 = ConstantOfShape[value = <Tensor>](%4232)\n",
      "  %4234 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4235 = Mul(%4233, %4234)\n",
      "  %4236 = Equal(%4231, %4235)\n",
      "  %4237 = Where(%4236, %4233, %4231)\n",
      "  %4238 = Expand(%4229, %4237)\n",
      "  %4239 = Constant[value = <Tensor>]()\n",
      "  %4240 = Unsqueeze(%4238, %4239)\n",
      "  %4241 = Shape(%4231)\n",
      "  %4242 = ConstantOfShape[value = <Tensor>](%4241)\n",
      "  %4243 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4244 = Mul(%4242, %4243)\n",
      "  %4245 = Equal(%4231, %4244)\n",
      "  %4246 = Where(%4245, %4242, %4231)\n",
      "  %4247 = Expand(%4227, %4246)\n",
      "  %4248 = Constant[value = <Tensor>]()\n",
      "  %4249 = Unsqueeze(%4247, %4248)\n",
      "  %4250 = Concat[axis = -1](%4240, %4249)\n",
      "  %4251 = Shape(%3923)\n",
      "  %4252 = Constant[value = <Tensor>]()\n",
      "  %4253 = Constant[value = <Tensor>]()\n",
      "  %4254 = Constant[value = <Tensor>]()\n",
      "  %4255 = Slice(%4251, %4253, %4254, %4252)\n",
      "  %4256 = Concat[axis = 0](%4231, %4255)\n",
      "  %4257 = Shape(%4256)\n",
      "  %4258 = ConstantOfShape[value = <Tensor>](%4257)\n",
      "  %4259 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4260 = Mul(%4258, %4259)\n",
      "  %4261 = Equal(%4256, %4260)\n",
      "  %4262 = Where(%4261, %4258, %4256)\n",
      "  %4263 = Expand(%4223, %4262)\n",
      "  %4264 = Reshape[allowzero = 0](%4263, %4256)\n",
      "  %4265 = ScatterND(%3923, %4250, %4264)\n",
      "  %4266 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4267 = Add(%beam_idx.36, %4266)\n",
      "  %4268 = Identity(%186)\n",
      "  %eos_token_id.70 = Identity(%eos_token_id.72)\n",
      "  %4270 = Identity(%3917)\n",
      "  %4271 = Identity(%3918)\n",
      "  %4272 = Identity(%3919)\n",
      "  %4273 = Identity(%3920)\n",
      "  %4274 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4275 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4268, %4274, %4275, %4275, %4267, %eos_token_id.70, %4270, %4271, %4272, %4273, %4173, %4219, %4265\n",
      "}\n",
      "\n",
      "graph torch-jit-export22 {\n",
      "  %4284 = Identity(%185)\n",
      "  %4285 = Identity(%3932)\n",
      "  %4286 = Identity(%3933)\n",
      "  %4287 = Identity(%3934)\n",
      "  %4288 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4289 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4290 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4284, %4285, %4286, %4287, %4288, %4289, %4290\n",
      "}\n",
      "\n",
      "graph torch-jit-export23 {\n",
      "  %4291 = Equal(%3935, %196)\n",
      "  %4292 = Cast[to = 9](%4291)\n",
      "  %4293, %4294, %4295 = If[else_branch = <graph torch-jit-export25>, then_branch = <graph torch-jit-export24>](%4292)\n",
      "  %4302 = Identity(%185)\n",
      "  %4303 = Identity(%3935)\n",
      "  %4304 = Identity(%3936)\n",
      "  return %4291, %4293, %4294, %4295, %4302, %4303, %4304\n",
      "}\n",
      "\n",
      "graph torch-jit-export24 {\n",
      "  %4296 = Identity(%186)\n",
      "  %4297 = Identity(%3935)\n",
      "  %4298 = Identity(%3936)\n",
      "  return %4296, %4297, %4298\n",
      "}\n",
      "\n",
      "graph torch-jit-export25 {\n",
      "  %4299 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4300 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4301 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4299, %4300, %4301\n",
      "}\n",
      "\n",
      "graph torch-jit-export26 {\n",
      "  %4309 = Identity(%4278)\n",
      "  %4310 = Identity(%4279)\n",
      "  %4311 = Identity(%4280)\n",
      "  return %4309, %4310, %4311\n",
      "}\n",
      "\n",
      "graph torch-jit-export27 {\n",
      "  %4312 = Identity(%4281)\n",
      "  %4313 = Identity(%4282)\n",
      "  %4314 = Identity(%4283)\n",
      "  return %4312, %4313, %4314\n",
      "}\n",
      "\n",
      "graph torch-jit-export28 {\n",
      "  %4325 = Identity(%185)\n",
      "  return %4325\n",
      "}\n",
      "\n",
      "graph torch-jit-export29 {\n",
      "  %4326 = Gather[axis = 0](%3908, %3712)\n",
      "  %4327 = Less(%4326, %num_beams)\n",
      "  %4328 = Cast[to = 9](%4327)\n",
      "  %4329 = If[else_branch = <graph torch-jit-export31>, then_branch = <graph torch-jit-export30>](%4328)\n",
      "  return %4329\n",
      "}\n",
      "\n",
      "graph torch-jit-export30 {\n",
      "  %4330 = Identity(%186)\n",
      "  return %4330\n",
      "}\n",
      "\n",
      "graph torch-jit-export31 {\n",
      "  %4331 = Identity(%185)\n",
      "  return %4331\n",
      "}\n",
      "\n",
      "graph torch-jit-export32 {\n",
      "  %4395 = Identity(%186)\n",
      "  return %4395\n",
      "}\n",
      "\n",
      "graph torch-jit-export33 {\n",
      "  %4396 = Greater(%max_length, %4386)\n",
      "  return %4396\n",
      "}\n",
      "\n",
      "graph torch-jit-export34 (\n",
      "  %4409[INT64, scalar]\n",
      "  %cond.9[BOOL, scalar]\n",
      "  %4411[INT64, scalar]\n",
      "  %4412[Unknown type sequence_type]\n",
      "  %4413[Unknown type sequence_type]\n",
      "  %4414[FLOAT, Loop3705_dim_0]\n",
      "  %4415[INT64, Loop3706_dim_0]\n",
      ") {\n",
      "  %4416 = Gather[axis = 0](%322, %4411)\n",
      "  %4417 = Cast[to = 9](%4416)\n",
      "  %4418, %4419, %4420, %4421 = If[else_branch = <graph torch-jit-export36>, then_branch = <graph torch-jit-export35>](%4417)\n",
      "  %4598 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4599 = Add(%4411, %4598)\n",
      "  %4600 = Less(%4599, %4401)\n",
      "  %4601 = Cast[to = 9](%4600)\n",
      "  %4602 = Cast[to = 9](%185)\n",
      "  %4603 = And(%4601, %4602)\n",
      "  %4604 = Cast[to = 9](%4603)\n",
      "  return %4604, %4599, %4418, %4419, %4420, %4421\n",
      "}\n",
      "\n",
      "graph torch-jit-export35 {\n",
      "  %4422 = Identity(%4412)\n",
      "  %4423 = Identity(%4413)\n",
      "  %4424 = Identity(%4414)\n",
      "  %4425 = Identity(%4415)\n",
      "  return %4422, %4423, %4424, %4425\n",
      "}\n",
      "\n",
      "graph torch-jit-export36 {\n",
      "  %4426, %4427, %4428, %4429 = Loop[body = <graph torch-jit-export37>](%num_beams, %185, %4412, %4413, %4414, %4415)\n",
      "  return %4426, %4427, %4428, %4429\n",
      "}\n",
      "\n",
      "graph torch-jit-export37 (\n",
      "  %beam_id.1[INT64, scalar]\n",
      "  %cond.7[BOOL, scalar]\n",
      "  %4432[Unknown type sequence_type]\n",
      "  %4433[Unknown type sequence_type]\n",
      "  %4434[FLOAT, Loop3705_dim_0]\n",
      "  %4435[INT64, Loop3706_dim_0]\n",
      ") {\n",
      "  %4436 = Mul(%4411, %num_beams)\n",
      "  %4437 = Add(%4436, %beam_id.1)\n",
      "  %4438 = Gather[axis = 0](%315, %4437)\n",
      "  %4439 = Gather[axis = 0](%314, %4437)\n",
      "  %4440 = Shape(%4439)\n",
      "  %4441 = Constant[value = <Tensor>]()\n",
      "  %4442 = Constant[value = <Tensor>]()\n",
      "  %4443 = Constant[value = <Tensor>]()\n",
      "  %4444 = Slice(%4440, %4442, %4443, %4441)\n",
      "  %4445 = Constant[value = <Tensor>]()\n",
      "  %4446 = Squeeze(%4444, %4445)\n",
      "  %4447 = Cast[to = 1](%4446)\n",
      "  %4448 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4449 = Pow(%4447, %4448)\n",
      "  %4450 = Div(%4438, %4449)\n",
      "  %4451 = Gather[axis = 0](%4435, %4411)\n",
      "  %4452 = Less(%4451, %num_beams)\n",
      "  %4453 = Cast[to = 9](%4452)\n",
      "  %4454 = If[else_branch = <graph torch-jit-export39>, then_branch = <graph torch-jit-export38>](%4453)\n",
      "  %4458 = Cast[to = 9](%4454)\n",
      "  %4459, %4460, %4461, %4462 = If[else_branch = <graph torch-jit-export45>, then_branch = <graph torch-jit-export40>](%4458)\n",
      "  %4597 = Identity(%185)\n",
      "  return %4597, %4459, %4460, %4461, %4462\n",
      "}\n",
      "\n",
      "graph torch-jit-export38 {\n",
      "  %4455 = Identity(%185)\n",
      "  return %4455\n",
      "}\n",
      "\n",
      "graph torch-jit-export39 {\n",
      "  %4456 = Gather[axis = 0](%4434, %4411)\n",
      "  %4457 = Less(%4456, %4450)\n",
      "  return %4457\n",
      "}\n",
      "\n",
      "graph torch-jit-export40 {\n",
      "  %4463 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4464 = Equal(%4411, %4463)\n",
      "  %4465 = Not(%4464)\n",
      "  %4466 = Cast[to = 9](%4465)\n",
      "  %4467 = If[else_branch = <graph torch-jit-export42>, then_branch = <graph torch-jit-export41>](%4466)\n",
      "  %4479 = Constant[value = <Tensor>]()\n",
      "  %4480 = Reshape[allowzero = 0](%4450, %4479)\n",
      "  %4481 = Cast[to = 1](%4480)\n",
      "  %4482 = Concat[axis = 0](%4481)\n",
      "  %4483 = SequenceInsert(%4432, %4482, %4467)\n",
      "  %4484 = SequenceInsert(%4433, %4439, %4467)\n",
      "  %4485 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4486 = Add(%4451, %4485)\n",
      "  %4487 = Greater(%4486, %num_beams)\n",
      "  %4488 = Cast[to = 9](%4487)\n",
      "  %4489, %4490, %4491, %4492 = If[else_branch = <graph torch-jit-export44>, then_branch = <graph torch-jit-export43>](%4488)\n",
      "  return %4490, %4489, %4491, %4492\n",
      "}\n",
      "\n",
      "graph torch-jit-export41 {\n",
      "  %4468 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4469 = Constant[value = <Tensor>]()\n",
      "  %4470 = Unsqueeze(%4468, %4469)\n",
      "  %4471 = Constant[value = <Tensor>]()\n",
      "  %4472 = Unsqueeze(%4411, %4471)\n",
      "  %4473 = Constant[value = <Tensor>]()\n",
      "  %4474 = Unsqueeze(%189, %4473)\n",
      "  %4475 = Constant[value = <Tensor>]()\n",
      "  %4476 = Slice(%4435, %4470, %4472, %4474, %4475)\n",
      "  %4477 = ReduceSum[keepdims = 0](%4476)\n",
      "  return %4477\n",
      "}\n",
      "\n",
      "graph torch-jit-export42 {\n",
      "  %4478 = Identity(%176)\n",
      "  return %4478\n",
      "}\n",
      "\n",
      "graph torch-jit-export43 {\n",
      "  %4493 = ConcatFromSequence[axis = 0](%4483)\n",
      "  %4494 = Add(%4467, %4451)\n",
      "  %4495 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4496 = Add(%4494, %4495)\n",
      "  %4497 = Constant[value = <Tensor>]()\n",
      "  %4498 = Unsqueeze(%4467, %4497)\n",
      "  %4499 = Constant[value = <Tensor>]()\n",
      "  %4500 = Unsqueeze(%4496, %4499)\n",
      "  %4501 = Constant[value = <Tensor>]()\n",
      "  %4502 = Unsqueeze(%189, %4501)\n",
      "  %4503 = Constant[value = <Tensor>]()\n",
      "  %4504 = Slice(%4493, %4498, %4500, %4502, %4503)\n",
      "  %4505 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4506 = Add(%4451, %4505)\n",
      "  %4507 = Constant[value = <Tensor>]()\n",
      "  %4508 = Reshape[allowzero = 0](%4506, %4507)\n",
      "  %4509, %4510 = TopK[axis = -1, largest = 0, sorted = 1](%4504, %4508)\n",
      "  %4511 = Gather[axis = 0](%4510, %189)\n",
      "  %4512 = Add(%4511, %4467)\n",
      "  %4513 = SequenceErase(%4484, %4512)\n",
      "  %4514 = SequenceErase(%4483, %4512)\n",
      "  %4515 = Gather[axis = 0](%4509, %187)\n",
      "  %4516 = Gather[axis = 0](%4434, %4411)\n",
      "  %4517 = Shape(%4516)\n",
      "  %4518 = Expand(%4515, %4517)\n",
      "  %4519 = Constant[value = <Tensor>]()\n",
      "  %4520 = Unsqueeze(%4411, %4519)\n",
      "  %4521 = Shape(%4520)\n",
      "  %4522 = Constant[value = <Tensor>]()\n",
      "  %4523 = Unsqueeze(%4520, %4522)\n",
      "  %4524 = Shape(%4434)\n",
      "  %4525 = Constant[value = <Tensor>]()\n",
      "  %4526 = Constant[value = <Tensor>]()\n",
      "  %4527 = Constant[value = <Tensor>]()\n",
      "  %4528 = Slice(%4524, %4526, %4527, %4525)\n",
      "  %4529 = Concat[axis = 0](%4521, %4528)\n",
      "  %4530 = Shape(%4529)\n",
      "  %4531 = ConstantOfShape[value = <Tensor>](%4530)\n",
      "  %4532 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4533 = Mul(%4531, %4532)\n",
      "  %4534 = Equal(%4529, %4533)\n",
      "  %4535 = Where(%4534, %4531, %4529)\n",
      "  %4536 = Expand(%4518, %4535)\n",
      "  %4537 = Reshape[allowzero = 0](%4536, %4529)\n",
      "  %4538 = ScatterND(%4434, %4523, %4537)\n",
      "  %4539 = Identity(%4435)\n",
      "  return %4513, %4514, %4538, %4539\n",
      "}\n",
      "\n",
      "graph torch-jit-export44 {\n",
      "  %4540 = Gather[axis = 0](%4434, %4411)\n",
      "  %4541 = Min(%4450, %4540)\n",
      "  %4542 = Gather[axis = 0](%4434, %4411)\n",
      "  %4543 = Cast[to = 1](%4541)\n",
      "  %4544 = Shape(%4542)\n",
      "  %4545 = Expand(%4543, %4544)\n",
      "  %4546 = Constant[value = <Tensor>]()\n",
      "  %4547 = Unsqueeze(%4411, %4546)\n",
      "  %4548 = Shape(%4547)\n",
      "  %4549 = Constant[value = <Tensor>]()\n",
      "  %4550 = Unsqueeze(%4547, %4549)\n",
      "  %4551 = Shape(%4434)\n",
      "  %4552 = Constant[value = <Tensor>]()\n",
      "  %4553 = Constant[value = <Tensor>]()\n",
      "  %4554 = Constant[value = <Tensor>]()\n",
      "  %4555 = Slice(%4551, %4553, %4554, %4552)\n",
      "  %4556 = Concat[axis = 0](%4548, %4555)\n",
      "  %4557 = Shape(%4556)\n",
      "  %4558 = ConstantOfShape[value = <Tensor>](%4557)\n",
      "  %4559 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4560 = Mul(%4558, %4559)\n",
      "  %4561 = Equal(%4556, %4560)\n",
      "  %4562 = Where(%4561, %4558, %4556)\n",
      "  %4563 = Expand(%4545, %4562)\n",
      "  %4564 = Reshape[allowzero = 0](%4563, %4556)\n",
      "  %4565 = ScatterND(%4434, %4550, %4564)\n",
      "  %4566 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4567 = Add(%4451, %4566)\n",
      "  %4568 = Gather[axis = 0](%4435, %4411)\n",
      "  %4569 = Shape(%4568)\n",
      "  %4570 = Expand(%4567, %4569)\n",
      "  %4571 = Constant[value = <Tensor>]()\n",
      "  %4572 = Unsqueeze(%4411, %4571)\n",
      "  %4573 = Shape(%4572)\n",
      "  %4574 = Constant[value = <Tensor>]()\n",
      "  %4575 = Unsqueeze(%4572, %4574)\n",
      "  %4576 = Shape(%4435)\n",
      "  %4577 = Constant[value = <Tensor>]()\n",
      "  %4578 = Constant[value = <Tensor>]()\n",
      "  %4579 = Constant[value = <Tensor>]()\n",
      "  %4580 = Slice(%4576, %4578, %4579, %4577)\n",
      "  %4581 = Concat[axis = 0](%4573, %4580)\n",
      "  %4582 = Shape(%4581)\n",
      "  %4583 = ConstantOfShape[value = <Tensor>](%4582)\n",
      "  %4584 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4585 = Mul(%4583, %4584)\n",
      "  %4586 = Equal(%4581, %4585)\n",
      "  %4587 = Where(%4586, %4583, %4581)\n",
      "  %4588 = Expand(%4570, %4587)\n",
      "  %4589 = Reshape[allowzero = 0](%4588, %4581)\n",
      "  %4590 = ScatterND(%4435, %4575, %4589)\n",
      "  %4591 = Identity(%4484)\n",
      "  %4592 = Identity(%4483)\n",
      "  return %4591, %4592, %4565, %4590\n",
      "}\n",
      "\n",
      "graph torch-jit-export45 {\n",
      "  %4593 = Identity(%4432)\n",
      "  %4594 = Identity(%4433)\n",
      "  %4595 = Identity(%4434)\n",
      "  %4596 = Identity(%4435)\n",
      "  return %4593, %4594, %4595, %4596\n",
      "}\n",
      "\n",
      "graph torch-jit-export46 (\n",
      "  %i.1[INT64, scalar]\n",
      "  %cond.13[BOOL, scalar]\n",
      "  %4616[INT64, 4616_dim_0]\n",
      "  %4617[Unknown type sequence_type]\n",
      ") {\n",
      "  %4618 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4619 = Greater(%i.1, %4618)\n",
      "  %4620 = Cast[to = 9](%4619)\n",
      "  %4621 = If[else_branch = <graph torch-jit-export48>, then_branch = <graph torch-jit-export47>](%4620)\n",
      "  %4633 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4634 = Add(%i.1, %4633)\n",
      "  %4635 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4636 = Constant[value = <Tensor>]()\n",
      "  %4637 = Unsqueeze(%4635, %4636)\n",
      "  %4638 = Constant[value = <Tensor>]()\n",
      "  %4639 = Unsqueeze(%4634, %4638)\n",
      "  %4640 = Constant[value = <Tensor>]()\n",
      "  %4641 = Unsqueeze(%189, %4640)\n",
      "  %4642 = Constant[value = <Tensor>]()\n",
      "  %4643 = Slice(%4408, %4637, %4639, %4641, %4642)\n",
      "  %4644 = ReduceSum[keepdims = 0](%4643)\n",
      "  %4645 = ConcatFromSequence[axis = 0](%4405)\n",
      "  %4646 = Constant[value = <Tensor>]()\n",
      "  %4647 = Unsqueeze(%4621, %4646)\n",
      "  %4648 = Constant[value = <Tensor>]()\n",
      "  %4649 = Unsqueeze(%4644, %4648)\n",
      "  %4650 = Constant[value = <Tensor>]()\n",
      "  %4651 = Unsqueeze(%189, %4650)\n",
      "  %4652 = Constant[value = <Tensor>]()\n",
      "  %4653 = Slice(%4645, %4647, %4649, %4651, %4652)\n",
      "  %4654 = Constant[value = <Tensor>]()\n",
      "  %4655 = Shape(%4653)\n",
      "  %4656 = Gather[axis = 0](%4655, %4654)\n",
      "  %4657 = Constant[value = <Tensor>]()\n",
      "  %4658 = Squeeze(%4656, %4657)\n",
      "  %4659 = Constant[value = <Tensor>]()\n",
      "  %4660 = Reshape[allowzero = 0](%4658, %4659)\n",
      "  %4661, %4662 = TopK[axis = -1, largest = 1, sorted = 1](%4653, %4660)\n",
      "  %4663, %4664 = Loop[body = <graph torch-jit-export49>](%187, %185, %4616, %4617)\n",
      "  %4706 = Identity(%185)\n",
      "  return %4706, %4663, %4664\n",
      "}\n",
      "\n",
      "graph torch-jit-export47 {\n",
      "  %4622 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4623 = Constant[value = <Tensor>]()\n",
      "  %4624 = Unsqueeze(%4622, %4623)\n",
      "  %4625 = Constant[value = <Tensor>]()\n",
      "  %4626 = Unsqueeze(%i.1, %4625)\n",
      "  %4627 = Constant[value = <Tensor>]()\n",
      "  %4628 = Unsqueeze(%189, %4627)\n",
      "  %4629 = Constant[value = <Tensor>]()\n",
      "  %4630 = Slice(%4408, %4624, %4626, %4628, %4629)\n",
      "  %4631 = ReduceSum[keepdims = 0](%4630)\n",
      "  return %4631\n",
      "}\n",
      "\n",
      "graph torch-jit-export48 {\n",
      "  %4632 = Identity(%176)\n",
      "  return %4632\n",
      "}\n",
      "\n",
      "graph torch-jit-export49 (\n",
      "  %j.1[INT64, scalar]\n",
      "  %cond.11[BOOL, scalar]\n",
      "  %4667[INT64, 4616_dim_0]\n",
      "  %4668[Unknown type sequence_type]\n",
      ") {\n",
      "  %4669 = Gather[axis = 0](%4662, %j.1)\n",
      "  %4670 = Add(%4621, %4669)\n",
      "  %4671 = SequenceAt(%4406, %4670)\n",
      "  %4672 = Constant[value = <Tensor>]()\n",
      "  %4673 = Shape(%4671)\n",
      "  %4674 = Gather[axis = 0](%4673, %4672)\n",
      "  %4675 = Constant[value = <Tensor>]()\n",
      "  %4676 = Squeeze(%4674, %4675)\n",
      "  %4677 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4678 = Mul(%4677, %i.1)\n",
      "  %4679 = Add(%4678, %j.1)\n",
      "  %4680 = Gather[axis = 0](%4667, %4679)\n",
      "  %4681 = Cast[to = 7](%4676)\n",
      "  %4682 = Shape(%4680)\n",
      "  %4683 = Expand(%4681, %4682)\n",
      "  %4684 = Constant[value = <Tensor>]()\n",
      "  %4685 = Unsqueeze(%4679, %4684)\n",
      "  %4686 = Shape(%4685)\n",
      "  %4687 = Constant[value = <Tensor>]()\n",
      "  %4688 = Unsqueeze(%4685, %4687)\n",
      "  %4689 = Shape(%4667)\n",
      "  %4690 = Constant[value = <Tensor>]()\n",
      "  %4691 = Constant[value = <Tensor>]()\n",
      "  %4692 = Constant[value = <Tensor>]()\n",
      "  %4693 = Slice(%4689, %4691, %4692, %4690)\n",
      "  %4694 = Concat[axis = 0](%4686, %4693)\n",
      "  %4695 = Shape(%4694)\n",
      "  %4696 = ConstantOfShape[value = <Tensor>](%4695)\n",
      "  %4697 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4698 = Mul(%4696, %4697)\n",
      "  %4699 = Equal(%4694, %4698)\n",
      "  %4700 = Where(%4699, %4696, %4694)\n",
      "  %4701 = Expand(%4683, %4700)\n",
      "  %4702 = Reshape[allowzero = 0](%4701, %4694)\n",
      "  %4703 = ScatterND(%4667, %4688, %4702)\n",
      "  %4704 = SequenceInsert(%4668, %4671)\n",
      "  %4705 = Identity(%185)\n",
      "  return %4705, %4703, %4704\n",
      "}\n",
      "\n",
      "graph torch-jit-export50 {\n",
      "  %4725 = Shape(%4718)\n",
      "  %4726 = ConstantOfShape[value = <Tensor>](%4725)\n",
      "  return %4726\n",
      "}\n",
      "\n",
      "graph torch-jit-export51 {\n",
      "  %4727 = Identity(%4718)\n",
      "  return %4727\n",
      "}\n",
      "\n",
      "graph torch-jit-export52 (\n",
      "  %i.17[INT64, scalar]\n",
      "  %cond[BOOL, scalar]\n",
      "  %4738[INT64, ConstantOfShape4726_dim_0xConstantOfShape4726_dim_1]\n",
      ") {\n",
      "  %4739 = SequenceAt(%4613, %i.17)\n",
      "  %4740 = Gather[axis = 0](%4738, %i.17)\n",
      "  %4741 = Gather[axis = 0](%4612, %i.17)\n",
      "  %4742 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4743 = Constant[value = <Tensor>]()\n",
      "  %4744 = Unsqueeze(%4742, %4743)\n",
      "  %4745 = Constant[value = <Tensor>]()\n",
      "  %4746 = Unsqueeze(%4741, %4745)\n",
      "  %4747 = Constant[value = <Tensor>]()\n",
      "  %4748 = Unsqueeze(%189, %4747)\n",
      "  %4749 = Constant[value = <Tensor>]()\n",
      "  %4750 = Slice(%4740, %4744, %4746, %4748, %4749)\n",
      "  %4751 = Shape(%4750)\n",
      "  %4752 = Expand(%4739, %4751)\n",
      "  %4753 = Constant[value = <Tensor>]()\n",
      "  %4754 = Unsqueeze(%i.17, %4753)\n",
      "  %4755 = Shape(%4738)\n",
      "  %4756 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4757 = Gather[axis = 0](%4755, %4756)\n",
      "  %4758 = Cast[to = 7](%4757)\n",
      "  %4759 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4760 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4761 = Range(%4759, %4758, %4760)\n",
      "  %4762 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4763 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4764 = Constant[value = <Tensor>]()\n",
      "  %4765 = Unsqueeze(%4763, %4764)\n",
      "  %4766 = Constant[value = <Tensor>]()\n",
      "  %4767 = Unsqueeze(%4741, %4766)\n",
      "  %4768 = Constant[value = <Tensor>]()\n",
      "  %4769 = Unsqueeze(%4762, %4768)\n",
      "  %4770 = Constant[value = <Tensor>]()\n",
      "  %4771 = Slice(%4761, %4765, %4767, %4769, %4770)\n",
      "  %4772 = Constant[value = <Tensor>]()\n",
      "  %4773 = Reshape[allowzero = 0](%4754, %4772)\n",
      "  %4774 = Add(%4773, %4771)\n",
      "  %4775 = Shape(%4774)\n",
      "  %4776 = Shape(%4775)\n",
      "  %4777 = ConstantOfShape[value = <Tensor>](%4776)\n",
      "  %4778 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4779 = Mul(%4777, %4778)\n",
      "  %4780 = Equal(%4775, %4779)\n",
      "  %4781 = Where(%4780, %4777, %4775)\n",
      "  %4782 = Expand(%4773, %4781)\n",
      "  %4783 = Constant[value = <Tensor>]()\n",
      "  %4784 = Unsqueeze(%4782, %4783)\n",
      "  %4785 = Shape(%4775)\n",
      "  %4786 = ConstantOfShape[value = <Tensor>](%4785)\n",
      "  %4787 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4788 = Mul(%4786, %4787)\n",
      "  %4789 = Equal(%4775, %4788)\n",
      "  %4790 = Where(%4789, %4786, %4775)\n",
      "  %4791 = Expand(%4771, %4790)\n",
      "  %4792 = Constant[value = <Tensor>]()\n",
      "  %4793 = Unsqueeze(%4791, %4792)\n",
      "  %4794 = Concat[axis = -1](%4784, %4793)\n",
      "  %4795 = Shape(%4738)\n",
      "  %4796 = Constant[value = <Tensor>]()\n",
      "  %4797 = Constant[value = <Tensor>]()\n",
      "  %4798 = Constant[value = <Tensor>]()\n",
      "  %4799 = Slice(%4795, %4797, %4798, %4796)\n",
      "  %4800 = Concat[axis = 0](%4775, %4799)\n",
      "  %4801 = Reshape[allowzero = 0](%4752, %4800)\n",
      "  %4802 = Cast[to = 7](%4801)\n",
      "  %4803 = ScatterND(%4738, %4794, %4802)\n",
      "  %4804 = Gather[axis = 0](%4612, %i.17)\n",
      "  %4805 = Less(%4804, %max_length)\n",
      "  %4806 = Cast[to = 9](%4805)\n",
      "  %4807 = If[else_branch = <graph torch-jit-export54>, then_branch = <graph torch-jit-export53>](%4806)\n",
      "  %4851 = Identity(%185)\n",
      "  return %4851, %4807\n",
      "}\n",
      "\n",
      "graph torch-jit-export53 {\n",
      "  %4808 = Gather[axis = 0](%4612, %i.17)\n",
      "  %4809 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4810 = Constant[value = <Tensor>]()\n",
      "  %4811 = Unsqueeze(%i.17, %4810)\n",
      "  %4812 = Constant[value = <Tensor>]()\n",
      "  %4813 = Reshape[allowzero = 0](%4811, %4812)\n",
      "  %4814 = Add(%4813, %4808)\n",
      "  %4815 = Shape(%4814)\n",
      "  %4816 = Shape(%4815)\n",
      "  %4817 = ConstantOfShape[value = <Tensor>](%4816)\n",
      "  %4818 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4819 = Mul(%4817, %4818)\n",
      "  %4820 = Equal(%4815, %4819)\n",
      "  %4821 = Where(%4820, %4817, %4815)\n",
      "  %4822 = Expand(%4813, %4821)\n",
      "  %4823 = Constant[value = <Tensor>]()\n",
      "  %4824 = Unsqueeze(%4822, %4823)\n",
      "  %4825 = Shape(%4815)\n",
      "  %4826 = ConstantOfShape[value = <Tensor>](%4825)\n",
      "  %4827 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4828 = Mul(%4826, %4827)\n",
      "  %4829 = Equal(%4815, %4828)\n",
      "  %4830 = Where(%4829, %4826, %4815)\n",
      "  %4831 = Expand(%4808, %4830)\n",
      "  %4832 = Constant[value = <Tensor>]()\n",
      "  %4833 = Unsqueeze(%4831, %4832)\n",
      "  %4834 = Concat[axis = -1](%4824, %4833)\n",
      "  %4835 = Shape(%4803)\n",
      "  %4836 = Constant[value = <Tensor>]()\n",
      "  %4837 = Constant[value = <Tensor>]()\n",
      "  %4838 = Constant[value = <Tensor>]()\n",
      "  %4839 = Slice(%4835, %4837, %4838, %4836)\n",
      "  %4840 = Concat[axis = 0](%4815, %4839)\n",
      "  %4841 = Shape(%4840)\n",
      "  %4842 = ConstantOfShape[value = <Tensor>](%4841)\n",
      "  %4843 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4844 = Mul(%4842, %4843)\n",
      "  %4845 = Equal(%4840, %4844)\n",
      "  %4846 = Where(%4845, %4842, %4840)\n",
      "  %4847 = Expand(%4809, %4846)\n",
      "  %4848 = Reshape[allowzero = 0](%4847, %4840)\n",
      "  %4849 = ScatterND(%4803, %4834, %4848)\n",
      "  return %4849\n",
      "}\n",
      "\n",
      "graph torch-jit-export54 {\n",
      "  %4850 = Identity(%4803)\n",
      "  return %4850\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model_onnx_beam = onnx.load(onnx_file_path)\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model_onnx_beam)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model_onnx_beam.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "options = onnxruntime.SessionOptions()\n",
    "\n",
    "ort_sess = onnxruntime.InferenceSession(onnx_file_path, sess_options=options )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,   365, 28715,\n",
      "          3638,  1207,    16,   282, 28715, 23940,  3942,    17, 18047,     2]])\n",
      "[array([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,   365,\n",
      "        28715,  3638,  1207,    16,   282, 28715, 23940,  3942,    17,\n",
      "        18047,     2]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "ort_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].cpu().numpy(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].cpu().numpy(),\n",
    "        \"num_beams\": np.array(num_beams, dtype=np.int64),\n",
    "        \"max_length\": np.array(max_length, dtype=np.int64),\n",
    "    }\n",
    "\n",
    "ort_out = ort_sess.run(\n",
    "    None,\n",
    "    ort_inputs\n",
    ")\n",
    "\n",
    "print(summary_ids)\n",
    "print(ort_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(summary_ids.cpu().numpy(), ort_out[0], rtol=1e-3, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeamsSearchSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature=2.0\n",
    "top_p=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_ids_temp = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    num_beams=num_beams,\n",
    "    max_length=max_length,\n",
    "    early_stopping=True,\n",
    "    decoder_start_token_id=septok,\n",
    "    pad_token_id=padtok,\n",
    "    bos_token_id=starttok,\n",
    "    eos_token_id=endtok,\n",
    "    forced_eos_token_id=endtok,\n",
    "    temperature=temperature,\n",
    "    top_p=top_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = None\n",
    "script_model_sample = torch.jit.script(GPT2BeamSearchSampleGenerator(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = 'gpt3_sample.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,   365, 28715,\n",
      "          3638,  1207,    16,   282, 28715, 23940,  3942,    17, 18047,     2]])\n"
     ]
    }
   ],
   "source": [
    "print(summary_ids_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_ids : Long(*, *, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %attention_mask : Long(1, 8, strides=[8, 1], requires_grad=0, device=cpu),\n",
      "      %num_beams : Long(device=cpu),\n",
      "      %max_length : Long(device=cpu),\n",
      "      %temperature : Double(requires_grad=0, device=cpu),\n",
      "      %top_p : Double(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.wte.weight : Float(50260, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.wpe.weight : Float(2048, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_1.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_1.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.masked_bias : Float(requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.bias : Byte(1, 1, 2048, 2048, strides=[4194304, 4194304, 2048, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight : Float(768, 2304, strides=[2304, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias : Float(2304, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight : Float(768, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_2.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.ln_2.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight : Float(768, 3072, strides=[3072, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias : Float(3072, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight : Float(3072, 768, strides=[768, 1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.ln_f.bias : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %decoder_no_past.decoder.transformer.ln_f.weight : Float(768, strides=[1], requires_grad=0, device=cpu),\n",
      "      %5038 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %5039 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
      "      %5040 : Float(768, 50260, strides=[1, 768], requires_grad=0, device=cpu),\n",
      "      %5041 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %178 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %179 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3072}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "  %180 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={64}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "  %181 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={12}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "  %182 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2304}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "  %183 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={768}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "  %184 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %185 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "  %186 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %187 : Bool(device=cpu) = onnx::Constant[value={1}]() # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:385:8\n",
      "  %188 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %189 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %190 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "  %191 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %192 : Float(device=cpu) = onnx::Cast[to=1](%temperature) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:811:22\n",
      "  %193 : Float(device=cpu) = onnx::Cast[to=1](%top_p) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:812:16\n",
      "  %194 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids) # <string>:7:9\n",
      "  %195 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %196 : Long(device=cpu) = onnx::Gather[axis=0](%194, %195)\n",
      "  %197 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %198 : Long(device=cpu) = onnx::Div(%num_beams, %197)\n",
      "  %199 : Long(device=cpu) = onnx::Cast[to=7](%198)\n",
      "  %200 : Long(device=cpu) = onnx::Cast[to=7](%199)\n",
      "  %201 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %202 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %201)\n",
      "  %203 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%202)\n",
      "  %204 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %205 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %204)\n",
      "  %206 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%205)\n",
      "  %207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %208 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %207)\n",
      "  %209 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%208)\n",
      "  %210 : Bool(*, device=cpu) = onnx::ConstantOfShape[value={0}](%203)\n",
      "  %211 : Long(*, device=cpu) = onnx::ConstantOfShape[value={0}](%206)\n",
      "  %212 : Float(*, device=cpu) = onnx::ConstantOfShape[value={0}](%209) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:330:39\n",
      "  %213 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e+09}]()\n",
      "  %214 : Float(*, device=cpu) = onnx::Add(%212, %213)\n",
      "  %215 : Long(*, device=cpu)[] = onnx::SequenceEmpty[dtype=7]()\n",
      "  %216 : Float(*, device=cpu)[] = onnx::SequenceEmpty[dtype=1]()\n",
      "  %217 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids) # <string>:7:9\n",
      "  %218 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %219 : Long(device=cpu) = onnx::Gather[axis=0](%217, %218) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:25\n",
      "  %220 : Long(device=cpu) = onnx::Cast[to=7](%219)\n",
      "  %221 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %222 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %223 : Long(*, device=cpu) = onnx::Range(%221, %220, %222) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %224 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %225 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%223, %224) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %228 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %229 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %228)\n",
      "  %230 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%5038, %229)\n",
      "  %233 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %234 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %233)\n",
      "  %235 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%5039, %234)\n",
      "  %236 : Long(1, strides=[1], device=cpu) = onnx::Shape(%230)\n",
      "  %237 : Long(2, strides=[1], device=cpu) = onnx::ConstantOfShape[value={1}](%236)\n",
      "  %238 : Long(*, 1, device=cpu) = onnx::Expand(%225, %237)\n",
      "  %239 : Long(*, *, device=cpu) = onnx::Tile(%238, %235) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %240 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %241 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%239, %240) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:542:12\n",
      "  %242 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%input_ids, %241) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:544:20\n",
      "  %243 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%attention_mask, %241) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:546:25\n",
      "  %244 : Long(2, strides=[1], device=cpu) = onnx::Shape(%242) # <string>:7:9\n",
      "  %245 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %246 : Long(device=cpu) = onnx::Gather(%244, %245)\n",
      "  %247 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %248 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %247)\n",
      "  %249 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %250 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%num_beams, %249)\n",
      "  %251 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%248, %250)\n",
      "  %252 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%251) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:712:8\n",
      "  %253 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %254 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %255 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %257 : Float(*, *, device=cpu) = onnx::Slice(%252, %254, %255, %253, %256) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:712:8\n",
      "  %258 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-1e+09}]()\n",
      "  %259 : Long(2, strides=[1], device=cpu) = onnx::Shape(%257)\n",
      "  %260 : FloatTensor(device=cpu) = onnx::Expand(%258, %259) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:712:8\n",
      "  %261 : Long(2, strides=[1], device=cpu) = onnx::Shape(%252)\n",
      "  %262 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %263 : Long(device=cpu) = onnx::Gather[axis=0](%261, %262)\n",
      "  %264 : Long(device=cpu) = onnx::Cast[to=7](%263)\n",
      "  %265 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %266 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %267 : Long(*, device=cpu) = onnx::Range(%265, %264, %266)\n",
      "  %268 : Long(2, strides=[1], device=cpu) = onnx::Shape(%252)\n",
      "  %269 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %270 : Long(device=cpu) = onnx::Gather[axis=0](%268, %269)\n",
      "  %271 : Long(device=cpu) = onnx::Cast[to=7](%270)\n",
      "  %272 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %273 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "  %274 : Long(*, device=cpu) = onnx::Range(%272, %271, %273)\n",
      "  %275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %276 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %277 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "  %279 : Long(*, device=cpu) = onnx::Slice(%274, %276, %277, %275, %278)\n",
      "  %280 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "  %281 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%267, %280)\n",
      "  %282 : Long(*, *, device=cpu) = onnx::Add(%281, %279)\n",
      "  %283 : Long(2, strides=[1], device=cpu) = onnx::Shape(%282)\n",
      "  %284 : Long(1, strides=[1], device=cpu) = onnx::Shape(%283)\n",
      "  %285 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%284)\n",
      "  %286 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %287 : Long(2, strides=[1], device=cpu) = onnx::Mul(%285, %286)\n",
      "  %288 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%283, %287)\n",
      "  %289 : Long(2, strides=[1], device=cpu) = onnx::Where(%288, %285, %283)\n",
      "  %290 : LongTensor(device=cpu) = onnx::Expand(%281, %289)\n",
      "  %291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %292 : LongTensor(device=cpu) = onnx::Unsqueeze(%290, %291)\n",
      "  %293 : Long(1, strides=[1], device=cpu) = onnx::Shape(%283)\n",
      "  %294 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%293)\n",
      "  %295 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %296 : Long(2, strides=[1], device=cpu) = onnx::Mul(%294, %295)\n",
      "  %297 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%283, %296)\n",
      "  %298 : Long(2, strides=[1], device=cpu) = onnx::Where(%297, %294, %283)\n",
      "  %299 : LongTensor(device=cpu) = onnx::Expand(%279, %298)\n",
      "  %300 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "  %301 : LongTensor(device=cpu) = onnx::Unsqueeze(%299, %300)\n",
      "  %302 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%292, %301)\n",
      "  %303 : Long(2, strides=[1], device=cpu) = onnx::Shape(%252)\n",
      "  %304 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %305 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "  %306 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "  %307 : Long(0, strides=[1], device=cpu) = onnx::Slice(%303, %305, %306, %304)\n",
      "  %308 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%283, %307)\n",
      "  %309 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%260, %308)\n",
      "  %310 : Float(*, *, device=cpu) = onnx::ScatterND(%252, %302, %309) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:712:8\n",
      "  %311 : Long(device=cpu) = onnx::Mul(%196, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:713:40\n",
      "  %312 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %313 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%311, %312)\n",
      "  %314 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%313)\n",
      "  %315 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%310, %314) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:713:22\n",
      "  %316 : Bool(device=cpu) = onnx::Greater(%max_length, %246) # <string>:11:9\n",
      "  %318 : Long(*, *, device=cpu), %319 : Float(*, device=cpu), %320 : Long(*, *, device=cpu), %321 : Long(device=cpu), %322 : Float(*, device=cpu)[], %323 : Long(*, device=cpu)[], %324 : Float(*, device=cpu), %325 : Long(*, device=cpu), %326 : Bool(*, device=cpu) = onnx::Loop(%184, %316, %242, %315, %243, %246, %216, %215, %214, %211, %210) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:718:8\n",
      "    block0(%327 : Long(requires_grad=0, device=cpu), %cond.5 : Bool(device=cpu), %input_ids.25 : Long(*, *, device=cpu), %beam_scores.17 : Float(*, device=cpu), %attention_mask.13 : Long(*, *, device=cpu), %cur_len.13 : Long(device=cpu), %333 : Float(*, device=cpu)[], %334 : Long(*, device=cpu)[], %335 : Float(*, device=cpu), %336 : Long(*, device=cpu), %337 : Bool(*, device=cpu)):\n",
      "      %338 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25), scope: __module.decoder/__module.decoder.transformer\n",
      "      %339 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %340 : Long(device=cpu) = onnx::Gather[axis=0](%338, %339), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:678:0\n",
      "      %341 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25), scope: __module.decoder/__module.decoder.transformer\n",
      "      %342 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %343 : Long(device=cpu) = onnx::Gather[axis=0](%341, %342), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:678:0\n",
      "      %344 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %345 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %344)\n",
      "      %346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %347 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%343, %346)\n",
      "      %348 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%345, %347)\n",
      "      %349 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %350 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %349)\n",
      "      %351 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %352 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%343, %351)\n",
      "      %353 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%350, %352)\n",
      "      %354 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%input_ids.25, %348), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:679:0\n",
      "      %355 : Long(2, strides=[1], device=cpu) = onnx::Shape(%354), scope: __module.decoder/__module.decoder.transformer\n",
      "      %356 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %357 : Long(device=cpu) = onnx::Gather[axis=0](%355, %356), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:680:0\n",
      "      %358 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %359 : Long(device=cpu) = onnx::Add(%343, %358)\n",
      "      %360 : Long(device=cpu) = onnx::Cast[to=7](%191), scope: __module.decoder/__module.decoder.transformer\n",
      "      %361 : Long(device=cpu) = onnx::Cast[to=7](%359), scope: __module.decoder/__module.decoder.transformer\n",
      "      %362 : Long(device=cpu) = onnx::Cast[to=7](%189), scope: __module.decoder/__module.decoder.transformer\n",
      "      %363 : Long(*, device=cpu) = onnx::Range(%360, %361, %362), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:700:0\n",
      "      %364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %365 : Long(1, *, device=cpu) = onnx::Unsqueeze(%363, %364), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:701:0\n",
      "      %366 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%365, %353), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:701:0\n",
      "      %367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %368 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%357, %367)\n",
      "      %369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %370 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %369)\n",
      "      %371 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%368, %370)\n",
      "      %372 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%attention_mask.13, %371), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %374 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%372, %373), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %376 : Long(*, *, *, *, device=cpu) = onnx::Unsqueeze(%374, %375), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:713:0\n",
      "      %377 : Float(*, *, *, *, device=cpu) = onnx::Cast[to=1](%376), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:720:0\n",
      "      %378 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %379 : Float(*, *, *, *, device=cpu) = onnx::Sub(%378, %377), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:548:0\n",
      "      %380 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}]()\n",
      "      %381 : Float(*, *, *, *, device=cpu) = onnx::Mul(%379, %380)\n",
      "      %382 : Float(*, *, *, device=cpu) = onnx::Gather(%decoder_no_past.decoder.transformer.wte.weight, %354), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.wte # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2044:0\n",
      "      %383 : Float(*, *, *, device=cpu) = onnx::Gather(%decoder_no_past.decoder.transformer.wpe.weight, %366), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.wpe # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2044:0\n",
      "      %384 : Float(*, *, *, device=cpu) = onnx::Add(%382, %383), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.drop # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %385 : Long(3, strides=[1], device=cpu) = onnx::Shape(%384), scope: __module.decoder/__module.decoder.transformer\n",
      "      %386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %387 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %389 : Long(1, strides=[1], device=cpu) = onnx::Slice(%385, %387, %388, %386), scope: __module.decoder/__module.decoder.transformer\n",
      "      %390 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer\n",
      "      %391 : Long(device=cpu) = onnx::Squeeze(%389, %390), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:751:0\n",
      "      %392 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%384), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %393 : Float(*, *, *, device=cpu) = onnx::Sub(%384, %392), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %394 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %395 : Float(*, *, *, device=cpu) = onnx::Pow(%393, %394), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %396 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%395), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %397 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %398 : Float(*, *, device=cpu) = onnx::Add(%396, %397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %399 : Float(*, *, device=cpu) = onnx::Sqrt(%398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %400 : Float(*, *, *, device=cpu) = onnx::Div(%393, %399), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %401 : Float(*, *, *, device=cpu) = onnx::Mul(%400, %decoder_no_past.decoder.transformer.h.0.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1\n",
      "      %402 : Float(*, *, *, device=cpu) = onnx::Add(%401, %decoder_no_past.decoder.transformer.h.0.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %403 : Long(3, strides=[1], device=cpu) = onnx::Shape(%402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %404 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %405 : Long(device=cpu) = onnx::Gather[axis=0](%403, %404), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %406 : Long(3, strides=[1], device=cpu) = onnx::Shape(%402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %407 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %408 : Long(device=cpu) = onnx::Gather[axis=0](%406, %407), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %409 : Long(3, strides=[1], device=cpu) = onnx::Shape(%402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %413 : Long(1, strides=[1], device=cpu) = onnx::Slice(%409, %411, %412, %410), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %414 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn\n",
      "      %415 : Long(device=cpu) = onnx::Squeeze(%413, %414), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %416 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %417 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %416)\n",
      "      %418 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %419 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%415, %418)\n",
      "      %420 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%417, %419)\n",
      "      %421 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%402, %420), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %422 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%421, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %423 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %424 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%405, %423)\n",
      "      %425 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %426 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%408, %425)\n",
      "      %427 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %428 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %427)\n",
      "      %429 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%424, %426, %428)\n",
      "      %430 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%422, %429), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %431 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %432 : Float(*, *, *, device=cpu), %433 : Float(*, *, *, device=cpu), %434 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%430, %431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %435 : Long(3, strides=[1], device=cpu) = onnx::Shape(%432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %436 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %437 : Long(device=cpu) = onnx::Gather[axis=0](%435, %436), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %438 : Long(3, strides=[1], device=cpu) = onnx::Shape(%432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %439 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %440 : Long(device=cpu) = onnx::Gather[axis=0](%438, %439), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %441 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %442 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%437, %441)\n",
      "      %443 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %444 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%440, %443)\n",
      "      %445 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %446 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %445)\n",
      "      %447 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %448 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %447)\n",
      "      %449 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%442, %444, %446, %448)\n",
      "      %450 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%432, %449), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %451 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%450), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %452 : Long(3, strides=[1], device=cpu) = onnx::Shape(%433), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %453 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %454 : Long(device=cpu) = onnx::Gather[axis=0](%452, %453), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %455 : Long(3, strides=[1], device=cpu) = onnx::Shape(%433), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %456 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %457 : Long(device=cpu) = onnx::Gather[axis=0](%455, %456), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%454, %458)\n",
      "      %460 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %461 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%457, %460)\n",
      "      %462 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %463 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %462)\n",
      "      %464 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %465 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %464)\n",
      "      %466 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%459, %461, %463, %465)\n",
      "      %467 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%433, %466), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %468 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%467), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %469 : Long(3, strides=[1], device=cpu) = onnx::Shape(%434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %470 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %471 : Long(device=cpu) = onnx::Gather[axis=0](%469, %470), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %472 : Long(3, strides=[1], device=cpu) = onnx::Shape(%434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %473 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %474 : Long(device=cpu) = onnx::Gather[axis=0](%472, %473), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %475 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %476 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%471, %475)\n",
      "      %477 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %478 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%474, %477)\n",
      "      %479 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %480 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %479)\n",
      "      %481 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %482 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %481)\n",
      "      %483 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%476, %478, %480, %482)\n",
      "      %484 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%434, %483), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %485 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%484), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %486 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%467), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %487 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%451, %486), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %488 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %489 : Float(*, *, *, *, device=cpu) = onnx::Div(%487, %488)\n",
      "      %490 : Long(4, strides=[1], device=cpu) = onnx::Shape(%451), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %493 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %494 : Long(1, strides=[1], device=cpu) = onnx::Slice(%490, %492, %493, %491), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %495 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %496 : Long(device=cpu) = onnx::Squeeze(%494, %495), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %497 : Long(4, strides=[1], device=cpu) = onnx::Shape(%468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %499 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %501 : Long(1, strides=[1], device=cpu) = onnx::Slice(%497, %499, %500, %498), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %503 : Long(device=cpu) = onnx::Squeeze(%501, %502), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %504 : Long(device=cpu) = onnx::Sub(%503, %496), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %506 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%504, %505), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %507 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %508 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%503, %507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %509 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %510 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %511 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %512 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.0.attn.bias, %506, %508, %510, %511), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %513 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %514 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %515 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %516 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%503, %515), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %517 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %518 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %517), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %519 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %520 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%512, %514, %516, %518, %519), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %521 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%520), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %522 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.0.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %523 : Float(*, *, *, *, device=cpu) = onnx::Where(%521, %489, %522), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %524 : Float(*, *, *, *, device=cpu) = onnx::Add(%523, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %525 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%524), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %526 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%525, %485), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %527 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%526), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %528 : Long(4, strides=[1], device=cpu) = onnx::Shape(%527), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %529 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %530 : Long(device=cpu) = onnx::Gather[axis=0](%528, %529), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %531 : Long(4, strides=[1], device=cpu) = onnx::Shape(%527), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %532 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn\n",
      "      %533 : Long(device=cpu) = onnx::Gather[axis=0](%531, %532), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %534 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %535 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%530, %534)\n",
      "      %536 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %537 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%533, %536)\n",
      "      %538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %539 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %538)\n",
      "      %540 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%535, %537, %539)\n",
      "      %541 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%527, %540), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %542 : Long(3, strides=[1], device=cpu) = onnx::Shape(%541), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %543 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %544 : Long(device=cpu) = onnx::Gather[axis=0](%542, %543), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %545 : Long(3, strides=[1], device=cpu) = onnx::Shape(%541), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %546 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %547 : Long(device=cpu) = onnx::Gather[axis=0](%545, %546), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %548 : Long(3, strides=[1], device=cpu) = onnx::Shape(%541), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %549 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %552 : Long(1, strides=[1], device=cpu) = onnx::Slice(%548, %550, %551, %549), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj\n",
      "      %554 : Long(device=cpu) = onnx::Squeeze(%552, %553), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %556 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %555)\n",
      "      %557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %558 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%554, %557)\n",
      "      %559 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%556, %558)\n",
      "      %560 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%541, %559), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %561 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%560, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %562 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %563 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%544, %562)\n",
      "      %564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %565 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%547, %564)\n",
      "      %566 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %567 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %566)\n",
      "      %568 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%563, %565, %567)\n",
      "      %569 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%561, %568), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.attn/__module.decoder.transformer.h.0.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %570 : Float(*, *, *, device=cpu) = onnx::Add(%569, %384), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %571 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%570), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %572 : Float(*, *, *, device=cpu) = onnx::Sub(%570, %571), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %573 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %574 : Float(*, *, *, device=cpu) = onnx::Pow(%572, %573), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %575 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%574), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %576 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %577 : Float(*, *, device=cpu) = onnx::Add(%575, %576), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %578 : Float(*, *, device=cpu) = onnx::Sqrt(%577), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %579 : Float(*, *, *, device=cpu) = onnx::Div(%572, %578), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %580 : Float(*, *, *, device=cpu) = onnx::Mul(%579, %decoder_no_past.decoder.transformer.h.0.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2\n",
      "      %581 : Float(*, *, *, device=cpu) = onnx::Add(%580, %decoder_no_past.decoder.transformer.h.0.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %582 : Long(3, strides=[1], device=cpu) = onnx::Shape(%581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %583 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %584 : Long(device=cpu) = onnx::Gather[axis=0](%582, %583), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %585 : Long(3, strides=[1], device=cpu) = onnx::Shape(%581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %586 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %587 : Long(device=cpu) = onnx::Gather[axis=0](%585, %586), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %588 : Long(3, strides=[1], device=cpu) = onnx::Shape(%581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %592 : Long(1, strides=[1], device=cpu) = onnx::Slice(%588, %590, %591, %589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc\n",
      "      %594 : Long(device=cpu) = onnx::Squeeze(%592, %593), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %596 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %595)\n",
      "      %597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %598 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%594, %597)\n",
      "      %599 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%596, %598)\n",
      "      %600 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%581, %599), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %601 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%600, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %603 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%584, %602)\n",
      "      %604 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %605 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%587, %604)\n",
      "      %606 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %607 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %606)\n",
      "      %608 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%603, %605, %607)\n",
      "      %609 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%601, %608), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %611 : Float(*, *, *, device=cpu) = onnx::Mul(%609, %610)\n",
      "      %612 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %613 : Float(*, *, *, device=cpu) = onnx::Pow(%609, %612), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %614 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %615 : Float(*, *, *, device=cpu) = onnx::Mul(%613, %614)\n",
      "      %616 : Float(*, *, *, device=cpu) = onnx::Add(%609, %615), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %617 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %618 : Float(*, *, *, device=cpu) = onnx::Mul(%616, %617)\n",
      "      %619 : Float(*, *, *, device=cpu) = onnx::Tanh(%618), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %620 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %621 : Float(*, *, *, device=cpu) = onnx::Add(%619, %620)\n",
      "      %622 : Float(*, *, *, device=cpu) = onnx::Mul(%611, %621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %623 : Long(3, strides=[1], device=cpu) = onnx::Shape(%622), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %624 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %625 : Long(device=cpu) = onnx::Gather[axis=0](%623, %624), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %626 : Long(3, strides=[1], device=cpu) = onnx::Shape(%622), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %627 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %628 : Long(device=cpu) = onnx::Gather[axis=0](%626, %627), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %629 : Long(3, strides=[1], device=cpu) = onnx::Shape(%622), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %632 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %633 : Long(1, strides=[1], device=cpu) = onnx::Slice(%629, %631, %632, %630), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %634 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj\n",
      "      %635 : Long(device=cpu) = onnx::Squeeze(%633, %634), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %636 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %637 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %636)\n",
      "      %638 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %639 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%635, %638)\n",
      "      %640 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%637, %639)\n",
      "      %641 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%622, %640), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %642 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%641, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %643 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %644 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%625, %643)\n",
      "      %645 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %646 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%628, %645)\n",
      "      %647 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %648 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %647)\n",
      "      %649 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%644, %646, %648)\n",
      "      %650 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%642, %649), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0/__module.decoder.transformer.h.0.mlp/__module.decoder.transformer.h.0.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %651 : Float(*, *, *, device=cpu) = onnx::Add(%570, %650), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.0 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %652 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%651), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %653 : Float(*, *, *, device=cpu) = onnx::Sub(%651, %652), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %654 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %655 : Float(*, *, *, device=cpu) = onnx::Pow(%653, %654), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %656 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%655), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %657 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %658 : Float(*, *, device=cpu) = onnx::Add(%656, %657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %659 : Float(*, *, device=cpu) = onnx::Sqrt(%658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %660 : Float(*, *, *, device=cpu) = onnx::Div(%653, %659), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %661 : Float(*, *, *, device=cpu) = onnx::Mul(%660, %decoder_no_past.decoder.transformer.h.1.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1\n",
      "      %662 : Float(*, *, *, device=cpu) = onnx::Add(%661, %decoder_no_past.decoder.transformer.h.1.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %663 : Long(3, strides=[1], device=cpu) = onnx::Shape(%662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %664 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %665 : Long(device=cpu) = onnx::Gather[axis=0](%663, %664), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %666 : Long(3, strides=[1], device=cpu) = onnx::Shape(%662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %667 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %668 : Long(device=cpu) = onnx::Gather[axis=0](%666, %667), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %669 : Long(3, strides=[1], device=cpu) = onnx::Shape(%662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %673 : Long(1, strides=[1], device=cpu) = onnx::Slice(%669, %671, %672, %670), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn\n",
      "      %675 : Long(device=cpu) = onnx::Squeeze(%673, %674), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %676 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %677 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %676)\n",
      "      %678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %679 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%675, %678)\n",
      "      %680 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%677, %679)\n",
      "      %681 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%662, %680), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %682 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%681, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%665, %683)\n",
      "      %685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %686 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%668, %685)\n",
      "      %687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %688 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %687)\n",
      "      %689 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%684, %686, %688)\n",
      "      %690 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%682, %689), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %691 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %692 : Float(*, *, *, device=cpu), %693 : Float(*, *, *, device=cpu), %694 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%690, %691), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %695 : Long(3, strides=[1], device=cpu) = onnx::Shape(%692), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %696 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %697 : Long(device=cpu) = onnx::Gather[axis=0](%695, %696), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %698 : Long(3, strides=[1], device=cpu) = onnx::Shape(%692), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %699 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %700 : Long(device=cpu) = onnx::Gather[axis=0](%698, %699), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %701 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %702 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%697, %701)\n",
      "      %703 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %704 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%700, %703)\n",
      "      %705 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %706 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %705)\n",
      "      %707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %708 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %707)\n",
      "      %709 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%702, %704, %706, %708)\n",
      "      %710 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%692, %709), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %711 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%710), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %712 : Long(3, strides=[1], device=cpu) = onnx::Shape(%693), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %713 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %714 : Long(device=cpu) = onnx::Gather[axis=0](%712, %713), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %715 : Long(3, strides=[1], device=cpu) = onnx::Shape(%693), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %716 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %717 : Long(device=cpu) = onnx::Gather[axis=0](%715, %716), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %719 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%714, %718)\n",
      "      %720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %721 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%717, %720)\n",
      "      %722 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %723 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %722)\n",
      "      %724 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %725 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %724)\n",
      "      %726 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%719, %721, %723, %725)\n",
      "      %727 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%693, %726), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %728 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%727), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %729 : Long(3, strides=[1], device=cpu) = onnx::Shape(%694), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %730 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %731 : Long(device=cpu) = onnx::Gather[axis=0](%729, %730), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %732 : Long(3, strides=[1], device=cpu) = onnx::Shape(%694), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %733 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %734 : Long(device=cpu) = onnx::Gather[axis=0](%732, %733), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %735 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %736 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%731, %735)\n",
      "      %737 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %738 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%734, %737)\n",
      "      %739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %740 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %739)\n",
      "      %741 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %742 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %741)\n",
      "      %743 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%736, %738, %740, %742)\n",
      "      %744 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%694, %743), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %745 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%744), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %746 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%727), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %747 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%711, %746), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %748 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %749 : Float(*, *, *, *, device=cpu) = onnx::Div(%747, %748)\n",
      "      %750 : Long(4, strides=[1], device=cpu) = onnx::Shape(%711), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %751 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %752 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %753 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %754 : Long(1, strides=[1], device=cpu) = onnx::Slice(%750, %752, %753, %751), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %755 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %756 : Long(device=cpu) = onnx::Squeeze(%754, %755), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %757 : Long(4, strides=[1], device=cpu) = onnx::Shape(%728), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %758 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %759 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %760 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %761 : Long(1, strides=[1], device=cpu) = onnx::Slice(%757, %759, %760, %758), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %762 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %763 : Long(device=cpu) = onnx::Squeeze(%761, %762), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %764 : Long(device=cpu) = onnx::Sub(%763, %756), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %765 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %766 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%764, %765), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %767 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %768 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%763, %767), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %769 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %770 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %771 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %772 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.1.attn.bias, %766, %768, %770, %771), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %773 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %774 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %773), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %775 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %776 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%763, %775), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %777 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %778 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %777), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %780 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%772, %774, %776, %778, %779), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %781 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%780), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %782 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.1.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %783 : Float(*, *, *, *, device=cpu) = onnx::Where(%781, %749, %782), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %784 : Float(*, *, *, *, device=cpu) = onnx::Add(%783, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %785 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%784), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %786 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%785, %745), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %787 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%786), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %788 : Long(4, strides=[1], device=cpu) = onnx::Shape(%787), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %789 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %790 : Long(device=cpu) = onnx::Gather[axis=0](%788, %789), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %791 : Long(4, strides=[1], device=cpu) = onnx::Shape(%787), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %792 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn\n",
      "      %793 : Long(device=cpu) = onnx::Gather[axis=0](%791, %792), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %794 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %795 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%790, %794)\n",
      "      %796 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %797 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%793, %796)\n",
      "      %798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %799 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %798)\n",
      "      %800 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%795, %797, %799)\n",
      "      %801 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%787, %800), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %802 : Long(3, strides=[1], device=cpu) = onnx::Shape(%801), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %803 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %804 : Long(device=cpu) = onnx::Gather[axis=0](%802, %803), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %805 : Long(3, strides=[1], device=cpu) = onnx::Shape(%801), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %806 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %807 : Long(device=cpu) = onnx::Gather[axis=0](%805, %806), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %808 : Long(3, strides=[1], device=cpu) = onnx::Shape(%801), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %810 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %812 : Long(1, strides=[1], device=cpu) = onnx::Slice(%808, %810, %811, %809), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj\n",
      "      %814 : Long(device=cpu) = onnx::Squeeze(%812, %813), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %816 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %815)\n",
      "      %817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %818 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%814, %817)\n",
      "      %819 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%816, %818)\n",
      "      %820 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%801, %819), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %821 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%820, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %822 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %823 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%804, %822)\n",
      "      %824 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %825 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%807, %824)\n",
      "      %826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %827 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %826)\n",
      "      %828 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%823, %825, %827)\n",
      "      %829 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%821, %828), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.attn/__module.decoder.transformer.h.1.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %830 : Float(*, *, *, device=cpu) = onnx::Add(%829, %651), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %831 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%830), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %832 : Float(*, *, *, device=cpu) = onnx::Sub(%830, %831), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %833 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %834 : Float(*, *, *, device=cpu) = onnx::Pow(%832, %833), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %835 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%834), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %836 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %837 : Float(*, *, device=cpu) = onnx::Add(%835, %836), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %838 : Float(*, *, device=cpu) = onnx::Sqrt(%837), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %839 : Float(*, *, *, device=cpu) = onnx::Div(%832, %838), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %840 : Float(*, *, *, device=cpu) = onnx::Mul(%839, %decoder_no_past.decoder.transformer.h.1.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2\n",
      "      %841 : Float(*, *, *, device=cpu) = onnx::Add(%840, %decoder_no_past.decoder.transformer.h.1.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %842 : Long(3, strides=[1], device=cpu) = onnx::Shape(%841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %843 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %844 : Long(device=cpu) = onnx::Gather[axis=0](%842, %843), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %845 : Long(3, strides=[1], device=cpu) = onnx::Shape(%841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %846 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %847 : Long(device=cpu) = onnx::Gather[axis=0](%845, %846), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %848 : Long(3, strides=[1], device=cpu) = onnx::Shape(%841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %850 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %852 : Long(1, strides=[1], device=cpu) = onnx::Slice(%848, %850, %851, %849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc\n",
      "      %854 : Long(device=cpu) = onnx::Squeeze(%852, %853), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %856 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %855)\n",
      "      %857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %858 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%854, %857)\n",
      "      %859 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%856, %858)\n",
      "      %860 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%841, %859), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %861 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%860, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %863 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%844, %862)\n",
      "      %864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %865 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%847, %864)\n",
      "      %866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %867 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %866)\n",
      "      %868 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%863, %865, %867)\n",
      "      %869 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%861, %868), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %870 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %871 : Float(*, *, *, device=cpu) = onnx::Mul(%869, %870)\n",
      "      %872 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %873 : Float(*, *, *, device=cpu) = onnx::Pow(%869, %872), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %874 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %875 : Float(*, *, *, device=cpu) = onnx::Mul(%873, %874)\n",
      "      %876 : Float(*, *, *, device=cpu) = onnx::Add(%869, %875), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %877 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %878 : Float(*, *, *, device=cpu) = onnx::Mul(%876, %877)\n",
      "      %879 : Float(*, *, *, device=cpu) = onnx::Tanh(%878), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %880 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %881 : Float(*, *, *, device=cpu) = onnx::Add(%879, %880)\n",
      "      %882 : Float(*, *, *, device=cpu) = onnx::Mul(%871, %881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %883 : Long(3, strides=[1], device=cpu) = onnx::Shape(%882), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %884 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %885 : Long(device=cpu) = onnx::Gather[axis=0](%883, %884), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %886 : Long(3, strides=[1], device=cpu) = onnx::Shape(%882), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %887 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %888 : Long(device=cpu) = onnx::Gather[axis=0](%886, %887), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %889 : Long(3, strides=[1], device=cpu) = onnx::Shape(%882), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %892 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %893 : Long(1, strides=[1], device=cpu) = onnx::Slice(%889, %891, %892, %890), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %894 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj\n",
      "      %895 : Long(device=cpu) = onnx::Squeeze(%893, %894), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %896 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %897 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %896)\n",
      "      %898 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %899 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%895, %898)\n",
      "      %900 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%897, %899)\n",
      "      %901 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%882, %900), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %902 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%901, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %903 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %904 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%885, %903)\n",
      "      %905 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %906 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%888, %905)\n",
      "      %907 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %908 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %907)\n",
      "      %909 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%904, %906, %908)\n",
      "      %910 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%902, %909), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1/__module.decoder.transformer.h.1.mlp/__module.decoder.transformer.h.1.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %911 : Float(*, *, *, device=cpu) = onnx::Add(%830, %910), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %912 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%911), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %913 : Float(*, *, *, device=cpu) = onnx::Sub(%911, %912), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %914 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %915 : Float(*, *, *, device=cpu) = onnx::Pow(%913, %914), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %916 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%915), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %917 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %918 : Float(*, *, device=cpu) = onnx::Add(%916, %917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %919 : Float(*, *, device=cpu) = onnx::Sqrt(%918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %920 : Float(*, *, *, device=cpu) = onnx::Div(%913, %919), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %921 : Float(*, *, *, device=cpu) = onnx::Mul(%920, %decoder_no_past.decoder.transformer.h.2.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1\n",
      "      %922 : Float(*, *, *, device=cpu) = onnx::Add(%921, %decoder_no_past.decoder.transformer.h.2.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %923 : Long(3, strides=[1], device=cpu) = onnx::Shape(%922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %924 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %925 : Long(device=cpu) = onnx::Gather[axis=0](%923, %924), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %926 : Long(3, strides=[1], device=cpu) = onnx::Shape(%922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %927 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %928 : Long(device=cpu) = onnx::Gather[axis=0](%926, %927), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %929 : Long(3, strides=[1], device=cpu) = onnx::Shape(%922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %933 : Long(1, strides=[1], device=cpu) = onnx::Slice(%929, %931, %932, %930), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn\n",
      "      %935 : Long(device=cpu) = onnx::Squeeze(%933, %934), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %936 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %937 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %936)\n",
      "      %938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %939 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%935, %938)\n",
      "      %940 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%937, %939)\n",
      "      %941 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%922, %940), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %942 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%941, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%925, %943)\n",
      "      %945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %946 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%928, %945)\n",
      "      %947 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %948 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %947)\n",
      "      %949 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%944, %946, %948)\n",
      "      %950 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%942, %949), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %951 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %952 : Float(*, *, *, device=cpu), %953 : Float(*, *, *, device=cpu), %954 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%950, %951), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %955 : Long(3, strides=[1], device=cpu) = onnx::Shape(%952), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %956 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %957 : Long(device=cpu) = onnx::Gather[axis=0](%955, %956), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %958 : Long(3, strides=[1], device=cpu) = onnx::Shape(%952), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %959 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %960 : Long(device=cpu) = onnx::Gather[axis=0](%958, %959), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %961 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %962 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%957, %961)\n",
      "      %963 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %964 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%960, %963)\n",
      "      %965 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %966 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %965)\n",
      "      %967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %968 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %967)\n",
      "      %969 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%962, %964, %966, %968)\n",
      "      %970 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%952, %969), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %971 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%970), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %972 : Long(3, strides=[1], device=cpu) = onnx::Shape(%953), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %973 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %974 : Long(device=cpu) = onnx::Gather[axis=0](%972, %973), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %975 : Long(3, strides=[1], device=cpu) = onnx::Shape(%953), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %976 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %977 : Long(device=cpu) = onnx::Gather[axis=0](%975, %976), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %979 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%974, %978)\n",
      "      %980 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %981 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%977, %980)\n",
      "      %982 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %983 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %982)\n",
      "      %984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %985 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %984)\n",
      "      %986 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%979, %981, %983, %985)\n",
      "      %987 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%953, %986), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %988 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%987), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %989 : Long(3, strides=[1], device=cpu) = onnx::Shape(%954), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %990 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %991 : Long(device=cpu) = onnx::Gather[axis=0](%989, %990), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %992 : Long(3, strides=[1], device=cpu) = onnx::Shape(%954), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %993 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %994 : Long(device=cpu) = onnx::Gather[axis=0](%992, %993), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %995 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %996 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%991, %995)\n",
      "      %997 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %998 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%994, %997)\n",
      "      %999 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1000 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %999)\n",
      "      %1001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1002 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1001)\n",
      "      %1003 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%996, %998, %1000, %1002)\n",
      "      %1004 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%954, %1003), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1005 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1004), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1006 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%987), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1007 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%971, %1006), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1008 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1009 : Float(*, *, *, *, device=cpu) = onnx::Div(%1007, %1008)\n",
      "      %1010 : Long(4, strides=[1], device=cpu) = onnx::Shape(%971), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1011 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1012 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1013 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1014 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1010, %1012, %1013, %1011), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1015 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1016 : Long(device=cpu) = onnx::Squeeze(%1014, %1015), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1017 : Long(4, strides=[1], device=cpu) = onnx::Shape(%988), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1019 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1021 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1017, %1019, %1020, %1018), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1023 : Long(device=cpu) = onnx::Squeeze(%1021, %1022), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1024 : Long(device=cpu) = onnx::Sub(%1023, %1016), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1026 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1024, %1025), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1028 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1023, %1027), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1029 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1030 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %1029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1032 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.2.attn.bias, %1026, %1028, %1030, %1031), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1033 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1034 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %1033), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1036 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1023, %1035), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1037 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1038 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %1037), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1039 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1040 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1032, %1034, %1036, %1038, %1039), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1041 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1040), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1042 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.2.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1043 : Float(*, *, *, *, device=cpu) = onnx::Where(%1041, %1009, %1042), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1044 : Float(*, *, *, *, device=cpu) = onnx::Add(%1043, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1045 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1044), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1046 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1045, %1005), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1047 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1046), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1048 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1047), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1049 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1050 : Long(device=cpu) = onnx::Gather[axis=0](%1048, %1049), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1051 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1047), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1052 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn\n",
      "      %1053 : Long(device=cpu) = onnx::Gather[axis=0](%1051, %1052), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1054 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1055 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1050, %1054)\n",
      "      %1056 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1057 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1053, %1056)\n",
      "      %1058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1059 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1058)\n",
      "      %1060 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1055, %1057, %1059)\n",
      "      %1061 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1047, %1060), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1062 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1061), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1063 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1064 : Long(device=cpu) = onnx::Gather[axis=0](%1062, %1063), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1065 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1061), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1066 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1067 : Long(device=cpu) = onnx::Gather[axis=0](%1065, %1066), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1068 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1061), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1070 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1072 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1068, %1070, %1071, %1069), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj\n",
      "      %1074 : Long(device=cpu) = onnx::Squeeze(%1072, %1073), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1076 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1075)\n",
      "      %1077 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1078 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1074, %1077)\n",
      "      %1079 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1076, %1078)\n",
      "      %1080 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1061, %1079), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1081 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1080, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1082 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1083 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1064, %1082)\n",
      "      %1084 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1085 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1067, %1084)\n",
      "      %1086 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1087 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1086)\n",
      "      %1088 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1083, %1085, %1087)\n",
      "      %1089 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1081, %1088), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.attn/__module.decoder.transformer.h.2.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1090 : Float(*, *, *, device=cpu) = onnx::Add(%1089, %911), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1091 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1090), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1092 : Float(*, *, *, device=cpu) = onnx::Sub(%1090, %1091), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1093 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1094 : Float(*, *, *, device=cpu) = onnx::Pow(%1092, %1093), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1095 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1094), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1096 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1097 : Float(*, *, device=cpu) = onnx::Add(%1095, %1096), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1098 : Float(*, *, device=cpu) = onnx::Sqrt(%1097), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1099 : Float(*, *, *, device=cpu) = onnx::Div(%1092, %1098), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1100 : Float(*, *, *, device=cpu) = onnx::Mul(%1099, %decoder_no_past.decoder.transformer.h.2.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2\n",
      "      %1101 : Float(*, *, *, device=cpu) = onnx::Add(%1100, %decoder_no_past.decoder.transformer.h.2.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1102 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1103 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1104 : Long(device=cpu) = onnx::Gather[axis=0](%1102, %1103), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1105 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1106 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1107 : Long(device=cpu) = onnx::Gather[axis=0](%1105, %1106), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1108 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1110 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1112 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1108, %1110, %1111, %1109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc\n",
      "      %1114 : Long(device=cpu) = onnx::Squeeze(%1112, %1113), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1115 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1116 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1115)\n",
      "      %1117 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1118 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1114, %1117)\n",
      "      %1119 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1116, %1118)\n",
      "      %1120 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1101, %1119), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1121 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1120, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1123 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1104, %1122)\n",
      "      %1124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1125 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1107, %1124)\n",
      "      %1126 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1127 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1126)\n",
      "      %1128 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1123, %1125, %1127)\n",
      "      %1129 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1121, %1128), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1130 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1131 : Float(*, *, *, device=cpu) = onnx::Mul(%1129, %1130)\n",
      "      %1132 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1133 : Float(*, *, *, device=cpu) = onnx::Pow(%1129, %1132), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1134 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1135 : Float(*, *, *, device=cpu) = onnx::Mul(%1133, %1134)\n",
      "      %1136 : Float(*, *, *, device=cpu) = onnx::Add(%1129, %1135), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1137 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1138 : Float(*, *, *, device=cpu) = onnx::Mul(%1136, %1137)\n",
      "      %1139 : Float(*, *, *, device=cpu) = onnx::Tanh(%1138), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1140 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1141 : Float(*, *, *, device=cpu) = onnx::Add(%1139, %1140)\n",
      "      %1142 : Float(*, *, *, device=cpu) = onnx::Mul(%1131, %1141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1143 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1142), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1144 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1145 : Long(device=cpu) = onnx::Gather[axis=0](%1143, %1144), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1146 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1142), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1147 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1148 : Long(device=cpu) = onnx::Gather[axis=0](%1146, %1147), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1149 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1142), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1153 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1149, %1151, %1152, %1150), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1154 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj\n",
      "      %1155 : Long(device=cpu) = onnx::Squeeze(%1153, %1154), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1156 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1157 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1156)\n",
      "      %1158 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1159 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1155, %1158)\n",
      "      %1160 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1157, %1159)\n",
      "      %1161 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1142, %1160), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1162 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1161, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1163 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1164 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1145, %1163)\n",
      "      %1165 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1166 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1148, %1165)\n",
      "      %1167 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1168 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1167)\n",
      "      %1169 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1164, %1166, %1168)\n",
      "      %1170 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1162, %1169), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2/__module.decoder.transformer.h.2.mlp/__module.decoder.transformer.h.2.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1171 : Float(*, *, *, device=cpu) = onnx::Add(%1090, %1170), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1172 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1171), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1173 : Float(*, *, *, device=cpu) = onnx::Sub(%1171, %1172), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1174 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1175 : Float(*, *, *, device=cpu) = onnx::Pow(%1173, %1174), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1176 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1175), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1177 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1178 : Float(*, *, device=cpu) = onnx::Add(%1176, %1177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1179 : Float(*, *, device=cpu) = onnx::Sqrt(%1178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1180 : Float(*, *, *, device=cpu) = onnx::Div(%1173, %1179), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1181 : Float(*, *, *, device=cpu) = onnx::Mul(%1180, %decoder_no_past.decoder.transformer.h.3.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1\n",
      "      %1182 : Float(*, *, *, device=cpu) = onnx::Add(%1181, %decoder_no_past.decoder.transformer.h.3.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1183 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1184 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1185 : Long(device=cpu) = onnx::Gather[axis=0](%1183, %1184), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1186 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1187 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1188 : Long(device=cpu) = onnx::Gather[axis=0](%1186, %1187), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1189 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1190 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1192 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1193 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1189, %1191, %1192, %1190), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1194 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn\n",
      "      %1195 : Long(device=cpu) = onnx::Squeeze(%1193, %1194), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1196 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1197 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1196)\n",
      "      %1198 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1199 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1195, %1198)\n",
      "      %1200 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1197, %1199)\n",
      "      %1201 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1182, %1200), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1202 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1201, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1185, %1203)\n",
      "      %1205 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1206 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1188, %1205)\n",
      "      %1207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1208 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %1207)\n",
      "      %1209 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1204, %1206, %1208)\n",
      "      %1210 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1202, %1209), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1211 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1212 : Float(*, *, *, device=cpu), %1213 : Float(*, *, *, device=cpu), %1214 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1210, %1211), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1215 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1212), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1216 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1217 : Long(device=cpu) = onnx::Gather[axis=0](%1215, %1216), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1218 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1212), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1219 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1220 : Long(device=cpu) = onnx::Gather[axis=0](%1218, %1219), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1221 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1222 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1217, %1221)\n",
      "      %1223 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1224 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1220, %1223)\n",
      "      %1225 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1226 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1225)\n",
      "      %1227 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1228 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1227)\n",
      "      %1229 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1222, %1224, %1226, %1228)\n",
      "      %1230 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1212, %1229), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1231 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1230), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1232 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1213), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1233 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1234 : Long(device=cpu) = onnx::Gather[axis=0](%1232, %1233), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1235 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1213), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1236 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1237 : Long(device=cpu) = onnx::Gather[axis=0](%1235, %1236), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1239 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1234, %1238)\n",
      "      %1240 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1241 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1237, %1240)\n",
      "      %1242 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1243 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1242)\n",
      "      %1244 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1245 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1244)\n",
      "      %1246 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1239, %1241, %1243, %1245)\n",
      "      %1247 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1213, %1246), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1248 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1247), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1249 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1214), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1250 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1251 : Long(device=cpu) = onnx::Gather[axis=0](%1249, %1250), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1252 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1214), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1253 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1254 : Long(device=cpu) = onnx::Gather[axis=0](%1252, %1253), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1255 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1256 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1251, %1255)\n",
      "      %1257 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1258 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1254, %1257)\n",
      "      %1259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1260 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1259)\n",
      "      %1261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1262 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1261)\n",
      "      %1263 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1256, %1258, %1260, %1262)\n",
      "      %1264 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1214, %1263), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1265 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1264), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1266 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1247), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1267 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1231, %1266), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1268 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1269 : Float(*, *, *, *, device=cpu) = onnx::Div(%1267, %1268)\n",
      "      %1270 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1231), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1272 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1273 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1274 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1270, %1272, %1273, %1271), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1275 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1276 : Long(device=cpu) = onnx::Squeeze(%1274, %1275), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1277 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1248), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1279 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1280 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1281 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1277, %1279, %1280, %1278), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1282 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1283 : Long(device=cpu) = onnx::Squeeze(%1281, %1282), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1284 : Long(device=cpu) = onnx::Sub(%1283, %1276), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1285 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1286 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1284, %1285), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1288 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1283, %1287), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1289 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1290 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %1289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1291 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1292 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.3.attn.bias, %1286, %1288, %1290, %1291), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1293 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1294 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %1293), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1296 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1283, %1295), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1298 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %1297), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1300 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1292, %1294, %1296, %1298, %1299), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1301 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1300), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1302 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.3.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1303 : Float(*, *, *, *, device=cpu) = onnx::Where(%1301, %1269, %1302), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1304 : Float(*, *, *, *, device=cpu) = onnx::Add(%1303, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1305 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1304), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1306 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1305, %1265), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1307 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1306), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1308 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1307), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1309 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1310 : Long(device=cpu) = onnx::Gather[axis=0](%1308, %1309), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1311 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1307), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1312 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn\n",
      "      %1313 : Long(device=cpu) = onnx::Gather[axis=0](%1311, %1312), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1314 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1315 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1310, %1314)\n",
      "      %1316 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1317 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1313, %1316)\n",
      "      %1318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1319 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1318)\n",
      "      %1320 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1315, %1317, %1319)\n",
      "      %1321 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1307, %1320), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1322 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1321), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1323 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1324 : Long(device=cpu) = onnx::Gather[axis=0](%1322, %1323), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1325 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1321), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1326 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1327 : Long(device=cpu) = onnx::Gather[axis=0](%1325, %1326), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1328 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1321), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1330 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1332 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1328, %1330, %1331, %1329), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj\n",
      "      %1334 : Long(device=cpu) = onnx::Squeeze(%1332, %1333), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1336 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1335)\n",
      "      %1337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1334, %1337)\n",
      "      %1339 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1336, %1338)\n",
      "      %1340 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1321, %1339), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1341 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1340, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1324, %1342)\n",
      "      %1344 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1345 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1327, %1344)\n",
      "      %1346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1347 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1346)\n",
      "      %1348 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1343, %1345, %1347)\n",
      "      %1349 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1341, %1348), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.attn/__module.decoder.transformer.h.3.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1350 : Float(*, *, *, device=cpu) = onnx::Add(%1349, %1171), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1351 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1350), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1352 : Float(*, *, *, device=cpu) = onnx::Sub(%1350, %1351), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1353 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1354 : Float(*, *, *, device=cpu) = onnx::Pow(%1352, %1353), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1355 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1354), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1356 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1357 : Float(*, *, device=cpu) = onnx::Add(%1355, %1356), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1358 : Float(*, *, device=cpu) = onnx::Sqrt(%1357), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1359 : Float(*, *, *, device=cpu) = onnx::Div(%1352, %1358), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1360 : Float(*, *, *, device=cpu) = onnx::Mul(%1359, %decoder_no_past.decoder.transformer.h.3.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2\n",
      "      %1361 : Float(*, *, *, device=cpu) = onnx::Add(%1360, %decoder_no_past.decoder.transformer.h.3.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1362 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1363 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1364 : Long(device=cpu) = onnx::Gather[axis=0](%1362, %1363), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1365 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1366 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1367 : Long(device=cpu) = onnx::Gather[axis=0](%1365, %1366), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1368 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1370 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1372 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1368, %1370, %1371, %1369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc\n",
      "      %1374 : Long(device=cpu) = onnx::Squeeze(%1372, %1373), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1376 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1375)\n",
      "      %1377 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1378 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1374, %1377)\n",
      "      %1379 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1376, %1378)\n",
      "      %1380 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1361, %1379), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1381 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1380, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1383 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1364, %1382)\n",
      "      %1384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1385 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1367, %1384)\n",
      "      %1386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1387 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1386)\n",
      "      %1388 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1383, %1385, %1387)\n",
      "      %1389 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1381, %1388), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1390 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1391 : Float(*, *, *, device=cpu) = onnx::Mul(%1389, %1390)\n",
      "      %1392 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1393 : Float(*, *, *, device=cpu) = onnx::Pow(%1389, %1392), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1394 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1395 : Float(*, *, *, device=cpu) = onnx::Mul(%1393, %1394)\n",
      "      %1396 : Float(*, *, *, device=cpu) = onnx::Add(%1389, %1395), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1397 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1398 : Float(*, *, *, device=cpu) = onnx::Mul(%1396, %1397)\n",
      "      %1399 : Float(*, *, *, device=cpu) = onnx::Tanh(%1398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1400 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1401 : Float(*, *, *, device=cpu) = onnx::Add(%1399, %1400)\n",
      "      %1402 : Float(*, *, *, device=cpu) = onnx::Mul(%1391, %1401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1403 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1404 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1405 : Long(device=cpu) = onnx::Gather[axis=0](%1403, %1404), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1406 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1407 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1408 : Long(device=cpu) = onnx::Gather[axis=0](%1406, %1407), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1409 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1402), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1413 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1409, %1411, %1412, %1410), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1414 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj\n",
      "      %1415 : Long(device=cpu) = onnx::Squeeze(%1413, %1414), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1416 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1417 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1416)\n",
      "      %1418 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1419 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1415, %1418)\n",
      "      %1420 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1417, %1419)\n",
      "      %1421 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1402, %1420), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1422 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1421, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1423 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1424 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1405, %1423)\n",
      "      %1425 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1426 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1408, %1425)\n",
      "      %1427 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1428 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1427)\n",
      "      %1429 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1424, %1426, %1428)\n",
      "      %1430 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1422, %1429), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3/__module.decoder.transformer.h.3.mlp/__module.decoder.transformer.h.3.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1431 : Float(*, *, *, device=cpu) = onnx::Add(%1350, %1430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.3 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1432 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1433 : Float(*, *, *, device=cpu) = onnx::Sub(%1431, %1432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1434 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1435 : Float(*, *, *, device=cpu) = onnx::Pow(%1433, %1434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1436 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1435), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1437 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1438 : Float(*, *, device=cpu) = onnx::Add(%1436, %1437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1439 : Float(*, *, device=cpu) = onnx::Sqrt(%1438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1440 : Float(*, *, *, device=cpu) = onnx::Div(%1433, %1439), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1441 : Float(*, *, *, device=cpu) = onnx::Mul(%1440, %decoder_no_past.decoder.transformer.h.4.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1\n",
      "      %1442 : Float(*, *, *, device=cpu) = onnx::Add(%1441, %decoder_no_past.decoder.transformer.h.4.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1443 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1444 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1445 : Long(device=cpu) = onnx::Gather[axis=0](%1443, %1444), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1446 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1447 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1448 : Long(device=cpu) = onnx::Gather[axis=0](%1446, %1447), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1449 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1450 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1452 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1453 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1449, %1451, %1452, %1450), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn\n",
      "      %1455 : Long(device=cpu) = onnx::Squeeze(%1453, %1454), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1456 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1457 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1456)\n",
      "      %1458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1455, %1458)\n",
      "      %1460 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1457, %1459)\n",
      "      %1461 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1442, %1460), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1462 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1461, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1464 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1445, %1463)\n",
      "      %1465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1466 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1448, %1465)\n",
      "      %1467 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1468 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %1467)\n",
      "      %1469 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1464, %1466, %1468)\n",
      "      %1470 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1462, %1469), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1471 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1472 : Float(*, *, *, device=cpu), %1473 : Float(*, *, *, device=cpu), %1474 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1470, %1471), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1475 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1472), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1476 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1477 : Long(device=cpu) = onnx::Gather[axis=0](%1475, %1476), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1478 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1472), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1479 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1480 : Long(device=cpu) = onnx::Gather[axis=0](%1478, %1479), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1481 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1482 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1477, %1481)\n",
      "      %1483 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1484 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1480, %1483)\n",
      "      %1485 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1486 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1485)\n",
      "      %1487 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1488 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1487)\n",
      "      %1489 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1482, %1484, %1486, %1488)\n",
      "      %1490 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1472, %1489), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1491 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1490), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1492 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1473), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1493 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1494 : Long(device=cpu) = onnx::Gather[axis=0](%1492, %1493), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1495 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1473), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1496 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1497 : Long(device=cpu) = onnx::Gather[axis=0](%1495, %1496), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1499 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1494, %1498)\n",
      "      %1500 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1501 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1497, %1500)\n",
      "      %1502 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1503 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1502)\n",
      "      %1504 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1505 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1504)\n",
      "      %1506 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1499, %1501, %1503, %1505)\n",
      "      %1507 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1473, %1506), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1508 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1509 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1474), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1510 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1511 : Long(device=cpu) = onnx::Gather[axis=0](%1509, %1510), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1512 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1474), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1513 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1514 : Long(device=cpu) = onnx::Gather[axis=0](%1512, %1513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1515 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1516 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1511, %1515)\n",
      "      %1517 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1518 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1514, %1517)\n",
      "      %1519 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1520 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1519)\n",
      "      %1521 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1522 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1521)\n",
      "      %1523 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1516, %1518, %1520, %1522)\n",
      "      %1524 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1474, %1523), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1525 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1524), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1526 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1507), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1527 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1491, %1526), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1528 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1529 : Float(*, *, *, *, device=cpu) = onnx::Div(%1527, %1528)\n",
      "      %1530 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1491), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1531 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1532 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1533 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1534 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1530, %1532, %1533, %1531), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1535 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1536 : Long(device=cpu) = onnx::Squeeze(%1534, %1535), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1537 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1508), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1539 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1541 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1537, %1539, %1540, %1538), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1542 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1543 : Long(device=cpu) = onnx::Squeeze(%1541, %1542), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1544 : Long(device=cpu) = onnx::Sub(%1543, %1536), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1545 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1546 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1544, %1545), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1547 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1548 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1543, %1547), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1549 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1550 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %1549), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1551 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1552 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.4.attn.bias, %1546, %1548, %1550, %1551), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1553 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1554 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %1553), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1556 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1543, %1555), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1558 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %1557), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1560 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1552, %1554, %1556, %1558, %1559), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1561 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1560), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1562 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.4.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1563 : Float(*, *, *, *, device=cpu) = onnx::Where(%1561, %1529, %1562), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1564 : Float(*, *, *, *, device=cpu) = onnx::Add(%1563, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1565 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1564), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1566 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1565, %1525), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1567 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1566), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1568 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1567), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1569 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1570 : Long(device=cpu) = onnx::Gather[axis=0](%1568, %1569), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1571 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1567), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1572 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn\n",
      "      %1573 : Long(device=cpu) = onnx::Gather[axis=0](%1571, %1572), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1574 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1575 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1570, %1574)\n",
      "      %1576 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1577 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1573, %1576)\n",
      "      %1578 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1579 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1578)\n",
      "      %1580 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1575, %1577, %1579)\n",
      "      %1581 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1567, %1580), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1582 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1583 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1584 : Long(device=cpu) = onnx::Gather[axis=0](%1582, %1583), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1585 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1586 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1587 : Long(device=cpu) = onnx::Gather[axis=0](%1585, %1586), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1588 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1581), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1592 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1588, %1590, %1591, %1589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj\n",
      "      %1594 : Long(device=cpu) = onnx::Squeeze(%1592, %1593), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1596 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1595)\n",
      "      %1597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1598 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1594, %1597)\n",
      "      %1599 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1596, %1598)\n",
      "      %1600 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1581, %1599), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1601 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1600, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1602 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1603 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1584, %1602)\n",
      "      %1604 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1605 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1587, %1604)\n",
      "      %1606 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1607 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1606)\n",
      "      %1608 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1603, %1605, %1607)\n",
      "      %1609 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1601, %1608), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.attn/__module.decoder.transformer.h.4.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1610 : Float(*, *, *, device=cpu) = onnx::Add(%1609, %1431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1611 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1610), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1612 : Float(*, *, *, device=cpu) = onnx::Sub(%1610, %1611), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1613 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1614 : Float(*, *, *, device=cpu) = onnx::Pow(%1612, %1613), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1615 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1614), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1616 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1617 : Float(*, *, device=cpu) = onnx::Add(%1615, %1616), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1618 : Float(*, *, device=cpu) = onnx::Sqrt(%1617), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1619 : Float(*, *, *, device=cpu) = onnx::Div(%1612, %1618), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1620 : Float(*, *, *, device=cpu) = onnx::Mul(%1619, %decoder_no_past.decoder.transformer.h.4.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2\n",
      "      %1621 : Float(*, *, *, device=cpu) = onnx::Add(%1620, %decoder_no_past.decoder.transformer.h.4.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1622 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1623 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1624 : Long(device=cpu) = onnx::Gather[axis=0](%1622, %1623), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1625 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1626 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1627 : Long(device=cpu) = onnx::Gather[axis=0](%1625, %1626), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1628 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1632 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1628, %1630, %1631, %1629), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc\n",
      "      %1634 : Long(device=cpu) = onnx::Squeeze(%1632, %1633), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1636 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1635)\n",
      "      %1637 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1638 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1634, %1637)\n",
      "      %1639 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1636, %1638)\n",
      "      %1640 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1621, %1639), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1641 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1640, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1642 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1643 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1624, %1642)\n",
      "      %1644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1645 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1627, %1644)\n",
      "      %1646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1647 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1646)\n",
      "      %1648 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1643, %1645, %1647)\n",
      "      %1649 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1641, %1648), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1650 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1651 : Float(*, *, *, device=cpu) = onnx::Mul(%1649, %1650)\n",
      "      %1652 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1653 : Float(*, *, *, device=cpu) = onnx::Pow(%1649, %1652), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1654 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1655 : Float(*, *, *, device=cpu) = onnx::Mul(%1653, %1654)\n",
      "      %1656 : Float(*, *, *, device=cpu) = onnx::Add(%1649, %1655), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1657 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1658 : Float(*, *, *, device=cpu) = onnx::Mul(%1656, %1657)\n",
      "      %1659 : Float(*, *, *, device=cpu) = onnx::Tanh(%1658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1660 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1661 : Float(*, *, *, device=cpu) = onnx::Add(%1659, %1660)\n",
      "      %1662 : Float(*, *, *, device=cpu) = onnx::Mul(%1651, %1661), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1663 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1664 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1665 : Long(device=cpu) = onnx::Gather[axis=0](%1663, %1664), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1666 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1667 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1668 : Long(device=cpu) = onnx::Gather[axis=0](%1666, %1667), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1669 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1662), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1672 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1673 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1669, %1671, %1672, %1670), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1674 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj\n",
      "      %1675 : Long(device=cpu) = onnx::Squeeze(%1673, %1674), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1676 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1677 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1676)\n",
      "      %1678 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1679 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1675, %1678)\n",
      "      %1680 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1677, %1679)\n",
      "      %1681 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1662, %1680), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1682 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1681, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1665, %1683)\n",
      "      %1685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1686 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1668, %1685)\n",
      "      %1687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1688 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1687)\n",
      "      %1689 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1684, %1686, %1688)\n",
      "      %1690 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1682, %1689), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4/__module.decoder.transformer.h.4.mlp/__module.decoder.transformer.h.4.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1691 : Float(*, *, *, device=cpu) = onnx::Add(%1610, %1690), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.4 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1692 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1691), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1693 : Float(*, *, *, device=cpu) = onnx::Sub(%1691, %1692), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1694 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1695 : Float(*, *, *, device=cpu) = onnx::Pow(%1693, %1694), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1696 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1695), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1697 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1698 : Float(*, *, device=cpu) = onnx::Add(%1696, %1697), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1699 : Float(*, *, device=cpu) = onnx::Sqrt(%1698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1700 : Float(*, *, *, device=cpu) = onnx::Div(%1693, %1699), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1701 : Float(*, *, *, device=cpu) = onnx::Mul(%1700, %decoder_no_past.decoder.transformer.h.5.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1\n",
      "      %1702 : Float(*, *, *, device=cpu) = onnx::Add(%1701, %decoder_no_past.decoder.transformer.h.5.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1703 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1704 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1705 : Long(device=cpu) = onnx::Gather[axis=0](%1703, %1704), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1706 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1707 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1708 : Long(device=cpu) = onnx::Gather[axis=0](%1706, %1707), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1709 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1713 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1709, %1711, %1712, %1710), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn\n",
      "      %1715 : Long(device=cpu) = onnx::Squeeze(%1713, %1714), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1716 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1717 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1716)\n",
      "      %1718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1719 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1715, %1718)\n",
      "      %1720 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1717, %1719)\n",
      "      %1721 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1702, %1720), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1722 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1721, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1724 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1705, %1723)\n",
      "      %1725 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1726 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1708, %1725)\n",
      "      %1727 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1728 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %1727)\n",
      "      %1729 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1724, %1726, %1728)\n",
      "      %1730 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1722, %1729), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1731 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1732 : Float(*, *, *, device=cpu), %1733 : Float(*, *, *, device=cpu), %1734 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1730, %1731), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1735 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1732), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1736 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1737 : Long(device=cpu) = onnx::Gather[axis=0](%1735, %1736), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1738 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1732), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1739 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1740 : Long(device=cpu) = onnx::Gather[axis=0](%1738, %1739), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1741 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1742 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1737, %1741)\n",
      "      %1743 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1744 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1740, %1743)\n",
      "      %1745 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1746 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1745)\n",
      "      %1747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1748 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1747)\n",
      "      %1749 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1742, %1744, %1746, %1748)\n",
      "      %1750 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1732, %1749), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1751 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1750), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1752 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1733), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1753 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1754 : Long(device=cpu) = onnx::Gather[axis=0](%1752, %1753), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1755 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1733), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1756 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1757 : Long(device=cpu) = onnx::Gather[axis=0](%1755, %1756), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1758 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1759 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1754, %1758)\n",
      "      %1760 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1761 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1757, %1760)\n",
      "      %1762 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1763 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1762)\n",
      "      %1764 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1765 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1764)\n",
      "      %1766 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1759, %1761, %1763, %1765)\n",
      "      %1767 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1733, %1766), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1768 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1767), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1769 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1734), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1770 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1771 : Long(device=cpu) = onnx::Gather[axis=0](%1769, %1770), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1772 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1734), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1773 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1774 : Long(device=cpu) = onnx::Gather[axis=0](%1772, %1773), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1775 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1776 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1771, %1775)\n",
      "      %1777 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1778 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1774, %1777)\n",
      "      %1779 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1780 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %1779)\n",
      "      %1781 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1782 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %1781)\n",
      "      %1783 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1776, %1778, %1780, %1782)\n",
      "      %1784 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1734, %1783), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %1785 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1784), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %1786 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1767), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1787 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1751, %1786), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %1788 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %1789 : Float(*, *, *, *, device=cpu) = onnx::Div(%1787, %1788)\n",
      "      %1790 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1751), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1791 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1792 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1793 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1794 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1790, %1792, %1793, %1791), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1795 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1796 : Long(device=cpu) = onnx::Squeeze(%1794, %1795), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1797 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1768), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1799 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1800 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1801 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1797, %1799, %1800, %1798), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1802 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1803 : Long(device=cpu) = onnx::Squeeze(%1801, %1802), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %1804 : Long(device=cpu) = onnx::Sub(%1803, %1796), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1805 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1806 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1804, %1805), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1807 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1808 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1803, %1807), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1810 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %1809), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1812 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.5.attn.bias, %1806, %1808, %1810, %1811), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1814 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %1813), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1816 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1803, %1815), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1818 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %1817), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1820 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%1812, %1814, %1816, %1818, %1819), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1821 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%1820), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %1822 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.5.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1823 : Float(*, *, *, *, device=cpu) = onnx::Where(%1821, %1789, %1822), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %1824 : Float(*, *, *, *, device=cpu) = onnx::Add(%1823, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %1825 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%1824), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1826 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%1825, %1785), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %1827 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1826), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %1828 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1827), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1829 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1830 : Long(device=cpu) = onnx::Gather[axis=0](%1828, %1829), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1831 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1827), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1832 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn\n",
      "      %1833 : Long(device=cpu) = onnx::Gather[axis=0](%1831, %1832), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %1834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1835 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1830, %1834)\n",
      "      %1836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1837 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1833, %1836)\n",
      "      %1838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1839 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1838)\n",
      "      %1840 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1835, %1837, %1839)\n",
      "      %1841 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1827, %1840), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %1842 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1843 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1844 : Long(device=cpu) = onnx::Gather[axis=0](%1842, %1843), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1845 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1846 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1847 : Long(device=cpu) = onnx::Gather[axis=0](%1845, %1846), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1848 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1841), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1850 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1852 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1848, %1850, %1851, %1849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj\n",
      "      %1854 : Long(device=cpu) = onnx::Squeeze(%1852, %1853), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1856 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1855)\n",
      "      %1857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1858 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1854, %1857)\n",
      "      %1859 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1856, %1858)\n",
      "      %1860 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1841, %1859), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1861 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1860, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1862 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1863 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1844, %1862)\n",
      "      %1864 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1865 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1847, %1864)\n",
      "      %1866 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1867 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1866)\n",
      "      %1868 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1863, %1865, %1867)\n",
      "      %1869 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1861, %1868), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.attn/__module.decoder.transformer.h.5.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1870 : Float(*, *, *, device=cpu) = onnx::Add(%1869, %1691), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %1871 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1870), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1872 : Float(*, *, *, device=cpu) = onnx::Sub(%1870, %1871), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1873 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1874 : Float(*, *, *, device=cpu) = onnx::Pow(%1872, %1873), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1875 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1874), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1876 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1877 : Float(*, *, device=cpu) = onnx::Add(%1875, %1876), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1878 : Float(*, *, device=cpu) = onnx::Sqrt(%1877), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1879 : Float(*, *, *, device=cpu) = onnx::Div(%1872, %1878), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1880 : Float(*, *, *, device=cpu) = onnx::Mul(%1879, %decoder_no_past.decoder.transformer.h.5.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2\n",
      "      %1881 : Float(*, *, *, device=cpu) = onnx::Add(%1880, %decoder_no_past.decoder.transformer.h.5.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1882 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1883 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1884 : Long(device=cpu) = onnx::Gather[axis=0](%1882, %1883), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1885 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1886 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1887 : Long(device=cpu) = onnx::Gather[axis=0](%1885, %1886), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1888 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1892 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1888, %1890, %1891, %1889), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc\n",
      "      %1894 : Long(device=cpu) = onnx::Squeeze(%1892, %1893), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1896 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1895)\n",
      "      %1897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1898 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1894, %1897)\n",
      "      %1899 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1896, %1898)\n",
      "      %1900 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1881, %1899), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1901 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1900, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1903 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1884, %1902)\n",
      "      %1904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1905 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1887, %1904)\n",
      "      %1906 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1907 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %1906)\n",
      "      %1908 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1903, %1905, %1907)\n",
      "      %1909 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1901, %1908), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1910 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %1911 : Float(*, *, *, device=cpu) = onnx::Mul(%1909, %1910)\n",
      "      %1912 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %1913 : Float(*, *, *, device=cpu) = onnx::Pow(%1909, %1912), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1914 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %1915 : Float(*, *, *, device=cpu) = onnx::Mul(%1913, %1914)\n",
      "      %1916 : Float(*, *, *, device=cpu) = onnx::Add(%1909, %1915), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1917 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %1918 : Float(*, *, *, device=cpu) = onnx::Mul(%1916, %1917)\n",
      "      %1919 : Float(*, *, *, device=cpu) = onnx::Tanh(%1918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1920 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %1921 : Float(*, *, *, device=cpu) = onnx::Add(%1919, %1920)\n",
      "      %1922 : Float(*, *, *, device=cpu) = onnx::Mul(%1911, %1921), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %1923 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1924 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1925 : Long(device=cpu) = onnx::Gather[axis=0](%1923, %1924), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1926 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1927 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1928 : Long(device=cpu) = onnx::Gather[axis=0](%1926, %1927), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1929 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1922), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1932 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1933 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1929, %1931, %1932, %1930), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1934 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj\n",
      "      %1935 : Long(device=cpu) = onnx::Squeeze(%1933, %1934), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1936 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1937 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1936)\n",
      "      %1938 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1939 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1935, %1938)\n",
      "      %1940 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1937, %1939)\n",
      "      %1941 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1922, %1940), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1942 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1941, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1944 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1925, %1943)\n",
      "      %1945 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1946 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1928, %1945)\n",
      "      %1947 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1948 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %1947)\n",
      "      %1949 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1944, %1946, %1948)\n",
      "      %1950 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1942, %1949), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5/__module.decoder.transformer.h.5.mlp/__module.decoder.transformer.h.5.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %1951 : Float(*, *, *, device=cpu) = onnx::Add(%1870, %1950), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.5 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %1952 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1951), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1953 : Float(*, *, *, device=cpu) = onnx::Sub(%1951, %1952), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1954 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %1955 : Float(*, *, *, device=cpu) = onnx::Pow(%1953, %1954), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1956 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%1955), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1957 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %1958 : Float(*, *, device=cpu) = onnx::Add(%1956, %1957), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1959 : Float(*, *, device=cpu) = onnx::Sqrt(%1958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1960 : Float(*, *, *, device=cpu) = onnx::Div(%1953, %1959), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1961 : Float(*, *, *, device=cpu) = onnx::Mul(%1960, %decoder_no_past.decoder.transformer.h.6.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1\n",
      "      %1962 : Float(*, *, *, device=cpu) = onnx::Add(%1961, %decoder_no_past.decoder.transformer.h.6.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %1963 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1964 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1965 : Long(device=cpu) = onnx::Gather[axis=0](%1963, %1964), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1966 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1967 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1968 : Long(device=cpu) = onnx::Gather[axis=0](%1966, %1967), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %1969 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1970 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1973 : Long(1, strides=[1], device=cpu) = onnx::Slice(%1969, %1971, %1972, %1970), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn\n",
      "      %1975 : Long(device=cpu) = onnx::Squeeze(%1973, %1974), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1977 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %1976)\n",
      "      %1978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1979 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1975, %1978)\n",
      "      %1980 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%1977, %1979)\n",
      "      %1981 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%1962, %1980), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1982 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%1981, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %1983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1984 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1965, %1983)\n",
      "      %1985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1986 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1968, %1985)\n",
      "      %1987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %1988 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %1987)\n",
      "      %1989 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1984, %1986, %1988)\n",
      "      %1990 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1982, %1989), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %1991 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1992 : Float(*, *, *, device=cpu), %1993 : Float(*, *, *, device=cpu), %1994 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%1990, %1991), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %1995 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1992), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1996 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1997 : Long(device=cpu) = onnx::Gather[axis=0](%1995, %1996), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %1998 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1992), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %1999 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2000 : Long(device=cpu) = onnx::Gather[axis=0](%1998, %1999), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2002 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%1997, %2001)\n",
      "      %2003 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2004 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2000, %2003)\n",
      "      %2005 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2006 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2005)\n",
      "      %2007 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2008 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2007)\n",
      "      %2009 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2002, %2004, %2006, %2008)\n",
      "      %2010 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1992, %2009), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2011 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2010), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2012 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1993), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2013 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2014 : Long(device=cpu) = onnx::Gather[axis=0](%2012, %2013), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2015 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1993), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2016 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2017 : Long(device=cpu) = onnx::Gather[axis=0](%2015, %2016), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2019 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2014, %2018)\n",
      "      %2020 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2021 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2017, %2020)\n",
      "      %2022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2023 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2022)\n",
      "      %2024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2025 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2024)\n",
      "      %2026 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2019, %2021, %2023, %2025)\n",
      "      %2027 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1993, %2026), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2028 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2027), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2029 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1994), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2030 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2031 : Long(device=cpu) = onnx::Gather[axis=0](%2029, %2030), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2032 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1994), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2033 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2034 : Long(device=cpu) = onnx::Gather[axis=0](%2032, %2033), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2035 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2036 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2031, %2035)\n",
      "      %2037 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2038 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2034, %2037)\n",
      "      %2039 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2040 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2039)\n",
      "      %2041 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2042 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2041)\n",
      "      %2043 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2036, %2038, %2040, %2042)\n",
      "      %2044 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%1994, %2043), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2045 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2044), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2046 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2027), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2047 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2011, %2046), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2048 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2049 : Float(*, *, *, *, device=cpu) = onnx::Div(%2047, %2048)\n",
      "      %2050 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2011), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2051 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2052 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2053 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2054 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2050, %2052, %2053, %2051), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2055 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2056 : Long(device=cpu) = onnx::Squeeze(%2054, %2055), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2057 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2028), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2059 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2061 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2057, %2059, %2060, %2058), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2062 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2063 : Long(device=cpu) = onnx::Squeeze(%2061, %2062), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2064 : Long(device=cpu) = onnx::Sub(%2063, %2056), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2065 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2066 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2064, %2065), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2067 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2068 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2063, %2067), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2070 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %2069), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2072 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.6.attn.bias, %2066, %2068, %2070, %2071), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2073 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2074 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %2073), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2076 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2063, %2075), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2077 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2078 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %2077), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2079 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2080 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2072, %2074, %2076, %2078, %2079), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2081 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2080), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2082 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.6.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2083 : Float(*, *, *, *, device=cpu) = onnx::Where(%2081, %2049, %2082), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2084 : Float(*, *, *, *, device=cpu) = onnx::Add(%2083, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2085 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2084), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2086 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2085, %2045), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2087 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2086), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2088 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2087), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2089 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2090 : Long(device=cpu) = onnx::Gather[axis=0](%2088, %2089), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2091 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2087), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2092 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn\n",
      "      %2093 : Long(device=cpu) = onnx::Gather[axis=0](%2091, %2092), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2094 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2095 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2090, %2094)\n",
      "      %2096 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2097 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2093, %2096)\n",
      "      %2098 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2099 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2098)\n",
      "      %2100 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2095, %2097, %2099)\n",
      "      %2101 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2087, %2100), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2102 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2103 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2104 : Long(device=cpu) = onnx::Gather[axis=0](%2102, %2103), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2105 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2106 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2107 : Long(device=cpu) = onnx::Gather[axis=0](%2105, %2106), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2108 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2101), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2110 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2112 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2108, %2110, %2111, %2109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj\n",
      "      %2114 : Long(device=cpu) = onnx::Squeeze(%2112, %2113), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2115 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2116 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2115)\n",
      "      %2117 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2118 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2114, %2117)\n",
      "      %2119 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2116, %2118)\n",
      "      %2120 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2101, %2119), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2121 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2120, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2122 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2123 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2104, %2122)\n",
      "      %2124 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2125 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2107, %2124)\n",
      "      %2126 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2127 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2126)\n",
      "      %2128 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2123, %2125, %2127)\n",
      "      %2129 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2121, %2128), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.attn/__module.decoder.transformer.h.6.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2130 : Float(*, *, *, device=cpu) = onnx::Add(%2129, %1951), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2131 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2130), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2132 : Float(*, *, *, device=cpu) = onnx::Sub(%2130, %2131), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2133 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2134 : Float(*, *, *, device=cpu) = onnx::Pow(%2132, %2133), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2135 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2134), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2136 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2137 : Float(*, *, device=cpu) = onnx::Add(%2135, %2136), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2138 : Float(*, *, device=cpu) = onnx::Sqrt(%2137), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2139 : Float(*, *, *, device=cpu) = onnx::Div(%2132, %2138), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2140 : Float(*, *, *, device=cpu) = onnx::Mul(%2139, %decoder_no_past.decoder.transformer.h.6.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2\n",
      "      %2141 : Float(*, *, *, device=cpu) = onnx::Add(%2140, %decoder_no_past.decoder.transformer.h.6.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2142 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2143 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2144 : Long(device=cpu) = onnx::Gather[axis=0](%2142, %2143), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2145 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2146 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2147 : Long(device=cpu) = onnx::Gather[axis=0](%2145, %2146), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2148 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2149 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2152 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2148, %2150, %2151, %2149), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc\n",
      "      %2154 : Long(device=cpu) = onnx::Squeeze(%2152, %2153), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2156 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2155)\n",
      "      %2157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2158 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2154, %2157)\n",
      "      %2159 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2156, %2158)\n",
      "      %2160 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2141, %2159), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2161 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2160, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2162 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2163 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2144, %2162)\n",
      "      %2164 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2165 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2147, %2164)\n",
      "      %2166 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2167 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2166)\n",
      "      %2168 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2163, %2165, %2167)\n",
      "      %2169 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2161, %2168), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2170 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2171 : Float(*, *, *, device=cpu) = onnx::Mul(%2169, %2170)\n",
      "      %2172 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2173 : Float(*, *, *, device=cpu) = onnx::Pow(%2169, %2172), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2174 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2175 : Float(*, *, *, device=cpu) = onnx::Mul(%2173, %2174)\n",
      "      %2176 : Float(*, *, *, device=cpu) = onnx::Add(%2169, %2175), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2177 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2178 : Float(*, *, *, device=cpu) = onnx::Mul(%2176, %2177)\n",
      "      %2179 : Float(*, *, *, device=cpu) = onnx::Tanh(%2178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2180 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2181 : Float(*, *, *, device=cpu) = onnx::Add(%2179, %2180)\n",
      "      %2182 : Float(*, *, *, device=cpu) = onnx::Mul(%2171, %2181), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2183 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2184 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2185 : Long(device=cpu) = onnx::Gather[axis=0](%2183, %2184), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2186 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2187 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2188 : Long(device=cpu) = onnx::Gather[axis=0](%2186, %2187), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2189 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2182), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2190 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2192 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2193 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2189, %2191, %2192, %2190), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2194 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj\n",
      "      %2195 : Long(device=cpu) = onnx::Squeeze(%2193, %2194), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2196 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2197 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2196)\n",
      "      %2198 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2199 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2195, %2198)\n",
      "      %2200 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2197, %2199)\n",
      "      %2201 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2182, %2200), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2202 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2201, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2203 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2185, %2203)\n",
      "      %2205 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2206 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2188, %2205)\n",
      "      %2207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2208 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2207)\n",
      "      %2209 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2204, %2206, %2208)\n",
      "      %2210 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2202, %2209), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6/__module.decoder.transformer.h.6.mlp/__module.decoder.transformer.h.6.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2211 : Float(*, *, *, device=cpu) = onnx::Add(%2130, %2210), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.6 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2212 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2211), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2213 : Float(*, *, *, device=cpu) = onnx::Sub(%2211, %2212), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2214 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2215 : Float(*, *, *, device=cpu) = onnx::Pow(%2213, %2214), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2216 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2215), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2217 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2218 : Float(*, *, device=cpu) = onnx::Add(%2216, %2217), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2219 : Float(*, *, device=cpu) = onnx::Sqrt(%2218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2220 : Float(*, *, *, device=cpu) = onnx::Div(%2213, %2219), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2221 : Float(*, *, *, device=cpu) = onnx::Mul(%2220, %decoder_no_past.decoder.transformer.h.7.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1\n",
      "      %2222 : Float(*, *, *, device=cpu) = onnx::Add(%2221, %decoder_no_past.decoder.transformer.h.7.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2223 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2224 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2225 : Long(device=cpu) = onnx::Gather[axis=0](%2223, %2224), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2226 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2227 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2228 : Long(device=cpu) = onnx::Gather[axis=0](%2226, %2227), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2229 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2231 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2233 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2229, %2231, %2232, %2230), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn\n",
      "      %2235 : Long(device=cpu) = onnx::Squeeze(%2233, %2234), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2237 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2236)\n",
      "      %2238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2239 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2235, %2238)\n",
      "      %2240 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2237, %2239)\n",
      "      %2241 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2222, %2240), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2242 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2241, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2244 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2225, %2243)\n",
      "      %2245 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2246 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2228, %2245)\n",
      "      %2247 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2248 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %2247)\n",
      "      %2249 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2244, %2246, %2248)\n",
      "      %2250 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2242, %2249), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2251 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2252 : Float(*, *, *, device=cpu), %2253 : Float(*, *, *, device=cpu), %2254 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2250, %2251), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2255 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2252), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2256 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2257 : Long(device=cpu) = onnx::Gather[axis=0](%2255, %2256), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2258 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2252), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2259 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2260 : Long(device=cpu) = onnx::Gather[axis=0](%2258, %2259), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2261 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2262 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2257, %2261)\n",
      "      %2263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2264 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2260, %2263)\n",
      "      %2265 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2266 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2265)\n",
      "      %2267 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2268 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2267)\n",
      "      %2269 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2262, %2264, %2266, %2268)\n",
      "      %2270 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2252, %2269), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2271 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2270), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2272 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2253), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2273 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2274 : Long(device=cpu) = onnx::Gather[axis=0](%2272, %2273), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2275 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2253), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2276 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2277 : Long(device=cpu) = onnx::Gather[axis=0](%2275, %2276), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2279 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2274, %2278)\n",
      "      %2280 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2281 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2277, %2280)\n",
      "      %2282 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2283 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2282)\n",
      "      %2284 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2285 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2284)\n",
      "      %2286 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2279, %2281, %2283, %2285)\n",
      "      %2287 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2253, %2286), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2288 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2287), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2289 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2254), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2290 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2291 : Long(device=cpu) = onnx::Gather[axis=0](%2289, %2290), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2292 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2254), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2293 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2294 : Long(device=cpu) = onnx::Gather[axis=0](%2292, %2293), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2295 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2296 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2291, %2295)\n",
      "      %2297 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2298 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2294, %2297)\n",
      "      %2299 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2300 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2299)\n",
      "      %2301 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2302 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2301)\n",
      "      %2303 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2296, %2298, %2300, %2302)\n",
      "      %2304 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2254, %2303), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2305 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2304), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2306 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2287), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2307 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2271, %2306), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2308 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2309 : Float(*, *, *, *, device=cpu) = onnx::Div(%2307, %2308)\n",
      "      %2310 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2271), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2311 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2312 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2313 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2314 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2310, %2312, %2313, %2311), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2315 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2316 : Long(device=cpu) = onnx::Squeeze(%2314, %2315), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2317 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2288), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2319 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2321 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2317, %2319, %2320, %2318), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2323 : Long(device=cpu) = onnx::Squeeze(%2321, %2322), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2324 : Long(device=cpu) = onnx::Sub(%2323, %2316), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2325 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2326 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2324, %2325), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2327 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2328 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2323, %2327), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2329 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2330 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %2329), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2331 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2332 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.7.attn.bias, %2326, %2328, %2330, %2331), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2334 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %2333), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2336 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2323, %2335), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %2337), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2340 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2332, %2334, %2336, %2338, %2339), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2341 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2340), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2342 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.7.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2343 : Float(*, *, *, *, device=cpu) = onnx::Where(%2341, %2309, %2342), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2344 : Float(*, *, *, *, device=cpu) = onnx::Add(%2343, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2345 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2344), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2346 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2345, %2305), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2347 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2346), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2348 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2347), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2349 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2350 : Long(device=cpu) = onnx::Gather[axis=0](%2348, %2349), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2351 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2347), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2352 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn\n",
      "      %2353 : Long(device=cpu) = onnx::Gather[axis=0](%2351, %2352), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2354 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2355 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2350, %2354)\n",
      "      %2356 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2357 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2353, %2356)\n",
      "      %2358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2359 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2358)\n",
      "      %2360 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2355, %2357, %2359)\n",
      "      %2361 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2347, %2360), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2362 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2363 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2364 : Long(device=cpu) = onnx::Gather[axis=0](%2362, %2363), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2365 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2366 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2367 : Long(device=cpu) = onnx::Gather[axis=0](%2365, %2366), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2368 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2361), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2370 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2372 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2368, %2370, %2371, %2369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj\n",
      "      %2374 : Long(device=cpu) = onnx::Squeeze(%2372, %2373), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2376 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2375)\n",
      "      %2377 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2378 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2374, %2377)\n",
      "      %2379 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2376, %2378)\n",
      "      %2380 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2361, %2379), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2381 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2380, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2382 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2383 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2364, %2382)\n",
      "      %2384 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2385 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2367, %2384)\n",
      "      %2386 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2387 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2386)\n",
      "      %2388 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2383, %2385, %2387)\n",
      "      %2389 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2381, %2388), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.attn/__module.decoder.transformer.h.7.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2390 : Float(*, *, *, device=cpu) = onnx::Add(%2389, %2211), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2391 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2390), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2392 : Float(*, *, *, device=cpu) = onnx::Sub(%2390, %2391), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2393 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2394 : Float(*, *, *, device=cpu) = onnx::Pow(%2392, %2393), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2395 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2394), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2396 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2397 : Float(*, *, device=cpu) = onnx::Add(%2395, %2396), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2398 : Float(*, *, device=cpu) = onnx::Sqrt(%2397), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2399 : Float(*, *, *, device=cpu) = onnx::Div(%2392, %2398), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2400 : Float(*, *, *, device=cpu) = onnx::Mul(%2399, %decoder_no_past.decoder.transformer.h.7.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2\n",
      "      %2401 : Float(*, *, *, device=cpu) = onnx::Add(%2400, %decoder_no_past.decoder.transformer.h.7.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2402 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2403 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2404 : Long(device=cpu) = onnx::Gather[axis=0](%2402, %2403), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2405 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2406 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2407 : Long(device=cpu) = onnx::Gather[axis=0](%2405, %2406), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2408 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2412 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2408, %2410, %2411, %2409), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2413 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc\n",
      "      %2414 : Long(device=cpu) = onnx::Squeeze(%2412, %2413), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2415 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2416 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2415)\n",
      "      %2417 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2418 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2414, %2417)\n",
      "      %2419 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2416, %2418)\n",
      "      %2420 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2401, %2419), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2421 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2420, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2422 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2423 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2404, %2422)\n",
      "      %2424 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2425 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2407, %2424)\n",
      "      %2426 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2427 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2426)\n",
      "      %2428 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2423, %2425, %2427)\n",
      "      %2429 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2421, %2428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2430 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2431 : Float(*, *, *, device=cpu) = onnx::Mul(%2429, %2430)\n",
      "      %2432 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2433 : Float(*, *, *, device=cpu) = onnx::Pow(%2429, %2432), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2434 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2435 : Float(*, *, *, device=cpu) = onnx::Mul(%2433, %2434)\n",
      "      %2436 : Float(*, *, *, device=cpu) = onnx::Add(%2429, %2435), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2437 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2438 : Float(*, *, *, device=cpu) = onnx::Mul(%2436, %2437)\n",
      "      %2439 : Float(*, *, *, device=cpu) = onnx::Tanh(%2438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2440 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2441 : Float(*, *, *, device=cpu) = onnx::Add(%2439, %2440)\n",
      "      %2442 : Float(*, *, *, device=cpu) = onnx::Mul(%2431, %2441), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2443 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2444 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2445 : Long(device=cpu) = onnx::Gather[axis=0](%2443, %2444), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2446 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2447 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2448 : Long(device=cpu) = onnx::Gather[axis=0](%2446, %2447), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2449 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2442), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2450 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2452 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2453 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2449, %2451, %2452, %2450), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2454 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj\n",
      "      %2455 : Long(device=cpu) = onnx::Squeeze(%2453, %2454), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2456 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2457 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2456)\n",
      "      %2458 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2459 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2455, %2458)\n",
      "      %2460 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2457, %2459)\n",
      "      %2461 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2442, %2460), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2462 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2461, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2463 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2464 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2445, %2463)\n",
      "      %2465 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2466 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2448, %2465)\n",
      "      %2467 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2468 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2467)\n",
      "      %2469 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2464, %2466, %2468)\n",
      "      %2470 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2462, %2469), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7/__module.decoder.transformer.h.7.mlp/__module.decoder.transformer.h.7.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2471 : Float(*, *, *, device=cpu) = onnx::Add(%2390, %2470), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.7 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2472 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2471), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2473 : Float(*, *, *, device=cpu) = onnx::Sub(%2471, %2472), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2474 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2475 : Float(*, *, *, device=cpu) = onnx::Pow(%2473, %2474), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2476 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2475), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2477 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2478 : Float(*, *, device=cpu) = onnx::Add(%2476, %2477), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2479 : Float(*, *, device=cpu) = onnx::Sqrt(%2478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2480 : Float(*, *, *, device=cpu) = onnx::Div(%2473, %2479), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2481 : Float(*, *, *, device=cpu) = onnx::Mul(%2480, %decoder_no_past.decoder.transformer.h.8.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1\n",
      "      %2482 : Float(*, *, *, device=cpu) = onnx::Add(%2481, %decoder_no_past.decoder.transformer.h.8.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2483 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2484 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2485 : Long(device=cpu) = onnx::Gather[axis=0](%2483, %2484), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2486 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2487 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2488 : Long(device=cpu) = onnx::Gather[axis=0](%2486, %2487), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2489 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2493 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2489, %2491, %2492, %2490), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn\n",
      "      %2495 : Long(device=cpu) = onnx::Squeeze(%2493, %2494), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2496 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2497 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2496)\n",
      "      %2498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2499 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2495, %2498)\n",
      "      %2500 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2497, %2499)\n",
      "      %2501 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2482, %2500), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2502 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2501, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2504 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2485, %2503)\n",
      "      %2505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2506 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2488, %2505)\n",
      "      %2507 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2508 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %2507)\n",
      "      %2509 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2504, %2506, %2508)\n",
      "      %2510 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2502, %2509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2511 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2512 : Float(*, *, *, device=cpu), %2513 : Float(*, *, *, device=cpu), %2514 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2510, %2511), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2515 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2512), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2516 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2517 : Long(device=cpu) = onnx::Gather[axis=0](%2515, %2516), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2518 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2512), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2519 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2520 : Long(device=cpu) = onnx::Gather[axis=0](%2518, %2519), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2521 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2522 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2517, %2521)\n",
      "      %2523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2524 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2520, %2523)\n",
      "      %2525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2526 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2525)\n",
      "      %2527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2528 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2527)\n",
      "      %2529 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2522, %2524, %2526, %2528)\n",
      "      %2530 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2512, %2529), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2531 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2530), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2532 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2533 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2534 : Long(device=cpu) = onnx::Gather[axis=0](%2532, %2533), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2535 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2513), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2536 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2537 : Long(device=cpu) = onnx::Gather[axis=0](%2535, %2536), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2538 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2539 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2534, %2538)\n",
      "      %2540 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2541 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2537, %2540)\n",
      "      %2542 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2543 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2542)\n",
      "      %2544 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2545 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2544)\n",
      "      %2546 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2539, %2541, %2543, %2545)\n",
      "      %2547 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2513, %2546), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2548 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2547), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2549 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2514), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2550 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2551 : Long(device=cpu) = onnx::Gather[axis=0](%2549, %2550), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2552 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2514), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2553 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2554 : Long(device=cpu) = onnx::Gather[axis=0](%2552, %2553), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2555 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2556 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2551, %2555)\n",
      "      %2557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2558 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2554, %2557)\n",
      "      %2559 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2560 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2559)\n",
      "      %2561 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2562 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2561)\n",
      "      %2563 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2556, %2558, %2560, %2562)\n",
      "      %2564 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2514, %2563), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2565 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2564), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2566 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2547), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2567 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2531, %2566), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2568 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2569 : Float(*, *, *, *, device=cpu) = onnx::Div(%2567, %2568)\n",
      "      %2570 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2531), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2571 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2572 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2574 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2570, %2572, %2573, %2571), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2575 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2576 : Long(device=cpu) = onnx::Squeeze(%2574, %2575), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2577 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2548), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2578 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2580 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2581 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2577, %2579, %2580, %2578), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2582 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2583 : Long(device=cpu) = onnx::Squeeze(%2581, %2582), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2584 : Long(device=cpu) = onnx::Sub(%2583, %2576), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2585 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2586 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2584, %2585), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2587 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2588 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2583, %2587), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2589 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2590 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %2589), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2592 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.8.attn.bias, %2586, %2588, %2590, %2591), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2593 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2594 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %2593), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2595 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2596 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2583, %2595), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2597 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2598 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %2597), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2599 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2600 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2592, %2594, %2596, %2598, %2599), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2601 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2600), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2602 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.8.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2603 : Float(*, *, *, *, device=cpu) = onnx::Where(%2601, %2569, %2602), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2604 : Float(*, *, *, *, device=cpu) = onnx::Add(%2603, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2605 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2604), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2606 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2605, %2565), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2607 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2606), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2608 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2607), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2609 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2610 : Long(device=cpu) = onnx::Gather[axis=0](%2608, %2609), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2611 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2607), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2612 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn\n",
      "      %2613 : Long(device=cpu) = onnx::Gather[axis=0](%2611, %2612), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2614 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2615 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2610, %2614)\n",
      "      %2616 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2617 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2613, %2616)\n",
      "      %2618 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2619 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2618)\n",
      "      %2620 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2615, %2617, %2619)\n",
      "      %2621 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2607, %2620), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2622 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2623 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2624 : Long(device=cpu) = onnx::Gather[axis=0](%2622, %2623), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2625 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2626 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2627 : Long(device=cpu) = onnx::Gather[axis=0](%2625, %2626), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2628 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2621), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2630 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2632 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2628, %2630, %2631, %2629), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj\n",
      "      %2634 : Long(device=cpu) = onnx::Squeeze(%2632, %2633), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2635 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2636 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2635)\n",
      "      %2637 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2638 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2634, %2637)\n",
      "      %2639 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2636, %2638)\n",
      "      %2640 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2621, %2639), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2641 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2640, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2642 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2643 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2624, %2642)\n",
      "      %2644 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2645 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2627, %2644)\n",
      "      %2646 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2647 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2646)\n",
      "      %2648 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2643, %2645, %2647)\n",
      "      %2649 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2641, %2648), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.attn/__module.decoder.transformer.h.8.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2650 : Float(*, *, *, device=cpu) = onnx::Add(%2649, %2471), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2651 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2650), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2652 : Float(*, *, *, device=cpu) = onnx::Sub(%2650, %2651), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2653 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2654 : Float(*, *, *, device=cpu) = onnx::Pow(%2652, %2653), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2655 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2654), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2656 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2657 : Float(*, *, device=cpu) = onnx::Add(%2655, %2656), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2658 : Float(*, *, device=cpu) = onnx::Sqrt(%2657), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2659 : Float(*, *, *, device=cpu) = onnx::Div(%2652, %2658), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2660 : Float(*, *, *, device=cpu) = onnx::Mul(%2659, %decoder_no_past.decoder.transformer.h.8.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2\n",
      "      %2661 : Float(*, *, *, device=cpu) = onnx::Add(%2660, %decoder_no_past.decoder.transformer.h.8.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2662 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2661), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2663 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2664 : Long(device=cpu) = onnx::Gather[axis=0](%2662, %2663), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2665 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2661), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2666 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2667 : Long(device=cpu) = onnx::Gather[axis=0](%2665, %2666), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2668 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2661), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2669 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2670 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2671 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2672 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2668, %2670, %2671, %2669), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2673 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc\n",
      "      %2674 : Long(device=cpu) = onnx::Squeeze(%2672, %2673), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2675 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2676 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2675)\n",
      "      %2677 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2678 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2674, %2677)\n",
      "      %2679 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2676, %2678)\n",
      "      %2680 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2661, %2679), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2681 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2680, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2683 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2664, %2682)\n",
      "      %2684 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2685 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2667, %2684)\n",
      "      %2686 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2687 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2686)\n",
      "      %2688 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2683, %2685, %2687)\n",
      "      %2689 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2681, %2688), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2691 : Float(*, *, *, device=cpu) = onnx::Mul(%2689, %2690)\n",
      "      %2692 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2693 : Float(*, *, *, device=cpu) = onnx::Pow(%2689, %2692), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2694 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2695 : Float(*, *, *, device=cpu) = onnx::Mul(%2693, %2694)\n",
      "      %2696 : Float(*, *, *, device=cpu) = onnx::Add(%2689, %2695), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2697 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2698 : Float(*, *, *, device=cpu) = onnx::Mul(%2696, %2697)\n",
      "      %2699 : Float(*, *, *, device=cpu) = onnx::Tanh(%2698), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2700 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2701 : Float(*, *, *, device=cpu) = onnx::Add(%2699, %2700)\n",
      "      %2702 : Float(*, *, *, device=cpu) = onnx::Mul(%2691, %2701), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2703 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2704 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2705 : Long(device=cpu) = onnx::Gather[axis=0](%2703, %2704), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2706 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2707 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2708 : Long(device=cpu) = onnx::Gather[axis=0](%2706, %2707), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2709 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2702), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2710 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2713 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2709, %2711, %2712, %2710), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2714 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj\n",
      "      %2715 : Long(device=cpu) = onnx::Squeeze(%2713, %2714), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2716 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2717 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2716)\n",
      "      %2718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2719 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2715, %2718)\n",
      "      %2720 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2717, %2719)\n",
      "      %2721 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2702, %2720), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2722 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2721, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2724 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2705, %2723)\n",
      "      %2725 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2726 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2708, %2725)\n",
      "      %2727 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2728 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2727)\n",
      "      %2729 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2724, %2726, %2728)\n",
      "      %2730 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2722, %2729), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8/__module.decoder.transformer.h.8.mlp/__module.decoder.transformer.h.8.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2731 : Float(*, *, *, device=cpu) = onnx::Add(%2650, %2730), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.8 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2732 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2731), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2733 : Float(*, *, *, device=cpu) = onnx::Sub(%2731, %2732), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2734 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2735 : Float(*, *, *, device=cpu) = onnx::Pow(%2733, %2734), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2736 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2735), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2737 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2738 : Float(*, *, device=cpu) = onnx::Add(%2736, %2737), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2739 : Float(*, *, device=cpu) = onnx::Sqrt(%2738), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2740 : Float(*, *, *, device=cpu) = onnx::Div(%2733, %2739), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2741 : Float(*, *, *, device=cpu) = onnx::Mul(%2740, %decoder_no_past.decoder.transformer.h.9.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1\n",
      "      %2742 : Float(*, *, *, device=cpu) = onnx::Add(%2741, %decoder_no_past.decoder.transformer.h.9.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2743 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2742), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2744 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2745 : Long(device=cpu) = onnx::Gather[axis=0](%2743, %2744), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2746 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2742), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2747 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2748 : Long(device=cpu) = onnx::Gather[axis=0](%2746, %2747), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2749 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2742), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2750 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2751 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2752 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2753 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2749, %2751, %2752, %2750), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2754 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn\n",
      "      %2755 : Long(device=cpu) = onnx::Squeeze(%2753, %2754), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2756 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2757 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2756)\n",
      "      %2758 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2759 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2755, %2758)\n",
      "      %2760 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2757, %2759)\n",
      "      %2761 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2742, %2760), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2762 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2761, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2764 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2745, %2763)\n",
      "      %2765 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2766 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2748, %2765)\n",
      "      %2767 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2768 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %2767)\n",
      "      %2769 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2764, %2766, %2768)\n",
      "      %2770 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2762, %2769), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2771 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2772 : Float(*, *, *, device=cpu), %2773 : Float(*, *, *, device=cpu), %2774 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%2770, %2771), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %2775 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2772), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2776 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2777 : Long(device=cpu) = onnx::Gather[axis=0](%2775, %2776), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2778 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2772), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2779 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2780 : Long(device=cpu) = onnx::Gather[axis=0](%2778, %2779), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2781 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2782 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2777, %2781)\n",
      "      %2783 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2784 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2780, %2783)\n",
      "      %2785 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2786 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2785)\n",
      "      %2787 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2788 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2787)\n",
      "      %2789 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2782, %2784, %2786, %2788)\n",
      "      %2790 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2772, %2789), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2791 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2790), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2792 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2773), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2793 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2794 : Long(device=cpu) = onnx::Gather[axis=0](%2792, %2793), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2795 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2773), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2796 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2797 : Long(device=cpu) = onnx::Gather[axis=0](%2795, %2796), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2798 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2799 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2794, %2798)\n",
      "      %2800 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2801 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2797, %2800)\n",
      "      %2802 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2803 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2802)\n",
      "      %2804 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2805 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2804)\n",
      "      %2806 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2799, %2801, %2803, %2805)\n",
      "      %2807 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2773, %2806), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2808 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2807), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2809 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2774), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2810 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2811 : Long(device=cpu) = onnx::Gather[axis=0](%2809, %2810), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2812 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2774), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2813 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2814 : Long(device=cpu) = onnx::Gather[axis=0](%2812, %2813), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %2815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2816 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2811, %2815)\n",
      "      %2817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2818 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2814, %2817)\n",
      "      %2819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2820 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %2819)\n",
      "      %2821 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2822 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %2821)\n",
      "      %2823 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%2816, %2818, %2820, %2822)\n",
      "      %2824 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2774, %2823), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %2825 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2824), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %2826 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%2807), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2827 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2791, %2826), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %2828 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %2829 : Float(*, *, *, *, device=cpu) = onnx::Div(%2827, %2828)\n",
      "      %2830 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2791), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2831 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2833 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2834 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2830, %2832, %2833, %2831), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2835 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2836 : Long(device=cpu) = onnx::Squeeze(%2834, %2835), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2837 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2808), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2839 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2840 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2841 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2837, %2839, %2840, %2838), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2842 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2843 : Long(device=cpu) = onnx::Squeeze(%2841, %2842), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %2844 : Long(device=cpu) = onnx::Sub(%2843, %2836), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2846 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2844, %2845), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2847 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2848 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2843, %2847), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2849 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2850 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %2849), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2851 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2852 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.9.attn.bias, %2846, %2848, %2850, %2851), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2853 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2854 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %2853), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2855 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2856 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2843, %2855), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2857 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2858 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %2857), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2859 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2860 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%2852, %2854, %2856, %2858, %2859), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2861 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%2860), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %2862 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.9.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2863 : Float(*, *, *, *, device=cpu) = onnx::Where(%2861, %2829, %2862), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %2864 : Float(*, *, *, *, device=cpu) = onnx::Add(%2863, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %2865 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%2864), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2866 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%2865, %2825), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %2867 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%2866), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %2868 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2867), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2869 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2870 : Long(device=cpu) = onnx::Gather[axis=0](%2868, %2869), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2871 : Long(4, strides=[1], device=cpu) = onnx::Shape(%2867), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2872 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn\n",
      "      %2873 : Long(device=cpu) = onnx::Gather[axis=0](%2871, %2872), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %2874 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2875 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2870, %2874)\n",
      "      %2876 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2877 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2873, %2876)\n",
      "      %2878 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2879 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2878)\n",
      "      %2880 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2875, %2877, %2879)\n",
      "      %2881 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2867, %2880), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %2882 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2883 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2884 : Long(device=cpu) = onnx::Gather[axis=0](%2882, %2883), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2885 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2886 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2887 : Long(device=cpu) = onnx::Gather[axis=0](%2885, %2886), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2888 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2881), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2889 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2890 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2891 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2892 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2888, %2890, %2891, %2889), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2893 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj\n",
      "      %2894 : Long(device=cpu) = onnx::Squeeze(%2892, %2893), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2895 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2896 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2895)\n",
      "      %2897 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2898 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2894, %2897)\n",
      "      %2899 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2896, %2898)\n",
      "      %2900 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2881, %2899), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2901 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2900, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2902 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2903 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2884, %2902)\n",
      "      %2904 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2905 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2887, %2904)\n",
      "      %2906 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2907 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2906)\n",
      "      %2908 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2903, %2905, %2907)\n",
      "      %2909 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2901, %2908), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.attn/__module.decoder.transformer.h.9.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2910 : Float(*, *, *, device=cpu) = onnx::Add(%2909, %2731), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %2911 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2910), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2912 : Float(*, *, *, device=cpu) = onnx::Sub(%2910, %2911), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2913 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2914 : Float(*, *, *, device=cpu) = onnx::Pow(%2912, %2913), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2915 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2914), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2916 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2917 : Float(*, *, device=cpu) = onnx::Add(%2915, %2916), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2918 : Float(*, *, device=cpu) = onnx::Sqrt(%2917), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2919 : Float(*, *, *, device=cpu) = onnx::Div(%2912, %2918), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2920 : Float(*, *, *, device=cpu) = onnx::Mul(%2919, %decoder_no_past.decoder.transformer.h.9.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2\n",
      "      %2921 : Float(*, *, *, device=cpu) = onnx::Add(%2920, %decoder_no_past.decoder.transformer.h.9.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %2922 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2921), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2923 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2924 : Long(device=cpu) = onnx::Gather[axis=0](%2922, %2923), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2925 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2921), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2926 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2927 : Long(device=cpu) = onnx::Gather[axis=0](%2925, %2926), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2928 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2921), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2930 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2932 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2928, %2930, %2931, %2929), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2933 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc\n",
      "      %2934 : Long(device=cpu) = onnx::Squeeze(%2932, %2933), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2935 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2936 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2935)\n",
      "      %2937 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2938 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2934, %2937)\n",
      "      %2939 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2936, %2938)\n",
      "      %2940 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2921, %2939), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2941 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2940, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2942 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2943 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2924, %2942)\n",
      "      %2944 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2945 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2927, %2944)\n",
      "      %2946 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2947 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %2946)\n",
      "      %2948 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2943, %2945, %2947)\n",
      "      %2949 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2941, %2948), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %2950 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %2951 : Float(*, *, *, device=cpu) = onnx::Mul(%2949, %2950)\n",
      "      %2952 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %2953 : Float(*, *, *, device=cpu) = onnx::Pow(%2949, %2952), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2954 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %2955 : Float(*, *, *, device=cpu) = onnx::Mul(%2953, %2954)\n",
      "      %2956 : Float(*, *, *, device=cpu) = onnx::Add(%2949, %2955), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2957 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %2958 : Float(*, *, *, device=cpu) = onnx::Mul(%2956, %2957)\n",
      "      %2959 : Float(*, *, *, device=cpu) = onnx::Tanh(%2958), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2960 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %2961 : Float(*, *, *, device=cpu) = onnx::Add(%2959, %2960)\n",
      "      %2962 : Float(*, *, *, device=cpu) = onnx::Mul(%2951, %2961), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %2963 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2964 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2965 : Long(device=cpu) = onnx::Gather[axis=0](%2963, %2964), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2966 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2967 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2968 : Long(device=cpu) = onnx::Gather[axis=0](%2966, %2967), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %2969 : Long(3, strides=[1], device=cpu) = onnx::Shape(%2962), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2970 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2971 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2972 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2973 : Long(1, strides=[1], device=cpu) = onnx::Slice(%2969, %2971, %2972, %2970), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2974 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj\n",
      "      %2975 : Long(device=cpu) = onnx::Squeeze(%2973, %2974), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2976 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2977 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %2976)\n",
      "      %2978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2979 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2975, %2978)\n",
      "      %2980 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%2977, %2979)\n",
      "      %2981 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%2962, %2980), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2982 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%2981, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %2983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2984 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2965, %2983)\n",
      "      %2985 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2986 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%2968, %2985)\n",
      "      %2987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %2988 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %2987)\n",
      "      %2989 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%2984, %2986, %2988)\n",
      "      %2990 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%2982, %2989), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9/__module.decoder.transformer.h.9.mlp/__module.decoder.transformer.h.9.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %2991 : Float(*, *, *, device=cpu) = onnx::Add(%2910, %2990), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.9 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %2992 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2991), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2993 : Float(*, *, *, device=cpu) = onnx::Sub(%2991, %2992), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2994 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %2995 : Float(*, *, *, device=cpu) = onnx::Pow(%2993, %2994), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2996 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%2995), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2997 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %2998 : Float(*, *, device=cpu) = onnx::Add(%2996, %2997), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %2999 : Float(*, *, device=cpu) = onnx::Sqrt(%2998), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %3000 : Float(*, *, *, device=cpu) = onnx::Div(%2993, %2999), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %3001 : Float(*, *, *, device=cpu) = onnx::Mul(%3000, %decoder_no_past.decoder.transformer.h.10.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1\n",
      "      %3002 : Float(*, *, *, device=cpu) = onnx::Add(%3001, %decoder_no_past.decoder.transformer.h.10.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3003 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3002), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3004 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3005 : Long(device=cpu) = onnx::Gather[axis=0](%3003, %3004), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3006 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3002), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3007 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3008 : Long(device=cpu) = onnx::Gather[axis=0](%3006, %3007), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3009 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3002), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3010 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3011 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3012 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3013 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3009, %3011, %3012, %3010), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3014 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn\n",
      "      %3015 : Long(device=cpu) = onnx::Squeeze(%3013, %3014), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3016 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3017 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3016)\n",
      "      %3018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3019 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3015, %3018)\n",
      "      %3020 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3017, %3019)\n",
      "      %3021 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3002, %3020), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3022 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3021, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3024 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3005, %3023)\n",
      "      %3025 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3026 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3008, %3025)\n",
      "      %3027 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3028 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %3027)\n",
      "      %3029 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3024, %3026, %3028)\n",
      "      %3030 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3022, %3029), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3031 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3032 : Float(*, *, *, device=cpu), %3033 : Float(*, *, *, device=cpu), %3034 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%3030, %3031), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %3035 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3032), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3036 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3037 : Long(device=cpu) = onnx::Gather[axis=0](%3035, %3036), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3038 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3032), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3039 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3040 : Long(device=cpu) = onnx::Gather[axis=0](%3038, %3039), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3041 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3042 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3037, %3041)\n",
      "      %3043 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3044 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3040, %3043)\n",
      "      %3045 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3046 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3045)\n",
      "      %3047 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3048 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3047)\n",
      "      %3049 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3042, %3044, %3046, %3048)\n",
      "      %3050 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3032, %3049), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3051 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3050), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3052 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3033), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3053 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3054 : Long(device=cpu) = onnx::Gather[axis=0](%3052, %3053), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3055 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3033), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3056 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3057 : Long(device=cpu) = onnx::Gather[axis=0](%3055, %3056), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3058 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3059 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3054, %3058)\n",
      "      %3060 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3061 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3057, %3060)\n",
      "      %3062 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3063 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3062)\n",
      "      %3064 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3065 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3064)\n",
      "      %3066 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3059, %3061, %3063, %3065)\n",
      "      %3067 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3033, %3066), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3068 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3067), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3069 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3034), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3070 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3071 : Long(device=cpu) = onnx::Gather[axis=0](%3069, %3070), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3072 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3034), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3073 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3074 : Long(device=cpu) = onnx::Gather[axis=0](%3072, %3073), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3075 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3076 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3071, %3075)\n",
      "      %3077 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3078 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3074, %3077)\n",
      "      %3079 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3080 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3079)\n",
      "      %3081 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3082 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3081)\n",
      "      %3083 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3076, %3078, %3080, %3082)\n",
      "      %3084 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3034, %3083), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3085 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3084), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3086 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%3067), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3087 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3051, %3086), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3088 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %3089 : Float(*, *, *, *, device=cpu) = onnx::Div(%3087, %3088)\n",
      "      %3090 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3051), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3091 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3092 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3093 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3094 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3090, %3092, %3093, %3091), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3095 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3096 : Long(device=cpu) = onnx::Squeeze(%3094, %3095), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3097 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3068), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3098 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3099 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3100 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3101 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3097, %3099, %3100, %3098), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3102 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3103 : Long(device=cpu) = onnx::Squeeze(%3101, %3102), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3104 : Long(device=cpu) = onnx::Sub(%3103, %3096), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3105 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3106 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3104, %3105), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3107 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3108 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3103, %3107), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3109 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3110 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %3109), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3111 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3112 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.10.attn.bias, %3106, %3108, %3110, %3111), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3113 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3114 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %3113), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3115 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3116 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3103, %3115), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3117 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3118 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %3117), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3119 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3120 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%3112, %3114, %3116, %3118, %3119), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3121 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%3120), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3122 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.10.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3123 : Float(*, *, *, *, device=cpu) = onnx::Where(%3121, %3089, %3122), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3124 : Float(*, *, *, *, device=cpu) = onnx::Add(%3123, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %3125 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%3124), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3126 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3125, %3085), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %3127 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3126), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %3128 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3127), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3129 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3130 : Long(device=cpu) = onnx::Gather[axis=0](%3128, %3129), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3131 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3127), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3132 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn\n",
      "      %3133 : Long(device=cpu) = onnx::Gather[axis=0](%3131, %3132), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3134 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3135 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3130, %3134)\n",
      "      %3136 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3137 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3133, %3136)\n",
      "      %3138 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3139 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3138)\n",
      "      %3140 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3135, %3137, %3139)\n",
      "      %3141 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3127, %3140), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %3142 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3143 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3144 : Long(device=cpu) = onnx::Gather[axis=0](%3142, %3143), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3145 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3146 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3147 : Long(device=cpu) = onnx::Gather[axis=0](%3145, %3146), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3148 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3141), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3149 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3150 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3152 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3148, %3150, %3151, %3149), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj\n",
      "      %3154 : Long(device=cpu) = onnx::Squeeze(%3152, %3153), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3156 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3155)\n",
      "      %3157 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3158 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3154, %3157)\n",
      "      %3159 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3156, %3158)\n",
      "      %3160 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3141, %3159), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3161 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3160, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3162 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3163 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3144, %3162)\n",
      "      %3164 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3165 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3147, %3164)\n",
      "      %3166 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3167 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3166)\n",
      "      %3168 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3163, %3165, %3167)\n",
      "      %3169 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3161, %3168), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.attn/__module.decoder.transformer.h.10.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3170 : Float(*, *, *, device=cpu) = onnx::Add(%3169, %2991), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %3171 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3170), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3172 : Float(*, *, *, device=cpu) = onnx::Sub(%3170, %3171), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3173 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3174 : Float(*, *, *, device=cpu) = onnx::Pow(%3172, %3173), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3175 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3174), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3176 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3177 : Float(*, *, device=cpu) = onnx::Add(%3175, %3176), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3178 : Float(*, *, device=cpu) = onnx::Sqrt(%3177), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3179 : Float(*, *, *, device=cpu) = onnx::Div(%3172, %3178), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3180 : Float(*, *, *, device=cpu) = onnx::Mul(%3179, %decoder_no_past.decoder.transformer.h.10.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2\n",
      "      %3181 : Float(*, *, *, device=cpu) = onnx::Add(%3180, %decoder_no_past.decoder.transformer.h.10.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3182 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3181), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3183 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3184 : Long(device=cpu) = onnx::Gather[axis=0](%3182, %3183), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3185 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3181), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3186 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3187 : Long(device=cpu) = onnx::Gather[axis=0](%3185, %3186), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3188 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3181), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3190 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3191 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3192 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3188, %3190, %3191, %3189), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3193 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc\n",
      "      %3194 : Long(device=cpu) = onnx::Squeeze(%3192, %3193), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3195 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3196 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3195)\n",
      "      %3197 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3198 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3194, %3197)\n",
      "      %3199 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3196, %3198)\n",
      "      %3200 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3181, %3199), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3201 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3200, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3202 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3203 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3184, %3202)\n",
      "      %3204 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3205 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3187, %3204)\n",
      "      %3206 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3207 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3206)\n",
      "      %3208 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3203, %3205, %3207)\n",
      "      %3209 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3201, %3208), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3210 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %3211 : Float(*, *, *, device=cpu) = onnx::Mul(%3209, %3210)\n",
      "      %3212 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %3213 : Float(*, *, *, device=cpu) = onnx::Pow(%3209, %3212), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3214 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %3215 : Float(*, *, *, device=cpu) = onnx::Mul(%3213, %3214)\n",
      "      %3216 : Float(*, *, *, device=cpu) = onnx::Add(%3209, %3215), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3217 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %3218 : Float(*, *, *, device=cpu) = onnx::Mul(%3216, %3217)\n",
      "      %3219 : Float(*, *, *, device=cpu) = onnx::Tanh(%3218), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3220 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3221 : Float(*, *, *, device=cpu) = onnx::Add(%3219, %3220)\n",
      "      %3222 : Float(*, *, *, device=cpu) = onnx::Mul(%3211, %3221), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3223 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3224 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3225 : Long(device=cpu) = onnx::Gather[axis=0](%3223, %3224), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3226 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3227 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3228 : Long(device=cpu) = onnx::Gather[axis=0](%3226, %3227), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3229 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3222), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3230 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3231 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3233 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3229, %3231, %3232, %3230), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3234 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj\n",
      "      %3235 : Long(device=cpu) = onnx::Squeeze(%3233, %3234), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3237 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3236)\n",
      "      %3238 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3239 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3235, %3238)\n",
      "      %3240 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3237, %3239)\n",
      "      %3241 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3222, %3240), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3242 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3241, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3243 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3244 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3225, %3243)\n",
      "      %3245 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3246 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3228, %3245)\n",
      "      %3247 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3248 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3247)\n",
      "      %3249 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3244, %3246, %3248)\n",
      "      %3250 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3242, %3249), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10/__module.decoder.transformer.h.10.mlp/__module.decoder.transformer.h.10.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3251 : Float(*, *, *, device=cpu) = onnx::Add(%3170, %3250), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.10 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %3252 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3251), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3253 : Float(*, *, *, device=cpu) = onnx::Sub(%3251, %3252), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3254 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3255 : Float(*, *, *, device=cpu) = onnx::Pow(%3253, %3254), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3256 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3255), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3257 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3258 : Float(*, *, device=cpu) = onnx::Add(%3256, %3257), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3259 : Float(*, *, device=cpu) = onnx::Sqrt(%3258), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3260 : Float(*, *, *, device=cpu) = onnx::Div(%3253, %3259), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3261 : Float(*, *, *, device=cpu) = onnx::Mul(%3260, %decoder_no_past.decoder.transformer.h.11.ln_1.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1\n",
      "      %3262 : Float(*, *, *, device=cpu) = onnx::Add(%3261, %decoder_no_past.decoder.transformer.h.11.ln_1.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_1 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3263 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3262), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3264 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3265 : Long(device=cpu) = onnx::Gather[axis=0](%3263, %3264), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3266 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3262), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3267 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3268 : Long(device=cpu) = onnx::Gather[axis=0](%3266, %3267), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3269 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3262), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3270 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3271 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3272 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3273 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3269, %3271, %3272, %3270), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3274 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn\n",
      "      %3275 : Long(device=cpu) = onnx::Squeeze(%3273, %3274), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3276 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3277 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3276)\n",
      "      %3278 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3279 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3275, %3278)\n",
      "      %3280 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3277, %3279)\n",
      "      %3281 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3262, %3280), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3282 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3281, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3283 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3284 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3265, %3283)\n",
      "      %3285 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3286 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3268, %3285)\n",
      "      %3287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3288 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%182, %3287)\n",
      "      %3289 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3284, %3286, %3288)\n",
      "      %3290 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3282, %3289), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3291 : Long(3, strides=[1], device=cpu) = onnx::Constant[value= 768  768  768 [ CPULongType{3} ]](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3292 : Float(*, *, *, device=cpu), %3293 : Float(*, *, *, device=cpu), %3294 : Float(*, *, *, device=cpu) = onnx::Split[axis=2](%3290, %3291), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\_tensor.py:510:0\n",
      "      %3295 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3292), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3296 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3297 : Long(device=cpu) = onnx::Gather[axis=0](%3295, %3296), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3298 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3292), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3299 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3300 : Long(device=cpu) = onnx::Gather[axis=0](%3298, %3299), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3301 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3302 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3297, %3301)\n",
      "      %3303 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3304 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3300, %3303)\n",
      "      %3305 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3306 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3305)\n",
      "      %3307 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3308 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3307)\n",
      "      %3309 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3302, %3304, %3306, %3308)\n",
      "      %3310 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3292, %3309), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3311 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3310), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3312 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3293), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3313 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3314 : Long(device=cpu) = onnx::Gather[axis=0](%3312, %3313), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3315 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3293), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3316 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3317 : Long(device=cpu) = onnx::Gather[axis=0](%3315, %3316), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3319 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3314, %3318)\n",
      "      %3320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3321 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3317, %3320)\n",
      "      %3322 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3323 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3322)\n",
      "      %3324 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3325 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3324)\n",
      "      %3326 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3319, %3321, %3323, %3325)\n",
      "      %3327 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3293, %3326), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3328 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3327), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3329 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3294), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3330 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3331 : Long(device=cpu) = onnx::Gather[axis=0](%3329, %3330), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3332 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3294), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3333 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3334 : Long(device=cpu) = onnx::Gather[axis=0](%3332, %3333), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:209:0\n",
      "      %3335 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3336 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3331, %3335)\n",
      "      %3337 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3338 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3334, %3337)\n",
      "      %3339 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3340 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%181, %3339)\n",
      "      %3341 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3342 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%180, %3341)\n",
      "      %3343 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%3336, %3338, %3340, %3342)\n",
      "      %3344 : Float(*, *, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3294, %3343), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:210:0\n",
      "      %3345 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3344), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:211:0\n",
      "      %3346 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%3327), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3347 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3311, %3346), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:179:0\n",
      "      %3348 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={8}]()\n",
      "      %3349 : Float(*, *, *, *, device=cpu) = onnx::Div(%3347, %3348)\n",
      "      %3350 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3311), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3351 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3352 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3353 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3354 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3350, %3352, %3353, %3351), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3355 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3356 : Long(device=cpu) = onnx::Squeeze(%3354, %3355), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3357 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3328), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3358 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3359 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-2}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3360 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3361 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3357, %3359, %3360, %3358), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3362 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3363 : Long(device=cpu) = onnx::Squeeze(%3361, %3362), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:186:0\n",
      "      %3364 : Long(device=cpu) = onnx::Sub(%3363, %3356), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3365 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3366 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3364, %3365), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3367 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3368 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3363, %3367), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3369 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3370 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%190, %3369), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3371 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3372 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%decoder_no_past.decoder.transformer.h.11.attn.bias, %3366, %3368, %3370, %3371), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3373 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3374 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %3373), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3375 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3376 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3363, %3375), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3377 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3378 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%185, %3377), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3380 : Byte(*, *, *, *, device=cpu) = onnx::Slice(%3372, %3374, %3376, %3378, %3379), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3381 : Bool(*, *, *, *, device=cpu) = onnx::Cast[to=9](%3380), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:187:0\n",
      "      %3382 : Float(device=cpu) = onnx::Cast[to=1](%decoder_no_past.decoder.transformer.h.11.attn.masked_bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3383 : Float(*, *, *, *, device=cpu) = onnx::Where(%3381, %3349, %3382), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:188:0\n",
      "      %3384 : Float(*, *, *, *, device=cpu) = onnx::Add(%3383, %381), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:192:0\n",
      "      %3385 : Float(*, *, *, *, device=cpu) = onnx::Softmax[axis=-1](%3384), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.attn_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3386 : Float(*, *, *, *, device=cpu) = onnx::MatMul(%3385, %3345), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:201:0\n",
      "      %3387 : Float(*, *, *, *, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%3386), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:217:0\n",
      "      %3388 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3387), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3389 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3390 : Long(device=cpu) = onnx::Gather[axis=0](%3388, %3389), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3391 : Long(4, strides=[1], device=cpu) = onnx::Shape(%3387), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3392 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn\n",
      "      %3393 : Long(device=cpu) = onnx::Gather[axis=0](%3391, %3392), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:218:0\n",
      "      %3394 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3395 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3390, %3394)\n",
      "      %3396 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3397 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3393, %3396)\n",
      "      %3398 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3399 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3398)\n",
      "      %3400 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3395, %3397, %3399)\n",
      "      %3401 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3387, %3400), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:219:0\n",
      "      %3402 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3403 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3404 : Long(device=cpu) = onnx::Gather[axis=0](%3402, %3403), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3405 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3406 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3407 : Long(device=cpu) = onnx::Gather[axis=0](%3405, %3406), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3408 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3401), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3409 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3411 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3412 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3408, %3410, %3411, %3409), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3413 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj\n",
      "      %3414 : Long(device=cpu) = onnx::Squeeze(%3412, %3413), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3415 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3416 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3415)\n",
      "      %3417 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3418 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3414, %3417)\n",
      "      %3419 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3416, %3418)\n",
      "      %3420 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3401, %3419), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3421 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3420, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3422 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3423 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3404, %3422)\n",
      "      %3424 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3425 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3407, %3424)\n",
      "      %3426 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3427 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3426)\n",
      "      %3428 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3423, %3425, %3427)\n",
      "      %3429 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3421, %3428), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.attn/__module.decoder.transformer.h.11.attn.resid_dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3430 : Float(*, *, *, device=cpu) = onnx::Add(%3429, %3251), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:329:0\n",
      "      %3431 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3430), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3432 : Float(*, *, *, device=cpu) = onnx::Sub(%3430, %3431), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3433 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3434 : Float(*, *, *, device=cpu) = onnx::Pow(%3432, %3433), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3435 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3434), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3436 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3437 : Float(*, *, device=cpu) = onnx::Add(%3435, %3436), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3438 : Float(*, *, device=cpu) = onnx::Sqrt(%3437), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3439 : Float(*, *, *, device=cpu) = onnx::Div(%3432, %3438), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3440 : Float(*, *, *, device=cpu) = onnx::Mul(%3439, %decoder_no_past.decoder.transformer.h.11.ln_2.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2\n",
      "      %3441 : Float(*, *, *, device=cpu) = onnx::Add(%3440, %decoder_no_past.decoder.transformer.h.11.ln_2.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.ln_2 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3442 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3441), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3443 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3444 : Long(device=cpu) = onnx::Gather[axis=0](%3442, %3443), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3445 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3441), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3446 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3447 : Long(device=cpu) = onnx::Gather[axis=0](%3445, %3446), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3448 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3441), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3449 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3450 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3451 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3452 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3448, %3450, %3451, %3449), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3453 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc\n",
      "      %3454 : Long(device=cpu) = onnx::Squeeze(%3452, %3453), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3455 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3456 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3455)\n",
      "      %3457 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3458 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3454, %3457)\n",
      "      %3459 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3456, %3458)\n",
      "      %3460 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3441, %3459), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3461 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3460, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3462 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3463 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3444, %3462)\n",
      "      %3464 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3465 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3447, %3464)\n",
      "      %3466 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3467 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%179, %3466)\n",
      "      %3468 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3463, %3465, %3467)\n",
      "      %3469 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3461, %3468), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_fc # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1732:0\n",
      "      %3470 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
      "      %3471 : Float(*, *, *, device=cpu) = onnx::Mul(%3469, %3470)\n",
      "      %3472 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={3}]()\n",
      "      %3473 : Float(*, *, *, device=cpu) = onnx::Pow(%3469, %3472), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3474 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.044715}]()\n",
      "      %3475 : Float(*, *, *, device=cpu) = onnx::Mul(%3473, %3474)\n",
      "      %3476 : Float(*, *, *, device=cpu) = onnx::Add(%3469, %3475), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3477 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.797885}]()\n",
      "      %3478 : Float(*, *, *, device=cpu) = onnx::Mul(%3476, %3477)\n",
      "      %3479 : Float(*, *, *, device=cpu) = onnx::Tanh(%3478), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3480 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3481 : Float(*, *, *, device=cpu) = onnx::Add(%3479, %3480)\n",
      "      %3482 : Float(*, *, *, device=cpu) = onnx::Mul(%3471, %3481), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\activations.py:42:0\n",
      "      %3483 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3484 : Long(device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3485 : Long(device=cpu) = onnx::Gather[axis=0](%3483, %3484), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3486 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3487 : Long(device=cpu) = onnx::Constant[value={1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3488 : Long(device=cpu) = onnx::Gather[axis=0](%3486, %3487), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1730:0\n",
      "      %3489 : Long(3, strides=[1], device=cpu) = onnx::Shape(%3482), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3490 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3491 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3492 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3493 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3489, %3491, %3492, %3490), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3494 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}](), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj\n",
      "      %3495 : Long(device=cpu) = onnx::Squeeze(%3493, %3494), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3496 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3497 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%186, %3496)\n",
      "      %3498 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3499 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3495, %3498)\n",
      "      %3500 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3497, %3499)\n",
      "      %3501 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3482, %3500), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3502 : Float(*, *, device=cpu) = onnx::Gemm[alpha=1., beta=1.](%3501, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.c_proj # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:1731:0\n",
      "      %3503 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3504 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3485, %3503)\n",
      "      %3505 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3506 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3488, %3505)\n",
      "      %3507 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3508 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%183, %3507)\n",
      "      %3509 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3504, %3506, %3508)\n",
      "      %3510 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3502, %3509), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11/__module.decoder.transformer.h.11.mlp/__module.decoder.transformer.h.11.mlp.dropout # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1169:0\n",
      "      %3511 : Float(*, *, *, device=cpu) = onnx::Add(%3430, %3510), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.h.11 # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:357:0\n",
      "      %3512 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3511), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3513 : Float(*, *, *, device=cpu) = onnx::Sub(%3511, %3512), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3514 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3515 : Float(*, *, *, device=cpu) = onnx::Pow(%3513, %3514), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3516 : Float(*, *, device=cpu) = onnx::ReduceMean[axes=[-1]](%3515), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3517 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-05}]()\n",
      "      %3518 : Float(*, *, device=cpu) = onnx::Add(%3516, %3517), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3519 : Float(*, *, device=cpu) = onnx::Sqrt(%3518), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3520 : Float(*, *, *, device=cpu) = onnx::Div(%3513, %3519), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3521 : Float(*, *, *, device=cpu) = onnx::Mul(%3520, %decoder_no_past.decoder.transformer.ln_f.weight), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f\n",
      "      %3522 : Float(*, *, *, device=cpu) = onnx::Add(%3521, %decoder_no_past.decoder.transformer.ln_f.bias), scope: __module.decoder/__module.decoder.transformer/__module.decoder.transformer.ln_f # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:2347:0\n",
      "      %3523 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3524 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%340, %3523)\n",
      "      %3525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3526 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%343, %3525)\n",
      "      %3527 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3528 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%391, %3527)\n",
      "      %3529 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%3524, %3526, %3528)\n",
      "      %3530 : Float(*, *, *, device=cpu) = onnx::Reshape[allowzero=0](%3522, %3529), scope: __module.decoder/__module.decoder.transformer # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:826:0\n",
      "      %3531 : Float(*, *, *, device=cpu) = onnx::MatMul(%3530, %5040) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:721:32\n",
      "      %3532 : Float(*, *, device=cpu) = onnx::Gather[axis=1](%3531, %186) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:721:32\n",
      "      %3533 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3534 : Long(device=cpu) = onnx::Sub(%max_length, %3533) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:24\n",
      "      %3535 : Bool(device=cpu) = onnx::Equal(%cur_len.13, %3534) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:13\n",
      "      %3536 : Bool(device=cpu) = onnx::Cast[to=9](%3535)\n",
      "      %3537 : Float(*, *, device=cpu) = onnx::If(%3536) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:553:13\n",
      "        block0():\n",
      "          %3538 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3532)\n",
      "          %3539 : Bool(*, *, device=cpu) = onnx::ConstantOfShape[value={1}](%3538) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3540 : Bool(*, device=cpu) = onnx::Gather[axis=1](%3539, %190) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3541 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3542 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3540)\n",
      "          %3543 : BoolTensor(device=cpu) = onnx::Expand(%3541, %3542) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3544 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3539)\n",
      "          %3545 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3546 : Long(device=cpu) = onnx::Gather[axis=0](%3544, %3545)\n",
      "          %3547 : Long(device=cpu) = onnx::Cast[to=7](%3546)\n",
      "          %3548 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3549 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "          %3550 : Long(*, device=cpu) = onnx::Range(%3548, %3547, %3549)\n",
      "          %3551 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3552 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %3553 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3550, %3552)\n",
      "          %3554 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3555 : Long(*, 1, device=cpu) = onnx::Add(%3553, %3554)\n",
      "          %3556 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3555)\n",
      "          %3557 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3556)\n",
      "          %3558 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3557)\n",
      "          %3559 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3560 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3558, %3559)\n",
      "          %3561 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3556, %3560)\n",
      "          %3562 : Long(2, strides=[1], device=cpu) = onnx::Where(%3561, %3558, %3556)\n",
      "          %3563 : LongTensor(device=cpu) = onnx::Expand(%3553, %3562)\n",
      "          %3564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3565 : LongTensor(device=cpu) = onnx::Unsqueeze(%3563, %3564)\n",
      "          %3566 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3556)\n",
      "          %3567 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3566)\n",
      "          %3568 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3569 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3567, %3568)\n",
      "          %3570 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3556, %3569)\n",
      "          %3571 : Long(2, strides=[1], device=cpu) = onnx::Where(%3570, %3567, %3556)\n",
      "          %3572 : LongTensor(device=cpu) = onnx::Expand(%3551, %3571)\n",
      "          %3573 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3574 : LongTensor(device=cpu) = onnx::Unsqueeze(%3572, %3573)\n",
      "          %3575 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3565, %3574)\n",
      "          %3576 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3539)\n",
      "          %3577 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3578 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3579 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %3580 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3576, %3578, %3579, %3577)\n",
      "          %3581 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3556, %3580)\n",
      "          %3582 : Bool(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3543, %3581)\n",
      "          %3583 : Bool(*, *, device=cpu) = onnx::ScatterND(%3539, %3575, %3582) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:561:8\n",
      "          %3584 : Bool(*, *, device=cpu) = onnx::Cast[to=9](%3583)\n",
      "          %3585 : Float(device=cpu) = onnx::Constant[value={-inf}]()\n",
      "          %3586 : Float(*, *, device=cpu) = onnx::Where(%3584, %3585, %3532) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:562:15\n",
      "          -> (%3586)\n",
      "        block1():\n",
      "          %3587 : Float(*, *, device=cpu) = onnx::Identity(%3532)\n",
      "          -> (%3587)\n",
      "      %3588 : Float(*, *, device=cpu) = onnx::LogSoftmax[axis=-1](%3537) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "      %3589 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids.25) # <string>:7:9\n",
      "      %3590 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3591 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3592 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3593 : Long(1, strides=[1], device=cpu) = onnx::Slice(%3589, %3591, %3592, %3590)\n",
      "      %3594 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3595 : Long(device=cpu) = onnx::Squeeze(%3593, %3594) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:100:18\n",
      "      %3596 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3597 : Bool(device=cpu) = onnx::Less(%3595, %3596) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:101:11\n",
      "      %3598 : Bool(device=cpu) = onnx::Cast[to=9](%3597)\n",
      "      %3599 : Float(*, *, device=cpu) = onnx::If(%3598) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:101:8\n",
      "        block0():\n",
      "          %3600 : Float(*, device=cpu) = onnx::Gather[axis=1](%3588, %190) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          %3601 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-inf}]()\n",
      "          %3602 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3600)\n",
      "          %3603 : FloatTensor(device=cpu) = onnx::Expand(%3601, %3602) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          %3604 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3588)\n",
      "          %3605 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3606 : Long(device=cpu) = onnx::Gather[axis=0](%3604, %3605)\n",
      "          %3607 : Long(device=cpu) = onnx::Cast[to=7](%3606)\n",
      "          %3608 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3609 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "          %3610 : Long(*, device=cpu) = onnx::Range(%3608, %3607, %3609)\n",
      "          %3611 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3612 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %3613 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3610, %3612)\n",
      "          %3614 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3615 : Long(*, 1, device=cpu) = onnx::Add(%3613, %3614)\n",
      "          %3616 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3615)\n",
      "          %3617 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3616)\n",
      "          %3618 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3617)\n",
      "          %3619 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3620 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3618, %3619)\n",
      "          %3621 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3616, %3620)\n",
      "          %3622 : Long(2, strides=[1], device=cpu) = onnx::Where(%3621, %3618, %3616)\n",
      "          %3623 : LongTensor(device=cpu) = onnx::Expand(%3613, %3622)\n",
      "          %3624 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3625 : LongTensor(device=cpu) = onnx::Unsqueeze(%3623, %3624)\n",
      "          %3626 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3616)\n",
      "          %3627 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3626)\n",
      "          %3628 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3629 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3627, %3628)\n",
      "          %3630 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3616, %3629)\n",
      "          %3631 : Long(2, strides=[1], device=cpu) = onnx::Where(%3630, %3627, %3616)\n",
      "          %3632 : LongTensor(device=cpu) = onnx::Expand(%3611, %3631)\n",
      "          %3633 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %3634 : LongTensor(device=cpu) = onnx::Unsqueeze(%3632, %3633)\n",
      "          %3635 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3625, %3634)\n",
      "          %3636 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3588)\n",
      "          %3637 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %3638 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %3639 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %3640 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3636, %3638, %3639, %3637)\n",
      "          %3641 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3616, %3640)\n",
      "          %3642 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3603, %3641)\n",
      "          %3643 : Float(*, *, device=cpu) = onnx::ScatterND(%3588, %3635, %3642) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:102:12\n",
      "          -> (%3643)\n",
      "        block1():\n",
      "          %3644 : Float(*, *, device=cpu) = onnx::Identity(%3588)\n",
      "          -> (%3644)\n",
      "      %3645 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3646 : Float(*, *, device=cpu) = onnx::Unsqueeze(%beam_scores.17, %3645) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:732:52\n",
      "      %3647 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3599)\n",
      "      %3648 : FloatTensor(device=cpu) = onnx::Expand(%3646, %3647) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:732:52\n",
      "      %3649 : FloatTensor(device=cpu) = onnx::Add(%3599, %3648) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:732:32\n",
      "      %3650 : FloatTensor(device=cpu) = onnx::Div(%3649, %192) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:735:32\n",
      "      %3651 : Long(*, device=cpu) = onnx::Shape(%3650)\n",
      "      %3652 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3653 : Long(1, strides=[1], device=cpu) = onnx::Gather(%3651, %3652)\n",
      "      %3654 : FloatTensor(device=cpu), %3655 : LongTensor(device=cpu) = onnx::TopK[axis=-1, largest=1](%3650, %3653) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:741:44\n",
      "      %3656 : FloatTensor(device=cpu) = onnx::Softmax[axis=-1](%3654) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:742:31\n",
      "      %3657 : Int(device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3658 : FloatTensor(device=cpu) = onnx::CumSum(%3656, %3657) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:742:31\n",
      "      %3659 : BoolTensor(device=cpu) = onnx::Greater(%3658, %193) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:748:12\n",
      "      %3660 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3661 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3662 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3663 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3664 : BoolTensor(device=cpu) = onnx::Slice(%3659, %3661, %3662, %3660, %3663) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:748:12\n",
      "      %3665 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3666 : Long(*, device=cpu) = onnx::Shape(%3664)\n",
      "      %3667 : BoolTensor(device=cpu) = onnx::Expand(%3665, %3666) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:748:12\n",
      "      %3668 : Long(*, device=cpu) = onnx::Shape(%3659)\n",
      "      %3669 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3670 : Long(device=cpu) = onnx::Gather[axis=0](%3668, %3669)\n",
      "      %3671 : Long(device=cpu) = onnx::Cast[to=7](%3670)\n",
      "      %3672 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3673 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3674 : Long(*, device=cpu) = onnx::Range(%3672, %3671, %3673)\n",
      "      %3675 : Long(*, device=cpu) = onnx::Shape(%3659)\n",
      "      %3676 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3677 : Long(device=cpu) = onnx::Gather[axis=0](%3675, %3676)\n",
      "      %3678 : Long(device=cpu) = onnx::Cast[to=7](%3677)\n",
      "      %3679 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3680 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3681 : Long(*, device=cpu) = onnx::Range(%3679, %3678, %3680)\n",
      "      %3682 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3684 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3686 : Long(*, device=cpu) = onnx::Slice(%3681, %3683, %3684, %3682, %3685)\n",
      "      %3687 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "      %3688 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3674, %3687)\n",
      "      %3689 : Long(*, *, device=cpu) = onnx::Add(%3688, %3686)\n",
      "      %3690 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3689)\n",
      "      %3691 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3690)\n",
      "      %3692 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3691)\n",
      "      %3693 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3694 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3692, %3693)\n",
      "      %3695 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3690, %3694)\n",
      "      %3696 : Long(2, strides=[1], device=cpu) = onnx::Where(%3695, %3692, %3690)\n",
      "      %3697 : LongTensor(device=cpu) = onnx::Expand(%3688, %3696)\n",
      "      %3698 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3699 : LongTensor(device=cpu) = onnx::Unsqueeze(%3697, %3698)\n",
      "      %3700 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3690)\n",
      "      %3701 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3700)\n",
      "      %3702 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3703 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3701, %3702)\n",
      "      %3704 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3690, %3703)\n",
      "      %3705 : Long(2, strides=[1], device=cpu) = onnx::Where(%3704, %3701, %3690)\n",
      "      %3706 : LongTensor(device=cpu) = onnx::Expand(%3686, %3705)\n",
      "      %3707 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3708 : LongTensor(device=cpu) = onnx::Unsqueeze(%3706, %3707)\n",
      "      %3709 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3699, %3708)\n",
      "      %3710 : Long(*, device=cpu) = onnx::Shape(%3659)\n",
      "      %3711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3714 : Long(*, device=cpu) = onnx::Slice(%3710, %3712, %3713, %3711)\n",
      "      %3715 : Long(*, device=cpu) = onnx::Concat[axis=0](%3690, %3714)\n",
      "      %3716 : BoolTensor(device=cpu) = onnx::Reshape[allowzero=0](%3667, %3715)\n",
      "      %3717 : BoolTensor(device=cpu) = onnx::ScatterND(%3659, %3709, %3716) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:751:12\n",
      "      %3718 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3719 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3720 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3721 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3722 : BoolTensor(device=cpu) = onnx::Slice(%3717, %3719, %3720, %3718, %3721) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:751:46\n",
      "      %3723 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3724 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3725 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3726 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3727 : BoolTensor(device=cpu) = onnx::Slice(%3717, %3724, %3725, %3723, %3726) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:751:12\n",
      "      %3728 : Long(*, device=cpu) = onnx::Shape(%3727)\n",
      "      %3729 : BoolTensor(device=cpu) = onnx::Expand(%3722, %3728) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:751:12\n",
      "      %3730 : Long(*, device=cpu) = onnx::Shape(%3717)\n",
      "      %3731 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3732 : Long(device=cpu) = onnx::Gather[axis=0](%3730, %3731)\n",
      "      %3733 : Long(device=cpu) = onnx::Cast[to=7](%3732)\n",
      "      %3734 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3735 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3736 : Long(*, device=cpu) = onnx::Range(%3734, %3733, %3735)\n",
      "      %3737 : Long(*, device=cpu) = onnx::Shape(%3717)\n",
      "      %3738 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3739 : Long(device=cpu) = onnx::Gather[axis=0](%3737, %3738)\n",
      "      %3740 : Long(device=cpu) = onnx::Cast[to=7](%3739)\n",
      "      %3741 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3742 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3743 : Long(*, device=cpu) = onnx::Range(%3741, %3740, %3742)\n",
      "      %3744 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3745 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3746 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3747 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3748 : Long(*, device=cpu) = onnx::Slice(%3743, %3745, %3746, %3744, %3747)\n",
      "      %3749 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "      %3750 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3736, %3749)\n",
      "      %3751 : Long(*, *, device=cpu) = onnx::Add(%3750, %3748)\n",
      "      %3752 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3751)\n",
      "      %3753 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3752)\n",
      "      %3754 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3753)\n",
      "      %3755 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3756 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3754, %3755)\n",
      "      %3757 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3752, %3756)\n",
      "      %3758 : Long(2, strides=[1], device=cpu) = onnx::Where(%3757, %3754, %3752)\n",
      "      %3759 : LongTensor(device=cpu) = onnx::Expand(%3750, %3758)\n",
      "      %3760 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3761 : LongTensor(device=cpu) = onnx::Unsqueeze(%3759, %3760)\n",
      "      %3762 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3752)\n",
      "      %3763 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3762)\n",
      "      %3764 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3765 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3763, %3764)\n",
      "      %3766 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3752, %3765)\n",
      "      %3767 : Long(2, strides=[1], device=cpu) = onnx::Where(%3766, %3763, %3752)\n",
      "      %3768 : LongTensor(device=cpu) = onnx::Expand(%3748, %3767)\n",
      "      %3769 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3770 : LongTensor(device=cpu) = onnx::Unsqueeze(%3768, %3769)\n",
      "      %3771 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3761, %3770)\n",
      "      %3772 : Long(*, device=cpu) = onnx::Shape(%3717)\n",
      "      %3773 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3774 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3775 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3776 : Long(*, device=cpu) = onnx::Slice(%3772, %3774, %3775, %3773)\n",
      "      %3777 : Long(*, device=cpu) = onnx::Concat[axis=0](%3752, %3776)\n",
      "      %3778 : BoolTensor(device=cpu) = onnx::Reshape[allowzero=0](%3729, %3777)\n",
      "      %3779 : BoolTensor(device=cpu) = onnx::ScatterND(%3717, %3771, %3778) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:752:12\n",
      "      %3780 : BoolTensor(device=cpu) = onnx::Gather[axis=1](%3779, %191) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:752:12\n",
      "      %3781 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3782 : Long(*, device=cpu) = onnx::Shape(%3780)\n",
      "      %3783 : BoolTensor(device=cpu) = onnx::Expand(%3781, %3782) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:752:12\n",
      "      %3784 : Long(*, device=cpu) = onnx::Shape(%3779)\n",
      "      %3785 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3786 : Long(device=cpu) = onnx::Gather[axis=0](%3784, %3785)\n",
      "      %3787 : Long(device=cpu) = onnx::Cast[to=7](%3786)\n",
      "      %3788 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3789 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3790 : Long(*, device=cpu) = onnx::Range(%3788, %3787, %3789)\n",
      "      %3791 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3792 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "      %3793 : Long(*, 1, device=cpu) = onnx::Reshape[allowzero=0](%3790, %3792)\n",
      "      %3794 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3795 : Long(*, 1, device=cpu) = onnx::Add(%3793, %3794)\n",
      "      %3796 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3795)\n",
      "      %3797 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3796)\n",
      "      %3798 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3797)\n",
      "      %3799 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3800 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3798, %3799)\n",
      "      %3801 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3796, %3800)\n",
      "      %3802 : Long(2, strides=[1], device=cpu) = onnx::Where(%3801, %3798, %3796)\n",
      "      %3803 : LongTensor(device=cpu) = onnx::Expand(%3793, %3802)\n",
      "      %3804 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3805 : LongTensor(device=cpu) = onnx::Unsqueeze(%3803, %3804)\n",
      "      %3806 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3796)\n",
      "      %3807 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3806)\n",
      "      %3808 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3809 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3807, %3808)\n",
      "      %3810 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3796, %3809)\n",
      "      %3811 : Long(2, strides=[1], device=cpu) = onnx::Where(%3810, %3807, %3796)\n",
      "      %3812 : LongTensor(device=cpu) = onnx::Expand(%3791, %3811)\n",
      "      %3813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3814 : LongTensor(device=cpu) = onnx::Unsqueeze(%3812, %3813)\n",
      "      %3815 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3805, %3814)\n",
      "      %3816 : Long(*, device=cpu) = onnx::Shape(%3779)\n",
      "      %3817 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3818 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "      %3819 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3820 : Long(*, device=cpu) = onnx::Slice(%3816, %3818, %3819, %3817)\n",
      "      %3821 : Long(*, device=cpu) = onnx::Concat[axis=0](%3796, %3820)\n",
      "      %3822 : BoolTensor(device=cpu) = onnx::Reshape[allowzero=0](%3783, %3821)\n",
      "      %3823 : BoolTensor(device=cpu) = onnx::ScatterND(%3779, %3815, %3822) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:752:12\n",
      "      %3824 : BoolTensor(device=cpu) = onnx::ScatterElements[axis=1](%3823, %3655, %3823) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:755:32\n",
      "      %3825 : BoolTensor(device=cpu) = onnx::Cast[to=9](%3824)\n",
      "      %3826 : Float(device=cpu) = onnx::Constant[value={-inf}]()\n",
      "      %3827 : FloatTensor(device=cpu) = onnx::Where(%3825, %3826, %3650) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:756:32\n",
      "      %3828 : int[] = onnx::Shape(%3827) # <string>:7:9\n",
      "      %3829 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3830 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %3831 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %3832 : Tensor(*) = onnx::Slice(%3828, %3830, %3831, %3829)\n",
      "      %3833 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3834 : Long(device=cpu) = onnx::Squeeze(%3832, %3833) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:760:25\n",
      "      %3835 : Long(device=cpu) = onnx::Mul(%num_beams, %3834) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:761:67\n",
      "      %3836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3837 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%196, %3836)\n",
      "      %3838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3839 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3835, %3838)\n",
      "      %3840 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3837, %3839)\n",
      "      %3841 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3827, %3840) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:761:32\n",
      "      %3842 : Float(*, *, device=cpu) = onnx::Softmax[axis=-1](%3841) # C:\\Users\\edbon\\anaconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\functional.py:1680:14\n",
      "      %3843 : Float(*, *, device=cpu) = onnx::Log(%3842)\n",
      "      %3844 : Long(*, *, device=cpu) = onnx::Multinomial[dtype=7, sample_size=8](%3843) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:765:26\n",
      "      %3845 : Float(*, *, device=cpu) = onnx::GatherElements[axis=-1](%3841, %3844) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:766:32\n",
      "      %3846 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3845)\n",
      "      %3847 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %3848 : Long(1, strides=[1], device=cpu) = onnx::Gather(%3846, %3847)\n",
      "      %3849 : Float(*, *, device=cpu), %3850 : Long(*, *, device=cpu) = onnx::TopK[axis=1, largest=1](%3845, %3848) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:768:42\n",
      "      %3851 : Long(*, *, device=cpu) = onnx::GatherElements[axis=-1](%3844, %3850) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:769:26\n",
      "      %3852 : Long(*, *, device=cpu) = onnx::Div(%3851, %3834)\n",
      "      %3853 : Long(*, *, device=cpu) = onnx::Cast[to=7](%3852)\n",
      "      %3854 : Long(*, *, device=cpu) = onnx::Cast[to=7](%3853) # <string>:3:9\n",
      "      %3855 : Long(*, *, device=cpu) = onnx::Div(%3851, %3834)\n",
      "      %3856 : Long(*, *, device=cpu) = onnx::Mul(%3855, %3834)\n",
      "      %3857 : Long(*, *, device=cpu) = onnx::Sub(%3851, %3856) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:773:26\n",
      "      %3858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3859 : Long(1, strides=[1], device=cpu) = onnx::Shape(%336)\n",
      "      %3860 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%3859, %3858)\n",
      "      %3861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3862 : Long(device=cpu) = onnx::Squeeze(%3860, %3861) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:402:21\n",
      "      %3863 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3864 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3862, %3863)\n",
      "      %3865 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3866 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%200, %3865)\n",
      "      %3867 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3864, %3866)\n",
      "      %3868 : Float(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3867) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:406:27\n",
      "      %3869 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3870 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3862, %3869)\n",
      "      %3871 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3872 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%200, %3871)\n",
      "      %3873 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3870, %3872)\n",
      "      %3874 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3873) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:407:27\n",
      "      %3875 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3876 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%3862, %3875)\n",
      "      %3877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3878 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%200, %3877)\n",
      "      %3879 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3876, %3878)\n",
      "      %3880 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%3879) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:408:28\n",
      "      %3881 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %3882 : Bool(device=cpu) = onnx::Greater(%3862, %3881)\n",
      "      %3883 : Long(device=cpu), %3884 : Long(device=cpu), %3885 : Long(device=cpu), %3886 : Float(*, *, device=cpu), %3887 : Long(*, *, device=cpu), %3888 : Long(*, *, device=cpu), %3889 : Float(*, device=cpu)[], %3890 : Long(*, device=cpu)[], %3891 : Float(*, device=cpu), %3892 : Long(*, device=cpu), %3893 : Bool(*, device=cpu) = onnx::Loop(%184, %3882, %190, %191, %191, %3868, %3874, %3880, %333, %334, %335, %336, %337) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:410:8\n",
      "        block0(%3894 : Long(requires_grad=0, device=cpu), %cond.3 : Bool(device=cpu), %eos_token_id.74 : Long(requires_grad=0, device=cpu), %pad_token_id.34 : Long(requires_grad=0, device=cpu), %3898 : Long(requires_grad=0, device=cpu), %3899 : Float(*, *, device=cpu), %3900 : Long(*, *, device=cpu), %3901 : Long(*, *, device=cpu), %3902 : Float(*, device=cpu)[], %3903 : Long(*, device=cpu)[], %3904 : Float(*, device=cpu), %3905 : Long(*, device=cpu), %3906 : Bool(*, device=cpu)):\n",
      "          %3907 : Bool(device=cpu) = onnx::Gather[axis=0](%3906, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:411:15\n",
      "          %3908 : Bool(device=cpu) = onnx::Cast[to=9](%3907)\n",
      "          %3909 : Long(device=cpu), %3910 : Long(device=cpu), %3911 : Float(*, *, device=cpu), %3912 : Long(*, *, device=cpu), %3913 : Long(*, *, device=cpu), %3914 : Float(*, device=cpu)[], %3915 : Long(*, device=cpu)[], %3916 : Float(*, device=cpu), %3917 : Long(*, device=cpu), %3918 : Bool(*, device=cpu) = onnx::If(%3908) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:411:12\n",
      "            block0():\n",
      "              %3919 : Float(*, device=cpu) = onnx::Gather[axis=0](%3899, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3920 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3921 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3919)\n",
      "              %3922 : FloatTensor(device=cpu) = onnx::Expand(%3920, %3921) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3923 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3924 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %3923)\n",
      "              %3925 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3899)\n",
      "              %3926 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3927 : Long(device=cpu) = onnx::Gather[axis=0](%3925, %3926)\n",
      "              %3928 : Long(device=cpu) = onnx::Cast[to=7](%3927)\n",
      "              %3929 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3930 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3931 : Long(*, device=cpu) = onnx::Range(%3929, %3928, %3930)\n",
      "              %3932 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %3933 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3924, %3932)\n",
      "              %3934 : Long(*, *, device=cpu) = onnx::Add(%3933, %3931)\n",
      "              %3935 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3934)\n",
      "              %3936 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3935)\n",
      "              %3937 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3936)\n",
      "              %3938 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3939 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3937, %3938)\n",
      "              %3940 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3935, %3939)\n",
      "              %3941 : Long(2, strides=[1], device=cpu) = onnx::Where(%3940, %3937, %3935)\n",
      "              %3942 : LongTensor(device=cpu) = onnx::Expand(%3933, %3941)\n",
      "              %3943 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3944 : LongTensor(device=cpu) = onnx::Unsqueeze(%3942, %3943)\n",
      "              %3945 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3935)\n",
      "              %3946 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3945)\n",
      "              %3947 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3948 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3946, %3947)\n",
      "              %3949 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3935, %3948)\n",
      "              %3950 : Long(2, strides=[1], device=cpu) = onnx::Where(%3949, %3946, %3935)\n",
      "              %3951 : LongTensor(device=cpu) = onnx::Expand(%3931, %3950)\n",
      "              %3952 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3953 : LongTensor(device=cpu) = onnx::Unsqueeze(%3951, %3952)\n",
      "              %3954 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3944, %3953)\n",
      "              %3955 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3899)\n",
      "              %3956 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3957 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %3958 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %3959 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3955, %3957, %3958, %3956)\n",
      "              %3960 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3935, %3959)\n",
      "              %3961 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3922, %3960)\n",
      "              %3962 : Float(*, *, device=cpu) = onnx::ScatterND(%3899, %3954, %3961) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:419:16\n",
      "              %3963 : Long(*, device=cpu) = onnx::Gather[axis=0](%3900, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %3964 : Long(device=cpu) = onnx::Cast[to=7](%pad_token_id.34)\n",
      "              %3965 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3963)\n",
      "              %3966 : LongTensor(device=cpu) = onnx::Expand(%3964, %3965) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %3967 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3968 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %3967)\n",
      "              %3969 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3900)\n",
      "              %3970 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3971 : Long(device=cpu) = onnx::Gather[axis=0](%3969, %3970)\n",
      "              %3972 : Long(device=cpu) = onnx::Cast[to=7](%3971)\n",
      "              %3973 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %3974 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %3975 : Long(*, device=cpu) = onnx::Range(%3973, %3972, %3974)\n",
      "              %3976 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %3977 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3968, %3976)\n",
      "              %3978 : Long(*, *, device=cpu) = onnx::Add(%3977, %3975)\n",
      "              %3979 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3978)\n",
      "              %3980 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3979)\n",
      "              %3981 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3980)\n",
      "              %3982 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3983 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3981, %3982)\n",
      "              %3984 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3979, %3983)\n",
      "              %3985 : Long(2, strides=[1], device=cpu) = onnx::Where(%3984, %3981, %3979)\n",
      "              %3986 : LongTensor(device=cpu) = onnx::Expand(%3977, %3985)\n",
      "              %3987 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3988 : LongTensor(device=cpu) = onnx::Unsqueeze(%3986, %3987)\n",
      "              %3989 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3979)\n",
      "              %3990 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%3989)\n",
      "              %3991 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3992 : Long(2, strides=[1], device=cpu) = onnx::Mul(%3990, %3991)\n",
      "              %3993 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%3979, %3992)\n",
      "              %3994 : Long(2, strides=[1], device=cpu) = onnx::Where(%3993, %3990, %3979)\n",
      "              %3995 : LongTensor(device=cpu) = onnx::Expand(%3975, %3994)\n",
      "              %3996 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %3997 : LongTensor(device=cpu) = onnx::Unsqueeze(%3995, %3996)\n",
      "              %3998 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%3988, %3997)\n",
      "              %3999 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3900)\n",
      "              %4000 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4001 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %4002 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4003 : Long(0, strides=[1], device=cpu) = onnx::Slice(%3999, %4001, %4002, %4000)\n",
      "              %4004 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%3979, %4003)\n",
      "              %4005 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%3966, %4004)\n",
      "              %4006 : Long(*, *, device=cpu) = onnx::ScatterND(%3900, %3998, %4005) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:420:16\n",
      "              %4007 : Long(*, device=cpu) = onnx::Gather[axis=0](%3901, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %4008 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4009 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4007)\n",
      "              %4010 : LongTensor(device=cpu) = onnx::Expand(%4008, %4009) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %4011 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4012 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4011)\n",
      "              %4013 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3901)\n",
      "              %4014 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4015 : Long(device=cpu) = onnx::Gather[axis=0](%4013, %4014)\n",
      "              %4016 : Long(device=cpu) = onnx::Cast[to=7](%4015)\n",
      "              %4017 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4018 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4019 : Long(*, device=cpu) = onnx::Range(%4017, %4016, %4018)\n",
      "              %4020 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "              %4021 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4012, %4020)\n",
      "              %4022 : Long(*, *, device=cpu) = onnx::Add(%4021, %4019)\n",
      "              %4023 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4022)\n",
      "              %4024 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4023)\n",
      "              %4025 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4024)\n",
      "              %4026 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4027 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4025, %4026)\n",
      "              %4028 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4023, %4027)\n",
      "              %4029 : Long(2, strides=[1], device=cpu) = onnx::Where(%4028, %4025, %4023)\n",
      "              %4030 : LongTensor(device=cpu) = onnx::Expand(%4021, %4029)\n",
      "              %4031 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4032 : LongTensor(device=cpu) = onnx::Unsqueeze(%4030, %4031)\n",
      "              %4033 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4023)\n",
      "              %4034 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4033)\n",
      "              %4035 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4036 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4034, %4035)\n",
      "              %4037 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4023, %4036)\n",
      "              %4038 : Long(2, strides=[1], device=cpu) = onnx::Where(%4037, %4034, %4023)\n",
      "              %4039 : LongTensor(device=cpu) = onnx::Expand(%4019, %4038)\n",
      "              %4040 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4041 : LongTensor(device=cpu) = onnx::Unsqueeze(%4039, %4040)\n",
      "              %4042 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%4032, %4041)\n",
      "              %4043 : Long(2, strides=[1], device=cpu) = onnx::Shape(%3901)\n",
      "              %4044 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4045 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "              %4046 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4047 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4043, %4045, %4046, %4044)\n",
      "              %4048 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4023, %4047)\n",
      "              %4049 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4010, %4048)\n",
      "              %4050 : Long(*, *, device=cpu) = onnx::ScatterND(%3901, %4042, %4049) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:421:16\n",
      "              %eos_token_id.71 : Long(device=cpu) = onnx::Identity(%eos_token_id.74)\n",
      "              %pad_token_id.31 : Long(device=cpu) = onnx::Identity(%pad_token_id.34)\n",
      "              %4053 : FloatTensor(device=cpu)[] = onnx::Identity(%3902)\n",
      "              %4054 : LongTensor(device=cpu)[] = onnx::Identity(%3903)\n",
      "              %4055 : Float(*, device=cpu) = onnx::Identity(%3904)\n",
      "              %4056 : Long(*, device=cpu) = onnx::Identity(%3905)\n",
      "              %4057 : Bool(*, device=cpu) = onnx::Identity(%3906)\n",
      "              -> (%eos_token_id.71, %pad_token_id.31, %3962, %4006, %4050, %4053, %4054, %4055, %4056, %4057)\n",
      "            block1():\n",
      "              %4058 : Long(*, device=cpu) = onnx::Gather[axis=0](%3857, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:20\n",
      "              %4059 : Float(*, device=cpu) = onnx::Gather[axis=0](%3849, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:44\n",
      "              %4060 : Long(*, device=cpu) = onnx::Gather[axis=0](%3854, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:427:68\n",
      "              %4061 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4062 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4058)\n",
      "              %4063 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4062, %4061)\n",
      "              %4064 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4065 : Long(device=cpu) = onnx::Squeeze(%4063, %4064) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %4066 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4067 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4059)\n",
      "              %4068 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4067, %4066)\n",
      "              %4069 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4070 : Long(device=cpu) = onnx::Squeeze(%4068, %4069) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %4071 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4072 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4060)\n",
      "              %4073 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4072, %4071)\n",
      "              %4074 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4075 : Long(device=cpu) = onnx::Squeeze(%4073, %4074) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %4076 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4077 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%184, %4076)\n",
      "              %4078 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4079 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4065, %4078)\n",
      "              %4080 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4081 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4070, %4080)\n",
      "              %4082 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4083 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4075, %4082)\n",
      "              %4084 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%4077, %4079, %4081, %4083)\n",
      "              %4085 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%4084) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "              %4086 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4087 : Bool(device=cpu) = onnx::Greater(%4085, %4086)\n",
      "              %4088 : Long(device=cpu), %4089 : Long(device=cpu), %4090 : Long(device=cpu), %4091 : Float(*, device=cpu)[], %4092 : Long(*, device=cpu)[], %4093 : Float(*, device=cpu), %4094 : Long(*, device=cpu), %4095 : Float(*, *, device=cpu), %4096 : Long(*, *, device=cpu), %4097 : Long(*, *, device=cpu) = onnx::Loop(%184, %4087, %191, %eos_token_id.74, %191, %3902, %3903, %3904, %3905, %3899, %3900, %3901) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                block0(%4098 : Long(requires_grad=0, device=cpu), %cond.1 : Bool(device=cpu), %beam_idx.36 : Long(requires_grad=0, device=cpu), %eos_token_id.72 : Long(requires_grad=0, device=cpu), %4102 : Long(requires_grad=0, device=cpu), %4103 : Float(*, device=cpu)[], %4104 : Long(*, device=cpu)[], %4105 : Float(*, device=cpu), %4106 : Long(*, device=cpu), %4107 : Float(*, *, device=cpu), %4108 : Long(*, *, device=cpu), %4109 : Long(*, *, device=cpu)):\n",
      "                  %4110 : Long(device=cpu) = onnx::Gather[axis=0](%4058, %4102) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                  %4111 : Float(device=cpu) = onnx::Gather[axis=0](%4059, %4102) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:438:24\n",
      "                  %4112 : Long(device=cpu) = onnx::Gather[axis=0](%4060, %4102) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:426:12\n",
      "                  %4113 : Long(device=cpu) = onnx::Mul(%3898, %200) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:429:33\n",
      "                  %4114 : Long(device=cpu) = onnx::Add(%4112, %4113) # <string>:5:9\n",
      "                  %4115 : Bool(device=cpu) = onnx::Equal(%4110, %eos_token_id.72) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:431:20\n",
      "                  %4116 : Bool(device=cpu) = onnx::Cast[to=9](%4115)\n",
      "                  %4117 : Bool(device=cpu), %4118 : Bool(device=cpu), %4119 : Long(requires_grad=0, device=cpu), %4120 : Long(device=cpu), %4121 : Long(requires_grad=0, device=cpu), %4122 : Long(requires_grad=0, device=cpu), %4123 : Float(*, device=cpu)[], %4124 : Long(*, device=cpu)[], %4125 : Float(*, device=cpu), %4126 : Long(*, device=cpu), %4127 : Float(*, *, device=cpu), %4128 : Long(*, *, device=cpu), %4129 : Long(*, *, device=cpu) = onnx::If(%4116) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:431:16\n",
      "                    block0():\n",
      "                      %4130 : Bool(device=cpu) = onnx::GreaterOrEqual(%4102, %200) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:433:61\n",
      "                      %4131 : Bool(device=cpu) = onnx::Cast[to=9](%4130)\n",
      "                      %4132 : Bool(device=cpu), %4133 : Long(requires_grad=0, device=cpu), %4134 : Long(device=cpu), %4135 : Long(requires_grad=0, device=cpu), %4136 : Long(requires_grad=0, device=cpu), %4137 : Float(*, device=cpu)[], %4138 : Long(*, device=cpu)[], %4139 : Float(*, device=cpu), %4140 : Long(*, device=cpu) = onnx::If(%4131) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:434:20\n",
      "                        block0():\n",
      "                          %4141 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                          %beam_idx.38 : Long(requires_grad=0, device=cpu) = onnx::Identity(%beam_idx.36)\n",
      "                          %eos_token_id.67 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                          %4144 : FloatTensor(device=cpu)[] = onnx::Identity(%4103)\n",
      "                          %4145 : LongTensor(device=cpu)[] = onnx::Identity(%4104)\n",
      "                          %4146 : Float(*, device=cpu) = onnx::Identity(%4105)\n",
      "                          %4147 : Long(*, device=cpu) = onnx::Identity(%4106)\n",
      "                          %beam_idx.34 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%4141, %beam_idx.38, %eos_token_id.67, %beam_idx.34, %beam_idx.34, %4144, %4145, %4146, %4147)\n",
      "                        block1():\n",
      "                          %4149 : Long(*, device=cpu) = onnx::Gather[axis=0](%input_ids.25, %4114) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:437:24\n",
      "                          %4150 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4149) # <string>:7:9\n",
      "                          %4151 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4152 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                          %4153 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                          %4154 : Long(1, strides=[1], device=cpu) = onnx::Slice(%4150, %4152, %4153, %4151)\n",
      "                          %4155 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4156 : Long(device=cpu) = onnx::Squeeze(%4154, %4155) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "                          %4157 : Float(device=cpu) = onnx::Cast[to=1](%4156)\n",
      "                          %4158 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                          %4159 : Float(device=cpu) = onnx::Pow(%4157, %4158) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "                          %4160 : Float(device=cpu) = onnx::Div(%4111, %4159) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:16\n",
      "                          %4161 : Long(device=cpu) = onnx::Gather[axis=0](%4106, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "                          %4162 : Bool(device=cpu) = onnx::Less(%4161, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                          %4163 : Bool(device=cpu) = onnx::Cast[to=9](%4162)\n",
      "                          %4164 : Bool(device=cpu) = onnx::If(%4163) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                            block0():\n",
      "                              %4165 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                              -> (%4165)\n",
      "                            block1():\n",
      "                              %4166 : Float(device=cpu) = onnx::Gather[axis=0](%4105, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:50\n",
      "                              %4167 : Bool(device=cpu) = onnx::Less(%4166, %4160) # <string>:15:9\n",
      "                              -> (%4167)\n",
      "                          %4168 : Bool(device=cpu) = onnx::Cast[to=9](%4164)\n",
      "                          %4169 : Float(*, device=cpu)[], %4170 : Long(*, device=cpu)[], %4171 : Float(*, device=cpu), %4172 : Long(*, device=cpu) = onnx::If(%4168) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:8\n",
      "                            block0():\n",
      "                              %4173 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                              %4174 : Bool(device=cpu) = onnx::Equal(%3898, %4173)\n",
      "                              %4175 : Bool(device=cpu) = onnx::Not(%4174) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:63\n",
      "                              %4176 : Bool(device=cpu) = onnx::Cast[to=9](%4175)\n",
      "                              %4177 : LongTensor(device=cpu) = onnx::If(%4176) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                                block0():\n",
      "                                  %4178 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4179 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4180 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4178, %4179)\n",
      "                                  %4181 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4182 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4181)\n",
      "                                  %4183 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4184 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4183)\n",
      "                                  %4185 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4186 : LongTensor(device=cpu) = onnx::Slice(%4106, %4180, %4182, %4184, %4185) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:26\n",
      "                                  %4187 : LongTensor(device=cpu) = onnx::ReduceSum[keepdims=0](%4186) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                                  -> (%4187)\n",
      "                                block1():\n",
      "                                  %4188 : Long(requires_grad=0, device=cpu) = onnx::Identity(%178)\n",
      "                                  -> (%4188)\n",
      "                              %4189 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                              %4190 : Float(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4160, %4189)\n",
      "                              %4191 : Float(*, device=cpu) = onnx::Cast[to=1](%4190)\n",
      "                              %4192 : Float(*, device=cpu) = onnx::Concat[axis=0](%4191) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:47\n",
      "                              %4193 : Float(*, device=cpu)[] = onnx::SequenceInsert(%4103, %4192, %4177) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:12\n",
      "                              %4194 : Long(*, device=cpu)[] = onnx::SequenceInsert(%4104, %4149, %4177) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:366:12\n",
      "                              %4195 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                              %4196 : Long(device=cpu) = onnx::Add(%4161, %4195) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                              %4197 : Bool(device=cpu) = onnx::Greater(%4196, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                              %4198 : Bool(device=cpu) = onnx::Cast[to=9](%4197)\n",
      "                              %4199 : Long(*, device=cpu)[], %4200 : Float(*, device=cpu)[], %4201 : Float(*, device=cpu), %4202 : Long(*, device=cpu) = onnx::If(%4198) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:12\n",
      "                                block0():\n",
      "                                  %4203 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4193) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                                  %4204 : LongTensor(device=cpu) = onnx::Add(%4177, %4161) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                                  %4205 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4206 : LongTensor(device=cpu) = onnx::Add(%4204, %4205) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                                  %4207 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4208 : LongTensor(device=cpu) = onnx::Unsqueeze(%4177, %4207)\n",
      "                                  %4209 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4210 : LongTensor(device=cpu) = onnx::Unsqueeze(%4206, %4209)\n",
      "                                  %4211 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4212 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4211)\n",
      "                                  %4213 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4214 : Float(*, device=cpu) = onnx::Slice(%4203, %4208, %4210, %4212, %4213) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                                  %4215 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4216 : Long(device=cpu) = onnx::Add(%4161, %4215) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:88\n",
      "                                  %4217 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4218 : Long(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4216, %4217)\n",
      "                                  %4219 : Float(*, device=cpu), %4220 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=0, sorted=1](%4214, %4218) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:368:53\n",
      "                                  %4221 : Long(device=cpu) = onnx::Gather[axis=0](%4220, %191) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                                  %4222 : LongTensor(device=cpu) = onnx::Add(%4221, %4177) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                                  %4223 : Long(*, device=cpu)[] = onnx::SequenceErase(%4194, %4222) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:20\n",
      "                                  %4224 : Float(*, device=cpu)[] = onnx::SequenceErase(%4193, %4222) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:372:20\n",
      "                                  %4225 : Float(device=cpu) = onnx::Gather[axis=0](%4219, %189) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:57\n",
      "                                  %4226 : Float(device=cpu) = onnx::Gather[axis=0](%4105, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4227 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4226)\n",
      "                                  %4228 : Float(device=cpu) = onnx::Expand(%4225, %4227) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4229 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4230 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4229)\n",
      "                                  %4231 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4230)\n",
      "                                  %4232 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4233 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4230, %4232)\n",
      "                                  %4234 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4105)\n",
      "                                  %4235 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4236 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4237 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4238 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4234, %4236, %4237, %4235)\n",
      "                                  %4239 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4231, %4238)\n",
      "                                  %4240 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4239)\n",
      "                                  %4241 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4240)\n",
      "                                  %4242 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4243 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4241, %4242)\n",
      "                                  %4244 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4239, %4243)\n",
      "                                  %4245 : Long(1, strides=[1], device=cpu) = onnx::Where(%4244, %4241, %4239)\n",
      "                                  %4246 : FloatTensor(device=cpu) = onnx::Expand(%4228, %4245)\n",
      "                                  %4247 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4246, %4239)\n",
      "                                  %4248 : Float(*, device=cpu) = onnx::ScatterND(%4105, %4233, %4247) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                                  %4249 : Long(*, device=cpu) = onnx::Identity(%4106)\n",
      "                                  -> (%4223, %4224, %4248, %4249)\n",
      "                                block1():\n",
      "                                  %4250 : Float(device=cpu) = onnx::Gather[axis=0](%4105, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:68\n",
      "                                  %4251 : Float(device=cpu) = onnx::Min(%4160, %4250) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:57\n",
      "                                  %4252 : Float(device=cpu) = onnx::Gather[axis=0](%4105, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4253 : Float(device=cpu) = onnx::Cast[to=1](%4251)\n",
      "                                  %4254 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4252)\n",
      "                                  %4255 : Float(device=cpu) = onnx::Expand(%4253, %4254) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4256 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4257 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4256)\n",
      "                                  %4258 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4257)\n",
      "                                  %4259 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4260 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4257, %4259)\n",
      "                                  %4261 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4105)\n",
      "                                  %4262 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4263 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4264 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4265 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4261, %4263, %4264, %4262)\n",
      "                                  %4266 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4258, %4265)\n",
      "                                  %4267 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4266)\n",
      "                                  %4268 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4267)\n",
      "                                  %4269 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4270 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4268, %4269)\n",
      "                                  %4271 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4266, %4270)\n",
      "                                  %4272 : Long(1, strides=[1], device=cpu) = onnx::Where(%4271, %4268, %4266)\n",
      "                                  %4273 : FloatTensor(device=cpu) = onnx::Expand(%4255, %4272)\n",
      "                                  %4274 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4273, %4266)\n",
      "                                  %4275 : Float(*, device=cpu) = onnx::ScatterND(%4105, %4260, %4274) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                                  %4276 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4277 : Long(device=cpu) = onnx::Add(%4161, %4276) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:50\n",
      "                                  %4278 : Long(device=cpu) = onnx::Gather[axis=0](%4106, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4279 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4278)\n",
      "                                  %4280 : Long(device=cpu) = onnx::Expand(%4277, %4279) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4281 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4282 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4281)\n",
      "                                  %4283 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4282)\n",
      "                                  %4284 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4285 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4282, %4284)\n",
      "                                  %4286 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4106)\n",
      "                                  %4287 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                                  %4288 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                                  %4289 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                                  %4290 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4286, %4288, %4289, %4287)\n",
      "                                  %4291 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4283, %4290)\n",
      "                                  %4292 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4291)\n",
      "                                  %4293 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4292)\n",
      "                                  %4294 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                                  %4295 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4293, %4294)\n",
      "                                  %4296 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4291, %4295)\n",
      "                                  %4297 : Long(1, strides=[1], device=cpu) = onnx::Where(%4296, %4293, %4291)\n",
      "                                  %4298 : LongTensor(device=cpu) = onnx::Expand(%4280, %4297)\n",
      "                                  %4299 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4298, %4291)\n",
      "                                  %4300 : Long(*, device=cpu) = onnx::ScatterND(%4106, %4285, %4299) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                                  %4301 : Long(*, device=cpu)[] = onnx::Identity(%4194)\n",
      "                                  %4302 : Float(*, device=cpu)[] = onnx::Identity(%4193)\n",
      "                                  -> (%4301, %4302, %4275, %4300)\n",
      "                              -> (%4200, %4199, %4201, %4202)\n",
      "                            block1():\n",
      "                              %4303 : Float(*, device=cpu)[] = onnx::Identity(%4103)\n",
      "                              %4304 : Long(*, device=cpu)[] = onnx::Identity(%4104)\n",
      "                              %4305 : Float(*, device=cpu) = onnx::Identity(%4105)\n",
      "                              %4306 : Long(*, device=cpu) = onnx::Identity(%4106)\n",
      "                              -> (%4303, %4304, %4305, %4306)\n",
      "                          %beam_idx.40 : Long(requires_grad=0, device=cpu) = onnx::Identity(%beam_idx.36)\n",
      "                          %eos_token_id.68 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                          %4309 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %beam_idx.33 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%4309, %beam_idx.33, %beam_idx.33, %beam_idx.40, %eos_token_id.68, %4169, %4170, %4171, %4172)\n",
      "                      %4311 : Float(*, *, device=cpu) = onnx::Identity(%4107)\n",
      "                      %4312 : Long(*, *, device=cpu) = onnx::Identity(%4108)\n",
      "                      %4313 : Long(*, *, device=cpu) = onnx::Identity(%4109)\n",
      "                      -> (%4130, %4132, %4133, %4134, %4135, %4136, %4137, %4138, %4139, %4140, %4311, %4312, %4313)\n",
      "                    block1():\n",
      "                      %4314 : Float(*, device=cpu) = onnx::Gather[axis=0](%4107, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4315 : Float(device=cpu) = onnx::Gather[axis=0](%4314, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4316 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4315)\n",
      "                      %4317 : Float(device=cpu) = onnx::Expand(%4111, %4316) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4318 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4319 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4318)\n",
      "                      %4320 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4321 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4320)\n",
      "                      %4322 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4323 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4319, %4322)\n",
      "                      %4324 : Long(*, *, device=cpu) = onnx::Add(%4323, %4321)\n",
      "                      %4325 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4324)\n",
      "                      %4326 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4325)\n",
      "                      %4327 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4326)\n",
      "                      %4328 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4329 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4327, %4328)\n",
      "                      %4330 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4325, %4329)\n",
      "                      %4331 : Long(2, strides=[1], device=cpu) = onnx::Where(%4330, %4327, %4325)\n",
      "                      %4332 : Long(*, *, device=cpu) = onnx::Expand(%4323, %4331)\n",
      "                      %4333 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4334 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4332, %4333)\n",
      "                      %4335 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4325)\n",
      "                      %4336 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4335)\n",
      "                      %4337 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4338 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4336, %4337)\n",
      "                      %4339 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4325, %4338)\n",
      "                      %4340 : Long(2, strides=[1], device=cpu) = onnx::Where(%4339, %4336, %4325)\n",
      "                      %4341 : Long(*, *, device=cpu) = onnx::Expand(%4321, %4340)\n",
      "                      %4342 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4343 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4341, %4342)\n",
      "                      %4344 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4334, %4343)\n",
      "                      %4345 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4107)\n",
      "                      %4346 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4347 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4348 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4349 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4345, %4347, %4348, %4346)\n",
      "                      %4350 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4325, %4349)\n",
      "                      %4351 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4350)\n",
      "                      %4352 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4351)\n",
      "                      %4353 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4354 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4352, %4353)\n",
      "                      %4355 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4350, %4354)\n",
      "                      %4356 : Long(2, strides=[1], device=cpu) = onnx::Where(%4355, %4352, %4350)\n",
      "                      %4357 : FloatTensor(device=cpu) = onnx::Expand(%4317, %4356)\n",
      "                      %4358 : Float(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4357, %4350)\n",
      "                      %4359 : Float(*, *, device=cpu) = onnx::ScatterND(%4107, %4344, %4358) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:443:20\n",
      "                      %4360 : Long(*, device=cpu) = onnx::Gather[axis=0](%4108, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4361 : Long(device=cpu) = onnx::Gather[axis=0](%4360, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4362 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4361)\n",
      "                      %4363 : Long(device=cpu) = onnx::Expand(%4110, %4362) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4364 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4365 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4364)\n",
      "                      %4366 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4367 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4366)\n",
      "                      %4368 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4369 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4365, %4368)\n",
      "                      %4370 : Long(*, *, device=cpu) = onnx::Add(%4369, %4367)\n",
      "                      %4371 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4370)\n",
      "                      %4372 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4371)\n",
      "                      %4373 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4372)\n",
      "                      %4374 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4375 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4373, %4374)\n",
      "                      %4376 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4371, %4375)\n",
      "                      %4377 : Long(2, strides=[1], device=cpu) = onnx::Where(%4376, %4373, %4371)\n",
      "                      %4378 : Long(*, *, device=cpu) = onnx::Expand(%4369, %4377)\n",
      "                      %4379 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4380 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4378, %4379)\n",
      "                      %4381 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4371)\n",
      "                      %4382 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4381)\n",
      "                      %4383 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4384 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4382, %4383)\n",
      "                      %4385 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4371, %4384)\n",
      "                      %4386 : Long(2, strides=[1], device=cpu) = onnx::Where(%4385, %4382, %4371)\n",
      "                      %4387 : Long(*, *, device=cpu) = onnx::Expand(%4367, %4386)\n",
      "                      %4388 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4389 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4387, %4388)\n",
      "                      %4390 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4380, %4389)\n",
      "                      %4391 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4108)\n",
      "                      %4392 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4393 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4394 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4395 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4391, %4393, %4394, %4392)\n",
      "                      %4396 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4371, %4395)\n",
      "                      %4397 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4396)\n",
      "                      %4398 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4397)\n",
      "                      %4399 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4400 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4398, %4399)\n",
      "                      %4401 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4396, %4400)\n",
      "                      %4402 : Long(2, strides=[1], device=cpu) = onnx::Where(%4401, %4398, %4396)\n",
      "                      %4403 : LongTensor(device=cpu) = onnx::Expand(%4363, %4402)\n",
      "                      %4404 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4403, %4396)\n",
      "                      %4405 : Long(*, *, device=cpu) = onnx::ScatterND(%4108, %4390, %4404) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:444:20\n",
      "                      %4406 : Long(*, device=cpu) = onnx::Gather[axis=0](%4109, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4407 : Long(device=cpu) = onnx::Gather[axis=0](%4406, %beam_idx.36) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4408 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4407)\n",
      "                      %4409 : Long(device=cpu) = onnx::Expand(%4114, %4408) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4410 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4411 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4410)\n",
      "                      %4412 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4413 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%beam_idx.36, %4412)\n",
      "                      %4414 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "                      %4415 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4411, %4414)\n",
      "                      %4416 : Long(*, *, device=cpu) = onnx::Add(%4415, %4413)\n",
      "                      %4417 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4416)\n",
      "                      %4418 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4417)\n",
      "                      %4419 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4418)\n",
      "                      %4420 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4421 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4419, %4420)\n",
      "                      %4422 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4417, %4421)\n",
      "                      %4423 : Long(2, strides=[1], device=cpu) = onnx::Where(%4422, %4419, %4417)\n",
      "                      %4424 : Long(*, *, device=cpu) = onnx::Expand(%4415, %4423)\n",
      "                      %4425 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4426 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4424, %4425)\n",
      "                      %4427 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4417)\n",
      "                      %4428 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4427)\n",
      "                      %4429 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4430 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4428, %4429)\n",
      "                      %4431 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4417, %4430)\n",
      "                      %4432 : Long(2, strides=[1], device=cpu) = onnx::Where(%4431, %4428, %4417)\n",
      "                      %4433 : Long(*, *, device=cpu) = onnx::Expand(%4413, %4432)\n",
      "                      %4434 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4435 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%4433, %4434)\n",
      "                      %4436 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%4426, %4435)\n",
      "                      %4437 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4109)\n",
      "                      %4438 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4439 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "                      %4440 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4441 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4437, %4439, %4440, %4438)\n",
      "                      %4442 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4417, %4441)\n",
      "                      %4443 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4442)\n",
      "                      %4444 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4443)\n",
      "                      %4445 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4446 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4444, %4445)\n",
      "                      %4447 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4442, %4446)\n",
      "                      %4448 : Long(2, strides=[1], device=cpu) = onnx::Where(%4447, %4444, %4442)\n",
      "                      %4449 : LongTensor(device=cpu) = onnx::Expand(%4409, %4448)\n",
      "                      %4450 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4449, %4442)\n",
      "                      %4451 : Long(*, *, device=cpu) = onnx::ScatterND(%4109, %4436, %4450) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:445:20\n",
      "                      %4452 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4453 : Long(device=cpu) = onnx::Add(%beam_idx.36, %4452) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:446:20\n",
      "                      %4454 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%188)\n",
      "                      %eos_token_id.70 : Long(device=cpu) = onnx::Identity(%eos_token_id.72)\n",
      "                      %4456 : Float(*, device=cpu)[] = onnx::Identity(%4103)\n",
      "                      %4457 : Long(*, device=cpu)[] = onnx::Identity(%4104)\n",
      "                      %4458 : Float(*, device=cpu) = onnx::Identity(%4105)\n",
      "                      %4459 : Long(*, device=cpu) = onnx::Identity(%4106)\n",
      "                      %4460 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4461 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      -> (%4454, %4460, %4461, %4461, %4453, %eos_token_id.70, %4456, %4457, %4458, %4459, %4359, %4405, %4451)\n",
      "                  %4462 : Bool(device=cpu) = onnx::Cast[to=9](%4117)\n",
      "                  %4463 : Bool(device=cpu), %4464 : Bool(device=cpu), %4465 : Long(device=cpu), %4466 : Long(device=cpu), %4467 : Bool(device=cpu), %4468 : Long(device=cpu), %4469 : Long(device=cpu) = onnx::If(%4462)\n",
      "                    block0():\n",
      "                      %4470 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                      %4471 : Bool(device=cpu) = onnx::Identity(%4118)\n",
      "                      %4472 : Long(device=cpu) = onnx::Identity(%4119)\n",
      "                      %4473 : Long(device=cpu) = onnx::Identity(%4120)\n",
      "                      %4474 : Bool(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4475 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4476 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      -> (%4470, %4471, %4472, %4473, %4474, %4475, %4476)\n",
      "                    block1():\n",
      "                      %4477 : Bool(device=cpu) = onnx::Equal(%4121, %200) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:449:19\n",
      "                      %4478 : Bool(device=cpu) = onnx::Cast[to=9](%4477)\n",
      "                      %4479 : Bool(requires_grad=0, device=cpu), %4480 : Long(device=cpu), %4481 : Long(device=cpu) = onnx::If(%4478) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:449:16\n",
      "                        block0():\n",
      "                          %4482 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%188)\n",
      "                          %4483 : Long(device=cpu) = onnx::Identity(%4121)\n",
      "                          %4484 : Long(device=cpu) = onnx::Identity(%4122)\n",
      "                          -> (%4482, %4483, %4484)\n",
      "                        block1():\n",
      "                          %4485 : Bool(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4486 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          %4487 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                          -> (%4485, %4486, %4487)\n",
      "                      %4488 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                      %4489 : Long(device=cpu) = onnx::Identity(%4121)\n",
      "                      %4490 : Long(device=cpu) = onnx::Identity(%4122)\n",
      "                      -> (%4477, %4479, %4480, %4481, %4488, %4489, %4490)\n",
      "                  %4491 : Bool(device=cpu) = onnx::Cast[to=9](%4463)\n",
      "                  %4492 : Bool(device=cpu), %4493 : Long(device=cpu), %4494 : Long(device=cpu) = onnx::If(%4491)\n",
      "                    block0():\n",
      "                      %4495 : Bool(device=cpu) = onnx::Identity(%4464)\n",
      "                      %4496 : Long(device=cpu) = onnx::Identity(%4465)\n",
      "                      %4497 : Long(device=cpu) = onnx::Identity(%4466)\n",
      "                      -> (%4495, %4496, %4497)\n",
      "                    block1():\n",
      "                      %4498 : Bool(device=cpu) = onnx::Identity(%4467)\n",
      "                      %4499 : Long(device=cpu) = onnx::Identity(%4468)\n",
      "                      %4500 : Long(device=cpu) = onnx::Identity(%4469)\n",
      "                      -> (%4498, %4499, %4500)\n",
      "                  %4501 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4502 : Long(device=cpu) = onnx::Add(%4102, %4501)\n",
      "                  %4503 : Bool(device=cpu) = onnx::Less(%4502, %4085)\n",
      "                  %4504 : Bool(device=cpu) = onnx::Cast[to=9](%4503)\n",
      "                  %4505 : Bool(device=cpu) = onnx::Cast[to=9](%4492)\n",
      "                  %4506 : Bool(device=cpu) = onnx::And(%4504, %4505)\n",
      "                  %4507 : Bool(device=cpu) = onnx::Cast[to=9](%4506)\n",
      "                  -> (%4507, %4493, %4494, %4502, %4123, %4124, %4125, %4126, %4127, %4128, %4129)\n",
      "              %4508 : Bool(device=cpu) = onnx::Gather[axis=0](%3906, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:36\n",
      "              %4509 : Bool(device=cpu) = onnx::Cast[to=9](%4508)\n",
      "              %4510 : Bool(device=cpu) = onnx::If(%4509) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:36\n",
      "                block0():\n",
      "                  %4511 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                  -> (%4511)\n",
      "                block1():\n",
      "                  %4512 : Long(device=cpu) = onnx::Gather[axis=0](%4094, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "                  %4513 : Bool(device=cpu) = onnx::Less(%4512, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:383:11\n",
      "                  %4514 : Bool(device=cpu) = onnx::Cast[to=9](%4513)\n",
      "                  %4515 : Bool(requires_grad=0, device=cpu) = onnx::If(%4514) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:383:8\n",
      "                    block0():\n",
      "                      %4516 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%188)\n",
      "                      -> (%4516)\n",
      "                    block1():\n",
      "                      %4517 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                      -> (%4517)\n",
      "                  -> (%4515)\n",
      "              %4518 : Bool(device=cpu) = onnx::Gather[axis=0](%3906, %3898) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %4519 : Bool(device=cpu) = onnx::Cast[to=9](%4510)\n",
      "              %4520 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4518)\n",
      "              %4521 : Bool(device=cpu) = onnx::Expand(%4519, %4520) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %4522 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4523 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%3898, %4522)\n",
      "              %4524 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4523)\n",
      "              %4525 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4526 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4523, %4525)\n",
      "              %4527 : Long(1, strides=[1], device=cpu) = onnx::Shape(%3906)\n",
      "              %4528 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4529 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4530 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4531 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4527, %4529, %4530, %4528)\n",
      "              %4532 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4524, %4531)\n",
      "              %4533 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4532)\n",
      "              %4534 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4533)\n",
      "              %4535 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4536 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4534, %4535)\n",
      "              %4537 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4532, %4536)\n",
      "              %4538 : Long(1, strides=[1], device=cpu) = onnx::Where(%4537, %4534, %4532)\n",
      "              %4539 : BoolTensor(device=cpu) = onnx::Expand(%4521, %4538)\n",
      "              %4540 : Bool(*, device=cpu) = onnx::Reshape[allowzero=0](%4539, %4532)\n",
      "              %4541 : Bool(*, device=cpu) = onnx::ScatterND(%3906, %4526, %4540) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:458:12\n",
      "              %pad_token_id.32 : Long(device=cpu) = onnx::Identity(%pad_token_id.34)\n",
      "              -> (%4089, %pad_token_id.32, %4095, %4096, %4097, %4091, %4092, %4093, %4094, %4541)\n",
      "          %4543 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4544 : Long(device=cpu) = onnx::Add(%3898, %4543)\n",
      "          %4545 : Bool(device=cpu) = onnx::Less(%4544, %3862)\n",
      "          %4546 : Bool(device=cpu) = onnx::Cast[to=9](%4545)\n",
      "          %4547 : Bool(device=cpu) = onnx::Cast[to=9](%187)\n",
      "          %4548 : Bool(device=cpu) = onnx::And(%4546, %4547)\n",
      "          %4549 : Bool(device=cpu) = onnx::Cast[to=9](%4548)\n",
      "          -> (%4549, %3909, %3910, %4544, %3911, %3912, %3913, %3914, %3915, %3916, %3917, %3918)\n",
      "      %4550 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4551 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%3886, %4550) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:15\n",
      "      %4552 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4553 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%3887, %4552) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:42\n",
      "      %4554 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4555 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%3888, %4554) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:464:69\n",
      "      %4556 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%input_ids.25, %4555) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:785:35\n",
      "      %4557 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4558 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4553, %4557) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:785:59\n",
      "      %4559 : Long(*, *, device=cpu) = onnx::Concat[axis=-1](%4556, %4558) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:785:24\n",
      "      %4560 : Long(*, *, device=cpu) = onnx::Gather[axis=0](%attention_mask.13, %4555) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:786:40\n",
      "      %4561 : Long(2, strides=[1], device=cpu) = onnx::Shape(%attention_mask.13) # <string>:7:9\n",
      "      %4562 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4563 : Long(device=cpu) = onnx::Gather[axis=0](%4561, %4562) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:786:80\n",
      "      %4564 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4565 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4563, %4564)\n",
      "      %4566 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4565)\n",
      "      %4567 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%4566) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:786:69\n",
      "      %4568 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4569 : Long(*, 1, device=cpu) = onnx::Unsqueeze(%4567, %4568) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:786:69\n",
      "      %4570 : Long(*, *, device=cpu) = onnx::Concat[axis=-1](%4560, %4569) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:786:29\n",
      "      %4571 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4572 : Long(device=cpu) = onnx::Add(%cur_len.13, %4571) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:788:22\n",
      "      %4573 : Bool(*, device=cpu) = onnx::Not(%3893)\n",
      "      %4574 : Long(*, device=cpu) = onnx::Cast[to=7](%4573)\n",
      "      %4575 : Long(device=cpu) = onnx::ReduceSum[keepdims=0, noop_with_empty_axes=0](%4574)\n",
      "      %4576 : Long(1, strides=[1], requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4577 : Bool(*, strides=[1], device=cpu) = onnx::Greater(%4575, %4576)\n",
      "      %4578 : Bool(*, device=cpu) = onnx::Not(%4577) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:304:15\n",
      "      %4579 : Bool(*, device=cpu) = onnx::Cast[to=9](%4578)\n",
      "      %4580 : Bool(requires_grad=0, device=cpu) = onnx::If(%4579) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:793:12\n",
      "        block0():\n",
      "          %4581 : Bool(requires_grad=0, device=cpu) = onnx::Identity(%188)\n",
      "          -> (%4581)\n",
      "        block1():\n",
      "          %4582 : Bool(device=cpu) = onnx::Greater(%max_length, %4572) # <string>:11:9\n",
      "          -> (%4582)\n",
      "      -> (%4580, %4559, %4551, %4570, %4572, %3889, %3890, %3891, %3892, %3893)\n",
      "  %4583 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4584 : Long(1, strides=[1], device=cpu) = onnx::Shape(%325)\n",
      "  %4585 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4584, %4583)\n",
      "  %4586 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4587 : Long(device=cpu) = onnx::Squeeze(%4585, %4586) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:475:21\n",
      "  %4588 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4589 : Bool(device=cpu) = onnx::Greater(%4587, %4588)\n",
      "  %4590 : Long(device=cpu), %4591 : Float(*, device=cpu)[], %4592 : Long(*, device=cpu)[], %4593 : Float(*, device=cpu), %4594 : Long(*, device=cpu) = onnx::Loop(%184, %4589, %191, %322, %323, %324, %325) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:478:8\n",
      "    block0(%4595 : Long(requires_grad=0, device=cpu), %cond.9 : Bool(device=cpu), %4597 : Long(requires_grad=0, device=cpu), %4598 : Float(*, device=cpu)[], %4599 : Long(*, device=cpu)[], %4600 : Float(*, device=cpu), %4601 : Long(*, device=cpu)):\n",
      "      %4602 : Bool(device=cpu) = onnx::Gather[axis=0](%326, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:479:15\n",
      "      %4603 : Bool(device=cpu) = onnx::Cast[to=9](%4602)\n",
      "      %4604 : Float(*, device=cpu)[], %4605 : Long(*, device=cpu)[], %4606 : Float(*, device=cpu), %4607 : Long(*, device=cpu) = onnx::If(%4603) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:479:12\n",
      "        block0():\n",
      "          %4608 : Float(*, device=cpu)[] = onnx::Identity(%4598)\n",
      "          %4609 : Long(*, device=cpu)[] = onnx::Identity(%4599)\n",
      "          %4610 : Float(*, device=cpu) = onnx::Identity(%4600)\n",
      "          %4611 : Long(*, device=cpu) = onnx::Identity(%4601)\n",
      "          -> (%4608, %4609, %4610, %4611)\n",
      "        block1():\n",
      "          %4612 : Float(*, device=cpu)[], %4613 : Long(*, device=cpu)[], %4614 : Float(*, device=cpu), %4615 : Long(*, device=cpu) = onnx::Loop(%num_beams, %187, %4598, %4599, %4600, %4601) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:484:12\n",
      "            block0(%beam_id.1 : Long(device=cpu), %cond.7 : Bool(device=cpu), %4618 : Float(*, device=cpu)[], %4619 : Long(*, device=cpu)[], %4620 : Float(*, device=cpu), %4621 : Long(*, device=cpu)):\n",
      "              %4622 : Long(device=cpu) = onnx::Mul(%4597, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:485:33\n",
      "              %4623 : Long(device=cpu) = onnx::Add(%4622, %beam_id.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:485:33\n",
      "              %4624 : Float(device=cpu) = onnx::Gather[axis=0](%319, %4623) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:486:30\n",
      "              %4625 : Long(*, device=cpu) = onnx::Gather[axis=0](%318, %4623) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:487:31\n",
      "              %4626 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4625) # <string>:7:9\n",
      "              %4627 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4628 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "              %4629 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "              %4630 : Long(1, strides=[1], device=cpu) = onnx::Slice(%4626, %4628, %4629, %4627)\n",
      "              %4631 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "              %4632 : Long(device=cpu) = onnx::Squeeze(%4630, %4631) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "              %4633 : Float(device=cpu) = onnx::Cast[to=1](%4632)\n",
      "              %4634 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "              %4635 : Float(device=cpu) = onnx::Pow(%4633, %4634) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:32\n",
      "              %4636 : Float(device=cpu) = onnx::Div(%4624, %4635) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:357:16\n",
      "              %4637 : Long(device=cpu) = onnx::Gather[axis=0](%4621, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:351:15\n",
      "              %4638 : Bool(device=cpu) = onnx::Less(%4637, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "              %4639 : Bool(device=cpu) = onnx::Cast[to=9](%4638)\n",
      "              %4640 : Bool(device=cpu) = onnx::If(%4639) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:11\n",
      "                block0():\n",
      "                  %4641 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "                  -> (%4641)\n",
      "                block1():\n",
      "                  %4642 : Float(device=cpu) = onnx::Gather[axis=0](%4620, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:50\n",
      "                  %4643 : Bool(device=cpu) = onnx::Less(%4642, %4636) # <string>:15:9\n",
      "                  -> (%4643)\n",
      "              %4644 : Bool(device=cpu) = onnx::Cast[to=9](%4640)\n",
      "              %4645 : Float(*, device=cpu)[], %4646 : Long(*, device=cpu)[], %4647 : Float(*, device=cpu), %4648 : Long(*, device=cpu) = onnx::If(%4644) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:359:8\n",
      "                block0():\n",
      "                  %4649 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "                  %4650 : Bool(device=cpu) = onnx::Equal(%4597, %4649)\n",
      "                  %4651 : Bool(device=cpu) = onnx::Not(%4650) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:63\n",
      "                  %4652 : Bool(device=cpu) = onnx::Cast[to=9](%4651)\n",
      "                  %4653 : LongTensor(device=cpu) = onnx::If(%4652) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                    block0():\n",
      "                      %4654 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4655 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4656 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4654, %4655)\n",
      "                      %4657 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4658 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4597, %4657)\n",
      "                      %4659 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4660 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4659)\n",
      "                      %4661 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4662 : LongTensor(device=cpu) = onnx::Slice(%4621, %4656, %4658, %4660, %4661) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:26\n",
      "                      %4663 : LongTensor(device=cpu) = onnx::ReduceSum[keepdims=0](%4662) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:363:16\n",
      "                      -> (%4663)\n",
      "                    block1():\n",
      "                      %4664 : Long(requires_grad=0, device=cpu) = onnx::Identity(%178)\n",
      "                      -> (%4664)\n",
      "                  %4665 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4666 : Float(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4636, %4665)\n",
      "                  %4667 : Float(*, device=cpu) = onnx::Cast[to=1](%4666)\n",
      "                  %4668 : Float(*, device=cpu) = onnx::Concat[axis=0](%4667) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:47\n",
      "                  %4669 : Float(*, device=cpu)[] = onnx::SequenceInsert(%4618, %4668, %4653) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:365:12\n",
      "                  %4670 : Long(*, device=cpu)[] = onnx::SequenceInsert(%4619, %4625, %4653) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:366:12\n",
      "                  %4671 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                  %4672 : Long(device=cpu) = onnx::Add(%4637, %4671) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                  %4673 : Bool(device=cpu) = onnx::Greater(%4672, %num_beams) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:15\n",
      "                  %4674 : Bool(device=cpu) = onnx::Cast[to=9](%4673)\n",
      "                  %4675 : Long(*, device=cpu)[], %4676 : Float(*, device=cpu)[], %4677 : Float(*, device=cpu), %4678 : Long(*, device=cpu) = onnx::If(%4674) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:367:12\n",
      "                    block0():\n",
      "                      %4679 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4669) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                      %4680 : LongTensor(device=cpu) = onnx::Add(%4653, %4637) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                      %4681 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4682 : LongTensor(device=cpu) = onnx::Add(%4680, %4681) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:60\n",
      "                      %4683 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4684 : LongTensor(device=cpu) = onnx::Unsqueeze(%4653, %4683)\n",
      "                      %4685 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4686 : LongTensor(device=cpu) = onnx::Unsqueeze(%4682, %4685)\n",
      "                      %4687 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4688 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4687)\n",
      "                      %4689 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4690 : Float(*, device=cpu) = onnx::Slice(%4679, %4684, %4686, %4688, %4689) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:20\n",
      "                      %4691 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4692 : Long(device=cpu) = onnx::Add(%4637, %4691) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:369:88\n",
      "                      %4693 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4694 : Long(*, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4692, %4693)\n",
      "                      %4695 : Float(*, device=cpu), %4696 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=0, sorted=1](%4690, %4694) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:368:53\n",
      "                      %4697 : Long(device=cpu) = onnx::Gather[axis=0](%4696, %191) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                      %4698 : LongTensor(device=cpu) = onnx::Add(%4697, %4653) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:41\n",
      "                      %4699 : Long(*, device=cpu)[] = onnx::SequenceErase(%4670, %4698) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:371:20\n",
      "                      %4700 : Float(*, device=cpu)[] = onnx::SequenceErase(%4669, %4698) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:372:20\n",
      "                      %4701 : Float(device=cpu) = onnx::Gather[axis=0](%4695, %189) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:57\n",
      "                      %4702 : Float(device=cpu) = onnx::Gather[axis=0](%4620, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4703 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4702)\n",
      "                      %4704 : Float(device=cpu) = onnx::Expand(%4701, %4703) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4705 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4706 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4597, %4705)\n",
      "                      %4707 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4706)\n",
      "                      %4708 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4709 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4706, %4708)\n",
      "                      %4710 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4620)\n",
      "                      %4711 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4712 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4713 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4714 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4710, %4712, %4713, %4711)\n",
      "                      %4715 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4707, %4714)\n",
      "                      %4716 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4715)\n",
      "                      %4717 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4716)\n",
      "                      %4718 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4719 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4717, %4718)\n",
      "                      %4720 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4715, %4719)\n",
      "                      %4721 : Long(1, strides=[1], device=cpu) = onnx::Where(%4720, %4717, %4715)\n",
      "                      %4722 : FloatTensor(device=cpu) = onnx::Expand(%4704, %4721)\n",
      "                      %4723 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4722, %4715)\n",
      "                      %4724 : Float(*, device=cpu) = onnx::ScatterND(%4620, %4709, %4723) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:373:16\n",
      "                      %4725 : Long(*, device=cpu) = onnx::Identity(%4621)\n",
      "                      -> (%4699, %4700, %4724, %4725)\n",
      "                    block1():\n",
      "                      %4726 : Float(device=cpu) = onnx::Gather[axis=0](%4620, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:68\n",
      "                      %4727 : Float(device=cpu) = onnx::Min(%4636, %4726) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:57\n",
      "                      %4728 : Float(device=cpu) = onnx::Gather[axis=0](%4620, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4729 : Float(device=cpu) = onnx::Cast[to=1](%4727)\n",
      "                      %4730 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4728)\n",
      "                      %4731 : Float(device=cpu) = onnx::Expand(%4729, %4730) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4732 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4733 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4597, %4732)\n",
      "                      %4734 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4733)\n",
      "                      %4735 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4736 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4733, %4735)\n",
      "                      %4737 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4620)\n",
      "                      %4738 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4739 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4740 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4741 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4737, %4739, %4740, %4738)\n",
      "                      %4742 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4734, %4741)\n",
      "                      %4743 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4742)\n",
      "                      %4744 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4743)\n",
      "                      %4745 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4746 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4744, %4745)\n",
      "                      %4747 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4742, %4746)\n",
      "                      %4748 : Long(1, strides=[1], device=cpu) = onnx::Where(%4747, %4744, %4742)\n",
      "                      %4749 : FloatTensor(device=cpu) = onnx::Expand(%4731, %4748)\n",
      "                      %4750 : Float(*, device=cpu) = onnx::Reshape[allowzero=0](%4749, %4742)\n",
      "                      %4751 : Float(*, device=cpu) = onnx::ScatterND(%4620, %4736, %4750) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:375:16\n",
      "                      %4752 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4753 : Long(device=cpu) = onnx::Add(%4637, %4752) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:50\n",
      "                      %4754 : Long(device=cpu) = onnx::Gather[axis=0](%4621, %4597) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4755 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4754)\n",
      "                      %4756 : Long(device=cpu) = onnx::Expand(%4753, %4755) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4757 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4758 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4597, %4757)\n",
      "                      %4759 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4758)\n",
      "                      %4760 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4761 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4758, %4760)\n",
      "                      %4762 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4621)\n",
      "                      %4763 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "                      %4764 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "                      %4765 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "                      %4766 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4762, %4764, %4765, %4763)\n",
      "                      %4767 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4759, %4766)\n",
      "                      %4768 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4767)\n",
      "                      %4769 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4768)\n",
      "                      %4770 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "                      %4771 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4769, %4770)\n",
      "                      %4772 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4767, %4771)\n",
      "                      %4773 : Long(1, strides=[1], device=cpu) = onnx::Where(%4772, %4769, %4767)\n",
      "                      %4774 : LongTensor(device=cpu) = onnx::Expand(%4756, %4773)\n",
      "                      %4775 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4774, %4767)\n",
      "                      %4776 : Long(*, device=cpu) = onnx::ScatterND(%4621, %4761, %4775) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:376:16\n",
      "                      %4777 : Long(*, device=cpu)[] = onnx::Identity(%4670)\n",
      "                      %4778 : Float(*, device=cpu)[] = onnx::Identity(%4669)\n",
      "                      -> (%4777, %4778, %4751, %4776)\n",
      "                  -> (%4676, %4675, %4677, %4678)\n",
      "                block1():\n",
      "                  %4779 : Float(*, device=cpu)[] = onnx::Identity(%4618)\n",
      "                  %4780 : Long(*, device=cpu)[] = onnx::Identity(%4619)\n",
      "                  %4781 : Float(*, device=cpu) = onnx::Identity(%4620)\n",
      "                  %4782 : Long(*, device=cpu) = onnx::Identity(%4621)\n",
      "                  -> (%4779, %4780, %4781, %4782)\n",
      "              %4783 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "              -> (%4783, %4645, %4646, %4647, %4648)\n",
      "          -> (%4612, %4613, %4614, %4615)\n",
      "      %4784 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4785 : Long(device=cpu) = onnx::Add(%4597, %4784)\n",
      "      %4786 : Bool(device=cpu) = onnx::Less(%4785, %4587)\n",
      "      %4787 : Bool(device=cpu) = onnx::Cast[to=9](%4786)\n",
      "      %4788 : Bool(device=cpu) = onnx::Cast[to=9](%187)\n",
      "      %4789 : Bool(device=cpu) = onnx::And(%4787, %4788)\n",
      "      %4790 : Bool(device=cpu) = onnx::Cast[to=9](%4789)\n",
      "      -> (%4790, %4785, %4604, %4605, %4606, %4607)\n",
      "  %4791 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4792 : Long(device=cpu) = onnx::Mul(%4587, %4791) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:492:35\n",
      "  %4793 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4794 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4792, %4793)\n",
      "  %4795 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4794)\n",
      "  %4796 : Long(*, device=cpu) = onnx::ConstantOfShape[value={0}](%4795) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:492:23\n",
      "  %best.1 : Long(*, device=cpu)[] = onnx::SequenceEmpty[dtype=7]()\n",
      "  %4798 : Long(*, device=cpu), %4799 : Long(*, device=cpu)[] = onnx::Loop(%4587, %187, %4796, %best.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:498:8\n",
      "    block0(%i.1 : Long(device=cpu), %cond.13 : Bool(device=cpu), %4802 : Long(*, device=cpu), %4803 : Long(*, device=cpu)[]):\n",
      "      %4804 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4805 : Bool(device=cpu) = onnx::Greater(%i.1, %4804) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:71\n",
      "      %4806 : Bool(device=cpu) = onnx::Cast[to=9](%4805)\n",
      "      %4807 : Long(device=cpu) = onnx::If(%4806) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:31\n",
      "        block0():\n",
      "          %4808 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4809 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4810 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4808, %4809)\n",
      "          %4811 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4812 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.1, %4811)\n",
      "          %4813 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4814 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4813)\n",
      "          %4815 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4816 : Long(*, device=cpu) = onnx::Slice(%4594, %4810, %4812, %4814, %4815) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:41\n",
      "          %4817 : Long(device=cpu) = onnx::ReduceSum[keepdims=0](%4816) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:500:31\n",
      "          -> (%4817)\n",
      "        block1():\n",
      "          %4818 : Long(requires_grad=0, device=cpu) = onnx::Identity(%178)\n",
      "          -> (%4818)\n",
      "      %4819 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4820 : Long(device=cpu) = onnx::Add(%i.1, %4819) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:63\n",
      "      %4821 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4822 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4823 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4821, %4822)\n",
      "      %4824 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4825 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4820, %4824)\n",
      "      %4826 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4827 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4826)\n",
      "      %4828 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4829 : Long(*, device=cpu) = onnx::Slice(%4594, %4823, %4825, %4827, %4828) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:39\n",
      "      %4830 : Long(device=cpu) = onnx::ReduceSum[keepdims=0](%4829) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:501:29\n",
      "      %4831 : Float(*, device=cpu) = onnx::ConcatFromSequence[axis=0](%4591) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:502:26\n",
      "      %4832 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4833 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4807, %4832)\n",
      "      %4834 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4835 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4830, %4834)\n",
      "      %4836 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4837 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4836)\n",
      "      %4838 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4839 : Float(*, device=cpu) = onnx::Slice(%4831, %4833, %4835, %4837, %4838) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:502:26\n",
      "      %4840 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4841 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4839)\n",
      "      %4842 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4841, %4840)\n",
      "      %4843 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4844 : Long(device=cpu) = onnx::Squeeze(%4842, %4843) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:503:73\n",
      "      %4845 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4846 : Long(1, strides=[1], device=cpu) = onnx::Reshape[allowzero=0](%4844, %4845)\n",
      "      %4847 : Float(*, device=cpu), %4848 : Long(*, device=cpu) = onnx::TopK[axis=-1, largest=1, sorted=1](%4839, %4846) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:503:49\n",
      "      %4849 : Long(*, device=cpu), %4850 : Long(*, device=cpu)[] = onnx::Loop(%189, %187, %4802, %4803) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:504:12\n",
      "        block0(%j.1 : Long(device=cpu), %cond.11 : Bool(device=cpu), %4853 : Long(*, device=cpu), %4854 : Long(*, device=cpu)[]):\n",
      "          %4855 : Long(device=cpu) = onnx::Gather[axis=0](%4848, %j.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:62\n",
      "          %4856 : Long(device=cpu) = onnx::Add(%4807, %4855) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:43\n",
      "          %4857 : Long(*, device=cpu) = onnx::SequenceAt(%4592, %4856) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:506:27\n",
      "          %4858 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4859 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4857)\n",
      "          %4860 : Long(1, strides=[1], device=cpu) = onnx::Gather[axis=0](%4859, %4858)\n",
      "          %4861 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4862 : Long(device=cpu) = onnx::Squeeze(%4860, %4861) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:67\n",
      "          %4863 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4864 : Long(device=cpu) = onnx::Mul(%4863, %i.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:29\n",
      "          %4865 : Long(device=cpu) = onnx::Add(%4864, %j.1) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:29\n",
      "          %4866 : Long(device=cpu) = onnx::Gather[axis=0](%4853, %4865) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4867 : Long(device=cpu) = onnx::Cast[to=7](%4862)\n",
      "          %4868 : Long(0, strides=[1], device=cpu) = onnx::Shape(%4866)\n",
      "          %4869 : Long(device=cpu) = onnx::Expand(%4867, %4868) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4870 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4871 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4865, %4870)\n",
      "          %4872 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4871)\n",
      "          %4873 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4874 : Long(*, *, device=cpu) = onnx::Unsqueeze(%4871, %4873)\n",
      "          %4875 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4853)\n",
      "          %4876 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4877 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "          %4878 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %4879 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4875, %4877, %4878, %4876)\n",
      "          %4880 : Long(1, strides=[1], device=cpu) = onnx::Concat[axis=0](%4872, %4879)\n",
      "          %4881 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4880)\n",
      "          %4882 : Long(1, device=cpu) = onnx::ConstantOfShape[value={1}](%4881)\n",
      "          %4883 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %4884 : Long(1, strides=[1], device=cpu) = onnx::Mul(%4882, %4883)\n",
      "          %4885 : Bool(1, strides=[1], device=cpu) = onnx::Equal(%4880, %4884)\n",
      "          %4886 : Long(1, strides=[1], device=cpu) = onnx::Where(%4885, %4882, %4880)\n",
      "          %4887 : LongTensor(device=cpu) = onnx::Expand(%4869, %4886)\n",
      "          %4888 : Long(*, device=cpu) = onnx::Reshape[allowzero=0](%4887, %4880)\n",
      "          %4889 : Long(*, device=cpu) = onnx::ScatterND(%4853, %4874, %4888) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:507:16\n",
      "          %4890 : Long(*, device=cpu)[] = onnx::SequenceInsert(%4854, %4857) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:509:16\n",
      "          %4891 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "          -> (%4891, %4889, %4890)\n",
      "      %4892 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "      -> (%4892, %4849, %4850)\n",
      "  %4893 : Long(device=cpu) = onnx::ReduceMax[keepdims=0](%4798) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:27\n",
      "  %4894 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4895 : Long(device=cpu) = onnx::Add(%4893, %4894) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:27\n",
      "  %4896 : Long(device=cpu) = onnx::Min(%4895, %max_length) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:513:23\n",
      "  %4897 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %4898 : Long(device=cpu) = onnx::Mul(%4587, %4897) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:514:30\n",
      "  %4899 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4900 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4898, %4899)\n",
      "  %4901 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4902 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4896, %4901)\n",
      "  %4903 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4900, %4902)\n",
      "  %4904 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%4903) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:514:18\n",
      "  %4905 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%4798) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:11\n",
      "  %4906 : Long(device=cpu) = onnx::ReduceMax[keepdims=0](%4798) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:33\n",
      "  %4907 : Bool(device=cpu) = onnx::Equal(%4905, %4906)\n",
      "  %4908 : Bool(device=cpu) = onnx::Not(%4907) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:11\n",
      "  %4909 : Bool(device=cpu) = onnx::Cast[to=9](%4908)\n",
      "  %4910 : Long(*, *, device=cpu) = onnx::If(%4909) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:516:8\n",
      "    block0():\n",
      "      %4911 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4904)\n",
      "      %4912 : Long(*, *, device=cpu) = onnx::ConstantOfShape[value={0}](%4911) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:518:12\n",
      "      -> (%4912)\n",
      "    block1():\n",
      "      %4913 : Long(*, *, device=cpu) = onnx::Identity(%4904)\n",
      "      -> (%4913)\n",
      "  %4914 : Long(device=cpu) = onnx::SequenceLength(%4799) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "  %4917 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "  %4918 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4914, %4917)\n",
      "  %4919 : Long(2, device=cpu) = onnx::Concat[axis=0](%5041, %4918)\n",
      "  %4920 : Long(device=cpu) = onnx::ReduceMin[keepdims=0](%4919) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "  %output_ids : Long(*, *, device=cpu) = onnx::Loop(%4920, %187, %4910) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "    block0(%i.17 : Long(device=cpu), %cond : Bool(device=cpu), %4924 : Long(*, *, device=cpu)):\n",
      "      %4925 : Long(*, device=cpu) = onnx::SequenceAt(%4799, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:521:8\n",
      "      %4926 : Long(*, device=cpu) = onnx::Gather[axis=0](%4924, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4927 : Long(device=cpu) = onnx::Gather[axis=0](%4798, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:25\n",
      "      %4928 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4929 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4930 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4928, %4929)\n",
      "      %4931 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4932 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4927, %4931)\n",
      "      %4933 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4934 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%191, %4933)\n",
      "      %4935 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4936 : Long(*, device=cpu) = onnx::Slice(%4926, %4930, %4932, %4934, %4935) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4937 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4936)\n",
      "      %4938 : LongTensor(device=cpu) = onnx::Expand(%4925, %4937) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4939 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4940 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.17, %4939)\n",
      "      %4941 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4924)\n",
      "      %4942 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4943 : Long(device=cpu) = onnx::Gather[axis=0](%4941, %4942)\n",
      "      %4944 : Long(device=cpu) = onnx::Cast[to=7](%4943)\n",
      "      %4945 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4946 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4947 : Long(*, device=cpu) = onnx::Range(%4945, %4944, %4946)\n",
      "      %4948 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4949 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4950 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4951 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4949, %4950)\n",
      "      %4952 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4953 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%4927, %4952)\n",
      "      %4954 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4955 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze(%4948, %4954)\n",
      "      %4956 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={1}]()\n",
      "      %4957 : Long(*, device=cpu) = onnx::Slice(%4947, %4951, %4953, %4955, %4956)\n",
      "      %4958 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "      %4959 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4940, %4958)\n",
      "      %4960 : Long(*, *, device=cpu) = onnx::Add(%4959, %4957)\n",
      "      %4961 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4960)\n",
      "      %4962 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4961)\n",
      "      %4963 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4962)\n",
      "      %4964 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4965 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4963, %4964)\n",
      "      %4966 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4961, %4965)\n",
      "      %4967 : Long(2, strides=[1], device=cpu) = onnx::Where(%4966, %4963, %4961)\n",
      "      %4968 : LongTensor(device=cpu) = onnx::Expand(%4959, %4967)\n",
      "      %4969 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4970 : LongTensor(device=cpu) = onnx::Unsqueeze(%4968, %4969)\n",
      "      %4971 : Long(1, strides=[1], device=cpu) = onnx::Shape(%4961)\n",
      "      %4972 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%4971)\n",
      "      %4973 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4974 : Long(2, strides=[1], device=cpu) = onnx::Mul(%4972, %4973)\n",
      "      %4975 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%4961, %4974)\n",
      "      %4976 : Long(2, strides=[1], device=cpu) = onnx::Where(%4975, %4972, %4961)\n",
      "      %4977 : LongTensor(device=cpu) = onnx::Expand(%4957, %4976)\n",
      "      %4978 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "      %4979 : LongTensor(device=cpu) = onnx::Unsqueeze(%4977, %4978)\n",
      "      %4980 : LongTensor(device=cpu) = onnx::Concat[axis=-1](%4970, %4979)\n",
      "      %4981 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4924)\n",
      "      %4982 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "      %4983 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "      %4984 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "      %4985 : Long(0, strides=[1], device=cpu) = onnx::Slice(%4981, %4983, %4984, %4982)\n",
      "      %4986 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%4961, %4985)\n",
      "      %4987 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4938, %4986)\n",
      "      %4988 : Long(*, *, device=cpu) = onnx::Cast[to=7](%4987)\n",
      "      %4989 : Long(*, *, device=cpu) = onnx::ScatterND(%4924, %4980, %4988) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:522:12\n",
      "      %4990 : Long(device=cpu) = onnx::Gather[axis=0](%4798, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:15\n",
      "      %4991 : Bool(device=cpu) = onnx::Less(%4990, %max_length) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:15\n",
      "      %4992 : Bool(device=cpu) = onnx::Cast[to=9](%4991)\n",
      "      %4993 : Long(*, *, device=cpu) = onnx::If(%4992) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:523:12\n",
      "        block0():\n",
      "          %4994 : Long(device=cpu) = onnx::Gather[axis=0](%4798, %i.17) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:524:27\n",
      "          %4995 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
      "          %4996 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %4997 : Long(*, strides=[1], device=cpu) = onnx::Unsqueeze(%i.17, %4996)\n",
      "          %4998 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=-1  1 [ CPULongType{2} ]]()\n",
      "          %4999 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%4997, %4998)\n",
      "          %5000 : Long(*, *, device=cpu) = onnx::Add(%4999, %4994)\n",
      "          %5001 : Long(2, strides=[1], device=cpu) = onnx::Shape(%5000)\n",
      "          %5002 : Long(1, strides=[1], device=cpu) = onnx::Shape(%5001)\n",
      "          %5003 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%5002)\n",
      "          %5004 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %5005 : Long(2, strides=[1], device=cpu) = onnx::Mul(%5003, %5004)\n",
      "          %5006 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%5001, %5005)\n",
      "          %5007 : Long(2, strides=[1], device=cpu) = onnx::Where(%5006, %5003, %5001)\n",
      "          %5008 : Long(*, *, device=cpu) = onnx::Expand(%4999, %5007)\n",
      "          %5009 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %5010 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%5008, %5009)\n",
      "          %5011 : Long(1, strides=[1], device=cpu) = onnx::Shape(%5001)\n",
      "          %5012 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%5011)\n",
      "          %5013 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %5014 : Long(2, strides=[1], device=cpu) = onnx::Mul(%5012, %5013)\n",
      "          %5015 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%5001, %5014)\n",
      "          %5016 : Long(2, strides=[1], device=cpu) = onnx::Where(%5015, %5012, %5001)\n",
      "          %5017 : Long(*, *, device=cpu) = onnx::Expand(%4994, %5016)\n",
      "          %5018 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %5019 : Long(*, *, *, device=cpu) = onnx::Unsqueeze(%5017, %5018)\n",
      "          %5020 : Long(*, *, *, device=cpu) = onnx::Concat[axis=-1](%5010, %5019)\n",
      "          %5021 : Long(2, strides=[1], device=cpu) = onnx::Shape(%4989)\n",
      "          %5022 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={0}]()\n",
      "          %5023 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={2}]()\n",
      "          %5024 : Long(1, strides=[1], device=cpu) = onnx::Constant[value={9223372036854775807}]()\n",
      "          %5025 : Long(0, strides=[1], device=cpu) = onnx::Slice(%5021, %5023, %5024, %5022)\n",
      "          %5026 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%5001, %5025)\n",
      "          %5027 : Long(1, strides=[1], device=cpu) = onnx::Shape(%5026)\n",
      "          %5028 : Long(2, device=cpu) = onnx::ConstantOfShape[value={1}](%5027)\n",
      "          %5029 : Long(requires_grad=0, device=cpu) = onnx::Constant[value={-1}]()\n",
      "          %5030 : Long(2, strides=[1], device=cpu) = onnx::Mul(%5028, %5029)\n",
      "          %5031 : Bool(2, strides=[1], device=cpu) = onnx::Equal(%5026, %5030)\n",
      "          %5032 : Long(2, strides=[1], device=cpu) = onnx::Where(%5031, %5028, %5026)\n",
      "          %5033 : LongTensor(device=cpu) = onnx::Expand(%4995, %5032)\n",
      "          %5034 : Long(*, *, device=cpu) = onnx::Reshape[allowzero=0](%5033, %5026)\n",
      "          %5035 : Long(*, *, device=cpu) = onnx::ScatterND(%4989, %5020, %5034) # c:\\Users\\edbon\\devproj\\faiky-tails\\onnx_models\\convert\\gpt3_onnx\\generation_onnx.py:524:16\n",
      "          -> (%5035)\n",
      "        block1():\n",
      "          %5036 : Long(*, *, device=cpu) = onnx::Identity(%4989)\n",
      "          -> (%5036)\n",
      "      %5037 : Bool(device=cpu) = onnx::Identity(%187)\n",
      "      -> (%5037, %4993)\n",
      "  return (%output_ids)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "        PROMT = [\"старик\", \"Кощей\"]\n",
    "\n",
    "        context = \" _kw_ \".join(PROMT)\n",
    "        context = tokenizer.encode(context)\n",
    "        endkeytok = tokenizer.convert_tokens_to_ids('_endkw_')\n",
    "\n",
    "        context = [starttok] + context + [endkeytok] + [septok]\n",
    "        context = tokenizer.decode(context)\n",
    "\n",
    "        inputs = tokenizer(context, max_length=model.config.n_ctx, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            script_model_sample,\n",
    "            (\n",
    "                inputs[\"input_ids\"],\n",
    "                inputs[\"attention_mask\"],\n",
    "                num_beams,\n",
    "                max_length,\n",
    "                temperature,\n",
    "                top_p\n",
    "            ),\n",
    "            onnx_file_path,\n",
    "            opset_version=14,  # TODO for gpt maybe 12?\n",
    "            input_names=[\"input_ids\", \"attention_mask\", \"num_beams\", \"max_length\", \"temperature\",\"top_p\"], \n",
    "            output_names=[\"output_ids\"],\n",
    "            dynamic_axes={\n",
    "                \"input_ids\": {0: \"batch\", 1: \"seq\"},\n",
    "                \"output_ids\": {0: \"batch\", 1: \"seq_out\"},\n",
    "            },\n",
    "            example_outputs=summary_ids_temp,\n",
    "            verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "model_onnx_sample = onnx.load(onnx_file_path)\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model_onnx_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input_ids[INT64, batchxseq]\n",
      "  %attention_mask[INT64, 1x8]\n",
      "  %num_beams[INT64, scalar]\n",
      "  %max_length[INT64, scalar]\n",
      "  %temperature[DOUBLE, scalar]\n",
      "  %top_p[DOUBLE, scalar]\n",
      ") initializers (\n",
      "  %decoder_no_past.decoder.transformer.wte.weight[FLOAT, 50260x768]\n",
      "  %decoder_no_past.decoder.transformer.wpe.weight[FLOAT, 2048x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_1.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_1.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.masked_bias[FLOAT, scalar]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.bias[UINT8, 1x1x2048x2048]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight[FLOAT, 768x2304]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias[FLOAT, 2304]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight[FLOAT, 768x768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_2.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.ln_2.weight[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight[FLOAT, 768x3072]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias[FLOAT, 3072]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight[FLOAT, 3072x768]\n",
      "  %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.ln_f.bias[FLOAT, 768]\n",
      "  %decoder_no_past.decoder.transformer.ln_f.weight[FLOAT, 768]\n",
      "  %5038[INT64, 1]\n",
      "  %5039[INT64, 1]\n",
      "  %5040[FLOAT, 768x50260]\n",
      "  %5041[INT64, 1]\n",
      ") {\n",
      "  %178 = Constant[value = <Scalar Tensor []>]()\n",
      "  %179 = Constant[value = <Scalar Tensor []>]()\n",
      "  %180 = Constant[value = <Scalar Tensor []>]()\n",
      "  %181 = Constant[value = <Scalar Tensor []>]()\n",
      "  %182 = Constant[value = <Scalar Tensor []>]()\n",
      "  %183 = Constant[value = <Scalar Tensor []>]()\n",
      "  %184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %185 = Constant[value = <Scalar Tensor []>]()\n",
      "  %186 = Constant[value = <Scalar Tensor []>]()\n",
      "  %187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %188 = Constant[value = <Scalar Tensor []>]()\n",
      "  %189 = Constant[value = <Scalar Tensor []>]()\n",
      "  %190 = Constant[value = <Scalar Tensor []>]()\n",
      "  %191 = Constant[value = <Scalar Tensor []>]()\n",
      "  %192 = Cast[to = 1](%temperature)\n",
      "  %193 = Cast[to = 1](%top_p)\n",
      "  %194 = Shape(%input_ids)\n",
      "  %195 = Constant[value = <Scalar Tensor []>]()\n",
      "  %196 = Gather[axis = 0](%194, %195)\n",
      "  %197 = Constant[value = <Scalar Tensor []>]()\n",
      "  %198 = Div(%num_beams, %197)\n",
      "  %199 = Cast[to = 7](%198)\n",
      "  %200 = Cast[to = 7](%199)\n",
      "  %201 = Constant[value = <Tensor>]()\n",
      "  %202 = Unsqueeze(%196, %201)\n",
      "  %203 = Concat[axis = 0](%202)\n",
      "  %204 = Constant[value = <Tensor>]()\n",
      "  %205 = Unsqueeze(%196, %204)\n",
      "  %206 = Concat[axis = 0](%205)\n",
      "  %207 = Constant[value = <Tensor>]()\n",
      "  %208 = Unsqueeze(%196, %207)\n",
      "  %209 = Concat[axis = 0](%208)\n",
      "  %210 = ConstantOfShape[value = <Tensor>](%203)\n",
      "  %211 = ConstantOfShape[value = <Tensor>](%206)\n",
      "  %212 = ConstantOfShape[value = <Tensor>](%209)\n",
      "  %213 = Constant[value = <Scalar Tensor []>]()\n",
      "  %214 = Add(%212, %213)\n",
      "  %215 = SequenceEmpty[dtype = 7]()\n",
      "  %216 = SequenceEmpty[dtype = 1]()\n",
      "  %217 = Shape(%input_ids)\n",
      "  %218 = Constant[value = <Scalar Tensor []>]()\n",
      "  %219 = Gather[axis = 0](%217, %218)\n",
      "  %220 = Cast[to = 7](%219)\n",
      "  %221 = Constant[value = <Scalar Tensor []>]()\n",
      "  %222 = Constant[value = <Scalar Tensor []>]()\n",
      "  %223 = Range(%221, %220, %222)\n",
      "  %224 = Constant[value = <Tensor>]()\n",
      "  %225 = Reshape[allowzero = 0](%223, %224)\n",
      "  %228 = Constant[value = <Tensor>]()\n",
      "  %229 = Unsqueeze(%num_beams, %228)\n",
      "  %230 = Concat[axis = 0](%5038, %229)\n",
      "  %233 = Constant[value = <Tensor>]()\n",
      "  %234 = Unsqueeze(%num_beams, %233)\n",
      "  %235 = Concat[axis = 0](%5039, %234)\n",
      "  %236 = Shape(%230)\n",
      "  %237 = ConstantOfShape[value = <Tensor>](%236)\n",
      "  %238 = Expand(%225, %237)\n",
      "  %239 = Tile(%238, %235)\n",
      "  %240 = Constant[value = <Tensor>]()\n",
      "  %241 = Reshape[allowzero = 0](%239, %240)\n",
      "  %242 = Gather[axis = 0](%input_ids, %241)\n",
      "  %243 = Gather[axis = 0](%attention_mask, %241)\n",
      "  %244 = Shape(%242)\n",
      "  %245 = Constant[value = <Scalar Tensor []>]()\n",
      "  %246 = Gather(%244, %245)\n",
      "  %247 = Constant[value = <Tensor>]()\n",
      "  %248 = Unsqueeze(%196, %247)\n",
      "  %249 = Constant[value = <Tensor>]()\n",
      "  %250 = Unsqueeze(%num_beams, %249)\n",
      "  %251 = Concat[axis = 0](%248, %250)\n",
      "  %252 = ConstantOfShape[value = <Tensor>](%251)\n",
      "  %253 = Constant[value = <Tensor>]()\n",
      "  %254 = Constant[value = <Tensor>]()\n",
      "  %255 = Constant[value = <Tensor>]()\n",
      "  %256 = Constant[value = <Tensor>]()\n",
      "  %257 = Slice(%252, %254, %255, %253, %256)\n",
      "  %258 = Constant[value = <Scalar Tensor []>]()\n",
      "  %259 = Shape(%257)\n",
      "  %260 = Expand(%258, %259)\n",
      "  %261 = Shape(%252)\n",
      "  %262 = Constant[value = <Scalar Tensor []>]()\n",
      "  %263 = Gather[axis = 0](%261, %262)\n",
      "  %264 = Cast[to = 7](%263)\n",
      "  %265 = Constant[value = <Scalar Tensor []>]()\n",
      "  %266 = Constant[value = <Scalar Tensor []>]()\n",
      "  %267 = Range(%265, %264, %266)\n",
      "  %268 = Shape(%252)\n",
      "  %269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %270 = Gather[axis = 0](%268, %269)\n",
      "  %271 = Cast[to = 7](%270)\n",
      "  %272 = Constant[value = <Scalar Tensor []>]()\n",
      "  %273 = Constant[value = <Scalar Tensor []>]()\n",
      "  %274 = Range(%272, %271, %273)\n",
      "  %275 = Constant[value = <Tensor>]()\n",
      "  %276 = Constant[value = <Tensor>]()\n",
      "  %277 = Constant[value = <Tensor>]()\n",
      "  %278 = Constant[value = <Tensor>]()\n",
      "  %279 = Slice(%274, %276, %277, %275, %278)\n",
      "  %280 = Constant[value = <Tensor>]()\n",
      "  %281 = Reshape[allowzero = 0](%267, %280)\n",
      "  %282 = Add(%281, %279)\n",
      "  %283 = Shape(%282)\n",
      "  %284 = Shape(%283)\n",
      "  %285 = ConstantOfShape[value = <Tensor>](%284)\n",
      "  %286 = Constant[value = <Scalar Tensor []>]()\n",
      "  %287 = Mul(%285, %286)\n",
      "  %288 = Equal(%283, %287)\n",
      "  %289 = Where(%288, %285, %283)\n",
      "  %290 = Expand(%281, %289)\n",
      "  %291 = Constant[value = <Tensor>]()\n",
      "  %292 = Unsqueeze(%290, %291)\n",
      "  %293 = Shape(%283)\n",
      "  %294 = ConstantOfShape[value = <Tensor>](%293)\n",
      "  %295 = Constant[value = <Scalar Tensor []>]()\n",
      "  %296 = Mul(%294, %295)\n",
      "  %297 = Equal(%283, %296)\n",
      "  %298 = Where(%297, %294, %283)\n",
      "  %299 = Expand(%279, %298)\n",
      "  %300 = Constant[value = <Tensor>]()\n",
      "  %301 = Unsqueeze(%299, %300)\n",
      "  %302 = Concat[axis = -1](%292, %301)\n",
      "  %303 = Shape(%252)\n",
      "  %304 = Constant[value = <Tensor>]()\n",
      "  %305 = Constant[value = <Tensor>]()\n",
      "  %306 = Constant[value = <Tensor>]()\n",
      "  %307 = Slice(%303, %305, %306, %304)\n",
      "  %308 = Concat[axis = 0](%283, %307)\n",
      "  %309 = Reshape[allowzero = 0](%260, %308)\n",
      "  %310 = ScatterND(%252, %302, %309)\n",
      "  %311 = Mul(%196, %num_beams)\n",
      "  %312 = Constant[value = <Tensor>]()\n",
      "  %313 = Unsqueeze(%311, %312)\n",
      "  %314 = Concat[axis = 0](%313)\n",
      "  %315 = Reshape[allowzero = 0](%310, %314)\n",
      "  %316 = Greater(%max_length, %246)\n",
      "  %318, %319, %320, %321, %322, %323, %324, %325, %326 = Loop[body = <graph torch-jit-export1>](%184, %316, %242, %315, %243, %246, %216, %215, %214, %211, %210)\n",
      "  %4583 = Constant[value = <Tensor>]()\n",
      "  %4584 = Shape(%325)\n",
      "  %4585 = Gather[axis = 0](%4584, %4583)\n",
      "  %4586 = Constant[value = <Tensor>]()\n",
      "  %4587 = Squeeze(%4585, %4586)\n",
      "  %4588 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4589 = Greater(%4587, %4588)\n",
      "  %4590, %4591, %4592, %4593, %4594 = Loop[body = <graph torch-jit-export34>](%184, %4589, %191, %322, %323, %324, %325)\n",
      "  %4791 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4792 = Mul(%4587, %4791)\n",
      "  %4793 = Constant[value = <Tensor>]()\n",
      "  %4794 = Unsqueeze(%4792, %4793)\n",
      "  %4795 = Concat[axis = 0](%4794)\n",
      "  %4796 = ConstantOfShape[value = <Tensor>](%4795)\n",
      "  %best.1 = SequenceEmpty[dtype = 7]()\n",
      "  %4798, %4799 = Loop[body = <graph torch-jit-export46>](%4587, %187, %4796, %best.1)\n",
      "  %4893 = ReduceMax[keepdims = 0](%4798)\n",
      "  %4894 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4895 = Add(%4893, %4894)\n",
      "  %4896 = Min(%4895, %max_length)\n",
      "  %4897 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4898 = Mul(%4587, %4897)\n",
      "  %4899 = Constant[value = <Tensor>]()\n",
      "  %4900 = Unsqueeze(%4898, %4899)\n",
      "  %4901 = Constant[value = <Tensor>]()\n",
      "  %4902 = Unsqueeze(%4896, %4901)\n",
      "  %4903 = Concat[axis = 0](%4900, %4902)\n",
      "  %4904 = ConstantOfShape[value = <Tensor>](%4903)\n",
      "  %4905 = ReduceMin[keepdims = 0](%4798)\n",
      "  %4906 = ReduceMax[keepdims = 0](%4798)\n",
      "  %4907 = Equal(%4905, %4906)\n",
      "  %4908 = Not(%4907)\n",
      "  %4909 = Cast[to = 9](%4908)\n",
      "  %4910 = If[else_branch = <graph torch-jit-export51>, then_branch = <graph torch-jit-export50>](%4909)\n",
      "  %4914 = SequenceLength(%4799)\n",
      "  %4917 = Constant[value = <Tensor>]()\n",
      "  %4918 = Unsqueeze(%4914, %4917)\n",
      "  %4919 = Concat[axis = 0](%5041, %4918)\n",
      "  %4920 = ReduceMin[keepdims = 0](%4919)\n",
      "  %output_ids = Loop[body = <graph torch-jit-export52>](%4920, %187, %4910)\n",
      "  return %output_ids\n",
      "}\n",
      "\n",
      "graph torch-jit-export1 (\n",
      "  %327[INT64, scalar]\n",
      "  %cond.5[BOOL, scalar]\n",
      "  %input_ids.25[INT64, input_ids.25_dim_0xinput_ids.25_dim_1]\n",
      "  %beam_scores.17[FLOAT, beam_scores.17_dim_0]\n",
      "  %attention_mask.13[INT64, attention_mask.13_dim_0xattention_mask.13_dim_1]\n",
      "  %cur_len.13[INT64, scalar]\n",
      "  %333[Unknown type sequence_type]\n",
      "  %334[Unknown type sequence_type]\n",
      "  %335[FLOAT, 335_dim_0]\n",
      "  %336[INT64, 336_dim_0]\n",
      "  %337[BOOL, 337_dim_0]\n",
      ") {\n",
      "  %338 = Shape(%input_ids.25)\n",
      "  %339 = Constant[value = <Scalar Tensor []>]()\n",
      "  %340 = Gather[axis = 0](%338, %339)\n",
      "  %341 = Shape(%input_ids.25)\n",
      "  %342 = Constant[value = <Scalar Tensor []>]()\n",
      "  %343 = Gather[axis = 0](%341, %342)\n",
      "  %344 = Constant[value = <Tensor>]()\n",
      "  %345 = Unsqueeze(%186, %344)\n",
      "  %346 = Constant[value = <Tensor>]()\n",
      "  %347 = Unsqueeze(%343, %346)\n",
      "  %348 = Concat[axis = 0](%345, %347)\n",
      "  %349 = Constant[value = <Tensor>]()\n",
      "  %350 = Unsqueeze(%186, %349)\n",
      "  %351 = Constant[value = <Tensor>]()\n",
      "  %352 = Unsqueeze(%343, %351)\n",
      "  %353 = Concat[axis = 0](%350, %352)\n",
      "  %354 = Reshape[allowzero = 0](%input_ids.25, %348)\n",
      "  %355 = Shape(%354)\n",
      "  %356 = Constant[value = <Scalar Tensor []>]()\n",
      "  %357 = Gather[axis = 0](%355, %356)\n",
      "  %358 = Constant[value = <Scalar Tensor []>]()\n",
      "  %359 = Add(%343, %358)\n",
      "  %360 = Cast[to = 7](%191)\n",
      "  %361 = Cast[to = 7](%359)\n",
      "  %362 = Cast[to = 7](%189)\n",
      "  %363 = Range(%360, %361, %362)\n",
      "  %364 = Constant[value = <Tensor>]()\n",
      "  %365 = Unsqueeze(%363, %364)\n",
      "  %366 = Reshape[allowzero = 0](%365, %353)\n",
      "  %367 = Constant[value = <Tensor>]()\n",
      "  %368 = Unsqueeze(%357, %367)\n",
      "  %369 = Constant[value = <Tensor>]()\n",
      "  %370 = Unsqueeze(%186, %369)\n",
      "  %371 = Concat[axis = 0](%368, %370)\n",
      "  %372 = Reshape[allowzero = 0](%attention_mask.13, %371)\n",
      "  %373 = Constant[value = <Tensor>]()\n",
      "  %374 = Unsqueeze(%372, %373)\n",
      "  %375 = Constant[value = <Tensor>]()\n",
      "  %376 = Unsqueeze(%374, %375)\n",
      "  %377 = Cast[to = 1](%376)\n",
      "  %378 = Constant[value = <Scalar Tensor []>]()\n",
      "  %379 = Sub(%378, %377)\n",
      "  %380 = Constant[value = <Scalar Tensor []>]()\n",
      "  %381 = Mul(%379, %380)\n",
      "  %382 = Gather(%decoder_no_past.decoder.transformer.wte.weight, %354)\n",
      "  %383 = Gather(%decoder_no_past.decoder.transformer.wpe.weight, %366)\n",
      "  %384 = Add(%382, %383)\n",
      "  %385 = Shape(%384)\n",
      "  %386 = Constant[value = <Tensor>]()\n",
      "  %387 = Constant[value = <Tensor>]()\n",
      "  %388 = Constant[value = <Tensor>]()\n",
      "  %389 = Slice(%385, %387, %388, %386)\n",
      "  %390 = Constant[value = <Tensor>]()\n",
      "  %391 = Squeeze(%389, %390)\n",
      "  %392 = ReduceMean[axes = [-1]](%384)\n",
      "  %393 = Sub(%384, %392)\n",
      "  %394 = Constant[value = <Scalar Tensor []>]()\n",
      "  %395 = Pow(%393, %394)\n",
      "  %396 = ReduceMean[axes = [-1]](%395)\n",
      "  %397 = Constant[value = <Scalar Tensor []>]()\n",
      "  %398 = Add(%396, %397)\n",
      "  %399 = Sqrt(%398)\n",
      "  %400 = Div(%393, %399)\n",
      "  %401 = Mul(%400, %decoder_no_past.decoder.transformer.h.0.ln_1.weight)\n",
      "  %402 = Add(%401, %decoder_no_past.decoder.transformer.h.0.ln_1.bias)\n",
      "  %403 = Shape(%402)\n",
      "  %404 = Constant[value = <Scalar Tensor []>]()\n",
      "  %405 = Gather[axis = 0](%403, %404)\n",
      "  %406 = Shape(%402)\n",
      "  %407 = Constant[value = <Scalar Tensor []>]()\n",
      "  %408 = Gather[axis = 0](%406, %407)\n",
      "  %409 = Shape(%402)\n",
      "  %410 = Constant[value = <Tensor>]()\n",
      "  %411 = Constant[value = <Tensor>]()\n",
      "  %412 = Constant[value = <Tensor>]()\n",
      "  %413 = Slice(%409, %411, %412, %410)\n",
      "  %414 = Constant[value = <Tensor>]()\n",
      "  %415 = Squeeze(%413, %414)\n",
      "  %416 = Constant[value = <Tensor>]()\n",
      "  %417 = Unsqueeze(%186, %416)\n",
      "  %418 = Constant[value = <Tensor>]()\n",
      "  %419 = Unsqueeze(%415, %418)\n",
      "  %420 = Concat[axis = 0](%417, %419)\n",
      "  %421 = Reshape[allowzero = 0](%402, %420)\n",
      "  %422 = Gemm[alpha = 1, beta = 1](%421, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_attn.bias)\n",
      "  %423 = Constant[value = <Tensor>]()\n",
      "  %424 = Unsqueeze(%405, %423)\n",
      "  %425 = Constant[value = <Tensor>]()\n",
      "  %426 = Unsqueeze(%408, %425)\n",
      "  %427 = Constant[value = <Tensor>]()\n",
      "  %428 = Unsqueeze(%182, %427)\n",
      "  %429 = Concat[axis = 0](%424, %426, %428)\n",
      "  %430 = Reshape[allowzero = 0](%422, %429)\n",
      "  %431 = Constant[value = <Tensor>]()\n",
      "  %432, %433, %434 = Split[axis = 2](%430, %431)\n",
      "  %435 = Shape(%432)\n",
      "  %436 = Constant[value = <Scalar Tensor []>]()\n",
      "  %437 = Gather[axis = 0](%435, %436)\n",
      "  %438 = Shape(%432)\n",
      "  %439 = Constant[value = <Scalar Tensor []>]()\n",
      "  %440 = Gather[axis = 0](%438, %439)\n",
      "  %441 = Constant[value = <Tensor>]()\n",
      "  %442 = Unsqueeze(%437, %441)\n",
      "  %443 = Constant[value = <Tensor>]()\n",
      "  %444 = Unsqueeze(%440, %443)\n",
      "  %445 = Constant[value = <Tensor>]()\n",
      "  %446 = Unsqueeze(%181, %445)\n",
      "  %447 = Constant[value = <Tensor>]()\n",
      "  %448 = Unsqueeze(%180, %447)\n",
      "  %449 = Concat[axis = 0](%442, %444, %446, %448)\n",
      "  %450 = Reshape[allowzero = 0](%432, %449)\n",
      "  %451 = Transpose[perm = [0, 2, 1, 3]](%450)\n",
      "  %452 = Shape(%433)\n",
      "  %453 = Constant[value = <Scalar Tensor []>]()\n",
      "  %454 = Gather[axis = 0](%452, %453)\n",
      "  %455 = Shape(%433)\n",
      "  %456 = Constant[value = <Scalar Tensor []>]()\n",
      "  %457 = Gather[axis = 0](%455, %456)\n",
      "  %458 = Constant[value = <Tensor>]()\n",
      "  %459 = Unsqueeze(%454, %458)\n",
      "  %460 = Constant[value = <Tensor>]()\n",
      "  %461 = Unsqueeze(%457, %460)\n",
      "  %462 = Constant[value = <Tensor>]()\n",
      "  %463 = Unsqueeze(%181, %462)\n",
      "  %464 = Constant[value = <Tensor>]()\n",
      "  %465 = Unsqueeze(%180, %464)\n",
      "  %466 = Concat[axis = 0](%459, %461, %463, %465)\n",
      "  %467 = Reshape[allowzero = 0](%433, %466)\n",
      "  %468 = Transpose[perm = [0, 2, 1, 3]](%467)\n",
      "  %469 = Shape(%434)\n",
      "  %470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %471 = Gather[axis = 0](%469, %470)\n",
      "  %472 = Shape(%434)\n",
      "  %473 = Constant[value = <Scalar Tensor []>]()\n",
      "  %474 = Gather[axis = 0](%472, %473)\n",
      "  %475 = Constant[value = <Tensor>]()\n",
      "  %476 = Unsqueeze(%471, %475)\n",
      "  %477 = Constant[value = <Tensor>]()\n",
      "  %478 = Unsqueeze(%474, %477)\n",
      "  %479 = Constant[value = <Tensor>]()\n",
      "  %480 = Unsqueeze(%181, %479)\n",
      "  %481 = Constant[value = <Tensor>]()\n",
      "  %482 = Unsqueeze(%180, %481)\n",
      "  %483 = Concat[axis = 0](%476, %478, %480, %482)\n",
      "  %484 = Reshape[allowzero = 0](%434, %483)\n",
      "  %485 = Transpose[perm = [0, 2, 1, 3]](%484)\n",
      "  %486 = Transpose[perm = [0, 2, 3, 1]](%467)\n",
      "  %487 = MatMul(%451, %486)\n",
      "  %488 = Constant[value = <Scalar Tensor []>]()\n",
      "  %489 = Div(%487, %488)\n",
      "  %490 = Shape(%451)\n",
      "  %491 = Constant[value = <Tensor>]()\n",
      "  %492 = Constant[value = <Tensor>]()\n",
      "  %493 = Constant[value = <Tensor>]()\n",
      "  %494 = Slice(%490, %492, %493, %491)\n",
      "  %495 = Constant[value = <Tensor>]()\n",
      "  %496 = Squeeze(%494, %495)\n",
      "  %497 = Shape(%468)\n",
      "  %498 = Constant[value = <Tensor>]()\n",
      "  %499 = Constant[value = <Tensor>]()\n",
      "  %500 = Constant[value = <Tensor>]()\n",
      "  %501 = Slice(%497, %499, %500, %498)\n",
      "  %502 = Constant[value = <Tensor>]()\n",
      "  %503 = Squeeze(%501, %502)\n",
      "  %504 = Sub(%503, %496)\n",
      "  %505 = Constant[value = <Tensor>]()\n",
      "  %506 = Unsqueeze(%504, %505)\n",
      "  %507 = Constant[value = <Tensor>]()\n",
      "  %508 = Unsqueeze(%503, %507)\n",
      "  %509 = Constant[value = <Tensor>]()\n",
      "  %510 = Unsqueeze(%190, %509)\n",
      "  %511 = Constant[value = <Tensor>]()\n",
      "  %512 = Slice(%decoder_no_past.decoder.transformer.h.0.attn.bias, %506, %508, %510, %511)\n",
      "  %513 = Constant[value = <Tensor>]()\n",
      "  %514 = Unsqueeze(%191, %513)\n",
      "  %515 = Constant[value = <Tensor>]()\n",
      "  %516 = Unsqueeze(%503, %515)\n",
      "  %517 = Constant[value = <Tensor>]()\n",
      "  %518 = Unsqueeze(%185, %517)\n",
      "  %519 = Constant[value = <Tensor>]()\n",
      "  %520 = Slice(%512, %514, %516, %518, %519)\n",
      "  %521 = Cast[to = 9](%520)\n",
      "  %522 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.0.attn.masked_bias)\n",
      "  %523 = Where(%521, %489, %522)\n",
      "  %524 = Add(%523, %381)\n",
      "  %525 = Softmax[axis = -1](%524)\n",
      "  %526 = MatMul(%525, %485)\n",
      "  %527 = Transpose[perm = [0, 2, 1, 3]](%526)\n",
      "  %528 = Shape(%527)\n",
      "  %529 = Constant[value = <Scalar Tensor []>]()\n",
      "  %530 = Gather[axis = 0](%528, %529)\n",
      "  %531 = Shape(%527)\n",
      "  %532 = Constant[value = <Scalar Tensor []>]()\n",
      "  %533 = Gather[axis = 0](%531, %532)\n",
      "  %534 = Constant[value = <Tensor>]()\n",
      "  %535 = Unsqueeze(%530, %534)\n",
      "  %536 = Constant[value = <Tensor>]()\n",
      "  %537 = Unsqueeze(%533, %536)\n",
      "  %538 = Constant[value = <Tensor>]()\n",
      "  %539 = Unsqueeze(%183, %538)\n",
      "  %540 = Concat[axis = 0](%535, %537, %539)\n",
      "  %541 = Reshape[allowzero = 0](%527, %540)\n",
      "  %542 = Shape(%541)\n",
      "  %543 = Constant[value = <Scalar Tensor []>]()\n",
      "  %544 = Gather[axis = 0](%542, %543)\n",
      "  %545 = Shape(%541)\n",
      "  %546 = Constant[value = <Scalar Tensor []>]()\n",
      "  %547 = Gather[axis = 0](%545, %546)\n",
      "  %548 = Shape(%541)\n",
      "  %549 = Constant[value = <Tensor>]()\n",
      "  %550 = Constant[value = <Tensor>]()\n",
      "  %551 = Constant[value = <Tensor>]()\n",
      "  %552 = Slice(%548, %550, %551, %549)\n",
      "  %553 = Constant[value = <Tensor>]()\n",
      "  %554 = Squeeze(%552, %553)\n",
      "  %555 = Constant[value = <Tensor>]()\n",
      "  %556 = Unsqueeze(%186, %555)\n",
      "  %557 = Constant[value = <Tensor>]()\n",
      "  %558 = Unsqueeze(%554, %557)\n",
      "  %559 = Concat[axis = 0](%556, %558)\n",
      "  %560 = Reshape[allowzero = 0](%541, %559)\n",
      "  %561 = Gemm[alpha = 1, beta = 1](%560, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.attn.c_proj.bias)\n",
      "  %562 = Constant[value = <Tensor>]()\n",
      "  %563 = Unsqueeze(%544, %562)\n",
      "  %564 = Constant[value = <Tensor>]()\n",
      "  %565 = Unsqueeze(%547, %564)\n",
      "  %566 = Constant[value = <Tensor>]()\n",
      "  %567 = Unsqueeze(%183, %566)\n",
      "  %568 = Concat[axis = 0](%563, %565, %567)\n",
      "  %569 = Reshape[allowzero = 0](%561, %568)\n",
      "  %570 = Add(%569, %384)\n",
      "  %571 = ReduceMean[axes = [-1]](%570)\n",
      "  %572 = Sub(%570, %571)\n",
      "  %573 = Constant[value = <Scalar Tensor []>]()\n",
      "  %574 = Pow(%572, %573)\n",
      "  %575 = ReduceMean[axes = [-1]](%574)\n",
      "  %576 = Constant[value = <Scalar Tensor []>]()\n",
      "  %577 = Add(%575, %576)\n",
      "  %578 = Sqrt(%577)\n",
      "  %579 = Div(%572, %578)\n",
      "  %580 = Mul(%579, %decoder_no_past.decoder.transformer.h.0.ln_2.weight)\n",
      "  %581 = Add(%580, %decoder_no_past.decoder.transformer.h.0.ln_2.bias)\n",
      "  %582 = Shape(%581)\n",
      "  %583 = Constant[value = <Scalar Tensor []>]()\n",
      "  %584 = Gather[axis = 0](%582, %583)\n",
      "  %585 = Shape(%581)\n",
      "  %586 = Constant[value = <Scalar Tensor []>]()\n",
      "  %587 = Gather[axis = 0](%585, %586)\n",
      "  %588 = Shape(%581)\n",
      "  %589 = Constant[value = <Tensor>]()\n",
      "  %590 = Constant[value = <Tensor>]()\n",
      "  %591 = Constant[value = <Tensor>]()\n",
      "  %592 = Slice(%588, %590, %591, %589)\n",
      "  %593 = Constant[value = <Tensor>]()\n",
      "  %594 = Squeeze(%592, %593)\n",
      "  %595 = Constant[value = <Tensor>]()\n",
      "  %596 = Unsqueeze(%186, %595)\n",
      "  %597 = Constant[value = <Tensor>]()\n",
      "  %598 = Unsqueeze(%594, %597)\n",
      "  %599 = Concat[axis = 0](%596, %598)\n",
      "  %600 = Reshape[allowzero = 0](%581, %599)\n",
      "  %601 = Gemm[alpha = 1, beta = 1](%600, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_fc.bias)\n",
      "  %602 = Constant[value = <Tensor>]()\n",
      "  %603 = Unsqueeze(%584, %602)\n",
      "  %604 = Constant[value = <Tensor>]()\n",
      "  %605 = Unsqueeze(%587, %604)\n",
      "  %606 = Constant[value = <Tensor>]()\n",
      "  %607 = Unsqueeze(%179, %606)\n",
      "  %608 = Concat[axis = 0](%603, %605, %607)\n",
      "  %609 = Reshape[allowzero = 0](%601, %608)\n",
      "  %610 = Constant[value = <Scalar Tensor []>]()\n",
      "  %611 = Mul(%609, %610)\n",
      "  %612 = Constant[value = <Scalar Tensor []>]()\n",
      "  %613 = Pow(%609, %612)\n",
      "  %614 = Constant[value = <Scalar Tensor []>]()\n",
      "  %615 = Mul(%613, %614)\n",
      "  %616 = Add(%609, %615)\n",
      "  %617 = Constant[value = <Scalar Tensor []>]()\n",
      "  %618 = Mul(%616, %617)\n",
      "  %619 = Tanh(%618)\n",
      "  %620 = Constant[value = <Scalar Tensor []>]()\n",
      "  %621 = Add(%619, %620)\n",
      "  %622 = Mul(%611, %621)\n",
      "  %623 = Shape(%622)\n",
      "  %624 = Constant[value = <Scalar Tensor []>]()\n",
      "  %625 = Gather[axis = 0](%623, %624)\n",
      "  %626 = Shape(%622)\n",
      "  %627 = Constant[value = <Scalar Tensor []>]()\n",
      "  %628 = Gather[axis = 0](%626, %627)\n",
      "  %629 = Shape(%622)\n",
      "  %630 = Constant[value = <Tensor>]()\n",
      "  %631 = Constant[value = <Tensor>]()\n",
      "  %632 = Constant[value = <Tensor>]()\n",
      "  %633 = Slice(%629, %631, %632, %630)\n",
      "  %634 = Constant[value = <Tensor>]()\n",
      "  %635 = Squeeze(%633, %634)\n",
      "  %636 = Constant[value = <Tensor>]()\n",
      "  %637 = Unsqueeze(%186, %636)\n",
      "  %638 = Constant[value = <Tensor>]()\n",
      "  %639 = Unsqueeze(%635, %638)\n",
      "  %640 = Concat[axis = 0](%637, %639)\n",
      "  %641 = Reshape[allowzero = 0](%622, %640)\n",
      "  %642 = Gemm[alpha = 1, beta = 1](%641, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.0.mlp.c_proj.bias)\n",
      "  %643 = Constant[value = <Tensor>]()\n",
      "  %644 = Unsqueeze(%625, %643)\n",
      "  %645 = Constant[value = <Tensor>]()\n",
      "  %646 = Unsqueeze(%628, %645)\n",
      "  %647 = Constant[value = <Tensor>]()\n",
      "  %648 = Unsqueeze(%183, %647)\n",
      "  %649 = Concat[axis = 0](%644, %646, %648)\n",
      "  %650 = Reshape[allowzero = 0](%642, %649)\n",
      "  %651 = Add(%570, %650)\n",
      "  %652 = ReduceMean[axes = [-1]](%651)\n",
      "  %653 = Sub(%651, %652)\n",
      "  %654 = Constant[value = <Scalar Tensor []>]()\n",
      "  %655 = Pow(%653, %654)\n",
      "  %656 = ReduceMean[axes = [-1]](%655)\n",
      "  %657 = Constant[value = <Scalar Tensor []>]()\n",
      "  %658 = Add(%656, %657)\n",
      "  %659 = Sqrt(%658)\n",
      "  %660 = Div(%653, %659)\n",
      "  %661 = Mul(%660, %decoder_no_past.decoder.transformer.h.1.ln_1.weight)\n",
      "  %662 = Add(%661, %decoder_no_past.decoder.transformer.h.1.ln_1.bias)\n",
      "  %663 = Shape(%662)\n",
      "  %664 = Constant[value = <Scalar Tensor []>]()\n",
      "  %665 = Gather[axis = 0](%663, %664)\n",
      "  %666 = Shape(%662)\n",
      "  %667 = Constant[value = <Scalar Tensor []>]()\n",
      "  %668 = Gather[axis = 0](%666, %667)\n",
      "  %669 = Shape(%662)\n",
      "  %670 = Constant[value = <Tensor>]()\n",
      "  %671 = Constant[value = <Tensor>]()\n",
      "  %672 = Constant[value = <Tensor>]()\n",
      "  %673 = Slice(%669, %671, %672, %670)\n",
      "  %674 = Constant[value = <Tensor>]()\n",
      "  %675 = Squeeze(%673, %674)\n",
      "  %676 = Constant[value = <Tensor>]()\n",
      "  %677 = Unsqueeze(%186, %676)\n",
      "  %678 = Constant[value = <Tensor>]()\n",
      "  %679 = Unsqueeze(%675, %678)\n",
      "  %680 = Concat[axis = 0](%677, %679)\n",
      "  %681 = Reshape[allowzero = 0](%662, %680)\n",
      "  %682 = Gemm[alpha = 1, beta = 1](%681, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_attn.bias)\n",
      "  %683 = Constant[value = <Tensor>]()\n",
      "  %684 = Unsqueeze(%665, %683)\n",
      "  %685 = Constant[value = <Tensor>]()\n",
      "  %686 = Unsqueeze(%668, %685)\n",
      "  %687 = Constant[value = <Tensor>]()\n",
      "  %688 = Unsqueeze(%182, %687)\n",
      "  %689 = Concat[axis = 0](%684, %686, %688)\n",
      "  %690 = Reshape[allowzero = 0](%682, %689)\n",
      "  %691 = Constant[value = <Tensor>]()\n",
      "  %692, %693, %694 = Split[axis = 2](%690, %691)\n",
      "  %695 = Shape(%692)\n",
      "  %696 = Constant[value = <Scalar Tensor []>]()\n",
      "  %697 = Gather[axis = 0](%695, %696)\n",
      "  %698 = Shape(%692)\n",
      "  %699 = Constant[value = <Scalar Tensor []>]()\n",
      "  %700 = Gather[axis = 0](%698, %699)\n",
      "  %701 = Constant[value = <Tensor>]()\n",
      "  %702 = Unsqueeze(%697, %701)\n",
      "  %703 = Constant[value = <Tensor>]()\n",
      "  %704 = Unsqueeze(%700, %703)\n",
      "  %705 = Constant[value = <Tensor>]()\n",
      "  %706 = Unsqueeze(%181, %705)\n",
      "  %707 = Constant[value = <Tensor>]()\n",
      "  %708 = Unsqueeze(%180, %707)\n",
      "  %709 = Concat[axis = 0](%702, %704, %706, %708)\n",
      "  %710 = Reshape[allowzero = 0](%692, %709)\n",
      "  %711 = Transpose[perm = [0, 2, 1, 3]](%710)\n",
      "  %712 = Shape(%693)\n",
      "  %713 = Constant[value = <Scalar Tensor []>]()\n",
      "  %714 = Gather[axis = 0](%712, %713)\n",
      "  %715 = Shape(%693)\n",
      "  %716 = Constant[value = <Scalar Tensor []>]()\n",
      "  %717 = Gather[axis = 0](%715, %716)\n",
      "  %718 = Constant[value = <Tensor>]()\n",
      "  %719 = Unsqueeze(%714, %718)\n",
      "  %720 = Constant[value = <Tensor>]()\n",
      "  %721 = Unsqueeze(%717, %720)\n",
      "  %722 = Constant[value = <Tensor>]()\n",
      "  %723 = Unsqueeze(%181, %722)\n",
      "  %724 = Constant[value = <Tensor>]()\n",
      "  %725 = Unsqueeze(%180, %724)\n",
      "  %726 = Concat[axis = 0](%719, %721, %723, %725)\n",
      "  %727 = Reshape[allowzero = 0](%693, %726)\n",
      "  %728 = Transpose[perm = [0, 2, 1, 3]](%727)\n",
      "  %729 = Shape(%694)\n",
      "  %730 = Constant[value = <Scalar Tensor []>]()\n",
      "  %731 = Gather[axis = 0](%729, %730)\n",
      "  %732 = Shape(%694)\n",
      "  %733 = Constant[value = <Scalar Tensor []>]()\n",
      "  %734 = Gather[axis = 0](%732, %733)\n",
      "  %735 = Constant[value = <Tensor>]()\n",
      "  %736 = Unsqueeze(%731, %735)\n",
      "  %737 = Constant[value = <Tensor>]()\n",
      "  %738 = Unsqueeze(%734, %737)\n",
      "  %739 = Constant[value = <Tensor>]()\n",
      "  %740 = Unsqueeze(%181, %739)\n",
      "  %741 = Constant[value = <Tensor>]()\n",
      "  %742 = Unsqueeze(%180, %741)\n",
      "  %743 = Concat[axis = 0](%736, %738, %740, %742)\n",
      "  %744 = Reshape[allowzero = 0](%694, %743)\n",
      "  %745 = Transpose[perm = [0, 2, 1, 3]](%744)\n",
      "  %746 = Transpose[perm = [0, 2, 3, 1]](%727)\n",
      "  %747 = MatMul(%711, %746)\n",
      "  %748 = Constant[value = <Scalar Tensor []>]()\n",
      "  %749 = Div(%747, %748)\n",
      "  %750 = Shape(%711)\n",
      "  %751 = Constant[value = <Tensor>]()\n",
      "  %752 = Constant[value = <Tensor>]()\n",
      "  %753 = Constant[value = <Tensor>]()\n",
      "  %754 = Slice(%750, %752, %753, %751)\n",
      "  %755 = Constant[value = <Tensor>]()\n",
      "  %756 = Squeeze(%754, %755)\n",
      "  %757 = Shape(%728)\n",
      "  %758 = Constant[value = <Tensor>]()\n",
      "  %759 = Constant[value = <Tensor>]()\n",
      "  %760 = Constant[value = <Tensor>]()\n",
      "  %761 = Slice(%757, %759, %760, %758)\n",
      "  %762 = Constant[value = <Tensor>]()\n",
      "  %763 = Squeeze(%761, %762)\n",
      "  %764 = Sub(%763, %756)\n",
      "  %765 = Constant[value = <Tensor>]()\n",
      "  %766 = Unsqueeze(%764, %765)\n",
      "  %767 = Constant[value = <Tensor>]()\n",
      "  %768 = Unsqueeze(%763, %767)\n",
      "  %769 = Constant[value = <Tensor>]()\n",
      "  %770 = Unsqueeze(%190, %769)\n",
      "  %771 = Constant[value = <Tensor>]()\n",
      "  %772 = Slice(%decoder_no_past.decoder.transformer.h.1.attn.bias, %766, %768, %770, %771)\n",
      "  %773 = Constant[value = <Tensor>]()\n",
      "  %774 = Unsqueeze(%191, %773)\n",
      "  %775 = Constant[value = <Tensor>]()\n",
      "  %776 = Unsqueeze(%763, %775)\n",
      "  %777 = Constant[value = <Tensor>]()\n",
      "  %778 = Unsqueeze(%185, %777)\n",
      "  %779 = Constant[value = <Tensor>]()\n",
      "  %780 = Slice(%772, %774, %776, %778, %779)\n",
      "  %781 = Cast[to = 9](%780)\n",
      "  %782 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.1.attn.masked_bias)\n",
      "  %783 = Where(%781, %749, %782)\n",
      "  %784 = Add(%783, %381)\n",
      "  %785 = Softmax[axis = -1](%784)\n",
      "  %786 = MatMul(%785, %745)\n",
      "  %787 = Transpose[perm = [0, 2, 1, 3]](%786)\n",
      "  %788 = Shape(%787)\n",
      "  %789 = Constant[value = <Scalar Tensor []>]()\n",
      "  %790 = Gather[axis = 0](%788, %789)\n",
      "  %791 = Shape(%787)\n",
      "  %792 = Constant[value = <Scalar Tensor []>]()\n",
      "  %793 = Gather[axis = 0](%791, %792)\n",
      "  %794 = Constant[value = <Tensor>]()\n",
      "  %795 = Unsqueeze(%790, %794)\n",
      "  %796 = Constant[value = <Tensor>]()\n",
      "  %797 = Unsqueeze(%793, %796)\n",
      "  %798 = Constant[value = <Tensor>]()\n",
      "  %799 = Unsqueeze(%183, %798)\n",
      "  %800 = Concat[axis = 0](%795, %797, %799)\n",
      "  %801 = Reshape[allowzero = 0](%787, %800)\n",
      "  %802 = Shape(%801)\n",
      "  %803 = Constant[value = <Scalar Tensor []>]()\n",
      "  %804 = Gather[axis = 0](%802, %803)\n",
      "  %805 = Shape(%801)\n",
      "  %806 = Constant[value = <Scalar Tensor []>]()\n",
      "  %807 = Gather[axis = 0](%805, %806)\n",
      "  %808 = Shape(%801)\n",
      "  %809 = Constant[value = <Tensor>]()\n",
      "  %810 = Constant[value = <Tensor>]()\n",
      "  %811 = Constant[value = <Tensor>]()\n",
      "  %812 = Slice(%808, %810, %811, %809)\n",
      "  %813 = Constant[value = <Tensor>]()\n",
      "  %814 = Squeeze(%812, %813)\n",
      "  %815 = Constant[value = <Tensor>]()\n",
      "  %816 = Unsqueeze(%186, %815)\n",
      "  %817 = Constant[value = <Tensor>]()\n",
      "  %818 = Unsqueeze(%814, %817)\n",
      "  %819 = Concat[axis = 0](%816, %818)\n",
      "  %820 = Reshape[allowzero = 0](%801, %819)\n",
      "  %821 = Gemm[alpha = 1, beta = 1](%820, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.attn.c_proj.bias)\n",
      "  %822 = Constant[value = <Tensor>]()\n",
      "  %823 = Unsqueeze(%804, %822)\n",
      "  %824 = Constant[value = <Tensor>]()\n",
      "  %825 = Unsqueeze(%807, %824)\n",
      "  %826 = Constant[value = <Tensor>]()\n",
      "  %827 = Unsqueeze(%183, %826)\n",
      "  %828 = Concat[axis = 0](%823, %825, %827)\n",
      "  %829 = Reshape[allowzero = 0](%821, %828)\n",
      "  %830 = Add(%829, %651)\n",
      "  %831 = ReduceMean[axes = [-1]](%830)\n",
      "  %832 = Sub(%830, %831)\n",
      "  %833 = Constant[value = <Scalar Tensor []>]()\n",
      "  %834 = Pow(%832, %833)\n",
      "  %835 = ReduceMean[axes = [-1]](%834)\n",
      "  %836 = Constant[value = <Scalar Tensor []>]()\n",
      "  %837 = Add(%835, %836)\n",
      "  %838 = Sqrt(%837)\n",
      "  %839 = Div(%832, %838)\n",
      "  %840 = Mul(%839, %decoder_no_past.decoder.transformer.h.1.ln_2.weight)\n",
      "  %841 = Add(%840, %decoder_no_past.decoder.transformer.h.1.ln_2.bias)\n",
      "  %842 = Shape(%841)\n",
      "  %843 = Constant[value = <Scalar Tensor []>]()\n",
      "  %844 = Gather[axis = 0](%842, %843)\n",
      "  %845 = Shape(%841)\n",
      "  %846 = Constant[value = <Scalar Tensor []>]()\n",
      "  %847 = Gather[axis = 0](%845, %846)\n",
      "  %848 = Shape(%841)\n",
      "  %849 = Constant[value = <Tensor>]()\n",
      "  %850 = Constant[value = <Tensor>]()\n",
      "  %851 = Constant[value = <Tensor>]()\n",
      "  %852 = Slice(%848, %850, %851, %849)\n",
      "  %853 = Constant[value = <Tensor>]()\n",
      "  %854 = Squeeze(%852, %853)\n",
      "  %855 = Constant[value = <Tensor>]()\n",
      "  %856 = Unsqueeze(%186, %855)\n",
      "  %857 = Constant[value = <Tensor>]()\n",
      "  %858 = Unsqueeze(%854, %857)\n",
      "  %859 = Concat[axis = 0](%856, %858)\n",
      "  %860 = Reshape[allowzero = 0](%841, %859)\n",
      "  %861 = Gemm[alpha = 1, beta = 1](%860, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_fc.bias)\n",
      "  %862 = Constant[value = <Tensor>]()\n",
      "  %863 = Unsqueeze(%844, %862)\n",
      "  %864 = Constant[value = <Tensor>]()\n",
      "  %865 = Unsqueeze(%847, %864)\n",
      "  %866 = Constant[value = <Tensor>]()\n",
      "  %867 = Unsqueeze(%179, %866)\n",
      "  %868 = Concat[axis = 0](%863, %865, %867)\n",
      "  %869 = Reshape[allowzero = 0](%861, %868)\n",
      "  %870 = Constant[value = <Scalar Tensor []>]()\n",
      "  %871 = Mul(%869, %870)\n",
      "  %872 = Constant[value = <Scalar Tensor []>]()\n",
      "  %873 = Pow(%869, %872)\n",
      "  %874 = Constant[value = <Scalar Tensor []>]()\n",
      "  %875 = Mul(%873, %874)\n",
      "  %876 = Add(%869, %875)\n",
      "  %877 = Constant[value = <Scalar Tensor []>]()\n",
      "  %878 = Mul(%876, %877)\n",
      "  %879 = Tanh(%878)\n",
      "  %880 = Constant[value = <Scalar Tensor []>]()\n",
      "  %881 = Add(%879, %880)\n",
      "  %882 = Mul(%871, %881)\n",
      "  %883 = Shape(%882)\n",
      "  %884 = Constant[value = <Scalar Tensor []>]()\n",
      "  %885 = Gather[axis = 0](%883, %884)\n",
      "  %886 = Shape(%882)\n",
      "  %887 = Constant[value = <Scalar Tensor []>]()\n",
      "  %888 = Gather[axis = 0](%886, %887)\n",
      "  %889 = Shape(%882)\n",
      "  %890 = Constant[value = <Tensor>]()\n",
      "  %891 = Constant[value = <Tensor>]()\n",
      "  %892 = Constant[value = <Tensor>]()\n",
      "  %893 = Slice(%889, %891, %892, %890)\n",
      "  %894 = Constant[value = <Tensor>]()\n",
      "  %895 = Squeeze(%893, %894)\n",
      "  %896 = Constant[value = <Tensor>]()\n",
      "  %897 = Unsqueeze(%186, %896)\n",
      "  %898 = Constant[value = <Tensor>]()\n",
      "  %899 = Unsqueeze(%895, %898)\n",
      "  %900 = Concat[axis = 0](%897, %899)\n",
      "  %901 = Reshape[allowzero = 0](%882, %900)\n",
      "  %902 = Gemm[alpha = 1, beta = 1](%901, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.1.mlp.c_proj.bias)\n",
      "  %903 = Constant[value = <Tensor>]()\n",
      "  %904 = Unsqueeze(%885, %903)\n",
      "  %905 = Constant[value = <Tensor>]()\n",
      "  %906 = Unsqueeze(%888, %905)\n",
      "  %907 = Constant[value = <Tensor>]()\n",
      "  %908 = Unsqueeze(%183, %907)\n",
      "  %909 = Concat[axis = 0](%904, %906, %908)\n",
      "  %910 = Reshape[allowzero = 0](%902, %909)\n",
      "  %911 = Add(%830, %910)\n",
      "  %912 = ReduceMean[axes = [-1]](%911)\n",
      "  %913 = Sub(%911, %912)\n",
      "  %914 = Constant[value = <Scalar Tensor []>]()\n",
      "  %915 = Pow(%913, %914)\n",
      "  %916 = ReduceMean[axes = [-1]](%915)\n",
      "  %917 = Constant[value = <Scalar Tensor []>]()\n",
      "  %918 = Add(%916, %917)\n",
      "  %919 = Sqrt(%918)\n",
      "  %920 = Div(%913, %919)\n",
      "  %921 = Mul(%920, %decoder_no_past.decoder.transformer.h.2.ln_1.weight)\n",
      "  %922 = Add(%921, %decoder_no_past.decoder.transformer.h.2.ln_1.bias)\n",
      "  %923 = Shape(%922)\n",
      "  %924 = Constant[value = <Scalar Tensor []>]()\n",
      "  %925 = Gather[axis = 0](%923, %924)\n",
      "  %926 = Shape(%922)\n",
      "  %927 = Constant[value = <Scalar Tensor []>]()\n",
      "  %928 = Gather[axis = 0](%926, %927)\n",
      "  %929 = Shape(%922)\n",
      "  %930 = Constant[value = <Tensor>]()\n",
      "  %931 = Constant[value = <Tensor>]()\n",
      "  %932 = Constant[value = <Tensor>]()\n",
      "  %933 = Slice(%929, %931, %932, %930)\n",
      "  %934 = Constant[value = <Tensor>]()\n",
      "  %935 = Squeeze(%933, %934)\n",
      "  %936 = Constant[value = <Tensor>]()\n",
      "  %937 = Unsqueeze(%186, %936)\n",
      "  %938 = Constant[value = <Tensor>]()\n",
      "  %939 = Unsqueeze(%935, %938)\n",
      "  %940 = Concat[axis = 0](%937, %939)\n",
      "  %941 = Reshape[allowzero = 0](%922, %940)\n",
      "  %942 = Gemm[alpha = 1, beta = 1](%941, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_attn.bias)\n",
      "  %943 = Constant[value = <Tensor>]()\n",
      "  %944 = Unsqueeze(%925, %943)\n",
      "  %945 = Constant[value = <Tensor>]()\n",
      "  %946 = Unsqueeze(%928, %945)\n",
      "  %947 = Constant[value = <Tensor>]()\n",
      "  %948 = Unsqueeze(%182, %947)\n",
      "  %949 = Concat[axis = 0](%944, %946, %948)\n",
      "  %950 = Reshape[allowzero = 0](%942, %949)\n",
      "  %951 = Constant[value = <Tensor>]()\n",
      "  %952, %953, %954 = Split[axis = 2](%950, %951)\n",
      "  %955 = Shape(%952)\n",
      "  %956 = Constant[value = <Scalar Tensor []>]()\n",
      "  %957 = Gather[axis = 0](%955, %956)\n",
      "  %958 = Shape(%952)\n",
      "  %959 = Constant[value = <Scalar Tensor []>]()\n",
      "  %960 = Gather[axis = 0](%958, %959)\n",
      "  %961 = Constant[value = <Tensor>]()\n",
      "  %962 = Unsqueeze(%957, %961)\n",
      "  %963 = Constant[value = <Tensor>]()\n",
      "  %964 = Unsqueeze(%960, %963)\n",
      "  %965 = Constant[value = <Tensor>]()\n",
      "  %966 = Unsqueeze(%181, %965)\n",
      "  %967 = Constant[value = <Tensor>]()\n",
      "  %968 = Unsqueeze(%180, %967)\n",
      "  %969 = Concat[axis = 0](%962, %964, %966, %968)\n",
      "  %970 = Reshape[allowzero = 0](%952, %969)\n",
      "  %971 = Transpose[perm = [0, 2, 1, 3]](%970)\n",
      "  %972 = Shape(%953)\n",
      "  %973 = Constant[value = <Scalar Tensor []>]()\n",
      "  %974 = Gather[axis = 0](%972, %973)\n",
      "  %975 = Shape(%953)\n",
      "  %976 = Constant[value = <Scalar Tensor []>]()\n",
      "  %977 = Gather[axis = 0](%975, %976)\n",
      "  %978 = Constant[value = <Tensor>]()\n",
      "  %979 = Unsqueeze(%974, %978)\n",
      "  %980 = Constant[value = <Tensor>]()\n",
      "  %981 = Unsqueeze(%977, %980)\n",
      "  %982 = Constant[value = <Tensor>]()\n",
      "  %983 = Unsqueeze(%181, %982)\n",
      "  %984 = Constant[value = <Tensor>]()\n",
      "  %985 = Unsqueeze(%180, %984)\n",
      "  %986 = Concat[axis = 0](%979, %981, %983, %985)\n",
      "  %987 = Reshape[allowzero = 0](%953, %986)\n",
      "  %988 = Transpose[perm = [0, 2, 1, 3]](%987)\n",
      "  %989 = Shape(%954)\n",
      "  %990 = Constant[value = <Scalar Tensor []>]()\n",
      "  %991 = Gather[axis = 0](%989, %990)\n",
      "  %992 = Shape(%954)\n",
      "  %993 = Constant[value = <Scalar Tensor []>]()\n",
      "  %994 = Gather[axis = 0](%992, %993)\n",
      "  %995 = Constant[value = <Tensor>]()\n",
      "  %996 = Unsqueeze(%991, %995)\n",
      "  %997 = Constant[value = <Tensor>]()\n",
      "  %998 = Unsqueeze(%994, %997)\n",
      "  %999 = Constant[value = <Tensor>]()\n",
      "  %1000 = Unsqueeze(%181, %999)\n",
      "  %1001 = Constant[value = <Tensor>]()\n",
      "  %1002 = Unsqueeze(%180, %1001)\n",
      "  %1003 = Concat[axis = 0](%996, %998, %1000, %1002)\n",
      "  %1004 = Reshape[allowzero = 0](%954, %1003)\n",
      "  %1005 = Transpose[perm = [0, 2, 1, 3]](%1004)\n",
      "  %1006 = Transpose[perm = [0, 2, 3, 1]](%987)\n",
      "  %1007 = MatMul(%971, %1006)\n",
      "  %1008 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1009 = Div(%1007, %1008)\n",
      "  %1010 = Shape(%971)\n",
      "  %1011 = Constant[value = <Tensor>]()\n",
      "  %1012 = Constant[value = <Tensor>]()\n",
      "  %1013 = Constant[value = <Tensor>]()\n",
      "  %1014 = Slice(%1010, %1012, %1013, %1011)\n",
      "  %1015 = Constant[value = <Tensor>]()\n",
      "  %1016 = Squeeze(%1014, %1015)\n",
      "  %1017 = Shape(%988)\n",
      "  %1018 = Constant[value = <Tensor>]()\n",
      "  %1019 = Constant[value = <Tensor>]()\n",
      "  %1020 = Constant[value = <Tensor>]()\n",
      "  %1021 = Slice(%1017, %1019, %1020, %1018)\n",
      "  %1022 = Constant[value = <Tensor>]()\n",
      "  %1023 = Squeeze(%1021, %1022)\n",
      "  %1024 = Sub(%1023, %1016)\n",
      "  %1025 = Constant[value = <Tensor>]()\n",
      "  %1026 = Unsqueeze(%1024, %1025)\n",
      "  %1027 = Constant[value = <Tensor>]()\n",
      "  %1028 = Unsqueeze(%1023, %1027)\n",
      "  %1029 = Constant[value = <Tensor>]()\n",
      "  %1030 = Unsqueeze(%190, %1029)\n",
      "  %1031 = Constant[value = <Tensor>]()\n",
      "  %1032 = Slice(%decoder_no_past.decoder.transformer.h.2.attn.bias, %1026, %1028, %1030, %1031)\n",
      "  %1033 = Constant[value = <Tensor>]()\n",
      "  %1034 = Unsqueeze(%191, %1033)\n",
      "  %1035 = Constant[value = <Tensor>]()\n",
      "  %1036 = Unsqueeze(%1023, %1035)\n",
      "  %1037 = Constant[value = <Tensor>]()\n",
      "  %1038 = Unsqueeze(%185, %1037)\n",
      "  %1039 = Constant[value = <Tensor>]()\n",
      "  %1040 = Slice(%1032, %1034, %1036, %1038, %1039)\n",
      "  %1041 = Cast[to = 9](%1040)\n",
      "  %1042 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.2.attn.masked_bias)\n",
      "  %1043 = Where(%1041, %1009, %1042)\n",
      "  %1044 = Add(%1043, %381)\n",
      "  %1045 = Softmax[axis = -1](%1044)\n",
      "  %1046 = MatMul(%1045, %1005)\n",
      "  %1047 = Transpose[perm = [0, 2, 1, 3]](%1046)\n",
      "  %1048 = Shape(%1047)\n",
      "  %1049 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1050 = Gather[axis = 0](%1048, %1049)\n",
      "  %1051 = Shape(%1047)\n",
      "  %1052 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1053 = Gather[axis = 0](%1051, %1052)\n",
      "  %1054 = Constant[value = <Tensor>]()\n",
      "  %1055 = Unsqueeze(%1050, %1054)\n",
      "  %1056 = Constant[value = <Tensor>]()\n",
      "  %1057 = Unsqueeze(%1053, %1056)\n",
      "  %1058 = Constant[value = <Tensor>]()\n",
      "  %1059 = Unsqueeze(%183, %1058)\n",
      "  %1060 = Concat[axis = 0](%1055, %1057, %1059)\n",
      "  %1061 = Reshape[allowzero = 0](%1047, %1060)\n",
      "  %1062 = Shape(%1061)\n",
      "  %1063 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1064 = Gather[axis = 0](%1062, %1063)\n",
      "  %1065 = Shape(%1061)\n",
      "  %1066 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1067 = Gather[axis = 0](%1065, %1066)\n",
      "  %1068 = Shape(%1061)\n",
      "  %1069 = Constant[value = <Tensor>]()\n",
      "  %1070 = Constant[value = <Tensor>]()\n",
      "  %1071 = Constant[value = <Tensor>]()\n",
      "  %1072 = Slice(%1068, %1070, %1071, %1069)\n",
      "  %1073 = Constant[value = <Tensor>]()\n",
      "  %1074 = Squeeze(%1072, %1073)\n",
      "  %1075 = Constant[value = <Tensor>]()\n",
      "  %1076 = Unsqueeze(%186, %1075)\n",
      "  %1077 = Constant[value = <Tensor>]()\n",
      "  %1078 = Unsqueeze(%1074, %1077)\n",
      "  %1079 = Concat[axis = 0](%1076, %1078)\n",
      "  %1080 = Reshape[allowzero = 0](%1061, %1079)\n",
      "  %1081 = Gemm[alpha = 1, beta = 1](%1080, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.attn.c_proj.bias)\n",
      "  %1082 = Constant[value = <Tensor>]()\n",
      "  %1083 = Unsqueeze(%1064, %1082)\n",
      "  %1084 = Constant[value = <Tensor>]()\n",
      "  %1085 = Unsqueeze(%1067, %1084)\n",
      "  %1086 = Constant[value = <Tensor>]()\n",
      "  %1087 = Unsqueeze(%183, %1086)\n",
      "  %1088 = Concat[axis = 0](%1083, %1085, %1087)\n",
      "  %1089 = Reshape[allowzero = 0](%1081, %1088)\n",
      "  %1090 = Add(%1089, %911)\n",
      "  %1091 = ReduceMean[axes = [-1]](%1090)\n",
      "  %1092 = Sub(%1090, %1091)\n",
      "  %1093 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1094 = Pow(%1092, %1093)\n",
      "  %1095 = ReduceMean[axes = [-1]](%1094)\n",
      "  %1096 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1097 = Add(%1095, %1096)\n",
      "  %1098 = Sqrt(%1097)\n",
      "  %1099 = Div(%1092, %1098)\n",
      "  %1100 = Mul(%1099, %decoder_no_past.decoder.transformer.h.2.ln_2.weight)\n",
      "  %1101 = Add(%1100, %decoder_no_past.decoder.transformer.h.2.ln_2.bias)\n",
      "  %1102 = Shape(%1101)\n",
      "  %1103 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1104 = Gather[axis = 0](%1102, %1103)\n",
      "  %1105 = Shape(%1101)\n",
      "  %1106 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1107 = Gather[axis = 0](%1105, %1106)\n",
      "  %1108 = Shape(%1101)\n",
      "  %1109 = Constant[value = <Tensor>]()\n",
      "  %1110 = Constant[value = <Tensor>]()\n",
      "  %1111 = Constant[value = <Tensor>]()\n",
      "  %1112 = Slice(%1108, %1110, %1111, %1109)\n",
      "  %1113 = Constant[value = <Tensor>]()\n",
      "  %1114 = Squeeze(%1112, %1113)\n",
      "  %1115 = Constant[value = <Tensor>]()\n",
      "  %1116 = Unsqueeze(%186, %1115)\n",
      "  %1117 = Constant[value = <Tensor>]()\n",
      "  %1118 = Unsqueeze(%1114, %1117)\n",
      "  %1119 = Concat[axis = 0](%1116, %1118)\n",
      "  %1120 = Reshape[allowzero = 0](%1101, %1119)\n",
      "  %1121 = Gemm[alpha = 1, beta = 1](%1120, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_fc.bias)\n",
      "  %1122 = Constant[value = <Tensor>]()\n",
      "  %1123 = Unsqueeze(%1104, %1122)\n",
      "  %1124 = Constant[value = <Tensor>]()\n",
      "  %1125 = Unsqueeze(%1107, %1124)\n",
      "  %1126 = Constant[value = <Tensor>]()\n",
      "  %1127 = Unsqueeze(%179, %1126)\n",
      "  %1128 = Concat[axis = 0](%1123, %1125, %1127)\n",
      "  %1129 = Reshape[allowzero = 0](%1121, %1128)\n",
      "  %1130 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1131 = Mul(%1129, %1130)\n",
      "  %1132 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1133 = Pow(%1129, %1132)\n",
      "  %1134 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1135 = Mul(%1133, %1134)\n",
      "  %1136 = Add(%1129, %1135)\n",
      "  %1137 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1138 = Mul(%1136, %1137)\n",
      "  %1139 = Tanh(%1138)\n",
      "  %1140 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1141 = Add(%1139, %1140)\n",
      "  %1142 = Mul(%1131, %1141)\n",
      "  %1143 = Shape(%1142)\n",
      "  %1144 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1145 = Gather[axis = 0](%1143, %1144)\n",
      "  %1146 = Shape(%1142)\n",
      "  %1147 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1148 = Gather[axis = 0](%1146, %1147)\n",
      "  %1149 = Shape(%1142)\n",
      "  %1150 = Constant[value = <Tensor>]()\n",
      "  %1151 = Constant[value = <Tensor>]()\n",
      "  %1152 = Constant[value = <Tensor>]()\n",
      "  %1153 = Slice(%1149, %1151, %1152, %1150)\n",
      "  %1154 = Constant[value = <Tensor>]()\n",
      "  %1155 = Squeeze(%1153, %1154)\n",
      "  %1156 = Constant[value = <Tensor>]()\n",
      "  %1157 = Unsqueeze(%186, %1156)\n",
      "  %1158 = Constant[value = <Tensor>]()\n",
      "  %1159 = Unsqueeze(%1155, %1158)\n",
      "  %1160 = Concat[axis = 0](%1157, %1159)\n",
      "  %1161 = Reshape[allowzero = 0](%1142, %1160)\n",
      "  %1162 = Gemm[alpha = 1, beta = 1](%1161, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.2.mlp.c_proj.bias)\n",
      "  %1163 = Constant[value = <Tensor>]()\n",
      "  %1164 = Unsqueeze(%1145, %1163)\n",
      "  %1165 = Constant[value = <Tensor>]()\n",
      "  %1166 = Unsqueeze(%1148, %1165)\n",
      "  %1167 = Constant[value = <Tensor>]()\n",
      "  %1168 = Unsqueeze(%183, %1167)\n",
      "  %1169 = Concat[axis = 0](%1164, %1166, %1168)\n",
      "  %1170 = Reshape[allowzero = 0](%1162, %1169)\n",
      "  %1171 = Add(%1090, %1170)\n",
      "  %1172 = ReduceMean[axes = [-1]](%1171)\n",
      "  %1173 = Sub(%1171, %1172)\n",
      "  %1174 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1175 = Pow(%1173, %1174)\n",
      "  %1176 = ReduceMean[axes = [-1]](%1175)\n",
      "  %1177 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1178 = Add(%1176, %1177)\n",
      "  %1179 = Sqrt(%1178)\n",
      "  %1180 = Div(%1173, %1179)\n",
      "  %1181 = Mul(%1180, %decoder_no_past.decoder.transformer.h.3.ln_1.weight)\n",
      "  %1182 = Add(%1181, %decoder_no_past.decoder.transformer.h.3.ln_1.bias)\n",
      "  %1183 = Shape(%1182)\n",
      "  %1184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1185 = Gather[axis = 0](%1183, %1184)\n",
      "  %1186 = Shape(%1182)\n",
      "  %1187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1188 = Gather[axis = 0](%1186, %1187)\n",
      "  %1189 = Shape(%1182)\n",
      "  %1190 = Constant[value = <Tensor>]()\n",
      "  %1191 = Constant[value = <Tensor>]()\n",
      "  %1192 = Constant[value = <Tensor>]()\n",
      "  %1193 = Slice(%1189, %1191, %1192, %1190)\n",
      "  %1194 = Constant[value = <Tensor>]()\n",
      "  %1195 = Squeeze(%1193, %1194)\n",
      "  %1196 = Constant[value = <Tensor>]()\n",
      "  %1197 = Unsqueeze(%186, %1196)\n",
      "  %1198 = Constant[value = <Tensor>]()\n",
      "  %1199 = Unsqueeze(%1195, %1198)\n",
      "  %1200 = Concat[axis = 0](%1197, %1199)\n",
      "  %1201 = Reshape[allowzero = 0](%1182, %1200)\n",
      "  %1202 = Gemm[alpha = 1, beta = 1](%1201, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_attn.bias)\n",
      "  %1203 = Constant[value = <Tensor>]()\n",
      "  %1204 = Unsqueeze(%1185, %1203)\n",
      "  %1205 = Constant[value = <Tensor>]()\n",
      "  %1206 = Unsqueeze(%1188, %1205)\n",
      "  %1207 = Constant[value = <Tensor>]()\n",
      "  %1208 = Unsqueeze(%182, %1207)\n",
      "  %1209 = Concat[axis = 0](%1204, %1206, %1208)\n",
      "  %1210 = Reshape[allowzero = 0](%1202, %1209)\n",
      "  %1211 = Constant[value = <Tensor>]()\n",
      "  %1212, %1213, %1214 = Split[axis = 2](%1210, %1211)\n",
      "  %1215 = Shape(%1212)\n",
      "  %1216 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1217 = Gather[axis = 0](%1215, %1216)\n",
      "  %1218 = Shape(%1212)\n",
      "  %1219 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1220 = Gather[axis = 0](%1218, %1219)\n",
      "  %1221 = Constant[value = <Tensor>]()\n",
      "  %1222 = Unsqueeze(%1217, %1221)\n",
      "  %1223 = Constant[value = <Tensor>]()\n",
      "  %1224 = Unsqueeze(%1220, %1223)\n",
      "  %1225 = Constant[value = <Tensor>]()\n",
      "  %1226 = Unsqueeze(%181, %1225)\n",
      "  %1227 = Constant[value = <Tensor>]()\n",
      "  %1228 = Unsqueeze(%180, %1227)\n",
      "  %1229 = Concat[axis = 0](%1222, %1224, %1226, %1228)\n",
      "  %1230 = Reshape[allowzero = 0](%1212, %1229)\n",
      "  %1231 = Transpose[perm = [0, 2, 1, 3]](%1230)\n",
      "  %1232 = Shape(%1213)\n",
      "  %1233 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1234 = Gather[axis = 0](%1232, %1233)\n",
      "  %1235 = Shape(%1213)\n",
      "  %1236 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1237 = Gather[axis = 0](%1235, %1236)\n",
      "  %1238 = Constant[value = <Tensor>]()\n",
      "  %1239 = Unsqueeze(%1234, %1238)\n",
      "  %1240 = Constant[value = <Tensor>]()\n",
      "  %1241 = Unsqueeze(%1237, %1240)\n",
      "  %1242 = Constant[value = <Tensor>]()\n",
      "  %1243 = Unsqueeze(%181, %1242)\n",
      "  %1244 = Constant[value = <Tensor>]()\n",
      "  %1245 = Unsqueeze(%180, %1244)\n",
      "  %1246 = Concat[axis = 0](%1239, %1241, %1243, %1245)\n",
      "  %1247 = Reshape[allowzero = 0](%1213, %1246)\n",
      "  %1248 = Transpose[perm = [0, 2, 1, 3]](%1247)\n",
      "  %1249 = Shape(%1214)\n",
      "  %1250 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1251 = Gather[axis = 0](%1249, %1250)\n",
      "  %1252 = Shape(%1214)\n",
      "  %1253 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1254 = Gather[axis = 0](%1252, %1253)\n",
      "  %1255 = Constant[value = <Tensor>]()\n",
      "  %1256 = Unsqueeze(%1251, %1255)\n",
      "  %1257 = Constant[value = <Tensor>]()\n",
      "  %1258 = Unsqueeze(%1254, %1257)\n",
      "  %1259 = Constant[value = <Tensor>]()\n",
      "  %1260 = Unsqueeze(%181, %1259)\n",
      "  %1261 = Constant[value = <Tensor>]()\n",
      "  %1262 = Unsqueeze(%180, %1261)\n",
      "  %1263 = Concat[axis = 0](%1256, %1258, %1260, %1262)\n",
      "  %1264 = Reshape[allowzero = 0](%1214, %1263)\n",
      "  %1265 = Transpose[perm = [0, 2, 1, 3]](%1264)\n",
      "  %1266 = Transpose[perm = [0, 2, 3, 1]](%1247)\n",
      "  %1267 = MatMul(%1231, %1266)\n",
      "  %1268 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1269 = Div(%1267, %1268)\n",
      "  %1270 = Shape(%1231)\n",
      "  %1271 = Constant[value = <Tensor>]()\n",
      "  %1272 = Constant[value = <Tensor>]()\n",
      "  %1273 = Constant[value = <Tensor>]()\n",
      "  %1274 = Slice(%1270, %1272, %1273, %1271)\n",
      "  %1275 = Constant[value = <Tensor>]()\n",
      "  %1276 = Squeeze(%1274, %1275)\n",
      "  %1277 = Shape(%1248)\n",
      "  %1278 = Constant[value = <Tensor>]()\n",
      "  %1279 = Constant[value = <Tensor>]()\n",
      "  %1280 = Constant[value = <Tensor>]()\n",
      "  %1281 = Slice(%1277, %1279, %1280, %1278)\n",
      "  %1282 = Constant[value = <Tensor>]()\n",
      "  %1283 = Squeeze(%1281, %1282)\n",
      "  %1284 = Sub(%1283, %1276)\n",
      "  %1285 = Constant[value = <Tensor>]()\n",
      "  %1286 = Unsqueeze(%1284, %1285)\n",
      "  %1287 = Constant[value = <Tensor>]()\n",
      "  %1288 = Unsqueeze(%1283, %1287)\n",
      "  %1289 = Constant[value = <Tensor>]()\n",
      "  %1290 = Unsqueeze(%190, %1289)\n",
      "  %1291 = Constant[value = <Tensor>]()\n",
      "  %1292 = Slice(%decoder_no_past.decoder.transformer.h.3.attn.bias, %1286, %1288, %1290, %1291)\n",
      "  %1293 = Constant[value = <Tensor>]()\n",
      "  %1294 = Unsqueeze(%191, %1293)\n",
      "  %1295 = Constant[value = <Tensor>]()\n",
      "  %1296 = Unsqueeze(%1283, %1295)\n",
      "  %1297 = Constant[value = <Tensor>]()\n",
      "  %1298 = Unsqueeze(%185, %1297)\n",
      "  %1299 = Constant[value = <Tensor>]()\n",
      "  %1300 = Slice(%1292, %1294, %1296, %1298, %1299)\n",
      "  %1301 = Cast[to = 9](%1300)\n",
      "  %1302 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.3.attn.masked_bias)\n",
      "  %1303 = Where(%1301, %1269, %1302)\n",
      "  %1304 = Add(%1303, %381)\n",
      "  %1305 = Softmax[axis = -1](%1304)\n",
      "  %1306 = MatMul(%1305, %1265)\n",
      "  %1307 = Transpose[perm = [0, 2, 1, 3]](%1306)\n",
      "  %1308 = Shape(%1307)\n",
      "  %1309 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1310 = Gather[axis = 0](%1308, %1309)\n",
      "  %1311 = Shape(%1307)\n",
      "  %1312 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1313 = Gather[axis = 0](%1311, %1312)\n",
      "  %1314 = Constant[value = <Tensor>]()\n",
      "  %1315 = Unsqueeze(%1310, %1314)\n",
      "  %1316 = Constant[value = <Tensor>]()\n",
      "  %1317 = Unsqueeze(%1313, %1316)\n",
      "  %1318 = Constant[value = <Tensor>]()\n",
      "  %1319 = Unsqueeze(%183, %1318)\n",
      "  %1320 = Concat[axis = 0](%1315, %1317, %1319)\n",
      "  %1321 = Reshape[allowzero = 0](%1307, %1320)\n",
      "  %1322 = Shape(%1321)\n",
      "  %1323 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1324 = Gather[axis = 0](%1322, %1323)\n",
      "  %1325 = Shape(%1321)\n",
      "  %1326 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1327 = Gather[axis = 0](%1325, %1326)\n",
      "  %1328 = Shape(%1321)\n",
      "  %1329 = Constant[value = <Tensor>]()\n",
      "  %1330 = Constant[value = <Tensor>]()\n",
      "  %1331 = Constant[value = <Tensor>]()\n",
      "  %1332 = Slice(%1328, %1330, %1331, %1329)\n",
      "  %1333 = Constant[value = <Tensor>]()\n",
      "  %1334 = Squeeze(%1332, %1333)\n",
      "  %1335 = Constant[value = <Tensor>]()\n",
      "  %1336 = Unsqueeze(%186, %1335)\n",
      "  %1337 = Constant[value = <Tensor>]()\n",
      "  %1338 = Unsqueeze(%1334, %1337)\n",
      "  %1339 = Concat[axis = 0](%1336, %1338)\n",
      "  %1340 = Reshape[allowzero = 0](%1321, %1339)\n",
      "  %1341 = Gemm[alpha = 1, beta = 1](%1340, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.attn.c_proj.bias)\n",
      "  %1342 = Constant[value = <Tensor>]()\n",
      "  %1343 = Unsqueeze(%1324, %1342)\n",
      "  %1344 = Constant[value = <Tensor>]()\n",
      "  %1345 = Unsqueeze(%1327, %1344)\n",
      "  %1346 = Constant[value = <Tensor>]()\n",
      "  %1347 = Unsqueeze(%183, %1346)\n",
      "  %1348 = Concat[axis = 0](%1343, %1345, %1347)\n",
      "  %1349 = Reshape[allowzero = 0](%1341, %1348)\n",
      "  %1350 = Add(%1349, %1171)\n",
      "  %1351 = ReduceMean[axes = [-1]](%1350)\n",
      "  %1352 = Sub(%1350, %1351)\n",
      "  %1353 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1354 = Pow(%1352, %1353)\n",
      "  %1355 = ReduceMean[axes = [-1]](%1354)\n",
      "  %1356 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1357 = Add(%1355, %1356)\n",
      "  %1358 = Sqrt(%1357)\n",
      "  %1359 = Div(%1352, %1358)\n",
      "  %1360 = Mul(%1359, %decoder_no_past.decoder.transformer.h.3.ln_2.weight)\n",
      "  %1361 = Add(%1360, %decoder_no_past.decoder.transformer.h.3.ln_2.bias)\n",
      "  %1362 = Shape(%1361)\n",
      "  %1363 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1364 = Gather[axis = 0](%1362, %1363)\n",
      "  %1365 = Shape(%1361)\n",
      "  %1366 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1367 = Gather[axis = 0](%1365, %1366)\n",
      "  %1368 = Shape(%1361)\n",
      "  %1369 = Constant[value = <Tensor>]()\n",
      "  %1370 = Constant[value = <Tensor>]()\n",
      "  %1371 = Constant[value = <Tensor>]()\n",
      "  %1372 = Slice(%1368, %1370, %1371, %1369)\n",
      "  %1373 = Constant[value = <Tensor>]()\n",
      "  %1374 = Squeeze(%1372, %1373)\n",
      "  %1375 = Constant[value = <Tensor>]()\n",
      "  %1376 = Unsqueeze(%186, %1375)\n",
      "  %1377 = Constant[value = <Tensor>]()\n",
      "  %1378 = Unsqueeze(%1374, %1377)\n",
      "  %1379 = Concat[axis = 0](%1376, %1378)\n",
      "  %1380 = Reshape[allowzero = 0](%1361, %1379)\n",
      "  %1381 = Gemm[alpha = 1, beta = 1](%1380, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_fc.bias)\n",
      "  %1382 = Constant[value = <Tensor>]()\n",
      "  %1383 = Unsqueeze(%1364, %1382)\n",
      "  %1384 = Constant[value = <Tensor>]()\n",
      "  %1385 = Unsqueeze(%1367, %1384)\n",
      "  %1386 = Constant[value = <Tensor>]()\n",
      "  %1387 = Unsqueeze(%179, %1386)\n",
      "  %1388 = Concat[axis = 0](%1383, %1385, %1387)\n",
      "  %1389 = Reshape[allowzero = 0](%1381, %1388)\n",
      "  %1390 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1391 = Mul(%1389, %1390)\n",
      "  %1392 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1393 = Pow(%1389, %1392)\n",
      "  %1394 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1395 = Mul(%1393, %1394)\n",
      "  %1396 = Add(%1389, %1395)\n",
      "  %1397 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1398 = Mul(%1396, %1397)\n",
      "  %1399 = Tanh(%1398)\n",
      "  %1400 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1401 = Add(%1399, %1400)\n",
      "  %1402 = Mul(%1391, %1401)\n",
      "  %1403 = Shape(%1402)\n",
      "  %1404 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1405 = Gather[axis = 0](%1403, %1404)\n",
      "  %1406 = Shape(%1402)\n",
      "  %1407 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1408 = Gather[axis = 0](%1406, %1407)\n",
      "  %1409 = Shape(%1402)\n",
      "  %1410 = Constant[value = <Tensor>]()\n",
      "  %1411 = Constant[value = <Tensor>]()\n",
      "  %1412 = Constant[value = <Tensor>]()\n",
      "  %1413 = Slice(%1409, %1411, %1412, %1410)\n",
      "  %1414 = Constant[value = <Tensor>]()\n",
      "  %1415 = Squeeze(%1413, %1414)\n",
      "  %1416 = Constant[value = <Tensor>]()\n",
      "  %1417 = Unsqueeze(%186, %1416)\n",
      "  %1418 = Constant[value = <Tensor>]()\n",
      "  %1419 = Unsqueeze(%1415, %1418)\n",
      "  %1420 = Concat[axis = 0](%1417, %1419)\n",
      "  %1421 = Reshape[allowzero = 0](%1402, %1420)\n",
      "  %1422 = Gemm[alpha = 1, beta = 1](%1421, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.3.mlp.c_proj.bias)\n",
      "  %1423 = Constant[value = <Tensor>]()\n",
      "  %1424 = Unsqueeze(%1405, %1423)\n",
      "  %1425 = Constant[value = <Tensor>]()\n",
      "  %1426 = Unsqueeze(%1408, %1425)\n",
      "  %1427 = Constant[value = <Tensor>]()\n",
      "  %1428 = Unsqueeze(%183, %1427)\n",
      "  %1429 = Concat[axis = 0](%1424, %1426, %1428)\n",
      "  %1430 = Reshape[allowzero = 0](%1422, %1429)\n",
      "  %1431 = Add(%1350, %1430)\n",
      "  %1432 = ReduceMean[axes = [-1]](%1431)\n",
      "  %1433 = Sub(%1431, %1432)\n",
      "  %1434 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1435 = Pow(%1433, %1434)\n",
      "  %1436 = ReduceMean[axes = [-1]](%1435)\n",
      "  %1437 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1438 = Add(%1436, %1437)\n",
      "  %1439 = Sqrt(%1438)\n",
      "  %1440 = Div(%1433, %1439)\n",
      "  %1441 = Mul(%1440, %decoder_no_past.decoder.transformer.h.4.ln_1.weight)\n",
      "  %1442 = Add(%1441, %decoder_no_past.decoder.transformer.h.4.ln_1.bias)\n",
      "  %1443 = Shape(%1442)\n",
      "  %1444 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1445 = Gather[axis = 0](%1443, %1444)\n",
      "  %1446 = Shape(%1442)\n",
      "  %1447 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1448 = Gather[axis = 0](%1446, %1447)\n",
      "  %1449 = Shape(%1442)\n",
      "  %1450 = Constant[value = <Tensor>]()\n",
      "  %1451 = Constant[value = <Tensor>]()\n",
      "  %1452 = Constant[value = <Tensor>]()\n",
      "  %1453 = Slice(%1449, %1451, %1452, %1450)\n",
      "  %1454 = Constant[value = <Tensor>]()\n",
      "  %1455 = Squeeze(%1453, %1454)\n",
      "  %1456 = Constant[value = <Tensor>]()\n",
      "  %1457 = Unsqueeze(%186, %1456)\n",
      "  %1458 = Constant[value = <Tensor>]()\n",
      "  %1459 = Unsqueeze(%1455, %1458)\n",
      "  %1460 = Concat[axis = 0](%1457, %1459)\n",
      "  %1461 = Reshape[allowzero = 0](%1442, %1460)\n",
      "  %1462 = Gemm[alpha = 1, beta = 1](%1461, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_attn.bias)\n",
      "  %1463 = Constant[value = <Tensor>]()\n",
      "  %1464 = Unsqueeze(%1445, %1463)\n",
      "  %1465 = Constant[value = <Tensor>]()\n",
      "  %1466 = Unsqueeze(%1448, %1465)\n",
      "  %1467 = Constant[value = <Tensor>]()\n",
      "  %1468 = Unsqueeze(%182, %1467)\n",
      "  %1469 = Concat[axis = 0](%1464, %1466, %1468)\n",
      "  %1470 = Reshape[allowzero = 0](%1462, %1469)\n",
      "  %1471 = Constant[value = <Tensor>]()\n",
      "  %1472, %1473, %1474 = Split[axis = 2](%1470, %1471)\n",
      "  %1475 = Shape(%1472)\n",
      "  %1476 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1477 = Gather[axis = 0](%1475, %1476)\n",
      "  %1478 = Shape(%1472)\n",
      "  %1479 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1480 = Gather[axis = 0](%1478, %1479)\n",
      "  %1481 = Constant[value = <Tensor>]()\n",
      "  %1482 = Unsqueeze(%1477, %1481)\n",
      "  %1483 = Constant[value = <Tensor>]()\n",
      "  %1484 = Unsqueeze(%1480, %1483)\n",
      "  %1485 = Constant[value = <Tensor>]()\n",
      "  %1486 = Unsqueeze(%181, %1485)\n",
      "  %1487 = Constant[value = <Tensor>]()\n",
      "  %1488 = Unsqueeze(%180, %1487)\n",
      "  %1489 = Concat[axis = 0](%1482, %1484, %1486, %1488)\n",
      "  %1490 = Reshape[allowzero = 0](%1472, %1489)\n",
      "  %1491 = Transpose[perm = [0, 2, 1, 3]](%1490)\n",
      "  %1492 = Shape(%1473)\n",
      "  %1493 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1494 = Gather[axis = 0](%1492, %1493)\n",
      "  %1495 = Shape(%1473)\n",
      "  %1496 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1497 = Gather[axis = 0](%1495, %1496)\n",
      "  %1498 = Constant[value = <Tensor>]()\n",
      "  %1499 = Unsqueeze(%1494, %1498)\n",
      "  %1500 = Constant[value = <Tensor>]()\n",
      "  %1501 = Unsqueeze(%1497, %1500)\n",
      "  %1502 = Constant[value = <Tensor>]()\n",
      "  %1503 = Unsqueeze(%181, %1502)\n",
      "  %1504 = Constant[value = <Tensor>]()\n",
      "  %1505 = Unsqueeze(%180, %1504)\n",
      "  %1506 = Concat[axis = 0](%1499, %1501, %1503, %1505)\n",
      "  %1507 = Reshape[allowzero = 0](%1473, %1506)\n",
      "  %1508 = Transpose[perm = [0, 2, 1, 3]](%1507)\n",
      "  %1509 = Shape(%1474)\n",
      "  %1510 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1511 = Gather[axis = 0](%1509, %1510)\n",
      "  %1512 = Shape(%1474)\n",
      "  %1513 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1514 = Gather[axis = 0](%1512, %1513)\n",
      "  %1515 = Constant[value = <Tensor>]()\n",
      "  %1516 = Unsqueeze(%1511, %1515)\n",
      "  %1517 = Constant[value = <Tensor>]()\n",
      "  %1518 = Unsqueeze(%1514, %1517)\n",
      "  %1519 = Constant[value = <Tensor>]()\n",
      "  %1520 = Unsqueeze(%181, %1519)\n",
      "  %1521 = Constant[value = <Tensor>]()\n",
      "  %1522 = Unsqueeze(%180, %1521)\n",
      "  %1523 = Concat[axis = 0](%1516, %1518, %1520, %1522)\n",
      "  %1524 = Reshape[allowzero = 0](%1474, %1523)\n",
      "  %1525 = Transpose[perm = [0, 2, 1, 3]](%1524)\n",
      "  %1526 = Transpose[perm = [0, 2, 3, 1]](%1507)\n",
      "  %1527 = MatMul(%1491, %1526)\n",
      "  %1528 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1529 = Div(%1527, %1528)\n",
      "  %1530 = Shape(%1491)\n",
      "  %1531 = Constant[value = <Tensor>]()\n",
      "  %1532 = Constant[value = <Tensor>]()\n",
      "  %1533 = Constant[value = <Tensor>]()\n",
      "  %1534 = Slice(%1530, %1532, %1533, %1531)\n",
      "  %1535 = Constant[value = <Tensor>]()\n",
      "  %1536 = Squeeze(%1534, %1535)\n",
      "  %1537 = Shape(%1508)\n",
      "  %1538 = Constant[value = <Tensor>]()\n",
      "  %1539 = Constant[value = <Tensor>]()\n",
      "  %1540 = Constant[value = <Tensor>]()\n",
      "  %1541 = Slice(%1537, %1539, %1540, %1538)\n",
      "  %1542 = Constant[value = <Tensor>]()\n",
      "  %1543 = Squeeze(%1541, %1542)\n",
      "  %1544 = Sub(%1543, %1536)\n",
      "  %1545 = Constant[value = <Tensor>]()\n",
      "  %1546 = Unsqueeze(%1544, %1545)\n",
      "  %1547 = Constant[value = <Tensor>]()\n",
      "  %1548 = Unsqueeze(%1543, %1547)\n",
      "  %1549 = Constant[value = <Tensor>]()\n",
      "  %1550 = Unsqueeze(%190, %1549)\n",
      "  %1551 = Constant[value = <Tensor>]()\n",
      "  %1552 = Slice(%decoder_no_past.decoder.transformer.h.4.attn.bias, %1546, %1548, %1550, %1551)\n",
      "  %1553 = Constant[value = <Tensor>]()\n",
      "  %1554 = Unsqueeze(%191, %1553)\n",
      "  %1555 = Constant[value = <Tensor>]()\n",
      "  %1556 = Unsqueeze(%1543, %1555)\n",
      "  %1557 = Constant[value = <Tensor>]()\n",
      "  %1558 = Unsqueeze(%185, %1557)\n",
      "  %1559 = Constant[value = <Tensor>]()\n",
      "  %1560 = Slice(%1552, %1554, %1556, %1558, %1559)\n",
      "  %1561 = Cast[to = 9](%1560)\n",
      "  %1562 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.4.attn.masked_bias)\n",
      "  %1563 = Where(%1561, %1529, %1562)\n",
      "  %1564 = Add(%1563, %381)\n",
      "  %1565 = Softmax[axis = -1](%1564)\n",
      "  %1566 = MatMul(%1565, %1525)\n",
      "  %1567 = Transpose[perm = [0, 2, 1, 3]](%1566)\n",
      "  %1568 = Shape(%1567)\n",
      "  %1569 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1570 = Gather[axis = 0](%1568, %1569)\n",
      "  %1571 = Shape(%1567)\n",
      "  %1572 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1573 = Gather[axis = 0](%1571, %1572)\n",
      "  %1574 = Constant[value = <Tensor>]()\n",
      "  %1575 = Unsqueeze(%1570, %1574)\n",
      "  %1576 = Constant[value = <Tensor>]()\n",
      "  %1577 = Unsqueeze(%1573, %1576)\n",
      "  %1578 = Constant[value = <Tensor>]()\n",
      "  %1579 = Unsqueeze(%183, %1578)\n",
      "  %1580 = Concat[axis = 0](%1575, %1577, %1579)\n",
      "  %1581 = Reshape[allowzero = 0](%1567, %1580)\n",
      "  %1582 = Shape(%1581)\n",
      "  %1583 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1584 = Gather[axis = 0](%1582, %1583)\n",
      "  %1585 = Shape(%1581)\n",
      "  %1586 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1587 = Gather[axis = 0](%1585, %1586)\n",
      "  %1588 = Shape(%1581)\n",
      "  %1589 = Constant[value = <Tensor>]()\n",
      "  %1590 = Constant[value = <Tensor>]()\n",
      "  %1591 = Constant[value = <Tensor>]()\n",
      "  %1592 = Slice(%1588, %1590, %1591, %1589)\n",
      "  %1593 = Constant[value = <Tensor>]()\n",
      "  %1594 = Squeeze(%1592, %1593)\n",
      "  %1595 = Constant[value = <Tensor>]()\n",
      "  %1596 = Unsqueeze(%186, %1595)\n",
      "  %1597 = Constant[value = <Tensor>]()\n",
      "  %1598 = Unsqueeze(%1594, %1597)\n",
      "  %1599 = Concat[axis = 0](%1596, %1598)\n",
      "  %1600 = Reshape[allowzero = 0](%1581, %1599)\n",
      "  %1601 = Gemm[alpha = 1, beta = 1](%1600, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.attn.c_proj.bias)\n",
      "  %1602 = Constant[value = <Tensor>]()\n",
      "  %1603 = Unsqueeze(%1584, %1602)\n",
      "  %1604 = Constant[value = <Tensor>]()\n",
      "  %1605 = Unsqueeze(%1587, %1604)\n",
      "  %1606 = Constant[value = <Tensor>]()\n",
      "  %1607 = Unsqueeze(%183, %1606)\n",
      "  %1608 = Concat[axis = 0](%1603, %1605, %1607)\n",
      "  %1609 = Reshape[allowzero = 0](%1601, %1608)\n",
      "  %1610 = Add(%1609, %1431)\n",
      "  %1611 = ReduceMean[axes = [-1]](%1610)\n",
      "  %1612 = Sub(%1610, %1611)\n",
      "  %1613 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1614 = Pow(%1612, %1613)\n",
      "  %1615 = ReduceMean[axes = [-1]](%1614)\n",
      "  %1616 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1617 = Add(%1615, %1616)\n",
      "  %1618 = Sqrt(%1617)\n",
      "  %1619 = Div(%1612, %1618)\n",
      "  %1620 = Mul(%1619, %decoder_no_past.decoder.transformer.h.4.ln_2.weight)\n",
      "  %1621 = Add(%1620, %decoder_no_past.decoder.transformer.h.4.ln_2.bias)\n",
      "  %1622 = Shape(%1621)\n",
      "  %1623 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1624 = Gather[axis = 0](%1622, %1623)\n",
      "  %1625 = Shape(%1621)\n",
      "  %1626 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1627 = Gather[axis = 0](%1625, %1626)\n",
      "  %1628 = Shape(%1621)\n",
      "  %1629 = Constant[value = <Tensor>]()\n",
      "  %1630 = Constant[value = <Tensor>]()\n",
      "  %1631 = Constant[value = <Tensor>]()\n",
      "  %1632 = Slice(%1628, %1630, %1631, %1629)\n",
      "  %1633 = Constant[value = <Tensor>]()\n",
      "  %1634 = Squeeze(%1632, %1633)\n",
      "  %1635 = Constant[value = <Tensor>]()\n",
      "  %1636 = Unsqueeze(%186, %1635)\n",
      "  %1637 = Constant[value = <Tensor>]()\n",
      "  %1638 = Unsqueeze(%1634, %1637)\n",
      "  %1639 = Concat[axis = 0](%1636, %1638)\n",
      "  %1640 = Reshape[allowzero = 0](%1621, %1639)\n",
      "  %1641 = Gemm[alpha = 1, beta = 1](%1640, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_fc.bias)\n",
      "  %1642 = Constant[value = <Tensor>]()\n",
      "  %1643 = Unsqueeze(%1624, %1642)\n",
      "  %1644 = Constant[value = <Tensor>]()\n",
      "  %1645 = Unsqueeze(%1627, %1644)\n",
      "  %1646 = Constant[value = <Tensor>]()\n",
      "  %1647 = Unsqueeze(%179, %1646)\n",
      "  %1648 = Concat[axis = 0](%1643, %1645, %1647)\n",
      "  %1649 = Reshape[allowzero = 0](%1641, %1648)\n",
      "  %1650 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1651 = Mul(%1649, %1650)\n",
      "  %1652 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1653 = Pow(%1649, %1652)\n",
      "  %1654 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1655 = Mul(%1653, %1654)\n",
      "  %1656 = Add(%1649, %1655)\n",
      "  %1657 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1658 = Mul(%1656, %1657)\n",
      "  %1659 = Tanh(%1658)\n",
      "  %1660 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1661 = Add(%1659, %1660)\n",
      "  %1662 = Mul(%1651, %1661)\n",
      "  %1663 = Shape(%1662)\n",
      "  %1664 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1665 = Gather[axis = 0](%1663, %1664)\n",
      "  %1666 = Shape(%1662)\n",
      "  %1667 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1668 = Gather[axis = 0](%1666, %1667)\n",
      "  %1669 = Shape(%1662)\n",
      "  %1670 = Constant[value = <Tensor>]()\n",
      "  %1671 = Constant[value = <Tensor>]()\n",
      "  %1672 = Constant[value = <Tensor>]()\n",
      "  %1673 = Slice(%1669, %1671, %1672, %1670)\n",
      "  %1674 = Constant[value = <Tensor>]()\n",
      "  %1675 = Squeeze(%1673, %1674)\n",
      "  %1676 = Constant[value = <Tensor>]()\n",
      "  %1677 = Unsqueeze(%186, %1676)\n",
      "  %1678 = Constant[value = <Tensor>]()\n",
      "  %1679 = Unsqueeze(%1675, %1678)\n",
      "  %1680 = Concat[axis = 0](%1677, %1679)\n",
      "  %1681 = Reshape[allowzero = 0](%1662, %1680)\n",
      "  %1682 = Gemm[alpha = 1, beta = 1](%1681, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.4.mlp.c_proj.bias)\n",
      "  %1683 = Constant[value = <Tensor>]()\n",
      "  %1684 = Unsqueeze(%1665, %1683)\n",
      "  %1685 = Constant[value = <Tensor>]()\n",
      "  %1686 = Unsqueeze(%1668, %1685)\n",
      "  %1687 = Constant[value = <Tensor>]()\n",
      "  %1688 = Unsqueeze(%183, %1687)\n",
      "  %1689 = Concat[axis = 0](%1684, %1686, %1688)\n",
      "  %1690 = Reshape[allowzero = 0](%1682, %1689)\n",
      "  %1691 = Add(%1610, %1690)\n",
      "  %1692 = ReduceMean[axes = [-1]](%1691)\n",
      "  %1693 = Sub(%1691, %1692)\n",
      "  %1694 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1695 = Pow(%1693, %1694)\n",
      "  %1696 = ReduceMean[axes = [-1]](%1695)\n",
      "  %1697 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1698 = Add(%1696, %1697)\n",
      "  %1699 = Sqrt(%1698)\n",
      "  %1700 = Div(%1693, %1699)\n",
      "  %1701 = Mul(%1700, %decoder_no_past.decoder.transformer.h.5.ln_1.weight)\n",
      "  %1702 = Add(%1701, %decoder_no_past.decoder.transformer.h.5.ln_1.bias)\n",
      "  %1703 = Shape(%1702)\n",
      "  %1704 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1705 = Gather[axis = 0](%1703, %1704)\n",
      "  %1706 = Shape(%1702)\n",
      "  %1707 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1708 = Gather[axis = 0](%1706, %1707)\n",
      "  %1709 = Shape(%1702)\n",
      "  %1710 = Constant[value = <Tensor>]()\n",
      "  %1711 = Constant[value = <Tensor>]()\n",
      "  %1712 = Constant[value = <Tensor>]()\n",
      "  %1713 = Slice(%1709, %1711, %1712, %1710)\n",
      "  %1714 = Constant[value = <Tensor>]()\n",
      "  %1715 = Squeeze(%1713, %1714)\n",
      "  %1716 = Constant[value = <Tensor>]()\n",
      "  %1717 = Unsqueeze(%186, %1716)\n",
      "  %1718 = Constant[value = <Tensor>]()\n",
      "  %1719 = Unsqueeze(%1715, %1718)\n",
      "  %1720 = Concat[axis = 0](%1717, %1719)\n",
      "  %1721 = Reshape[allowzero = 0](%1702, %1720)\n",
      "  %1722 = Gemm[alpha = 1, beta = 1](%1721, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_attn.bias)\n",
      "  %1723 = Constant[value = <Tensor>]()\n",
      "  %1724 = Unsqueeze(%1705, %1723)\n",
      "  %1725 = Constant[value = <Tensor>]()\n",
      "  %1726 = Unsqueeze(%1708, %1725)\n",
      "  %1727 = Constant[value = <Tensor>]()\n",
      "  %1728 = Unsqueeze(%182, %1727)\n",
      "  %1729 = Concat[axis = 0](%1724, %1726, %1728)\n",
      "  %1730 = Reshape[allowzero = 0](%1722, %1729)\n",
      "  %1731 = Constant[value = <Tensor>]()\n",
      "  %1732, %1733, %1734 = Split[axis = 2](%1730, %1731)\n",
      "  %1735 = Shape(%1732)\n",
      "  %1736 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1737 = Gather[axis = 0](%1735, %1736)\n",
      "  %1738 = Shape(%1732)\n",
      "  %1739 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1740 = Gather[axis = 0](%1738, %1739)\n",
      "  %1741 = Constant[value = <Tensor>]()\n",
      "  %1742 = Unsqueeze(%1737, %1741)\n",
      "  %1743 = Constant[value = <Tensor>]()\n",
      "  %1744 = Unsqueeze(%1740, %1743)\n",
      "  %1745 = Constant[value = <Tensor>]()\n",
      "  %1746 = Unsqueeze(%181, %1745)\n",
      "  %1747 = Constant[value = <Tensor>]()\n",
      "  %1748 = Unsqueeze(%180, %1747)\n",
      "  %1749 = Concat[axis = 0](%1742, %1744, %1746, %1748)\n",
      "  %1750 = Reshape[allowzero = 0](%1732, %1749)\n",
      "  %1751 = Transpose[perm = [0, 2, 1, 3]](%1750)\n",
      "  %1752 = Shape(%1733)\n",
      "  %1753 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1754 = Gather[axis = 0](%1752, %1753)\n",
      "  %1755 = Shape(%1733)\n",
      "  %1756 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1757 = Gather[axis = 0](%1755, %1756)\n",
      "  %1758 = Constant[value = <Tensor>]()\n",
      "  %1759 = Unsqueeze(%1754, %1758)\n",
      "  %1760 = Constant[value = <Tensor>]()\n",
      "  %1761 = Unsqueeze(%1757, %1760)\n",
      "  %1762 = Constant[value = <Tensor>]()\n",
      "  %1763 = Unsqueeze(%181, %1762)\n",
      "  %1764 = Constant[value = <Tensor>]()\n",
      "  %1765 = Unsqueeze(%180, %1764)\n",
      "  %1766 = Concat[axis = 0](%1759, %1761, %1763, %1765)\n",
      "  %1767 = Reshape[allowzero = 0](%1733, %1766)\n",
      "  %1768 = Transpose[perm = [0, 2, 1, 3]](%1767)\n",
      "  %1769 = Shape(%1734)\n",
      "  %1770 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1771 = Gather[axis = 0](%1769, %1770)\n",
      "  %1772 = Shape(%1734)\n",
      "  %1773 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1774 = Gather[axis = 0](%1772, %1773)\n",
      "  %1775 = Constant[value = <Tensor>]()\n",
      "  %1776 = Unsqueeze(%1771, %1775)\n",
      "  %1777 = Constant[value = <Tensor>]()\n",
      "  %1778 = Unsqueeze(%1774, %1777)\n",
      "  %1779 = Constant[value = <Tensor>]()\n",
      "  %1780 = Unsqueeze(%181, %1779)\n",
      "  %1781 = Constant[value = <Tensor>]()\n",
      "  %1782 = Unsqueeze(%180, %1781)\n",
      "  %1783 = Concat[axis = 0](%1776, %1778, %1780, %1782)\n",
      "  %1784 = Reshape[allowzero = 0](%1734, %1783)\n",
      "  %1785 = Transpose[perm = [0, 2, 1, 3]](%1784)\n",
      "  %1786 = Transpose[perm = [0, 2, 3, 1]](%1767)\n",
      "  %1787 = MatMul(%1751, %1786)\n",
      "  %1788 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1789 = Div(%1787, %1788)\n",
      "  %1790 = Shape(%1751)\n",
      "  %1791 = Constant[value = <Tensor>]()\n",
      "  %1792 = Constant[value = <Tensor>]()\n",
      "  %1793 = Constant[value = <Tensor>]()\n",
      "  %1794 = Slice(%1790, %1792, %1793, %1791)\n",
      "  %1795 = Constant[value = <Tensor>]()\n",
      "  %1796 = Squeeze(%1794, %1795)\n",
      "  %1797 = Shape(%1768)\n",
      "  %1798 = Constant[value = <Tensor>]()\n",
      "  %1799 = Constant[value = <Tensor>]()\n",
      "  %1800 = Constant[value = <Tensor>]()\n",
      "  %1801 = Slice(%1797, %1799, %1800, %1798)\n",
      "  %1802 = Constant[value = <Tensor>]()\n",
      "  %1803 = Squeeze(%1801, %1802)\n",
      "  %1804 = Sub(%1803, %1796)\n",
      "  %1805 = Constant[value = <Tensor>]()\n",
      "  %1806 = Unsqueeze(%1804, %1805)\n",
      "  %1807 = Constant[value = <Tensor>]()\n",
      "  %1808 = Unsqueeze(%1803, %1807)\n",
      "  %1809 = Constant[value = <Tensor>]()\n",
      "  %1810 = Unsqueeze(%190, %1809)\n",
      "  %1811 = Constant[value = <Tensor>]()\n",
      "  %1812 = Slice(%decoder_no_past.decoder.transformer.h.5.attn.bias, %1806, %1808, %1810, %1811)\n",
      "  %1813 = Constant[value = <Tensor>]()\n",
      "  %1814 = Unsqueeze(%191, %1813)\n",
      "  %1815 = Constant[value = <Tensor>]()\n",
      "  %1816 = Unsqueeze(%1803, %1815)\n",
      "  %1817 = Constant[value = <Tensor>]()\n",
      "  %1818 = Unsqueeze(%185, %1817)\n",
      "  %1819 = Constant[value = <Tensor>]()\n",
      "  %1820 = Slice(%1812, %1814, %1816, %1818, %1819)\n",
      "  %1821 = Cast[to = 9](%1820)\n",
      "  %1822 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.5.attn.masked_bias)\n",
      "  %1823 = Where(%1821, %1789, %1822)\n",
      "  %1824 = Add(%1823, %381)\n",
      "  %1825 = Softmax[axis = -1](%1824)\n",
      "  %1826 = MatMul(%1825, %1785)\n",
      "  %1827 = Transpose[perm = [0, 2, 1, 3]](%1826)\n",
      "  %1828 = Shape(%1827)\n",
      "  %1829 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1830 = Gather[axis = 0](%1828, %1829)\n",
      "  %1831 = Shape(%1827)\n",
      "  %1832 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1833 = Gather[axis = 0](%1831, %1832)\n",
      "  %1834 = Constant[value = <Tensor>]()\n",
      "  %1835 = Unsqueeze(%1830, %1834)\n",
      "  %1836 = Constant[value = <Tensor>]()\n",
      "  %1837 = Unsqueeze(%1833, %1836)\n",
      "  %1838 = Constant[value = <Tensor>]()\n",
      "  %1839 = Unsqueeze(%183, %1838)\n",
      "  %1840 = Concat[axis = 0](%1835, %1837, %1839)\n",
      "  %1841 = Reshape[allowzero = 0](%1827, %1840)\n",
      "  %1842 = Shape(%1841)\n",
      "  %1843 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1844 = Gather[axis = 0](%1842, %1843)\n",
      "  %1845 = Shape(%1841)\n",
      "  %1846 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1847 = Gather[axis = 0](%1845, %1846)\n",
      "  %1848 = Shape(%1841)\n",
      "  %1849 = Constant[value = <Tensor>]()\n",
      "  %1850 = Constant[value = <Tensor>]()\n",
      "  %1851 = Constant[value = <Tensor>]()\n",
      "  %1852 = Slice(%1848, %1850, %1851, %1849)\n",
      "  %1853 = Constant[value = <Tensor>]()\n",
      "  %1854 = Squeeze(%1852, %1853)\n",
      "  %1855 = Constant[value = <Tensor>]()\n",
      "  %1856 = Unsqueeze(%186, %1855)\n",
      "  %1857 = Constant[value = <Tensor>]()\n",
      "  %1858 = Unsqueeze(%1854, %1857)\n",
      "  %1859 = Concat[axis = 0](%1856, %1858)\n",
      "  %1860 = Reshape[allowzero = 0](%1841, %1859)\n",
      "  %1861 = Gemm[alpha = 1, beta = 1](%1860, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.attn.c_proj.bias)\n",
      "  %1862 = Constant[value = <Tensor>]()\n",
      "  %1863 = Unsqueeze(%1844, %1862)\n",
      "  %1864 = Constant[value = <Tensor>]()\n",
      "  %1865 = Unsqueeze(%1847, %1864)\n",
      "  %1866 = Constant[value = <Tensor>]()\n",
      "  %1867 = Unsqueeze(%183, %1866)\n",
      "  %1868 = Concat[axis = 0](%1863, %1865, %1867)\n",
      "  %1869 = Reshape[allowzero = 0](%1861, %1868)\n",
      "  %1870 = Add(%1869, %1691)\n",
      "  %1871 = ReduceMean[axes = [-1]](%1870)\n",
      "  %1872 = Sub(%1870, %1871)\n",
      "  %1873 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1874 = Pow(%1872, %1873)\n",
      "  %1875 = ReduceMean[axes = [-1]](%1874)\n",
      "  %1876 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1877 = Add(%1875, %1876)\n",
      "  %1878 = Sqrt(%1877)\n",
      "  %1879 = Div(%1872, %1878)\n",
      "  %1880 = Mul(%1879, %decoder_no_past.decoder.transformer.h.5.ln_2.weight)\n",
      "  %1881 = Add(%1880, %decoder_no_past.decoder.transformer.h.5.ln_2.bias)\n",
      "  %1882 = Shape(%1881)\n",
      "  %1883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1884 = Gather[axis = 0](%1882, %1883)\n",
      "  %1885 = Shape(%1881)\n",
      "  %1886 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1887 = Gather[axis = 0](%1885, %1886)\n",
      "  %1888 = Shape(%1881)\n",
      "  %1889 = Constant[value = <Tensor>]()\n",
      "  %1890 = Constant[value = <Tensor>]()\n",
      "  %1891 = Constant[value = <Tensor>]()\n",
      "  %1892 = Slice(%1888, %1890, %1891, %1889)\n",
      "  %1893 = Constant[value = <Tensor>]()\n",
      "  %1894 = Squeeze(%1892, %1893)\n",
      "  %1895 = Constant[value = <Tensor>]()\n",
      "  %1896 = Unsqueeze(%186, %1895)\n",
      "  %1897 = Constant[value = <Tensor>]()\n",
      "  %1898 = Unsqueeze(%1894, %1897)\n",
      "  %1899 = Concat[axis = 0](%1896, %1898)\n",
      "  %1900 = Reshape[allowzero = 0](%1881, %1899)\n",
      "  %1901 = Gemm[alpha = 1, beta = 1](%1900, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_fc.bias)\n",
      "  %1902 = Constant[value = <Tensor>]()\n",
      "  %1903 = Unsqueeze(%1884, %1902)\n",
      "  %1904 = Constant[value = <Tensor>]()\n",
      "  %1905 = Unsqueeze(%1887, %1904)\n",
      "  %1906 = Constant[value = <Tensor>]()\n",
      "  %1907 = Unsqueeze(%179, %1906)\n",
      "  %1908 = Concat[axis = 0](%1903, %1905, %1907)\n",
      "  %1909 = Reshape[allowzero = 0](%1901, %1908)\n",
      "  %1910 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1911 = Mul(%1909, %1910)\n",
      "  %1912 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1913 = Pow(%1909, %1912)\n",
      "  %1914 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1915 = Mul(%1913, %1914)\n",
      "  %1916 = Add(%1909, %1915)\n",
      "  %1917 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1918 = Mul(%1916, %1917)\n",
      "  %1919 = Tanh(%1918)\n",
      "  %1920 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1921 = Add(%1919, %1920)\n",
      "  %1922 = Mul(%1911, %1921)\n",
      "  %1923 = Shape(%1922)\n",
      "  %1924 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1925 = Gather[axis = 0](%1923, %1924)\n",
      "  %1926 = Shape(%1922)\n",
      "  %1927 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1928 = Gather[axis = 0](%1926, %1927)\n",
      "  %1929 = Shape(%1922)\n",
      "  %1930 = Constant[value = <Tensor>]()\n",
      "  %1931 = Constant[value = <Tensor>]()\n",
      "  %1932 = Constant[value = <Tensor>]()\n",
      "  %1933 = Slice(%1929, %1931, %1932, %1930)\n",
      "  %1934 = Constant[value = <Tensor>]()\n",
      "  %1935 = Squeeze(%1933, %1934)\n",
      "  %1936 = Constant[value = <Tensor>]()\n",
      "  %1937 = Unsqueeze(%186, %1936)\n",
      "  %1938 = Constant[value = <Tensor>]()\n",
      "  %1939 = Unsqueeze(%1935, %1938)\n",
      "  %1940 = Concat[axis = 0](%1937, %1939)\n",
      "  %1941 = Reshape[allowzero = 0](%1922, %1940)\n",
      "  %1942 = Gemm[alpha = 1, beta = 1](%1941, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.5.mlp.c_proj.bias)\n",
      "  %1943 = Constant[value = <Tensor>]()\n",
      "  %1944 = Unsqueeze(%1925, %1943)\n",
      "  %1945 = Constant[value = <Tensor>]()\n",
      "  %1946 = Unsqueeze(%1928, %1945)\n",
      "  %1947 = Constant[value = <Tensor>]()\n",
      "  %1948 = Unsqueeze(%183, %1947)\n",
      "  %1949 = Concat[axis = 0](%1944, %1946, %1948)\n",
      "  %1950 = Reshape[allowzero = 0](%1942, %1949)\n",
      "  %1951 = Add(%1870, %1950)\n",
      "  %1952 = ReduceMean[axes = [-1]](%1951)\n",
      "  %1953 = Sub(%1951, %1952)\n",
      "  %1954 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1955 = Pow(%1953, %1954)\n",
      "  %1956 = ReduceMean[axes = [-1]](%1955)\n",
      "  %1957 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1958 = Add(%1956, %1957)\n",
      "  %1959 = Sqrt(%1958)\n",
      "  %1960 = Div(%1953, %1959)\n",
      "  %1961 = Mul(%1960, %decoder_no_past.decoder.transformer.h.6.ln_1.weight)\n",
      "  %1962 = Add(%1961, %decoder_no_past.decoder.transformer.h.6.ln_1.bias)\n",
      "  %1963 = Shape(%1962)\n",
      "  %1964 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1965 = Gather[axis = 0](%1963, %1964)\n",
      "  %1966 = Shape(%1962)\n",
      "  %1967 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1968 = Gather[axis = 0](%1966, %1967)\n",
      "  %1969 = Shape(%1962)\n",
      "  %1970 = Constant[value = <Tensor>]()\n",
      "  %1971 = Constant[value = <Tensor>]()\n",
      "  %1972 = Constant[value = <Tensor>]()\n",
      "  %1973 = Slice(%1969, %1971, %1972, %1970)\n",
      "  %1974 = Constant[value = <Tensor>]()\n",
      "  %1975 = Squeeze(%1973, %1974)\n",
      "  %1976 = Constant[value = <Tensor>]()\n",
      "  %1977 = Unsqueeze(%186, %1976)\n",
      "  %1978 = Constant[value = <Tensor>]()\n",
      "  %1979 = Unsqueeze(%1975, %1978)\n",
      "  %1980 = Concat[axis = 0](%1977, %1979)\n",
      "  %1981 = Reshape[allowzero = 0](%1962, %1980)\n",
      "  %1982 = Gemm[alpha = 1, beta = 1](%1981, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_attn.bias)\n",
      "  %1983 = Constant[value = <Tensor>]()\n",
      "  %1984 = Unsqueeze(%1965, %1983)\n",
      "  %1985 = Constant[value = <Tensor>]()\n",
      "  %1986 = Unsqueeze(%1968, %1985)\n",
      "  %1987 = Constant[value = <Tensor>]()\n",
      "  %1988 = Unsqueeze(%182, %1987)\n",
      "  %1989 = Concat[axis = 0](%1984, %1986, %1988)\n",
      "  %1990 = Reshape[allowzero = 0](%1982, %1989)\n",
      "  %1991 = Constant[value = <Tensor>]()\n",
      "  %1992, %1993, %1994 = Split[axis = 2](%1990, %1991)\n",
      "  %1995 = Shape(%1992)\n",
      "  %1996 = Constant[value = <Scalar Tensor []>]()\n",
      "  %1997 = Gather[axis = 0](%1995, %1996)\n",
      "  %1998 = Shape(%1992)\n",
      "  %1999 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2000 = Gather[axis = 0](%1998, %1999)\n",
      "  %2001 = Constant[value = <Tensor>]()\n",
      "  %2002 = Unsqueeze(%1997, %2001)\n",
      "  %2003 = Constant[value = <Tensor>]()\n",
      "  %2004 = Unsqueeze(%2000, %2003)\n",
      "  %2005 = Constant[value = <Tensor>]()\n",
      "  %2006 = Unsqueeze(%181, %2005)\n",
      "  %2007 = Constant[value = <Tensor>]()\n",
      "  %2008 = Unsqueeze(%180, %2007)\n",
      "  %2009 = Concat[axis = 0](%2002, %2004, %2006, %2008)\n",
      "  %2010 = Reshape[allowzero = 0](%1992, %2009)\n",
      "  %2011 = Transpose[perm = [0, 2, 1, 3]](%2010)\n",
      "  %2012 = Shape(%1993)\n",
      "  %2013 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2014 = Gather[axis = 0](%2012, %2013)\n",
      "  %2015 = Shape(%1993)\n",
      "  %2016 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2017 = Gather[axis = 0](%2015, %2016)\n",
      "  %2018 = Constant[value = <Tensor>]()\n",
      "  %2019 = Unsqueeze(%2014, %2018)\n",
      "  %2020 = Constant[value = <Tensor>]()\n",
      "  %2021 = Unsqueeze(%2017, %2020)\n",
      "  %2022 = Constant[value = <Tensor>]()\n",
      "  %2023 = Unsqueeze(%181, %2022)\n",
      "  %2024 = Constant[value = <Tensor>]()\n",
      "  %2025 = Unsqueeze(%180, %2024)\n",
      "  %2026 = Concat[axis = 0](%2019, %2021, %2023, %2025)\n",
      "  %2027 = Reshape[allowzero = 0](%1993, %2026)\n",
      "  %2028 = Transpose[perm = [0, 2, 1, 3]](%2027)\n",
      "  %2029 = Shape(%1994)\n",
      "  %2030 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2031 = Gather[axis = 0](%2029, %2030)\n",
      "  %2032 = Shape(%1994)\n",
      "  %2033 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2034 = Gather[axis = 0](%2032, %2033)\n",
      "  %2035 = Constant[value = <Tensor>]()\n",
      "  %2036 = Unsqueeze(%2031, %2035)\n",
      "  %2037 = Constant[value = <Tensor>]()\n",
      "  %2038 = Unsqueeze(%2034, %2037)\n",
      "  %2039 = Constant[value = <Tensor>]()\n",
      "  %2040 = Unsqueeze(%181, %2039)\n",
      "  %2041 = Constant[value = <Tensor>]()\n",
      "  %2042 = Unsqueeze(%180, %2041)\n",
      "  %2043 = Concat[axis = 0](%2036, %2038, %2040, %2042)\n",
      "  %2044 = Reshape[allowzero = 0](%1994, %2043)\n",
      "  %2045 = Transpose[perm = [0, 2, 1, 3]](%2044)\n",
      "  %2046 = Transpose[perm = [0, 2, 3, 1]](%2027)\n",
      "  %2047 = MatMul(%2011, %2046)\n",
      "  %2048 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2049 = Div(%2047, %2048)\n",
      "  %2050 = Shape(%2011)\n",
      "  %2051 = Constant[value = <Tensor>]()\n",
      "  %2052 = Constant[value = <Tensor>]()\n",
      "  %2053 = Constant[value = <Tensor>]()\n",
      "  %2054 = Slice(%2050, %2052, %2053, %2051)\n",
      "  %2055 = Constant[value = <Tensor>]()\n",
      "  %2056 = Squeeze(%2054, %2055)\n",
      "  %2057 = Shape(%2028)\n",
      "  %2058 = Constant[value = <Tensor>]()\n",
      "  %2059 = Constant[value = <Tensor>]()\n",
      "  %2060 = Constant[value = <Tensor>]()\n",
      "  %2061 = Slice(%2057, %2059, %2060, %2058)\n",
      "  %2062 = Constant[value = <Tensor>]()\n",
      "  %2063 = Squeeze(%2061, %2062)\n",
      "  %2064 = Sub(%2063, %2056)\n",
      "  %2065 = Constant[value = <Tensor>]()\n",
      "  %2066 = Unsqueeze(%2064, %2065)\n",
      "  %2067 = Constant[value = <Tensor>]()\n",
      "  %2068 = Unsqueeze(%2063, %2067)\n",
      "  %2069 = Constant[value = <Tensor>]()\n",
      "  %2070 = Unsqueeze(%190, %2069)\n",
      "  %2071 = Constant[value = <Tensor>]()\n",
      "  %2072 = Slice(%decoder_no_past.decoder.transformer.h.6.attn.bias, %2066, %2068, %2070, %2071)\n",
      "  %2073 = Constant[value = <Tensor>]()\n",
      "  %2074 = Unsqueeze(%191, %2073)\n",
      "  %2075 = Constant[value = <Tensor>]()\n",
      "  %2076 = Unsqueeze(%2063, %2075)\n",
      "  %2077 = Constant[value = <Tensor>]()\n",
      "  %2078 = Unsqueeze(%185, %2077)\n",
      "  %2079 = Constant[value = <Tensor>]()\n",
      "  %2080 = Slice(%2072, %2074, %2076, %2078, %2079)\n",
      "  %2081 = Cast[to = 9](%2080)\n",
      "  %2082 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.6.attn.masked_bias)\n",
      "  %2083 = Where(%2081, %2049, %2082)\n",
      "  %2084 = Add(%2083, %381)\n",
      "  %2085 = Softmax[axis = -1](%2084)\n",
      "  %2086 = MatMul(%2085, %2045)\n",
      "  %2087 = Transpose[perm = [0, 2, 1, 3]](%2086)\n",
      "  %2088 = Shape(%2087)\n",
      "  %2089 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2090 = Gather[axis = 0](%2088, %2089)\n",
      "  %2091 = Shape(%2087)\n",
      "  %2092 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2093 = Gather[axis = 0](%2091, %2092)\n",
      "  %2094 = Constant[value = <Tensor>]()\n",
      "  %2095 = Unsqueeze(%2090, %2094)\n",
      "  %2096 = Constant[value = <Tensor>]()\n",
      "  %2097 = Unsqueeze(%2093, %2096)\n",
      "  %2098 = Constant[value = <Tensor>]()\n",
      "  %2099 = Unsqueeze(%183, %2098)\n",
      "  %2100 = Concat[axis = 0](%2095, %2097, %2099)\n",
      "  %2101 = Reshape[allowzero = 0](%2087, %2100)\n",
      "  %2102 = Shape(%2101)\n",
      "  %2103 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2104 = Gather[axis = 0](%2102, %2103)\n",
      "  %2105 = Shape(%2101)\n",
      "  %2106 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2107 = Gather[axis = 0](%2105, %2106)\n",
      "  %2108 = Shape(%2101)\n",
      "  %2109 = Constant[value = <Tensor>]()\n",
      "  %2110 = Constant[value = <Tensor>]()\n",
      "  %2111 = Constant[value = <Tensor>]()\n",
      "  %2112 = Slice(%2108, %2110, %2111, %2109)\n",
      "  %2113 = Constant[value = <Tensor>]()\n",
      "  %2114 = Squeeze(%2112, %2113)\n",
      "  %2115 = Constant[value = <Tensor>]()\n",
      "  %2116 = Unsqueeze(%186, %2115)\n",
      "  %2117 = Constant[value = <Tensor>]()\n",
      "  %2118 = Unsqueeze(%2114, %2117)\n",
      "  %2119 = Concat[axis = 0](%2116, %2118)\n",
      "  %2120 = Reshape[allowzero = 0](%2101, %2119)\n",
      "  %2121 = Gemm[alpha = 1, beta = 1](%2120, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.attn.c_proj.bias)\n",
      "  %2122 = Constant[value = <Tensor>]()\n",
      "  %2123 = Unsqueeze(%2104, %2122)\n",
      "  %2124 = Constant[value = <Tensor>]()\n",
      "  %2125 = Unsqueeze(%2107, %2124)\n",
      "  %2126 = Constant[value = <Tensor>]()\n",
      "  %2127 = Unsqueeze(%183, %2126)\n",
      "  %2128 = Concat[axis = 0](%2123, %2125, %2127)\n",
      "  %2129 = Reshape[allowzero = 0](%2121, %2128)\n",
      "  %2130 = Add(%2129, %1951)\n",
      "  %2131 = ReduceMean[axes = [-1]](%2130)\n",
      "  %2132 = Sub(%2130, %2131)\n",
      "  %2133 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2134 = Pow(%2132, %2133)\n",
      "  %2135 = ReduceMean[axes = [-1]](%2134)\n",
      "  %2136 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2137 = Add(%2135, %2136)\n",
      "  %2138 = Sqrt(%2137)\n",
      "  %2139 = Div(%2132, %2138)\n",
      "  %2140 = Mul(%2139, %decoder_no_past.decoder.transformer.h.6.ln_2.weight)\n",
      "  %2141 = Add(%2140, %decoder_no_past.decoder.transformer.h.6.ln_2.bias)\n",
      "  %2142 = Shape(%2141)\n",
      "  %2143 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2144 = Gather[axis = 0](%2142, %2143)\n",
      "  %2145 = Shape(%2141)\n",
      "  %2146 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2147 = Gather[axis = 0](%2145, %2146)\n",
      "  %2148 = Shape(%2141)\n",
      "  %2149 = Constant[value = <Tensor>]()\n",
      "  %2150 = Constant[value = <Tensor>]()\n",
      "  %2151 = Constant[value = <Tensor>]()\n",
      "  %2152 = Slice(%2148, %2150, %2151, %2149)\n",
      "  %2153 = Constant[value = <Tensor>]()\n",
      "  %2154 = Squeeze(%2152, %2153)\n",
      "  %2155 = Constant[value = <Tensor>]()\n",
      "  %2156 = Unsqueeze(%186, %2155)\n",
      "  %2157 = Constant[value = <Tensor>]()\n",
      "  %2158 = Unsqueeze(%2154, %2157)\n",
      "  %2159 = Concat[axis = 0](%2156, %2158)\n",
      "  %2160 = Reshape[allowzero = 0](%2141, %2159)\n",
      "  %2161 = Gemm[alpha = 1, beta = 1](%2160, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_fc.bias)\n",
      "  %2162 = Constant[value = <Tensor>]()\n",
      "  %2163 = Unsqueeze(%2144, %2162)\n",
      "  %2164 = Constant[value = <Tensor>]()\n",
      "  %2165 = Unsqueeze(%2147, %2164)\n",
      "  %2166 = Constant[value = <Tensor>]()\n",
      "  %2167 = Unsqueeze(%179, %2166)\n",
      "  %2168 = Concat[axis = 0](%2163, %2165, %2167)\n",
      "  %2169 = Reshape[allowzero = 0](%2161, %2168)\n",
      "  %2170 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2171 = Mul(%2169, %2170)\n",
      "  %2172 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2173 = Pow(%2169, %2172)\n",
      "  %2174 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2175 = Mul(%2173, %2174)\n",
      "  %2176 = Add(%2169, %2175)\n",
      "  %2177 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2178 = Mul(%2176, %2177)\n",
      "  %2179 = Tanh(%2178)\n",
      "  %2180 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2181 = Add(%2179, %2180)\n",
      "  %2182 = Mul(%2171, %2181)\n",
      "  %2183 = Shape(%2182)\n",
      "  %2184 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2185 = Gather[axis = 0](%2183, %2184)\n",
      "  %2186 = Shape(%2182)\n",
      "  %2187 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2188 = Gather[axis = 0](%2186, %2187)\n",
      "  %2189 = Shape(%2182)\n",
      "  %2190 = Constant[value = <Tensor>]()\n",
      "  %2191 = Constant[value = <Tensor>]()\n",
      "  %2192 = Constant[value = <Tensor>]()\n",
      "  %2193 = Slice(%2189, %2191, %2192, %2190)\n",
      "  %2194 = Constant[value = <Tensor>]()\n",
      "  %2195 = Squeeze(%2193, %2194)\n",
      "  %2196 = Constant[value = <Tensor>]()\n",
      "  %2197 = Unsqueeze(%186, %2196)\n",
      "  %2198 = Constant[value = <Tensor>]()\n",
      "  %2199 = Unsqueeze(%2195, %2198)\n",
      "  %2200 = Concat[axis = 0](%2197, %2199)\n",
      "  %2201 = Reshape[allowzero = 0](%2182, %2200)\n",
      "  %2202 = Gemm[alpha = 1, beta = 1](%2201, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.6.mlp.c_proj.bias)\n",
      "  %2203 = Constant[value = <Tensor>]()\n",
      "  %2204 = Unsqueeze(%2185, %2203)\n",
      "  %2205 = Constant[value = <Tensor>]()\n",
      "  %2206 = Unsqueeze(%2188, %2205)\n",
      "  %2207 = Constant[value = <Tensor>]()\n",
      "  %2208 = Unsqueeze(%183, %2207)\n",
      "  %2209 = Concat[axis = 0](%2204, %2206, %2208)\n",
      "  %2210 = Reshape[allowzero = 0](%2202, %2209)\n",
      "  %2211 = Add(%2130, %2210)\n",
      "  %2212 = ReduceMean[axes = [-1]](%2211)\n",
      "  %2213 = Sub(%2211, %2212)\n",
      "  %2214 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2215 = Pow(%2213, %2214)\n",
      "  %2216 = ReduceMean[axes = [-1]](%2215)\n",
      "  %2217 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2218 = Add(%2216, %2217)\n",
      "  %2219 = Sqrt(%2218)\n",
      "  %2220 = Div(%2213, %2219)\n",
      "  %2221 = Mul(%2220, %decoder_no_past.decoder.transformer.h.7.ln_1.weight)\n",
      "  %2222 = Add(%2221, %decoder_no_past.decoder.transformer.h.7.ln_1.bias)\n",
      "  %2223 = Shape(%2222)\n",
      "  %2224 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2225 = Gather[axis = 0](%2223, %2224)\n",
      "  %2226 = Shape(%2222)\n",
      "  %2227 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2228 = Gather[axis = 0](%2226, %2227)\n",
      "  %2229 = Shape(%2222)\n",
      "  %2230 = Constant[value = <Tensor>]()\n",
      "  %2231 = Constant[value = <Tensor>]()\n",
      "  %2232 = Constant[value = <Tensor>]()\n",
      "  %2233 = Slice(%2229, %2231, %2232, %2230)\n",
      "  %2234 = Constant[value = <Tensor>]()\n",
      "  %2235 = Squeeze(%2233, %2234)\n",
      "  %2236 = Constant[value = <Tensor>]()\n",
      "  %2237 = Unsqueeze(%186, %2236)\n",
      "  %2238 = Constant[value = <Tensor>]()\n",
      "  %2239 = Unsqueeze(%2235, %2238)\n",
      "  %2240 = Concat[axis = 0](%2237, %2239)\n",
      "  %2241 = Reshape[allowzero = 0](%2222, %2240)\n",
      "  %2242 = Gemm[alpha = 1, beta = 1](%2241, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_attn.bias)\n",
      "  %2243 = Constant[value = <Tensor>]()\n",
      "  %2244 = Unsqueeze(%2225, %2243)\n",
      "  %2245 = Constant[value = <Tensor>]()\n",
      "  %2246 = Unsqueeze(%2228, %2245)\n",
      "  %2247 = Constant[value = <Tensor>]()\n",
      "  %2248 = Unsqueeze(%182, %2247)\n",
      "  %2249 = Concat[axis = 0](%2244, %2246, %2248)\n",
      "  %2250 = Reshape[allowzero = 0](%2242, %2249)\n",
      "  %2251 = Constant[value = <Tensor>]()\n",
      "  %2252, %2253, %2254 = Split[axis = 2](%2250, %2251)\n",
      "  %2255 = Shape(%2252)\n",
      "  %2256 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2257 = Gather[axis = 0](%2255, %2256)\n",
      "  %2258 = Shape(%2252)\n",
      "  %2259 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2260 = Gather[axis = 0](%2258, %2259)\n",
      "  %2261 = Constant[value = <Tensor>]()\n",
      "  %2262 = Unsqueeze(%2257, %2261)\n",
      "  %2263 = Constant[value = <Tensor>]()\n",
      "  %2264 = Unsqueeze(%2260, %2263)\n",
      "  %2265 = Constant[value = <Tensor>]()\n",
      "  %2266 = Unsqueeze(%181, %2265)\n",
      "  %2267 = Constant[value = <Tensor>]()\n",
      "  %2268 = Unsqueeze(%180, %2267)\n",
      "  %2269 = Concat[axis = 0](%2262, %2264, %2266, %2268)\n",
      "  %2270 = Reshape[allowzero = 0](%2252, %2269)\n",
      "  %2271 = Transpose[perm = [0, 2, 1, 3]](%2270)\n",
      "  %2272 = Shape(%2253)\n",
      "  %2273 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2274 = Gather[axis = 0](%2272, %2273)\n",
      "  %2275 = Shape(%2253)\n",
      "  %2276 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2277 = Gather[axis = 0](%2275, %2276)\n",
      "  %2278 = Constant[value = <Tensor>]()\n",
      "  %2279 = Unsqueeze(%2274, %2278)\n",
      "  %2280 = Constant[value = <Tensor>]()\n",
      "  %2281 = Unsqueeze(%2277, %2280)\n",
      "  %2282 = Constant[value = <Tensor>]()\n",
      "  %2283 = Unsqueeze(%181, %2282)\n",
      "  %2284 = Constant[value = <Tensor>]()\n",
      "  %2285 = Unsqueeze(%180, %2284)\n",
      "  %2286 = Concat[axis = 0](%2279, %2281, %2283, %2285)\n",
      "  %2287 = Reshape[allowzero = 0](%2253, %2286)\n",
      "  %2288 = Transpose[perm = [0, 2, 1, 3]](%2287)\n",
      "  %2289 = Shape(%2254)\n",
      "  %2290 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2291 = Gather[axis = 0](%2289, %2290)\n",
      "  %2292 = Shape(%2254)\n",
      "  %2293 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2294 = Gather[axis = 0](%2292, %2293)\n",
      "  %2295 = Constant[value = <Tensor>]()\n",
      "  %2296 = Unsqueeze(%2291, %2295)\n",
      "  %2297 = Constant[value = <Tensor>]()\n",
      "  %2298 = Unsqueeze(%2294, %2297)\n",
      "  %2299 = Constant[value = <Tensor>]()\n",
      "  %2300 = Unsqueeze(%181, %2299)\n",
      "  %2301 = Constant[value = <Tensor>]()\n",
      "  %2302 = Unsqueeze(%180, %2301)\n",
      "  %2303 = Concat[axis = 0](%2296, %2298, %2300, %2302)\n",
      "  %2304 = Reshape[allowzero = 0](%2254, %2303)\n",
      "  %2305 = Transpose[perm = [0, 2, 1, 3]](%2304)\n",
      "  %2306 = Transpose[perm = [0, 2, 3, 1]](%2287)\n",
      "  %2307 = MatMul(%2271, %2306)\n",
      "  %2308 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2309 = Div(%2307, %2308)\n",
      "  %2310 = Shape(%2271)\n",
      "  %2311 = Constant[value = <Tensor>]()\n",
      "  %2312 = Constant[value = <Tensor>]()\n",
      "  %2313 = Constant[value = <Tensor>]()\n",
      "  %2314 = Slice(%2310, %2312, %2313, %2311)\n",
      "  %2315 = Constant[value = <Tensor>]()\n",
      "  %2316 = Squeeze(%2314, %2315)\n",
      "  %2317 = Shape(%2288)\n",
      "  %2318 = Constant[value = <Tensor>]()\n",
      "  %2319 = Constant[value = <Tensor>]()\n",
      "  %2320 = Constant[value = <Tensor>]()\n",
      "  %2321 = Slice(%2317, %2319, %2320, %2318)\n",
      "  %2322 = Constant[value = <Tensor>]()\n",
      "  %2323 = Squeeze(%2321, %2322)\n",
      "  %2324 = Sub(%2323, %2316)\n",
      "  %2325 = Constant[value = <Tensor>]()\n",
      "  %2326 = Unsqueeze(%2324, %2325)\n",
      "  %2327 = Constant[value = <Tensor>]()\n",
      "  %2328 = Unsqueeze(%2323, %2327)\n",
      "  %2329 = Constant[value = <Tensor>]()\n",
      "  %2330 = Unsqueeze(%190, %2329)\n",
      "  %2331 = Constant[value = <Tensor>]()\n",
      "  %2332 = Slice(%decoder_no_past.decoder.transformer.h.7.attn.bias, %2326, %2328, %2330, %2331)\n",
      "  %2333 = Constant[value = <Tensor>]()\n",
      "  %2334 = Unsqueeze(%191, %2333)\n",
      "  %2335 = Constant[value = <Tensor>]()\n",
      "  %2336 = Unsqueeze(%2323, %2335)\n",
      "  %2337 = Constant[value = <Tensor>]()\n",
      "  %2338 = Unsqueeze(%185, %2337)\n",
      "  %2339 = Constant[value = <Tensor>]()\n",
      "  %2340 = Slice(%2332, %2334, %2336, %2338, %2339)\n",
      "  %2341 = Cast[to = 9](%2340)\n",
      "  %2342 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.7.attn.masked_bias)\n",
      "  %2343 = Where(%2341, %2309, %2342)\n",
      "  %2344 = Add(%2343, %381)\n",
      "  %2345 = Softmax[axis = -1](%2344)\n",
      "  %2346 = MatMul(%2345, %2305)\n",
      "  %2347 = Transpose[perm = [0, 2, 1, 3]](%2346)\n",
      "  %2348 = Shape(%2347)\n",
      "  %2349 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2350 = Gather[axis = 0](%2348, %2349)\n",
      "  %2351 = Shape(%2347)\n",
      "  %2352 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2353 = Gather[axis = 0](%2351, %2352)\n",
      "  %2354 = Constant[value = <Tensor>]()\n",
      "  %2355 = Unsqueeze(%2350, %2354)\n",
      "  %2356 = Constant[value = <Tensor>]()\n",
      "  %2357 = Unsqueeze(%2353, %2356)\n",
      "  %2358 = Constant[value = <Tensor>]()\n",
      "  %2359 = Unsqueeze(%183, %2358)\n",
      "  %2360 = Concat[axis = 0](%2355, %2357, %2359)\n",
      "  %2361 = Reshape[allowzero = 0](%2347, %2360)\n",
      "  %2362 = Shape(%2361)\n",
      "  %2363 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2364 = Gather[axis = 0](%2362, %2363)\n",
      "  %2365 = Shape(%2361)\n",
      "  %2366 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2367 = Gather[axis = 0](%2365, %2366)\n",
      "  %2368 = Shape(%2361)\n",
      "  %2369 = Constant[value = <Tensor>]()\n",
      "  %2370 = Constant[value = <Tensor>]()\n",
      "  %2371 = Constant[value = <Tensor>]()\n",
      "  %2372 = Slice(%2368, %2370, %2371, %2369)\n",
      "  %2373 = Constant[value = <Tensor>]()\n",
      "  %2374 = Squeeze(%2372, %2373)\n",
      "  %2375 = Constant[value = <Tensor>]()\n",
      "  %2376 = Unsqueeze(%186, %2375)\n",
      "  %2377 = Constant[value = <Tensor>]()\n",
      "  %2378 = Unsqueeze(%2374, %2377)\n",
      "  %2379 = Concat[axis = 0](%2376, %2378)\n",
      "  %2380 = Reshape[allowzero = 0](%2361, %2379)\n",
      "  %2381 = Gemm[alpha = 1, beta = 1](%2380, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.attn.c_proj.bias)\n",
      "  %2382 = Constant[value = <Tensor>]()\n",
      "  %2383 = Unsqueeze(%2364, %2382)\n",
      "  %2384 = Constant[value = <Tensor>]()\n",
      "  %2385 = Unsqueeze(%2367, %2384)\n",
      "  %2386 = Constant[value = <Tensor>]()\n",
      "  %2387 = Unsqueeze(%183, %2386)\n",
      "  %2388 = Concat[axis = 0](%2383, %2385, %2387)\n",
      "  %2389 = Reshape[allowzero = 0](%2381, %2388)\n",
      "  %2390 = Add(%2389, %2211)\n",
      "  %2391 = ReduceMean[axes = [-1]](%2390)\n",
      "  %2392 = Sub(%2390, %2391)\n",
      "  %2393 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2394 = Pow(%2392, %2393)\n",
      "  %2395 = ReduceMean[axes = [-1]](%2394)\n",
      "  %2396 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2397 = Add(%2395, %2396)\n",
      "  %2398 = Sqrt(%2397)\n",
      "  %2399 = Div(%2392, %2398)\n",
      "  %2400 = Mul(%2399, %decoder_no_past.decoder.transformer.h.7.ln_2.weight)\n",
      "  %2401 = Add(%2400, %decoder_no_past.decoder.transformer.h.7.ln_2.bias)\n",
      "  %2402 = Shape(%2401)\n",
      "  %2403 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2404 = Gather[axis = 0](%2402, %2403)\n",
      "  %2405 = Shape(%2401)\n",
      "  %2406 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2407 = Gather[axis = 0](%2405, %2406)\n",
      "  %2408 = Shape(%2401)\n",
      "  %2409 = Constant[value = <Tensor>]()\n",
      "  %2410 = Constant[value = <Tensor>]()\n",
      "  %2411 = Constant[value = <Tensor>]()\n",
      "  %2412 = Slice(%2408, %2410, %2411, %2409)\n",
      "  %2413 = Constant[value = <Tensor>]()\n",
      "  %2414 = Squeeze(%2412, %2413)\n",
      "  %2415 = Constant[value = <Tensor>]()\n",
      "  %2416 = Unsqueeze(%186, %2415)\n",
      "  %2417 = Constant[value = <Tensor>]()\n",
      "  %2418 = Unsqueeze(%2414, %2417)\n",
      "  %2419 = Concat[axis = 0](%2416, %2418)\n",
      "  %2420 = Reshape[allowzero = 0](%2401, %2419)\n",
      "  %2421 = Gemm[alpha = 1, beta = 1](%2420, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_fc.bias)\n",
      "  %2422 = Constant[value = <Tensor>]()\n",
      "  %2423 = Unsqueeze(%2404, %2422)\n",
      "  %2424 = Constant[value = <Tensor>]()\n",
      "  %2425 = Unsqueeze(%2407, %2424)\n",
      "  %2426 = Constant[value = <Tensor>]()\n",
      "  %2427 = Unsqueeze(%179, %2426)\n",
      "  %2428 = Concat[axis = 0](%2423, %2425, %2427)\n",
      "  %2429 = Reshape[allowzero = 0](%2421, %2428)\n",
      "  %2430 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2431 = Mul(%2429, %2430)\n",
      "  %2432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2433 = Pow(%2429, %2432)\n",
      "  %2434 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2435 = Mul(%2433, %2434)\n",
      "  %2436 = Add(%2429, %2435)\n",
      "  %2437 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2438 = Mul(%2436, %2437)\n",
      "  %2439 = Tanh(%2438)\n",
      "  %2440 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2441 = Add(%2439, %2440)\n",
      "  %2442 = Mul(%2431, %2441)\n",
      "  %2443 = Shape(%2442)\n",
      "  %2444 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2445 = Gather[axis = 0](%2443, %2444)\n",
      "  %2446 = Shape(%2442)\n",
      "  %2447 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2448 = Gather[axis = 0](%2446, %2447)\n",
      "  %2449 = Shape(%2442)\n",
      "  %2450 = Constant[value = <Tensor>]()\n",
      "  %2451 = Constant[value = <Tensor>]()\n",
      "  %2452 = Constant[value = <Tensor>]()\n",
      "  %2453 = Slice(%2449, %2451, %2452, %2450)\n",
      "  %2454 = Constant[value = <Tensor>]()\n",
      "  %2455 = Squeeze(%2453, %2454)\n",
      "  %2456 = Constant[value = <Tensor>]()\n",
      "  %2457 = Unsqueeze(%186, %2456)\n",
      "  %2458 = Constant[value = <Tensor>]()\n",
      "  %2459 = Unsqueeze(%2455, %2458)\n",
      "  %2460 = Concat[axis = 0](%2457, %2459)\n",
      "  %2461 = Reshape[allowzero = 0](%2442, %2460)\n",
      "  %2462 = Gemm[alpha = 1, beta = 1](%2461, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.7.mlp.c_proj.bias)\n",
      "  %2463 = Constant[value = <Tensor>]()\n",
      "  %2464 = Unsqueeze(%2445, %2463)\n",
      "  %2465 = Constant[value = <Tensor>]()\n",
      "  %2466 = Unsqueeze(%2448, %2465)\n",
      "  %2467 = Constant[value = <Tensor>]()\n",
      "  %2468 = Unsqueeze(%183, %2467)\n",
      "  %2469 = Concat[axis = 0](%2464, %2466, %2468)\n",
      "  %2470 = Reshape[allowzero = 0](%2462, %2469)\n",
      "  %2471 = Add(%2390, %2470)\n",
      "  %2472 = ReduceMean[axes = [-1]](%2471)\n",
      "  %2473 = Sub(%2471, %2472)\n",
      "  %2474 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2475 = Pow(%2473, %2474)\n",
      "  %2476 = ReduceMean[axes = [-1]](%2475)\n",
      "  %2477 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2478 = Add(%2476, %2477)\n",
      "  %2479 = Sqrt(%2478)\n",
      "  %2480 = Div(%2473, %2479)\n",
      "  %2481 = Mul(%2480, %decoder_no_past.decoder.transformer.h.8.ln_1.weight)\n",
      "  %2482 = Add(%2481, %decoder_no_past.decoder.transformer.h.8.ln_1.bias)\n",
      "  %2483 = Shape(%2482)\n",
      "  %2484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2485 = Gather[axis = 0](%2483, %2484)\n",
      "  %2486 = Shape(%2482)\n",
      "  %2487 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2488 = Gather[axis = 0](%2486, %2487)\n",
      "  %2489 = Shape(%2482)\n",
      "  %2490 = Constant[value = <Tensor>]()\n",
      "  %2491 = Constant[value = <Tensor>]()\n",
      "  %2492 = Constant[value = <Tensor>]()\n",
      "  %2493 = Slice(%2489, %2491, %2492, %2490)\n",
      "  %2494 = Constant[value = <Tensor>]()\n",
      "  %2495 = Squeeze(%2493, %2494)\n",
      "  %2496 = Constant[value = <Tensor>]()\n",
      "  %2497 = Unsqueeze(%186, %2496)\n",
      "  %2498 = Constant[value = <Tensor>]()\n",
      "  %2499 = Unsqueeze(%2495, %2498)\n",
      "  %2500 = Concat[axis = 0](%2497, %2499)\n",
      "  %2501 = Reshape[allowzero = 0](%2482, %2500)\n",
      "  %2502 = Gemm[alpha = 1, beta = 1](%2501, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_attn.bias)\n",
      "  %2503 = Constant[value = <Tensor>]()\n",
      "  %2504 = Unsqueeze(%2485, %2503)\n",
      "  %2505 = Constant[value = <Tensor>]()\n",
      "  %2506 = Unsqueeze(%2488, %2505)\n",
      "  %2507 = Constant[value = <Tensor>]()\n",
      "  %2508 = Unsqueeze(%182, %2507)\n",
      "  %2509 = Concat[axis = 0](%2504, %2506, %2508)\n",
      "  %2510 = Reshape[allowzero = 0](%2502, %2509)\n",
      "  %2511 = Constant[value = <Tensor>]()\n",
      "  %2512, %2513, %2514 = Split[axis = 2](%2510, %2511)\n",
      "  %2515 = Shape(%2512)\n",
      "  %2516 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2517 = Gather[axis = 0](%2515, %2516)\n",
      "  %2518 = Shape(%2512)\n",
      "  %2519 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2520 = Gather[axis = 0](%2518, %2519)\n",
      "  %2521 = Constant[value = <Tensor>]()\n",
      "  %2522 = Unsqueeze(%2517, %2521)\n",
      "  %2523 = Constant[value = <Tensor>]()\n",
      "  %2524 = Unsqueeze(%2520, %2523)\n",
      "  %2525 = Constant[value = <Tensor>]()\n",
      "  %2526 = Unsqueeze(%181, %2525)\n",
      "  %2527 = Constant[value = <Tensor>]()\n",
      "  %2528 = Unsqueeze(%180, %2527)\n",
      "  %2529 = Concat[axis = 0](%2522, %2524, %2526, %2528)\n",
      "  %2530 = Reshape[allowzero = 0](%2512, %2529)\n",
      "  %2531 = Transpose[perm = [0, 2, 1, 3]](%2530)\n",
      "  %2532 = Shape(%2513)\n",
      "  %2533 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2534 = Gather[axis = 0](%2532, %2533)\n",
      "  %2535 = Shape(%2513)\n",
      "  %2536 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2537 = Gather[axis = 0](%2535, %2536)\n",
      "  %2538 = Constant[value = <Tensor>]()\n",
      "  %2539 = Unsqueeze(%2534, %2538)\n",
      "  %2540 = Constant[value = <Tensor>]()\n",
      "  %2541 = Unsqueeze(%2537, %2540)\n",
      "  %2542 = Constant[value = <Tensor>]()\n",
      "  %2543 = Unsqueeze(%181, %2542)\n",
      "  %2544 = Constant[value = <Tensor>]()\n",
      "  %2545 = Unsqueeze(%180, %2544)\n",
      "  %2546 = Concat[axis = 0](%2539, %2541, %2543, %2545)\n",
      "  %2547 = Reshape[allowzero = 0](%2513, %2546)\n",
      "  %2548 = Transpose[perm = [0, 2, 1, 3]](%2547)\n",
      "  %2549 = Shape(%2514)\n",
      "  %2550 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2551 = Gather[axis = 0](%2549, %2550)\n",
      "  %2552 = Shape(%2514)\n",
      "  %2553 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2554 = Gather[axis = 0](%2552, %2553)\n",
      "  %2555 = Constant[value = <Tensor>]()\n",
      "  %2556 = Unsqueeze(%2551, %2555)\n",
      "  %2557 = Constant[value = <Tensor>]()\n",
      "  %2558 = Unsqueeze(%2554, %2557)\n",
      "  %2559 = Constant[value = <Tensor>]()\n",
      "  %2560 = Unsqueeze(%181, %2559)\n",
      "  %2561 = Constant[value = <Tensor>]()\n",
      "  %2562 = Unsqueeze(%180, %2561)\n",
      "  %2563 = Concat[axis = 0](%2556, %2558, %2560, %2562)\n",
      "  %2564 = Reshape[allowzero = 0](%2514, %2563)\n",
      "  %2565 = Transpose[perm = [0, 2, 1, 3]](%2564)\n",
      "  %2566 = Transpose[perm = [0, 2, 3, 1]](%2547)\n",
      "  %2567 = MatMul(%2531, %2566)\n",
      "  %2568 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2569 = Div(%2567, %2568)\n",
      "  %2570 = Shape(%2531)\n",
      "  %2571 = Constant[value = <Tensor>]()\n",
      "  %2572 = Constant[value = <Tensor>]()\n",
      "  %2573 = Constant[value = <Tensor>]()\n",
      "  %2574 = Slice(%2570, %2572, %2573, %2571)\n",
      "  %2575 = Constant[value = <Tensor>]()\n",
      "  %2576 = Squeeze(%2574, %2575)\n",
      "  %2577 = Shape(%2548)\n",
      "  %2578 = Constant[value = <Tensor>]()\n",
      "  %2579 = Constant[value = <Tensor>]()\n",
      "  %2580 = Constant[value = <Tensor>]()\n",
      "  %2581 = Slice(%2577, %2579, %2580, %2578)\n",
      "  %2582 = Constant[value = <Tensor>]()\n",
      "  %2583 = Squeeze(%2581, %2582)\n",
      "  %2584 = Sub(%2583, %2576)\n",
      "  %2585 = Constant[value = <Tensor>]()\n",
      "  %2586 = Unsqueeze(%2584, %2585)\n",
      "  %2587 = Constant[value = <Tensor>]()\n",
      "  %2588 = Unsqueeze(%2583, %2587)\n",
      "  %2589 = Constant[value = <Tensor>]()\n",
      "  %2590 = Unsqueeze(%190, %2589)\n",
      "  %2591 = Constant[value = <Tensor>]()\n",
      "  %2592 = Slice(%decoder_no_past.decoder.transformer.h.8.attn.bias, %2586, %2588, %2590, %2591)\n",
      "  %2593 = Constant[value = <Tensor>]()\n",
      "  %2594 = Unsqueeze(%191, %2593)\n",
      "  %2595 = Constant[value = <Tensor>]()\n",
      "  %2596 = Unsqueeze(%2583, %2595)\n",
      "  %2597 = Constant[value = <Tensor>]()\n",
      "  %2598 = Unsqueeze(%185, %2597)\n",
      "  %2599 = Constant[value = <Tensor>]()\n",
      "  %2600 = Slice(%2592, %2594, %2596, %2598, %2599)\n",
      "  %2601 = Cast[to = 9](%2600)\n",
      "  %2602 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.8.attn.masked_bias)\n",
      "  %2603 = Where(%2601, %2569, %2602)\n",
      "  %2604 = Add(%2603, %381)\n",
      "  %2605 = Softmax[axis = -1](%2604)\n",
      "  %2606 = MatMul(%2605, %2565)\n",
      "  %2607 = Transpose[perm = [0, 2, 1, 3]](%2606)\n",
      "  %2608 = Shape(%2607)\n",
      "  %2609 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2610 = Gather[axis = 0](%2608, %2609)\n",
      "  %2611 = Shape(%2607)\n",
      "  %2612 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2613 = Gather[axis = 0](%2611, %2612)\n",
      "  %2614 = Constant[value = <Tensor>]()\n",
      "  %2615 = Unsqueeze(%2610, %2614)\n",
      "  %2616 = Constant[value = <Tensor>]()\n",
      "  %2617 = Unsqueeze(%2613, %2616)\n",
      "  %2618 = Constant[value = <Tensor>]()\n",
      "  %2619 = Unsqueeze(%183, %2618)\n",
      "  %2620 = Concat[axis = 0](%2615, %2617, %2619)\n",
      "  %2621 = Reshape[allowzero = 0](%2607, %2620)\n",
      "  %2622 = Shape(%2621)\n",
      "  %2623 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2624 = Gather[axis = 0](%2622, %2623)\n",
      "  %2625 = Shape(%2621)\n",
      "  %2626 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2627 = Gather[axis = 0](%2625, %2626)\n",
      "  %2628 = Shape(%2621)\n",
      "  %2629 = Constant[value = <Tensor>]()\n",
      "  %2630 = Constant[value = <Tensor>]()\n",
      "  %2631 = Constant[value = <Tensor>]()\n",
      "  %2632 = Slice(%2628, %2630, %2631, %2629)\n",
      "  %2633 = Constant[value = <Tensor>]()\n",
      "  %2634 = Squeeze(%2632, %2633)\n",
      "  %2635 = Constant[value = <Tensor>]()\n",
      "  %2636 = Unsqueeze(%186, %2635)\n",
      "  %2637 = Constant[value = <Tensor>]()\n",
      "  %2638 = Unsqueeze(%2634, %2637)\n",
      "  %2639 = Concat[axis = 0](%2636, %2638)\n",
      "  %2640 = Reshape[allowzero = 0](%2621, %2639)\n",
      "  %2641 = Gemm[alpha = 1, beta = 1](%2640, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.attn.c_proj.bias)\n",
      "  %2642 = Constant[value = <Tensor>]()\n",
      "  %2643 = Unsqueeze(%2624, %2642)\n",
      "  %2644 = Constant[value = <Tensor>]()\n",
      "  %2645 = Unsqueeze(%2627, %2644)\n",
      "  %2646 = Constant[value = <Tensor>]()\n",
      "  %2647 = Unsqueeze(%183, %2646)\n",
      "  %2648 = Concat[axis = 0](%2643, %2645, %2647)\n",
      "  %2649 = Reshape[allowzero = 0](%2641, %2648)\n",
      "  %2650 = Add(%2649, %2471)\n",
      "  %2651 = ReduceMean[axes = [-1]](%2650)\n",
      "  %2652 = Sub(%2650, %2651)\n",
      "  %2653 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2654 = Pow(%2652, %2653)\n",
      "  %2655 = ReduceMean[axes = [-1]](%2654)\n",
      "  %2656 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2657 = Add(%2655, %2656)\n",
      "  %2658 = Sqrt(%2657)\n",
      "  %2659 = Div(%2652, %2658)\n",
      "  %2660 = Mul(%2659, %decoder_no_past.decoder.transformer.h.8.ln_2.weight)\n",
      "  %2661 = Add(%2660, %decoder_no_past.decoder.transformer.h.8.ln_2.bias)\n",
      "  %2662 = Shape(%2661)\n",
      "  %2663 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2664 = Gather[axis = 0](%2662, %2663)\n",
      "  %2665 = Shape(%2661)\n",
      "  %2666 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2667 = Gather[axis = 0](%2665, %2666)\n",
      "  %2668 = Shape(%2661)\n",
      "  %2669 = Constant[value = <Tensor>]()\n",
      "  %2670 = Constant[value = <Tensor>]()\n",
      "  %2671 = Constant[value = <Tensor>]()\n",
      "  %2672 = Slice(%2668, %2670, %2671, %2669)\n",
      "  %2673 = Constant[value = <Tensor>]()\n",
      "  %2674 = Squeeze(%2672, %2673)\n",
      "  %2675 = Constant[value = <Tensor>]()\n",
      "  %2676 = Unsqueeze(%186, %2675)\n",
      "  %2677 = Constant[value = <Tensor>]()\n",
      "  %2678 = Unsqueeze(%2674, %2677)\n",
      "  %2679 = Concat[axis = 0](%2676, %2678)\n",
      "  %2680 = Reshape[allowzero = 0](%2661, %2679)\n",
      "  %2681 = Gemm[alpha = 1, beta = 1](%2680, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_fc.bias)\n",
      "  %2682 = Constant[value = <Tensor>]()\n",
      "  %2683 = Unsqueeze(%2664, %2682)\n",
      "  %2684 = Constant[value = <Tensor>]()\n",
      "  %2685 = Unsqueeze(%2667, %2684)\n",
      "  %2686 = Constant[value = <Tensor>]()\n",
      "  %2687 = Unsqueeze(%179, %2686)\n",
      "  %2688 = Concat[axis = 0](%2683, %2685, %2687)\n",
      "  %2689 = Reshape[allowzero = 0](%2681, %2688)\n",
      "  %2690 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2691 = Mul(%2689, %2690)\n",
      "  %2692 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2693 = Pow(%2689, %2692)\n",
      "  %2694 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2695 = Mul(%2693, %2694)\n",
      "  %2696 = Add(%2689, %2695)\n",
      "  %2697 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2698 = Mul(%2696, %2697)\n",
      "  %2699 = Tanh(%2698)\n",
      "  %2700 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2701 = Add(%2699, %2700)\n",
      "  %2702 = Mul(%2691, %2701)\n",
      "  %2703 = Shape(%2702)\n",
      "  %2704 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2705 = Gather[axis = 0](%2703, %2704)\n",
      "  %2706 = Shape(%2702)\n",
      "  %2707 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2708 = Gather[axis = 0](%2706, %2707)\n",
      "  %2709 = Shape(%2702)\n",
      "  %2710 = Constant[value = <Tensor>]()\n",
      "  %2711 = Constant[value = <Tensor>]()\n",
      "  %2712 = Constant[value = <Tensor>]()\n",
      "  %2713 = Slice(%2709, %2711, %2712, %2710)\n",
      "  %2714 = Constant[value = <Tensor>]()\n",
      "  %2715 = Squeeze(%2713, %2714)\n",
      "  %2716 = Constant[value = <Tensor>]()\n",
      "  %2717 = Unsqueeze(%186, %2716)\n",
      "  %2718 = Constant[value = <Tensor>]()\n",
      "  %2719 = Unsqueeze(%2715, %2718)\n",
      "  %2720 = Concat[axis = 0](%2717, %2719)\n",
      "  %2721 = Reshape[allowzero = 0](%2702, %2720)\n",
      "  %2722 = Gemm[alpha = 1, beta = 1](%2721, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.8.mlp.c_proj.bias)\n",
      "  %2723 = Constant[value = <Tensor>]()\n",
      "  %2724 = Unsqueeze(%2705, %2723)\n",
      "  %2725 = Constant[value = <Tensor>]()\n",
      "  %2726 = Unsqueeze(%2708, %2725)\n",
      "  %2727 = Constant[value = <Tensor>]()\n",
      "  %2728 = Unsqueeze(%183, %2727)\n",
      "  %2729 = Concat[axis = 0](%2724, %2726, %2728)\n",
      "  %2730 = Reshape[allowzero = 0](%2722, %2729)\n",
      "  %2731 = Add(%2650, %2730)\n",
      "  %2732 = ReduceMean[axes = [-1]](%2731)\n",
      "  %2733 = Sub(%2731, %2732)\n",
      "  %2734 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2735 = Pow(%2733, %2734)\n",
      "  %2736 = ReduceMean[axes = [-1]](%2735)\n",
      "  %2737 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2738 = Add(%2736, %2737)\n",
      "  %2739 = Sqrt(%2738)\n",
      "  %2740 = Div(%2733, %2739)\n",
      "  %2741 = Mul(%2740, %decoder_no_past.decoder.transformer.h.9.ln_1.weight)\n",
      "  %2742 = Add(%2741, %decoder_no_past.decoder.transformer.h.9.ln_1.bias)\n",
      "  %2743 = Shape(%2742)\n",
      "  %2744 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2745 = Gather[axis = 0](%2743, %2744)\n",
      "  %2746 = Shape(%2742)\n",
      "  %2747 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2748 = Gather[axis = 0](%2746, %2747)\n",
      "  %2749 = Shape(%2742)\n",
      "  %2750 = Constant[value = <Tensor>]()\n",
      "  %2751 = Constant[value = <Tensor>]()\n",
      "  %2752 = Constant[value = <Tensor>]()\n",
      "  %2753 = Slice(%2749, %2751, %2752, %2750)\n",
      "  %2754 = Constant[value = <Tensor>]()\n",
      "  %2755 = Squeeze(%2753, %2754)\n",
      "  %2756 = Constant[value = <Tensor>]()\n",
      "  %2757 = Unsqueeze(%186, %2756)\n",
      "  %2758 = Constant[value = <Tensor>]()\n",
      "  %2759 = Unsqueeze(%2755, %2758)\n",
      "  %2760 = Concat[axis = 0](%2757, %2759)\n",
      "  %2761 = Reshape[allowzero = 0](%2742, %2760)\n",
      "  %2762 = Gemm[alpha = 1, beta = 1](%2761, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_attn.bias)\n",
      "  %2763 = Constant[value = <Tensor>]()\n",
      "  %2764 = Unsqueeze(%2745, %2763)\n",
      "  %2765 = Constant[value = <Tensor>]()\n",
      "  %2766 = Unsqueeze(%2748, %2765)\n",
      "  %2767 = Constant[value = <Tensor>]()\n",
      "  %2768 = Unsqueeze(%182, %2767)\n",
      "  %2769 = Concat[axis = 0](%2764, %2766, %2768)\n",
      "  %2770 = Reshape[allowzero = 0](%2762, %2769)\n",
      "  %2771 = Constant[value = <Tensor>]()\n",
      "  %2772, %2773, %2774 = Split[axis = 2](%2770, %2771)\n",
      "  %2775 = Shape(%2772)\n",
      "  %2776 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2777 = Gather[axis = 0](%2775, %2776)\n",
      "  %2778 = Shape(%2772)\n",
      "  %2779 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2780 = Gather[axis = 0](%2778, %2779)\n",
      "  %2781 = Constant[value = <Tensor>]()\n",
      "  %2782 = Unsqueeze(%2777, %2781)\n",
      "  %2783 = Constant[value = <Tensor>]()\n",
      "  %2784 = Unsqueeze(%2780, %2783)\n",
      "  %2785 = Constant[value = <Tensor>]()\n",
      "  %2786 = Unsqueeze(%181, %2785)\n",
      "  %2787 = Constant[value = <Tensor>]()\n",
      "  %2788 = Unsqueeze(%180, %2787)\n",
      "  %2789 = Concat[axis = 0](%2782, %2784, %2786, %2788)\n",
      "  %2790 = Reshape[allowzero = 0](%2772, %2789)\n",
      "  %2791 = Transpose[perm = [0, 2, 1, 3]](%2790)\n",
      "  %2792 = Shape(%2773)\n",
      "  %2793 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2794 = Gather[axis = 0](%2792, %2793)\n",
      "  %2795 = Shape(%2773)\n",
      "  %2796 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2797 = Gather[axis = 0](%2795, %2796)\n",
      "  %2798 = Constant[value = <Tensor>]()\n",
      "  %2799 = Unsqueeze(%2794, %2798)\n",
      "  %2800 = Constant[value = <Tensor>]()\n",
      "  %2801 = Unsqueeze(%2797, %2800)\n",
      "  %2802 = Constant[value = <Tensor>]()\n",
      "  %2803 = Unsqueeze(%181, %2802)\n",
      "  %2804 = Constant[value = <Tensor>]()\n",
      "  %2805 = Unsqueeze(%180, %2804)\n",
      "  %2806 = Concat[axis = 0](%2799, %2801, %2803, %2805)\n",
      "  %2807 = Reshape[allowzero = 0](%2773, %2806)\n",
      "  %2808 = Transpose[perm = [0, 2, 1, 3]](%2807)\n",
      "  %2809 = Shape(%2774)\n",
      "  %2810 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2811 = Gather[axis = 0](%2809, %2810)\n",
      "  %2812 = Shape(%2774)\n",
      "  %2813 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2814 = Gather[axis = 0](%2812, %2813)\n",
      "  %2815 = Constant[value = <Tensor>]()\n",
      "  %2816 = Unsqueeze(%2811, %2815)\n",
      "  %2817 = Constant[value = <Tensor>]()\n",
      "  %2818 = Unsqueeze(%2814, %2817)\n",
      "  %2819 = Constant[value = <Tensor>]()\n",
      "  %2820 = Unsqueeze(%181, %2819)\n",
      "  %2821 = Constant[value = <Tensor>]()\n",
      "  %2822 = Unsqueeze(%180, %2821)\n",
      "  %2823 = Concat[axis = 0](%2816, %2818, %2820, %2822)\n",
      "  %2824 = Reshape[allowzero = 0](%2774, %2823)\n",
      "  %2825 = Transpose[perm = [0, 2, 1, 3]](%2824)\n",
      "  %2826 = Transpose[perm = [0, 2, 3, 1]](%2807)\n",
      "  %2827 = MatMul(%2791, %2826)\n",
      "  %2828 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2829 = Div(%2827, %2828)\n",
      "  %2830 = Shape(%2791)\n",
      "  %2831 = Constant[value = <Tensor>]()\n",
      "  %2832 = Constant[value = <Tensor>]()\n",
      "  %2833 = Constant[value = <Tensor>]()\n",
      "  %2834 = Slice(%2830, %2832, %2833, %2831)\n",
      "  %2835 = Constant[value = <Tensor>]()\n",
      "  %2836 = Squeeze(%2834, %2835)\n",
      "  %2837 = Shape(%2808)\n",
      "  %2838 = Constant[value = <Tensor>]()\n",
      "  %2839 = Constant[value = <Tensor>]()\n",
      "  %2840 = Constant[value = <Tensor>]()\n",
      "  %2841 = Slice(%2837, %2839, %2840, %2838)\n",
      "  %2842 = Constant[value = <Tensor>]()\n",
      "  %2843 = Squeeze(%2841, %2842)\n",
      "  %2844 = Sub(%2843, %2836)\n",
      "  %2845 = Constant[value = <Tensor>]()\n",
      "  %2846 = Unsqueeze(%2844, %2845)\n",
      "  %2847 = Constant[value = <Tensor>]()\n",
      "  %2848 = Unsqueeze(%2843, %2847)\n",
      "  %2849 = Constant[value = <Tensor>]()\n",
      "  %2850 = Unsqueeze(%190, %2849)\n",
      "  %2851 = Constant[value = <Tensor>]()\n",
      "  %2852 = Slice(%decoder_no_past.decoder.transformer.h.9.attn.bias, %2846, %2848, %2850, %2851)\n",
      "  %2853 = Constant[value = <Tensor>]()\n",
      "  %2854 = Unsqueeze(%191, %2853)\n",
      "  %2855 = Constant[value = <Tensor>]()\n",
      "  %2856 = Unsqueeze(%2843, %2855)\n",
      "  %2857 = Constant[value = <Tensor>]()\n",
      "  %2858 = Unsqueeze(%185, %2857)\n",
      "  %2859 = Constant[value = <Tensor>]()\n",
      "  %2860 = Slice(%2852, %2854, %2856, %2858, %2859)\n",
      "  %2861 = Cast[to = 9](%2860)\n",
      "  %2862 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.9.attn.masked_bias)\n",
      "  %2863 = Where(%2861, %2829, %2862)\n",
      "  %2864 = Add(%2863, %381)\n",
      "  %2865 = Softmax[axis = -1](%2864)\n",
      "  %2866 = MatMul(%2865, %2825)\n",
      "  %2867 = Transpose[perm = [0, 2, 1, 3]](%2866)\n",
      "  %2868 = Shape(%2867)\n",
      "  %2869 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2870 = Gather[axis = 0](%2868, %2869)\n",
      "  %2871 = Shape(%2867)\n",
      "  %2872 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2873 = Gather[axis = 0](%2871, %2872)\n",
      "  %2874 = Constant[value = <Tensor>]()\n",
      "  %2875 = Unsqueeze(%2870, %2874)\n",
      "  %2876 = Constant[value = <Tensor>]()\n",
      "  %2877 = Unsqueeze(%2873, %2876)\n",
      "  %2878 = Constant[value = <Tensor>]()\n",
      "  %2879 = Unsqueeze(%183, %2878)\n",
      "  %2880 = Concat[axis = 0](%2875, %2877, %2879)\n",
      "  %2881 = Reshape[allowzero = 0](%2867, %2880)\n",
      "  %2882 = Shape(%2881)\n",
      "  %2883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2884 = Gather[axis = 0](%2882, %2883)\n",
      "  %2885 = Shape(%2881)\n",
      "  %2886 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2887 = Gather[axis = 0](%2885, %2886)\n",
      "  %2888 = Shape(%2881)\n",
      "  %2889 = Constant[value = <Tensor>]()\n",
      "  %2890 = Constant[value = <Tensor>]()\n",
      "  %2891 = Constant[value = <Tensor>]()\n",
      "  %2892 = Slice(%2888, %2890, %2891, %2889)\n",
      "  %2893 = Constant[value = <Tensor>]()\n",
      "  %2894 = Squeeze(%2892, %2893)\n",
      "  %2895 = Constant[value = <Tensor>]()\n",
      "  %2896 = Unsqueeze(%186, %2895)\n",
      "  %2897 = Constant[value = <Tensor>]()\n",
      "  %2898 = Unsqueeze(%2894, %2897)\n",
      "  %2899 = Concat[axis = 0](%2896, %2898)\n",
      "  %2900 = Reshape[allowzero = 0](%2881, %2899)\n",
      "  %2901 = Gemm[alpha = 1, beta = 1](%2900, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.attn.c_proj.bias)\n",
      "  %2902 = Constant[value = <Tensor>]()\n",
      "  %2903 = Unsqueeze(%2884, %2902)\n",
      "  %2904 = Constant[value = <Tensor>]()\n",
      "  %2905 = Unsqueeze(%2887, %2904)\n",
      "  %2906 = Constant[value = <Tensor>]()\n",
      "  %2907 = Unsqueeze(%183, %2906)\n",
      "  %2908 = Concat[axis = 0](%2903, %2905, %2907)\n",
      "  %2909 = Reshape[allowzero = 0](%2901, %2908)\n",
      "  %2910 = Add(%2909, %2731)\n",
      "  %2911 = ReduceMean[axes = [-1]](%2910)\n",
      "  %2912 = Sub(%2910, %2911)\n",
      "  %2913 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2914 = Pow(%2912, %2913)\n",
      "  %2915 = ReduceMean[axes = [-1]](%2914)\n",
      "  %2916 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2917 = Add(%2915, %2916)\n",
      "  %2918 = Sqrt(%2917)\n",
      "  %2919 = Div(%2912, %2918)\n",
      "  %2920 = Mul(%2919, %decoder_no_past.decoder.transformer.h.9.ln_2.weight)\n",
      "  %2921 = Add(%2920, %decoder_no_past.decoder.transformer.h.9.ln_2.bias)\n",
      "  %2922 = Shape(%2921)\n",
      "  %2923 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2924 = Gather[axis = 0](%2922, %2923)\n",
      "  %2925 = Shape(%2921)\n",
      "  %2926 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2927 = Gather[axis = 0](%2925, %2926)\n",
      "  %2928 = Shape(%2921)\n",
      "  %2929 = Constant[value = <Tensor>]()\n",
      "  %2930 = Constant[value = <Tensor>]()\n",
      "  %2931 = Constant[value = <Tensor>]()\n",
      "  %2932 = Slice(%2928, %2930, %2931, %2929)\n",
      "  %2933 = Constant[value = <Tensor>]()\n",
      "  %2934 = Squeeze(%2932, %2933)\n",
      "  %2935 = Constant[value = <Tensor>]()\n",
      "  %2936 = Unsqueeze(%186, %2935)\n",
      "  %2937 = Constant[value = <Tensor>]()\n",
      "  %2938 = Unsqueeze(%2934, %2937)\n",
      "  %2939 = Concat[axis = 0](%2936, %2938)\n",
      "  %2940 = Reshape[allowzero = 0](%2921, %2939)\n",
      "  %2941 = Gemm[alpha = 1, beta = 1](%2940, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_fc.bias)\n",
      "  %2942 = Constant[value = <Tensor>]()\n",
      "  %2943 = Unsqueeze(%2924, %2942)\n",
      "  %2944 = Constant[value = <Tensor>]()\n",
      "  %2945 = Unsqueeze(%2927, %2944)\n",
      "  %2946 = Constant[value = <Tensor>]()\n",
      "  %2947 = Unsqueeze(%179, %2946)\n",
      "  %2948 = Concat[axis = 0](%2943, %2945, %2947)\n",
      "  %2949 = Reshape[allowzero = 0](%2941, %2948)\n",
      "  %2950 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2951 = Mul(%2949, %2950)\n",
      "  %2952 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2953 = Pow(%2949, %2952)\n",
      "  %2954 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2955 = Mul(%2953, %2954)\n",
      "  %2956 = Add(%2949, %2955)\n",
      "  %2957 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2958 = Mul(%2956, %2957)\n",
      "  %2959 = Tanh(%2958)\n",
      "  %2960 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2961 = Add(%2959, %2960)\n",
      "  %2962 = Mul(%2951, %2961)\n",
      "  %2963 = Shape(%2962)\n",
      "  %2964 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2965 = Gather[axis = 0](%2963, %2964)\n",
      "  %2966 = Shape(%2962)\n",
      "  %2967 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2968 = Gather[axis = 0](%2966, %2967)\n",
      "  %2969 = Shape(%2962)\n",
      "  %2970 = Constant[value = <Tensor>]()\n",
      "  %2971 = Constant[value = <Tensor>]()\n",
      "  %2972 = Constant[value = <Tensor>]()\n",
      "  %2973 = Slice(%2969, %2971, %2972, %2970)\n",
      "  %2974 = Constant[value = <Tensor>]()\n",
      "  %2975 = Squeeze(%2973, %2974)\n",
      "  %2976 = Constant[value = <Tensor>]()\n",
      "  %2977 = Unsqueeze(%186, %2976)\n",
      "  %2978 = Constant[value = <Tensor>]()\n",
      "  %2979 = Unsqueeze(%2975, %2978)\n",
      "  %2980 = Concat[axis = 0](%2977, %2979)\n",
      "  %2981 = Reshape[allowzero = 0](%2962, %2980)\n",
      "  %2982 = Gemm[alpha = 1, beta = 1](%2981, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.9.mlp.c_proj.bias)\n",
      "  %2983 = Constant[value = <Tensor>]()\n",
      "  %2984 = Unsqueeze(%2965, %2983)\n",
      "  %2985 = Constant[value = <Tensor>]()\n",
      "  %2986 = Unsqueeze(%2968, %2985)\n",
      "  %2987 = Constant[value = <Tensor>]()\n",
      "  %2988 = Unsqueeze(%183, %2987)\n",
      "  %2989 = Concat[axis = 0](%2984, %2986, %2988)\n",
      "  %2990 = Reshape[allowzero = 0](%2982, %2989)\n",
      "  %2991 = Add(%2910, %2990)\n",
      "  %2992 = ReduceMean[axes = [-1]](%2991)\n",
      "  %2993 = Sub(%2991, %2992)\n",
      "  %2994 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2995 = Pow(%2993, %2994)\n",
      "  %2996 = ReduceMean[axes = [-1]](%2995)\n",
      "  %2997 = Constant[value = <Scalar Tensor []>]()\n",
      "  %2998 = Add(%2996, %2997)\n",
      "  %2999 = Sqrt(%2998)\n",
      "  %3000 = Div(%2993, %2999)\n",
      "  %3001 = Mul(%3000, %decoder_no_past.decoder.transformer.h.10.ln_1.weight)\n",
      "  %3002 = Add(%3001, %decoder_no_past.decoder.transformer.h.10.ln_1.bias)\n",
      "  %3003 = Shape(%3002)\n",
      "  %3004 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3005 = Gather[axis = 0](%3003, %3004)\n",
      "  %3006 = Shape(%3002)\n",
      "  %3007 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3008 = Gather[axis = 0](%3006, %3007)\n",
      "  %3009 = Shape(%3002)\n",
      "  %3010 = Constant[value = <Tensor>]()\n",
      "  %3011 = Constant[value = <Tensor>]()\n",
      "  %3012 = Constant[value = <Tensor>]()\n",
      "  %3013 = Slice(%3009, %3011, %3012, %3010)\n",
      "  %3014 = Constant[value = <Tensor>]()\n",
      "  %3015 = Squeeze(%3013, %3014)\n",
      "  %3016 = Constant[value = <Tensor>]()\n",
      "  %3017 = Unsqueeze(%186, %3016)\n",
      "  %3018 = Constant[value = <Tensor>]()\n",
      "  %3019 = Unsqueeze(%3015, %3018)\n",
      "  %3020 = Concat[axis = 0](%3017, %3019)\n",
      "  %3021 = Reshape[allowzero = 0](%3002, %3020)\n",
      "  %3022 = Gemm[alpha = 1, beta = 1](%3021, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_attn.bias)\n",
      "  %3023 = Constant[value = <Tensor>]()\n",
      "  %3024 = Unsqueeze(%3005, %3023)\n",
      "  %3025 = Constant[value = <Tensor>]()\n",
      "  %3026 = Unsqueeze(%3008, %3025)\n",
      "  %3027 = Constant[value = <Tensor>]()\n",
      "  %3028 = Unsqueeze(%182, %3027)\n",
      "  %3029 = Concat[axis = 0](%3024, %3026, %3028)\n",
      "  %3030 = Reshape[allowzero = 0](%3022, %3029)\n",
      "  %3031 = Constant[value = <Tensor>]()\n",
      "  %3032, %3033, %3034 = Split[axis = 2](%3030, %3031)\n",
      "  %3035 = Shape(%3032)\n",
      "  %3036 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3037 = Gather[axis = 0](%3035, %3036)\n",
      "  %3038 = Shape(%3032)\n",
      "  %3039 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3040 = Gather[axis = 0](%3038, %3039)\n",
      "  %3041 = Constant[value = <Tensor>]()\n",
      "  %3042 = Unsqueeze(%3037, %3041)\n",
      "  %3043 = Constant[value = <Tensor>]()\n",
      "  %3044 = Unsqueeze(%3040, %3043)\n",
      "  %3045 = Constant[value = <Tensor>]()\n",
      "  %3046 = Unsqueeze(%181, %3045)\n",
      "  %3047 = Constant[value = <Tensor>]()\n",
      "  %3048 = Unsqueeze(%180, %3047)\n",
      "  %3049 = Concat[axis = 0](%3042, %3044, %3046, %3048)\n",
      "  %3050 = Reshape[allowzero = 0](%3032, %3049)\n",
      "  %3051 = Transpose[perm = [0, 2, 1, 3]](%3050)\n",
      "  %3052 = Shape(%3033)\n",
      "  %3053 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3054 = Gather[axis = 0](%3052, %3053)\n",
      "  %3055 = Shape(%3033)\n",
      "  %3056 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3057 = Gather[axis = 0](%3055, %3056)\n",
      "  %3058 = Constant[value = <Tensor>]()\n",
      "  %3059 = Unsqueeze(%3054, %3058)\n",
      "  %3060 = Constant[value = <Tensor>]()\n",
      "  %3061 = Unsqueeze(%3057, %3060)\n",
      "  %3062 = Constant[value = <Tensor>]()\n",
      "  %3063 = Unsqueeze(%181, %3062)\n",
      "  %3064 = Constant[value = <Tensor>]()\n",
      "  %3065 = Unsqueeze(%180, %3064)\n",
      "  %3066 = Concat[axis = 0](%3059, %3061, %3063, %3065)\n",
      "  %3067 = Reshape[allowzero = 0](%3033, %3066)\n",
      "  %3068 = Transpose[perm = [0, 2, 1, 3]](%3067)\n",
      "  %3069 = Shape(%3034)\n",
      "  %3070 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3071 = Gather[axis = 0](%3069, %3070)\n",
      "  %3072 = Shape(%3034)\n",
      "  %3073 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3074 = Gather[axis = 0](%3072, %3073)\n",
      "  %3075 = Constant[value = <Tensor>]()\n",
      "  %3076 = Unsqueeze(%3071, %3075)\n",
      "  %3077 = Constant[value = <Tensor>]()\n",
      "  %3078 = Unsqueeze(%3074, %3077)\n",
      "  %3079 = Constant[value = <Tensor>]()\n",
      "  %3080 = Unsqueeze(%181, %3079)\n",
      "  %3081 = Constant[value = <Tensor>]()\n",
      "  %3082 = Unsqueeze(%180, %3081)\n",
      "  %3083 = Concat[axis = 0](%3076, %3078, %3080, %3082)\n",
      "  %3084 = Reshape[allowzero = 0](%3034, %3083)\n",
      "  %3085 = Transpose[perm = [0, 2, 1, 3]](%3084)\n",
      "  %3086 = Transpose[perm = [0, 2, 3, 1]](%3067)\n",
      "  %3087 = MatMul(%3051, %3086)\n",
      "  %3088 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3089 = Div(%3087, %3088)\n",
      "  %3090 = Shape(%3051)\n",
      "  %3091 = Constant[value = <Tensor>]()\n",
      "  %3092 = Constant[value = <Tensor>]()\n",
      "  %3093 = Constant[value = <Tensor>]()\n",
      "  %3094 = Slice(%3090, %3092, %3093, %3091)\n",
      "  %3095 = Constant[value = <Tensor>]()\n",
      "  %3096 = Squeeze(%3094, %3095)\n",
      "  %3097 = Shape(%3068)\n",
      "  %3098 = Constant[value = <Tensor>]()\n",
      "  %3099 = Constant[value = <Tensor>]()\n",
      "  %3100 = Constant[value = <Tensor>]()\n",
      "  %3101 = Slice(%3097, %3099, %3100, %3098)\n",
      "  %3102 = Constant[value = <Tensor>]()\n",
      "  %3103 = Squeeze(%3101, %3102)\n",
      "  %3104 = Sub(%3103, %3096)\n",
      "  %3105 = Constant[value = <Tensor>]()\n",
      "  %3106 = Unsqueeze(%3104, %3105)\n",
      "  %3107 = Constant[value = <Tensor>]()\n",
      "  %3108 = Unsqueeze(%3103, %3107)\n",
      "  %3109 = Constant[value = <Tensor>]()\n",
      "  %3110 = Unsqueeze(%190, %3109)\n",
      "  %3111 = Constant[value = <Tensor>]()\n",
      "  %3112 = Slice(%decoder_no_past.decoder.transformer.h.10.attn.bias, %3106, %3108, %3110, %3111)\n",
      "  %3113 = Constant[value = <Tensor>]()\n",
      "  %3114 = Unsqueeze(%191, %3113)\n",
      "  %3115 = Constant[value = <Tensor>]()\n",
      "  %3116 = Unsqueeze(%3103, %3115)\n",
      "  %3117 = Constant[value = <Tensor>]()\n",
      "  %3118 = Unsqueeze(%185, %3117)\n",
      "  %3119 = Constant[value = <Tensor>]()\n",
      "  %3120 = Slice(%3112, %3114, %3116, %3118, %3119)\n",
      "  %3121 = Cast[to = 9](%3120)\n",
      "  %3122 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.10.attn.masked_bias)\n",
      "  %3123 = Where(%3121, %3089, %3122)\n",
      "  %3124 = Add(%3123, %381)\n",
      "  %3125 = Softmax[axis = -1](%3124)\n",
      "  %3126 = MatMul(%3125, %3085)\n",
      "  %3127 = Transpose[perm = [0, 2, 1, 3]](%3126)\n",
      "  %3128 = Shape(%3127)\n",
      "  %3129 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3130 = Gather[axis = 0](%3128, %3129)\n",
      "  %3131 = Shape(%3127)\n",
      "  %3132 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3133 = Gather[axis = 0](%3131, %3132)\n",
      "  %3134 = Constant[value = <Tensor>]()\n",
      "  %3135 = Unsqueeze(%3130, %3134)\n",
      "  %3136 = Constant[value = <Tensor>]()\n",
      "  %3137 = Unsqueeze(%3133, %3136)\n",
      "  %3138 = Constant[value = <Tensor>]()\n",
      "  %3139 = Unsqueeze(%183, %3138)\n",
      "  %3140 = Concat[axis = 0](%3135, %3137, %3139)\n",
      "  %3141 = Reshape[allowzero = 0](%3127, %3140)\n",
      "  %3142 = Shape(%3141)\n",
      "  %3143 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3144 = Gather[axis = 0](%3142, %3143)\n",
      "  %3145 = Shape(%3141)\n",
      "  %3146 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3147 = Gather[axis = 0](%3145, %3146)\n",
      "  %3148 = Shape(%3141)\n",
      "  %3149 = Constant[value = <Tensor>]()\n",
      "  %3150 = Constant[value = <Tensor>]()\n",
      "  %3151 = Constant[value = <Tensor>]()\n",
      "  %3152 = Slice(%3148, %3150, %3151, %3149)\n",
      "  %3153 = Constant[value = <Tensor>]()\n",
      "  %3154 = Squeeze(%3152, %3153)\n",
      "  %3155 = Constant[value = <Tensor>]()\n",
      "  %3156 = Unsqueeze(%186, %3155)\n",
      "  %3157 = Constant[value = <Tensor>]()\n",
      "  %3158 = Unsqueeze(%3154, %3157)\n",
      "  %3159 = Concat[axis = 0](%3156, %3158)\n",
      "  %3160 = Reshape[allowzero = 0](%3141, %3159)\n",
      "  %3161 = Gemm[alpha = 1, beta = 1](%3160, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.attn.c_proj.bias)\n",
      "  %3162 = Constant[value = <Tensor>]()\n",
      "  %3163 = Unsqueeze(%3144, %3162)\n",
      "  %3164 = Constant[value = <Tensor>]()\n",
      "  %3165 = Unsqueeze(%3147, %3164)\n",
      "  %3166 = Constant[value = <Tensor>]()\n",
      "  %3167 = Unsqueeze(%183, %3166)\n",
      "  %3168 = Concat[axis = 0](%3163, %3165, %3167)\n",
      "  %3169 = Reshape[allowzero = 0](%3161, %3168)\n",
      "  %3170 = Add(%3169, %2991)\n",
      "  %3171 = ReduceMean[axes = [-1]](%3170)\n",
      "  %3172 = Sub(%3170, %3171)\n",
      "  %3173 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3174 = Pow(%3172, %3173)\n",
      "  %3175 = ReduceMean[axes = [-1]](%3174)\n",
      "  %3176 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3177 = Add(%3175, %3176)\n",
      "  %3178 = Sqrt(%3177)\n",
      "  %3179 = Div(%3172, %3178)\n",
      "  %3180 = Mul(%3179, %decoder_no_past.decoder.transformer.h.10.ln_2.weight)\n",
      "  %3181 = Add(%3180, %decoder_no_past.decoder.transformer.h.10.ln_2.bias)\n",
      "  %3182 = Shape(%3181)\n",
      "  %3183 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3184 = Gather[axis = 0](%3182, %3183)\n",
      "  %3185 = Shape(%3181)\n",
      "  %3186 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3187 = Gather[axis = 0](%3185, %3186)\n",
      "  %3188 = Shape(%3181)\n",
      "  %3189 = Constant[value = <Tensor>]()\n",
      "  %3190 = Constant[value = <Tensor>]()\n",
      "  %3191 = Constant[value = <Tensor>]()\n",
      "  %3192 = Slice(%3188, %3190, %3191, %3189)\n",
      "  %3193 = Constant[value = <Tensor>]()\n",
      "  %3194 = Squeeze(%3192, %3193)\n",
      "  %3195 = Constant[value = <Tensor>]()\n",
      "  %3196 = Unsqueeze(%186, %3195)\n",
      "  %3197 = Constant[value = <Tensor>]()\n",
      "  %3198 = Unsqueeze(%3194, %3197)\n",
      "  %3199 = Concat[axis = 0](%3196, %3198)\n",
      "  %3200 = Reshape[allowzero = 0](%3181, %3199)\n",
      "  %3201 = Gemm[alpha = 1, beta = 1](%3200, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_fc.bias)\n",
      "  %3202 = Constant[value = <Tensor>]()\n",
      "  %3203 = Unsqueeze(%3184, %3202)\n",
      "  %3204 = Constant[value = <Tensor>]()\n",
      "  %3205 = Unsqueeze(%3187, %3204)\n",
      "  %3206 = Constant[value = <Tensor>]()\n",
      "  %3207 = Unsqueeze(%179, %3206)\n",
      "  %3208 = Concat[axis = 0](%3203, %3205, %3207)\n",
      "  %3209 = Reshape[allowzero = 0](%3201, %3208)\n",
      "  %3210 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3211 = Mul(%3209, %3210)\n",
      "  %3212 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3213 = Pow(%3209, %3212)\n",
      "  %3214 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3215 = Mul(%3213, %3214)\n",
      "  %3216 = Add(%3209, %3215)\n",
      "  %3217 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3218 = Mul(%3216, %3217)\n",
      "  %3219 = Tanh(%3218)\n",
      "  %3220 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3221 = Add(%3219, %3220)\n",
      "  %3222 = Mul(%3211, %3221)\n",
      "  %3223 = Shape(%3222)\n",
      "  %3224 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3225 = Gather[axis = 0](%3223, %3224)\n",
      "  %3226 = Shape(%3222)\n",
      "  %3227 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3228 = Gather[axis = 0](%3226, %3227)\n",
      "  %3229 = Shape(%3222)\n",
      "  %3230 = Constant[value = <Tensor>]()\n",
      "  %3231 = Constant[value = <Tensor>]()\n",
      "  %3232 = Constant[value = <Tensor>]()\n",
      "  %3233 = Slice(%3229, %3231, %3232, %3230)\n",
      "  %3234 = Constant[value = <Tensor>]()\n",
      "  %3235 = Squeeze(%3233, %3234)\n",
      "  %3236 = Constant[value = <Tensor>]()\n",
      "  %3237 = Unsqueeze(%186, %3236)\n",
      "  %3238 = Constant[value = <Tensor>]()\n",
      "  %3239 = Unsqueeze(%3235, %3238)\n",
      "  %3240 = Concat[axis = 0](%3237, %3239)\n",
      "  %3241 = Reshape[allowzero = 0](%3222, %3240)\n",
      "  %3242 = Gemm[alpha = 1, beta = 1](%3241, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.10.mlp.c_proj.bias)\n",
      "  %3243 = Constant[value = <Tensor>]()\n",
      "  %3244 = Unsqueeze(%3225, %3243)\n",
      "  %3245 = Constant[value = <Tensor>]()\n",
      "  %3246 = Unsqueeze(%3228, %3245)\n",
      "  %3247 = Constant[value = <Tensor>]()\n",
      "  %3248 = Unsqueeze(%183, %3247)\n",
      "  %3249 = Concat[axis = 0](%3244, %3246, %3248)\n",
      "  %3250 = Reshape[allowzero = 0](%3242, %3249)\n",
      "  %3251 = Add(%3170, %3250)\n",
      "  %3252 = ReduceMean[axes = [-1]](%3251)\n",
      "  %3253 = Sub(%3251, %3252)\n",
      "  %3254 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3255 = Pow(%3253, %3254)\n",
      "  %3256 = ReduceMean[axes = [-1]](%3255)\n",
      "  %3257 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3258 = Add(%3256, %3257)\n",
      "  %3259 = Sqrt(%3258)\n",
      "  %3260 = Div(%3253, %3259)\n",
      "  %3261 = Mul(%3260, %decoder_no_past.decoder.transformer.h.11.ln_1.weight)\n",
      "  %3262 = Add(%3261, %decoder_no_past.decoder.transformer.h.11.ln_1.bias)\n",
      "  %3263 = Shape(%3262)\n",
      "  %3264 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3265 = Gather[axis = 0](%3263, %3264)\n",
      "  %3266 = Shape(%3262)\n",
      "  %3267 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3268 = Gather[axis = 0](%3266, %3267)\n",
      "  %3269 = Shape(%3262)\n",
      "  %3270 = Constant[value = <Tensor>]()\n",
      "  %3271 = Constant[value = <Tensor>]()\n",
      "  %3272 = Constant[value = <Tensor>]()\n",
      "  %3273 = Slice(%3269, %3271, %3272, %3270)\n",
      "  %3274 = Constant[value = <Tensor>]()\n",
      "  %3275 = Squeeze(%3273, %3274)\n",
      "  %3276 = Constant[value = <Tensor>]()\n",
      "  %3277 = Unsqueeze(%186, %3276)\n",
      "  %3278 = Constant[value = <Tensor>]()\n",
      "  %3279 = Unsqueeze(%3275, %3278)\n",
      "  %3280 = Concat[axis = 0](%3277, %3279)\n",
      "  %3281 = Reshape[allowzero = 0](%3262, %3280)\n",
      "  %3282 = Gemm[alpha = 1, beta = 1](%3281, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_attn.bias)\n",
      "  %3283 = Constant[value = <Tensor>]()\n",
      "  %3284 = Unsqueeze(%3265, %3283)\n",
      "  %3285 = Constant[value = <Tensor>]()\n",
      "  %3286 = Unsqueeze(%3268, %3285)\n",
      "  %3287 = Constant[value = <Tensor>]()\n",
      "  %3288 = Unsqueeze(%182, %3287)\n",
      "  %3289 = Concat[axis = 0](%3284, %3286, %3288)\n",
      "  %3290 = Reshape[allowzero = 0](%3282, %3289)\n",
      "  %3291 = Constant[value = <Tensor>]()\n",
      "  %3292, %3293, %3294 = Split[axis = 2](%3290, %3291)\n",
      "  %3295 = Shape(%3292)\n",
      "  %3296 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3297 = Gather[axis = 0](%3295, %3296)\n",
      "  %3298 = Shape(%3292)\n",
      "  %3299 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3300 = Gather[axis = 0](%3298, %3299)\n",
      "  %3301 = Constant[value = <Tensor>]()\n",
      "  %3302 = Unsqueeze(%3297, %3301)\n",
      "  %3303 = Constant[value = <Tensor>]()\n",
      "  %3304 = Unsqueeze(%3300, %3303)\n",
      "  %3305 = Constant[value = <Tensor>]()\n",
      "  %3306 = Unsqueeze(%181, %3305)\n",
      "  %3307 = Constant[value = <Tensor>]()\n",
      "  %3308 = Unsqueeze(%180, %3307)\n",
      "  %3309 = Concat[axis = 0](%3302, %3304, %3306, %3308)\n",
      "  %3310 = Reshape[allowzero = 0](%3292, %3309)\n",
      "  %3311 = Transpose[perm = [0, 2, 1, 3]](%3310)\n",
      "  %3312 = Shape(%3293)\n",
      "  %3313 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3314 = Gather[axis = 0](%3312, %3313)\n",
      "  %3315 = Shape(%3293)\n",
      "  %3316 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3317 = Gather[axis = 0](%3315, %3316)\n",
      "  %3318 = Constant[value = <Tensor>]()\n",
      "  %3319 = Unsqueeze(%3314, %3318)\n",
      "  %3320 = Constant[value = <Tensor>]()\n",
      "  %3321 = Unsqueeze(%3317, %3320)\n",
      "  %3322 = Constant[value = <Tensor>]()\n",
      "  %3323 = Unsqueeze(%181, %3322)\n",
      "  %3324 = Constant[value = <Tensor>]()\n",
      "  %3325 = Unsqueeze(%180, %3324)\n",
      "  %3326 = Concat[axis = 0](%3319, %3321, %3323, %3325)\n",
      "  %3327 = Reshape[allowzero = 0](%3293, %3326)\n",
      "  %3328 = Transpose[perm = [0, 2, 1, 3]](%3327)\n",
      "  %3329 = Shape(%3294)\n",
      "  %3330 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3331 = Gather[axis = 0](%3329, %3330)\n",
      "  %3332 = Shape(%3294)\n",
      "  %3333 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3334 = Gather[axis = 0](%3332, %3333)\n",
      "  %3335 = Constant[value = <Tensor>]()\n",
      "  %3336 = Unsqueeze(%3331, %3335)\n",
      "  %3337 = Constant[value = <Tensor>]()\n",
      "  %3338 = Unsqueeze(%3334, %3337)\n",
      "  %3339 = Constant[value = <Tensor>]()\n",
      "  %3340 = Unsqueeze(%181, %3339)\n",
      "  %3341 = Constant[value = <Tensor>]()\n",
      "  %3342 = Unsqueeze(%180, %3341)\n",
      "  %3343 = Concat[axis = 0](%3336, %3338, %3340, %3342)\n",
      "  %3344 = Reshape[allowzero = 0](%3294, %3343)\n",
      "  %3345 = Transpose[perm = [0, 2, 1, 3]](%3344)\n",
      "  %3346 = Transpose[perm = [0, 2, 3, 1]](%3327)\n",
      "  %3347 = MatMul(%3311, %3346)\n",
      "  %3348 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3349 = Div(%3347, %3348)\n",
      "  %3350 = Shape(%3311)\n",
      "  %3351 = Constant[value = <Tensor>]()\n",
      "  %3352 = Constant[value = <Tensor>]()\n",
      "  %3353 = Constant[value = <Tensor>]()\n",
      "  %3354 = Slice(%3350, %3352, %3353, %3351)\n",
      "  %3355 = Constant[value = <Tensor>]()\n",
      "  %3356 = Squeeze(%3354, %3355)\n",
      "  %3357 = Shape(%3328)\n",
      "  %3358 = Constant[value = <Tensor>]()\n",
      "  %3359 = Constant[value = <Tensor>]()\n",
      "  %3360 = Constant[value = <Tensor>]()\n",
      "  %3361 = Slice(%3357, %3359, %3360, %3358)\n",
      "  %3362 = Constant[value = <Tensor>]()\n",
      "  %3363 = Squeeze(%3361, %3362)\n",
      "  %3364 = Sub(%3363, %3356)\n",
      "  %3365 = Constant[value = <Tensor>]()\n",
      "  %3366 = Unsqueeze(%3364, %3365)\n",
      "  %3367 = Constant[value = <Tensor>]()\n",
      "  %3368 = Unsqueeze(%3363, %3367)\n",
      "  %3369 = Constant[value = <Tensor>]()\n",
      "  %3370 = Unsqueeze(%190, %3369)\n",
      "  %3371 = Constant[value = <Tensor>]()\n",
      "  %3372 = Slice(%decoder_no_past.decoder.transformer.h.11.attn.bias, %3366, %3368, %3370, %3371)\n",
      "  %3373 = Constant[value = <Tensor>]()\n",
      "  %3374 = Unsqueeze(%191, %3373)\n",
      "  %3375 = Constant[value = <Tensor>]()\n",
      "  %3376 = Unsqueeze(%3363, %3375)\n",
      "  %3377 = Constant[value = <Tensor>]()\n",
      "  %3378 = Unsqueeze(%185, %3377)\n",
      "  %3379 = Constant[value = <Tensor>]()\n",
      "  %3380 = Slice(%3372, %3374, %3376, %3378, %3379)\n",
      "  %3381 = Cast[to = 9](%3380)\n",
      "  %3382 = Cast[to = 1](%decoder_no_past.decoder.transformer.h.11.attn.masked_bias)\n",
      "  %3383 = Where(%3381, %3349, %3382)\n",
      "  %3384 = Add(%3383, %381)\n",
      "  %3385 = Softmax[axis = -1](%3384)\n",
      "  %3386 = MatMul(%3385, %3345)\n",
      "  %3387 = Transpose[perm = [0, 2, 1, 3]](%3386)\n",
      "  %3388 = Shape(%3387)\n",
      "  %3389 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3390 = Gather[axis = 0](%3388, %3389)\n",
      "  %3391 = Shape(%3387)\n",
      "  %3392 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3393 = Gather[axis = 0](%3391, %3392)\n",
      "  %3394 = Constant[value = <Tensor>]()\n",
      "  %3395 = Unsqueeze(%3390, %3394)\n",
      "  %3396 = Constant[value = <Tensor>]()\n",
      "  %3397 = Unsqueeze(%3393, %3396)\n",
      "  %3398 = Constant[value = <Tensor>]()\n",
      "  %3399 = Unsqueeze(%183, %3398)\n",
      "  %3400 = Concat[axis = 0](%3395, %3397, %3399)\n",
      "  %3401 = Reshape[allowzero = 0](%3387, %3400)\n",
      "  %3402 = Shape(%3401)\n",
      "  %3403 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3404 = Gather[axis = 0](%3402, %3403)\n",
      "  %3405 = Shape(%3401)\n",
      "  %3406 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3407 = Gather[axis = 0](%3405, %3406)\n",
      "  %3408 = Shape(%3401)\n",
      "  %3409 = Constant[value = <Tensor>]()\n",
      "  %3410 = Constant[value = <Tensor>]()\n",
      "  %3411 = Constant[value = <Tensor>]()\n",
      "  %3412 = Slice(%3408, %3410, %3411, %3409)\n",
      "  %3413 = Constant[value = <Tensor>]()\n",
      "  %3414 = Squeeze(%3412, %3413)\n",
      "  %3415 = Constant[value = <Tensor>]()\n",
      "  %3416 = Unsqueeze(%186, %3415)\n",
      "  %3417 = Constant[value = <Tensor>]()\n",
      "  %3418 = Unsqueeze(%3414, %3417)\n",
      "  %3419 = Concat[axis = 0](%3416, %3418)\n",
      "  %3420 = Reshape[allowzero = 0](%3401, %3419)\n",
      "  %3421 = Gemm[alpha = 1, beta = 1](%3420, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.attn.c_proj.bias)\n",
      "  %3422 = Constant[value = <Tensor>]()\n",
      "  %3423 = Unsqueeze(%3404, %3422)\n",
      "  %3424 = Constant[value = <Tensor>]()\n",
      "  %3425 = Unsqueeze(%3407, %3424)\n",
      "  %3426 = Constant[value = <Tensor>]()\n",
      "  %3427 = Unsqueeze(%183, %3426)\n",
      "  %3428 = Concat[axis = 0](%3423, %3425, %3427)\n",
      "  %3429 = Reshape[allowzero = 0](%3421, %3428)\n",
      "  %3430 = Add(%3429, %3251)\n",
      "  %3431 = ReduceMean[axes = [-1]](%3430)\n",
      "  %3432 = Sub(%3430, %3431)\n",
      "  %3433 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3434 = Pow(%3432, %3433)\n",
      "  %3435 = ReduceMean[axes = [-1]](%3434)\n",
      "  %3436 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3437 = Add(%3435, %3436)\n",
      "  %3438 = Sqrt(%3437)\n",
      "  %3439 = Div(%3432, %3438)\n",
      "  %3440 = Mul(%3439, %decoder_no_past.decoder.transformer.h.11.ln_2.weight)\n",
      "  %3441 = Add(%3440, %decoder_no_past.decoder.transformer.h.11.ln_2.bias)\n",
      "  %3442 = Shape(%3441)\n",
      "  %3443 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3444 = Gather[axis = 0](%3442, %3443)\n",
      "  %3445 = Shape(%3441)\n",
      "  %3446 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3447 = Gather[axis = 0](%3445, %3446)\n",
      "  %3448 = Shape(%3441)\n",
      "  %3449 = Constant[value = <Tensor>]()\n",
      "  %3450 = Constant[value = <Tensor>]()\n",
      "  %3451 = Constant[value = <Tensor>]()\n",
      "  %3452 = Slice(%3448, %3450, %3451, %3449)\n",
      "  %3453 = Constant[value = <Tensor>]()\n",
      "  %3454 = Squeeze(%3452, %3453)\n",
      "  %3455 = Constant[value = <Tensor>]()\n",
      "  %3456 = Unsqueeze(%186, %3455)\n",
      "  %3457 = Constant[value = <Tensor>]()\n",
      "  %3458 = Unsqueeze(%3454, %3457)\n",
      "  %3459 = Concat[axis = 0](%3456, %3458)\n",
      "  %3460 = Reshape[allowzero = 0](%3441, %3459)\n",
      "  %3461 = Gemm[alpha = 1, beta = 1](%3460, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_fc.bias)\n",
      "  %3462 = Constant[value = <Tensor>]()\n",
      "  %3463 = Unsqueeze(%3444, %3462)\n",
      "  %3464 = Constant[value = <Tensor>]()\n",
      "  %3465 = Unsqueeze(%3447, %3464)\n",
      "  %3466 = Constant[value = <Tensor>]()\n",
      "  %3467 = Unsqueeze(%179, %3466)\n",
      "  %3468 = Concat[axis = 0](%3463, %3465, %3467)\n",
      "  %3469 = Reshape[allowzero = 0](%3461, %3468)\n",
      "  %3470 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3471 = Mul(%3469, %3470)\n",
      "  %3472 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3473 = Pow(%3469, %3472)\n",
      "  %3474 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3475 = Mul(%3473, %3474)\n",
      "  %3476 = Add(%3469, %3475)\n",
      "  %3477 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3478 = Mul(%3476, %3477)\n",
      "  %3479 = Tanh(%3478)\n",
      "  %3480 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3481 = Add(%3479, %3480)\n",
      "  %3482 = Mul(%3471, %3481)\n",
      "  %3483 = Shape(%3482)\n",
      "  %3484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3485 = Gather[axis = 0](%3483, %3484)\n",
      "  %3486 = Shape(%3482)\n",
      "  %3487 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3488 = Gather[axis = 0](%3486, %3487)\n",
      "  %3489 = Shape(%3482)\n",
      "  %3490 = Constant[value = <Tensor>]()\n",
      "  %3491 = Constant[value = <Tensor>]()\n",
      "  %3492 = Constant[value = <Tensor>]()\n",
      "  %3493 = Slice(%3489, %3491, %3492, %3490)\n",
      "  %3494 = Constant[value = <Tensor>]()\n",
      "  %3495 = Squeeze(%3493, %3494)\n",
      "  %3496 = Constant[value = <Tensor>]()\n",
      "  %3497 = Unsqueeze(%186, %3496)\n",
      "  %3498 = Constant[value = <Tensor>]()\n",
      "  %3499 = Unsqueeze(%3495, %3498)\n",
      "  %3500 = Concat[axis = 0](%3497, %3499)\n",
      "  %3501 = Reshape[allowzero = 0](%3482, %3500)\n",
      "  %3502 = Gemm[alpha = 1, beta = 1](%3501, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.weight, %decoder_no_past.decoder.transformer.h.11.mlp.c_proj.bias)\n",
      "  %3503 = Constant[value = <Tensor>]()\n",
      "  %3504 = Unsqueeze(%3485, %3503)\n",
      "  %3505 = Constant[value = <Tensor>]()\n",
      "  %3506 = Unsqueeze(%3488, %3505)\n",
      "  %3507 = Constant[value = <Tensor>]()\n",
      "  %3508 = Unsqueeze(%183, %3507)\n",
      "  %3509 = Concat[axis = 0](%3504, %3506, %3508)\n",
      "  %3510 = Reshape[allowzero = 0](%3502, %3509)\n",
      "  %3511 = Add(%3430, %3510)\n",
      "  %3512 = ReduceMean[axes = [-1]](%3511)\n",
      "  %3513 = Sub(%3511, %3512)\n",
      "  %3514 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3515 = Pow(%3513, %3514)\n",
      "  %3516 = ReduceMean[axes = [-1]](%3515)\n",
      "  %3517 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3518 = Add(%3516, %3517)\n",
      "  %3519 = Sqrt(%3518)\n",
      "  %3520 = Div(%3513, %3519)\n",
      "  %3521 = Mul(%3520, %decoder_no_past.decoder.transformer.ln_f.weight)\n",
      "  %3522 = Add(%3521, %decoder_no_past.decoder.transformer.ln_f.bias)\n",
      "  %3523 = Constant[value = <Tensor>]()\n",
      "  %3524 = Unsqueeze(%340, %3523)\n",
      "  %3525 = Constant[value = <Tensor>]()\n",
      "  %3526 = Unsqueeze(%343, %3525)\n",
      "  %3527 = Constant[value = <Tensor>]()\n",
      "  %3528 = Unsqueeze(%391, %3527)\n",
      "  %3529 = Concat[axis = 0](%3524, %3526, %3528)\n",
      "  %3530 = Reshape[allowzero = 0](%3522, %3529)\n",
      "  %3531 = MatMul(%3530, %5040)\n",
      "  %3532 = Gather[axis = 1](%3531, %186)\n",
      "  %3533 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3534 = Sub(%max_length, %3533)\n",
      "  %3535 = Equal(%cur_len.13, %3534)\n",
      "  %3536 = Cast[to = 9](%3535)\n",
      "  %3537 = If[else_branch = <graph torch-jit-export3>, then_branch = <graph torch-jit-export2>](%3536)\n",
      "  %3588 = LogSoftmax[axis = -1](%3537)\n",
      "  %3589 = Shape(%input_ids.25)\n",
      "  %3590 = Constant[value = <Tensor>]()\n",
      "  %3591 = Constant[value = <Tensor>]()\n",
      "  %3592 = Constant[value = <Tensor>]()\n",
      "  %3593 = Slice(%3589, %3591, %3592, %3590)\n",
      "  %3594 = Constant[value = <Tensor>]()\n",
      "  %3595 = Squeeze(%3593, %3594)\n",
      "  %3596 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3597 = Less(%3595, %3596)\n",
      "  %3598 = Cast[to = 9](%3597)\n",
      "  %3599 = If[else_branch = <graph torch-jit-export5>, then_branch = <graph torch-jit-export4>](%3598)\n",
      "  %3645 = Constant[value = <Tensor>]()\n",
      "  %3646 = Unsqueeze(%beam_scores.17, %3645)\n",
      "  %3647 = Shape(%3599)\n",
      "  %3648 = Expand(%3646, %3647)\n",
      "  %3649 = Add(%3599, %3648)\n",
      "  %3650 = Div(%3649, %192)\n",
      "  %3651 = Shape(%3650)\n",
      "  %3652 = Constant[value = <Tensor>]()\n",
      "  %3653 = Gather(%3651, %3652)\n",
      "  %3654, %3655 = TopK[axis = -1, largest = 1](%3650, %3653)\n",
      "  %3656 = Softmax[axis = -1](%3654)\n",
      "  %3657 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3658 = CumSum(%3656, %3657)\n",
      "  %3659 = Greater(%3658, %193)\n",
      "  %3660 = Constant[value = <Tensor>]()\n",
      "  %3661 = Constant[value = <Tensor>]()\n",
      "  %3662 = Constant[value = <Tensor>]()\n",
      "  %3663 = Constant[value = <Tensor>]()\n",
      "  %3664 = Slice(%3659, %3661, %3662, %3660, %3663)\n",
      "  %3665 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3666 = Shape(%3664)\n",
      "  %3667 = Expand(%3665, %3666)\n",
      "  %3668 = Shape(%3659)\n",
      "  %3669 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3670 = Gather[axis = 0](%3668, %3669)\n",
      "  %3671 = Cast[to = 7](%3670)\n",
      "  %3672 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3673 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3674 = Range(%3672, %3671, %3673)\n",
      "  %3675 = Shape(%3659)\n",
      "  %3676 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3677 = Gather[axis = 0](%3675, %3676)\n",
      "  %3678 = Cast[to = 7](%3677)\n",
      "  %3679 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3680 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3681 = Range(%3679, %3678, %3680)\n",
      "  %3682 = Constant[value = <Tensor>]()\n",
      "  %3683 = Constant[value = <Tensor>]()\n",
      "  %3684 = Constant[value = <Tensor>]()\n",
      "  %3685 = Constant[value = <Tensor>]()\n",
      "  %3686 = Slice(%3681, %3683, %3684, %3682, %3685)\n",
      "  %3687 = Constant[value = <Tensor>]()\n",
      "  %3688 = Reshape[allowzero = 0](%3674, %3687)\n",
      "  %3689 = Add(%3688, %3686)\n",
      "  %3690 = Shape(%3689)\n",
      "  %3691 = Shape(%3690)\n",
      "  %3692 = ConstantOfShape[value = <Tensor>](%3691)\n",
      "  %3693 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3694 = Mul(%3692, %3693)\n",
      "  %3695 = Equal(%3690, %3694)\n",
      "  %3696 = Where(%3695, %3692, %3690)\n",
      "  %3697 = Expand(%3688, %3696)\n",
      "  %3698 = Constant[value = <Tensor>]()\n",
      "  %3699 = Unsqueeze(%3697, %3698)\n",
      "  %3700 = Shape(%3690)\n",
      "  %3701 = ConstantOfShape[value = <Tensor>](%3700)\n",
      "  %3702 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3703 = Mul(%3701, %3702)\n",
      "  %3704 = Equal(%3690, %3703)\n",
      "  %3705 = Where(%3704, %3701, %3690)\n",
      "  %3706 = Expand(%3686, %3705)\n",
      "  %3707 = Constant[value = <Tensor>]()\n",
      "  %3708 = Unsqueeze(%3706, %3707)\n",
      "  %3709 = Concat[axis = -1](%3699, %3708)\n",
      "  %3710 = Shape(%3659)\n",
      "  %3711 = Constant[value = <Tensor>]()\n",
      "  %3712 = Constant[value = <Tensor>]()\n",
      "  %3713 = Constant[value = <Tensor>]()\n",
      "  %3714 = Slice(%3710, %3712, %3713, %3711)\n",
      "  %3715 = Concat[axis = 0](%3690, %3714)\n",
      "  %3716 = Reshape[allowzero = 0](%3667, %3715)\n",
      "  %3717 = ScatterND(%3659, %3709, %3716)\n",
      "  %3718 = Constant[value = <Tensor>]()\n",
      "  %3719 = Constant[value = <Tensor>]()\n",
      "  %3720 = Constant[value = <Tensor>]()\n",
      "  %3721 = Constant[value = <Tensor>]()\n",
      "  %3722 = Slice(%3717, %3719, %3720, %3718, %3721)\n",
      "  %3723 = Constant[value = <Tensor>]()\n",
      "  %3724 = Constant[value = <Tensor>]()\n",
      "  %3725 = Constant[value = <Tensor>]()\n",
      "  %3726 = Constant[value = <Tensor>]()\n",
      "  %3727 = Slice(%3717, %3724, %3725, %3723, %3726)\n",
      "  %3728 = Shape(%3727)\n",
      "  %3729 = Expand(%3722, %3728)\n",
      "  %3730 = Shape(%3717)\n",
      "  %3731 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3732 = Gather[axis = 0](%3730, %3731)\n",
      "  %3733 = Cast[to = 7](%3732)\n",
      "  %3734 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3735 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3736 = Range(%3734, %3733, %3735)\n",
      "  %3737 = Shape(%3717)\n",
      "  %3738 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3739 = Gather[axis = 0](%3737, %3738)\n",
      "  %3740 = Cast[to = 7](%3739)\n",
      "  %3741 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3742 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3743 = Range(%3741, %3740, %3742)\n",
      "  %3744 = Constant[value = <Tensor>]()\n",
      "  %3745 = Constant[value = <Tensor>]()\n",
      "  %3746 = Constant[value = <Tensor>]()\n",
      "  %3747 = Constant[value = <Tensor>]()\n",
      "  %3748 = Slice(%3743, %3745, %3746, %3744, %3747)\n",
      "  %3749 = Constant[value = <Tensor>]()\n",
      "  %3750 = Reshape[allowzero = 0](%3736, %3749)\n",
      "  %3751 = Add(%3750, %3748)\n",
      "  %3752 = Shape(%3751)\n",
      "  %3753 = Shape(%3752)\n",
      "  %3754 = ConstantOfShape[value = <Tensor>](%3753)\n",
      "  %3755 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3756 = Mul(%3754, %3755)\n",
      "  %3757 = Equal(%3752, %3756)\n",
      "  %3758 = Where(%3757, %3754, %3752)\n",
      "  %3759 = Expand(%3750, %3758)\n",
      "  %3760 = Constant[value = <Tensor>]()\n",
      "  %3761 = Unsqueeze(%3759, %3760)\n",
      "  %3762 = Shape(%3752)\n",
      "  %3763 = ConstantOfShape[value = <Tensor>](%3762)\n",
      "  %3764 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3765 = Mul(%3763, %3764)\n",
      "  %3766 = Equal(%3752, %3765)\n",
      "  %3767 = Where(%3766, %3763, %3752)\n",
      "  %3768 = Expand(%3748, %3767)\n",
      "  %3769 = Constant[value = <Tensor>]()\n",
      "  %3770 = Unsqueeze(%3768, %3769)\n",
      "  %3771 = Concat[axis = -1](%3761, %3770)\n",
      "  %3772 = Shape(%3717)\n",
      "  %3773 = Constant[value = <Tensor>]()\n",
      "  %3774 = Constant[value = <Tensor>]()\n",
      "  %3775 = Constant[value = <Tensor>]()\n",
      "  %3776 = Slice(%3772, %3774, %3775, %3773)\n",
      "  %3777 = Concat[axis = 0](%3752, %3776)\n",
      "  %3778 = Reshape[allowzero = 0](%3729, %3777)\n",
      "  %3779 = ScatterND(%3717, %3771, %3778)\n",
      "  %3780 = Gather[axis = 1](%3779, %191)\n",
      "  %3781 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3782 = Shape(%3780)\n",
      "  %3783 = Expand(%3781, %3782)\n",
      "  %3784 = Shape(%3779)\n",
      "  %3785 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3786 = Gather[axis = 0](%3784, %3785)\n",
      "  %3787 = Cast[to = 7](%3786)\n",
      "  %3788 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3789 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3790 = Range(%3788, %3787, %3789)\n",
      "  %3791 = Constant[value = <Tensor>]()\n",
      "  %3792 = Constant[value = <Tensor>]()\n",
      "  %3793 = Reshape[allowzero = 0](%3790, %3792)\n",
      "  %3794 = Constant[value = <Tensor>]()\n",
      "  %3795 = Add(%3793, %3794)\n",
      "  %3796 = Shape(%3795)\n",
      "  %3797 = Shape(%3796)\n",
      "  %3798 = ConstantOfShape[value = <Tensor>](%3797)\n",
      "  %3799 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3800 = Mul(%3798, %3799)\n",
      "  %3801 = Equal(%3796, %3800)\n",
      "  %3802 = Where(%3801, %3798, %3796)\n",
      "  %3803 = Expand(%3793, %3802)\n",
      "  %3804 = Constant[value = <Tensor>]()\n",
      "  %3805 = Unsqueeze(%3803, %3804)\n",
      "  %3806 = Shape(%3796)\n",
      "  %3807 = ConstantOfShape[value = <Tensor>](%3806)\n",
      "  %3808 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3809 = Mul(%3807, %3808)\n",
      "  %3810 = Equal(%3796, %3809)\n",
      "  %3811 = Where(%3810, %3807, %3796)\n",
      "  %3812 = Expand(%3791, %3811)\n",
      "  %3813 = Constant[value = <Tensor>]()\n",
      "  %3814 = Unsqueeze(%3812, %3813)\n",
      "  %3815 = Concat[axis = -1](%3805, %3814)\n",
      "  %3816 = Shape(%3779)\n",
      "  %3817 = Constant[value = <Tensor>]()\n",
      "  %3818 = Constant[value = <Tensor>]()\n",
      "  %3819 = Constant[value = <Tensor>]()\n",
      "  %3820 = Slice(%3816, %3818, %3819, %3817)\n",
      "  %3821 = Concat[axis = 0](%3796, %3820)\n",
      "  %3822 = Reshape[allowzero = 0](%3783, %3821)\n",
      "  %3823 = ScatterND(%3779, %3815, %3822)\n",
      "  %3824 = ScatterElements[axis = 1](%3823, %3655, %3823)\n",
      "  %3825 = Cast[to = 9](%3824)\n",
      "  %3826 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3827 = Where(%3825, %3826, %3650)\n",
      "  %3828 = Shape(%3827)\n",
      "  %3829 = Constant[value = <Tensor>]()\n",
      "  %3830 = Constant[value = <Tensor>]()\n",
      "  %3831 = Constant[value = <Tensor>]()\n",
      "  %3832 = Slice(%3828, %3830, %3831, %3829)\n",
      "  %3833 = Constant[value = <Tensor>]()\n",
      "  %3834 = Squeeze(%3832, %3833)\n",
      "  %3835 = Mul(%num_beams, %3834)\n",
      "  %3836 = Constant[value = <Tensor>]()\n",
      "  %3837 = Unsqueeze(%196, %3836)\n",
      "  %3838 = Constant[value = <Tensor>]()\n",
      "  %3839 = Unsqueeze(%3835, %3838)\n",
      "  %3840 = Concat[axis = 0](%3837, %3839)\n",
      "  %3841 = Reshape[allowzero = 0](%3827, %3840)\n",
      "  %3842 = Softmax[axis = -1](%3841)\n",
      "  %3843 = Log(%3842)\n",
      "  %3844 = Multinomial[dtype = 7, sample_size = 8](%3843)\n",
      "  %3845 = GatherElements[axis = -1](%3841, %3844)\n",
      "  %3846 = Shape(%3845)\n",
      "  %3847 = Constant[value = <Tensor>]()\n",
      "  %3848 = Gather(%3846, %3847)\n",
      "  %3849, %3850 = TopK[axis = 1, largest = 1](%3845, %3848)\n",
      "  %3851 = GatherElements[axis = -1](%3844, %3850)\n",
      "  %3852 = Div(%3851, %3834)\n",
      "  %3853 = Cast[to = 7](%3852)\n",
      "  %3854 = Cast[to = 7](%3853)\n",
      "  %3855 = Div(%3851, %3834)\n",
      "  %3856 = Mul(%3855, %3834)\n",
      "  %3857 = Sub(%3851, %3856)\n",
      "  %3858 = Constant[value = <Tensor>]()\n",
      "  %3859 = Shape(%336)\n",
      "  %3860 = Gather[axis = 0](%3859, %3858)\n",
      "  %3861 = Constant[value = <Tensor>]()\n",
      "  %3862 = Squeeze(%3860, %3861)\n",
      "  %3863 = Constant[value = <Tensor>]()\n",
      "  %3864 = Unsqueeze(%3862, %3863)\n",
      "  %3865 = Constant[value = <Tensor>]()\n",
      "  %3866 = Unsqueeze(%200, %3865)\n",
      "  %3867 = Concat[axis = 0](%3864, %3866)\n",
      "  %3868 = ConstantOfShape[value = <Tensor>](%3867)\n",
      "  %3869 = Constant[value = <Tensor>]()\n",
      "  %3870 = Unsqueeze(%3862, %3869)\n",
      "  %3871 = Constant[value = <Tensor>]()\n",
      "  %3872 = Unsqueeze(%200, %3871)\n",
      "  %3873 = Concat[axis = 0](%3870, %3872)\n",
      "  %3874 = ConstantOfShape[value = <Tensor>](%3873)\n",
      "  %3875 = Constant[value = <Tensor>]()\n",
      "  %3876 = Unsqueeze(%3862, %3875)\n",
      "  %3877 = Constant[value = <Tensor>]()\n",
      "  %3878 = Unsqueeze(%200, %3877)\n",
      "  %3879 = Concat[axis = 0](%3876, %3878)\n",
      "  %3880 = ConstantOfShape[value = <Tensor>](%3879)\n",
      "  %3881 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3882 = Greater(%3862, %3881)\n",
      "  %3883, %3884, %3885, %3886, %3887, %3888, %3889, %3890, %3891, %3892, %3893 = Loop[body = <graph torch-jit-export6>](%184, %3882, %190, %191, %191, %3868, %3874, %3880, %333, %334, %335, %336, %337)\n",
      "  %4550 = Constant[value = <Tensor>]()\n",
      "  %4551 = Reshape[allowzero = 0](%3886, %4550)\n",
      "  %4552 = Constant[value = <Tensor>]()\n",
      "  %4553 = Reshape[allowzero = 0](%3887, %4552)\n",
      "  %4554 = Constant[value = <Tensor>]()\n",
      "  %4555 = Reshape[allowzero = 0](%3888, %4554)\n",
      "  %4556 = Gather[axis = 0](%input_ids.25, %4555)\n",
      "  %4557 = Constant[value = <Tensor>]()\n",
      "  %4558 = Unsqueeze(%4553, %4557)\n",
      "  %4559 = Concat[axis = -1](%4556, %4558)\n",
      "  %4560 = Gather[axis = 0](%attention_mask.13, %4555)\n",
      "  %4561 = Shape(%attention_mask.13)\n",
      "  %4562 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4563 = Gather[axis = 0](%4561, %4562)\n",
      "  %4564 = Constant[value = <Tensor>]()\n",
      "  %4565 = Unsqueeze(%4563, %4564)\n",
      "  %4566 = Concat[axis = 0](%4565)\n",
      "  %4567 = ConstantOfShape[value = <Tensor>](%4566)\n",
      "  %4568 = Constant[value = <Tensor>]()\n",
      "  %4569 = Unsqueeze(%4567, %4568)\n",
      "  %4570 = Concat[axis = -1](%4560, %4569)\n",
      "  %4571 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4572 = Add(%cur_len.13, %4571)\n",
      "  %4573 = Not(%3893)\n",
      "  %4574 = Cast[to = 7](%4573)\n",
      "  %4575 = ReduceSum[keepdims = 0, noop_with_empty_axes = 0](%4574)\n",
      "  %4576 = Constant[value = <Tensor>]()\n",
      "  %4577 = Greater(%4575, %4576)\n",
      "  %4578 = Not(%4577)\n",
      "  %4579 = Cast[to = 9](%4578)\n",
      "  %4580 = If[else_branch = <graph torch-jit-export33>, then_branch = <graph torch-jit-export32>](%4579)\n",
      "  return %4580, %4559, %4551, %4570, %4572, %3889, %3890, %3891, %3892, %3893\n",
      "}\n",
      "\n",
      "graph torch-jit-export2 {\n",
      "  %3538 = Shape(%3532)\n",
      "  %3539 = ConstantOfShape[value = <Tensor>](%3538)\n",
      "  %3540 = Gather[axis = 1](%3539, %190)\n",
      "  %3541 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3542 = Shape(%3540)\n",
      "  %3543 = Expand(%3541, %3542)\n",
      "  %3544 = Shape(%3539)\n",
      "  %3545 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3546 = Gather[axis = 0](%3544, %3545)\n",
      "  %3547 = Cast[to = 7](%3546)\n",
      "  %3548 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3549 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3550 = Range(%3548, %3547, %3549)\n",
      "  %3551 = Constant[value = <Tensor>]()\n",
      "  %3552 = Constant[value = <Tensor>]()\n",
      "  %3553 = Reshape[allowzero = 0](%3550, %3552)\n",
      "  %3554 = Constant[value = <Tensor>]()\n",
      "  %3555 = Add(%3553, %3554)\n",
      "  %3556 = Shape(%3555)\n",
      "  %3557 = Shape(%3556)\n",
      "  %3558 = ConstantOfShape[value = <Tensor>](%3557)\n",
      "  %3559 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3560 = Mul(%3558, %3559)\n",
      "  %3561 = Equal(%3556, %3560)\n",
      "  %3562 = Where(%3561, %3558, %3556)\n",
      "  %3563 = Expand(%3553, %3562)\n",
      "  %3564 = Constant[value = <Tensor>]()\n",
      "  %3565 = Unsqueeze(%3563, %3564)\n",
      "  %3566 = Shape(%3556)\n",
      "  %3567 = ConstantOfShape[value = <Tensor>](%3566)\n",
      "  %3568 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3569 = Mul(%3567, %3568)\n",
      "  %3570 = Equal(%3556, %3569)\n",
      "  %3571 = Where(%3570, %3567, %3556)\n",
      "  %3572 = Expand(%3551, %3571)\n",
      "  %3573 = Constant[value = <Tensor>]()\n",
      "  %3574 = Unsqueeze(%3572, %3573)\n",
      "  %3575 = Concat[axis = -1](%3565, %3574)\n",
      "  %3576 = Shape(%3539)\n",
      "  %3577 = Constant[value = <Tensor>]()\n",
      "  %3578 = Constant[value = <Tensor>]()\n",
      "  %3579 = Constant[value = <Tensor>]()\n",
      "  %3580 = Slice(%3576, %3578, %3579, %3577)\n",
      "  %3581 = Concat[axis = 0](%3556, %3580)\n",
      "  %3582 = Reshape[allowzero = 0](%3543, %3581)\n",
      "  %3583 = ScatterND(%3539, %3575, %3582)\n",
      "  %3584 = Cast[to = 9](%3583)\n",
      "  %3585 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3586 = Where(%3584, %3585, %3532)\n",
      "  return %3586\n",
      "}\n",
      "\n",
      "graph torch-jit-export3 {\n",
      "  %3587 = Identity(%3532)\n",
      "  return %3587\n",
      "}\n",
      "\n",
      "graph torch-jit-export4 {\n",
      "  %3600 = Gather[axis = 1](%3588, %190)\n",
      "  %3601 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3602 = Shape(%3600)\n",
      "  %3603 = Expand(%3601, %3602)\n",
      "  %3604 = Shape(%3588)\n",
      "  %3605 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3606 = Gather[axis = 0](%3604, %3605)\n",
      "  %3607 = Cast[to = 7](%3606)\n",
      "  %3608 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3609 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3610 = Range(%3608, %3607, %3609)\n",
      "  %3611 = Constant[value = <Tensor>]()\n",
      "  %3612 = Constant[value = <Tensor>]()\n",
      "  %3613 = Reshape[allowzero = 0](%3610, %3612)\n",
      "  %3614 = Constant[value = <Tensor>]()\n",
      "  %3615 = Add(%3613, %3614)\n",
      "  %3616 = Shape(%3615)\n",
      "  %3617 = Shape(%3616)\n",
      "  %3618 = ConstantOfShape[value = <Tensor>](%3617)\n",
      "  %3619 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3620 = Mul(%3618, %3619)\n",
      "  %3621 = Equal(%3616, %3620)\n",
      "  %3622 = Where(%3621, %3618, %3616)\n",
      "  %3623 = Expand(%3613, %3622)\n",
      "  %3624 = Constant[value = <Tensor>]()\n",
      "  %3625 = Unsqueeze(%3623, %3624)\n",
      "  %3626 = Shape(%3616)\n",
      "  %3627 = ConstantOfShape[value = <Tensor>](%3626)\n",
      "  %3628 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3629 = Mul(%3627, %3628)\n",
      "  %3630 = Equal(%3616, %3629)\n",
      "  %3631 = Where(%3630, %3627, %3616)\n",
      "  %3632 = Expand(%3611, %3631)\n",
      "  %3633 = Constant[value = <Tensor>]()\n",
      "  %3634 = Unsqueeze(%3632, %3633)\n",
      "  %3635 = Concat[axis = -1](%3625, %3634)\n",
      "  %3636 = Shape(%3588)\n",
      "  %3637 = Constant[value = <Tensor>]()\n",
      "  %3638 = Constant[value = <Tensor>]()\n",
      "  %3639 = Constant[value = <Tensor>]()\n",
      "  %3640 = Slice(%3636, %3638, %3639, %3637)\n",
      "  %3641 = Concat[axis = 0](%3616, %3640)\n",
      "  %3642 = Reshape[allowzero = 0](%3603, %3641)\n",
      "  %3643 = ScatterND(%3588, %3635, %3642)\n",
      "  return %3643\n",
      "}\n",
      "\n",
      "graph torch-jit-export5 {\n",
      "  %3644 = Identity(%3588)\n",
      "  return %3644\n",
      "}\n",
      "\n",
      "graph torch-jit-export6 (\n",
      "  %3894[INT64, scalar]\n",
      "  %cond.3[BOOL, scalar]\n",
      "  %eos_token_id.74[INT64, scalar]\n",
      "  %pad_token_id.34[INT64, scalar]\n",
      "  %3898[INT64, scalar]\n",
      "  %3899[FLOAT, 3899_dim_0x3899_dim_1]\n",
      "  %3900[INT64, 3900_dim_0x3900_dim_1]\n",
      "  %3901[INT64, 3901_dim_0x3901_dim_1]\n",
      "  %3902[Unknown type sequence_type]\n",
      "  %3903[Unknown type sequence_type]\n",
      "  %3904[FLOAT, 335_dim_0]\n",
      "  %3905[INT64, 336_dim_0]\n",
      "  %3906[BOOL, 337_dim_0]\n",
      ") {\n",
      "  %3907 = Gather[axis = 0](%3906, %3898)\n",
      "  %3908 = Cast[to = 9](%3907)\n",
      "  %3909, %3910, %3911, %3912, %3913, %3914, %3915, %3916, %3917, %3918 = If[else_branch = <graph torch-jit-export8>, then_branch = <graph torch-jit-export7>](%3908)\n",
      "  %4543 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4544 = Add(%3898, %4543)\n",
      "  %4545 = Less(%4544, %3862)\n",
      "  %4546 = Cast[to = 9](%4545)\n",
      "  %4547 = Cast[to = 9](%187)\n",
      "  %4548 = And(%4546, %4547)\n",
      "  %4549 = Cast[to = 9](%4548)\n",
      "  return %4549, %3909, %3910, %4544, %3911, %3912, %3913, %3914, %3915, %3916, %3917, %3918\n",
      "}\n",
      "\n",
      "graph torch-jit-export7 {\n",
      "  %3919 = Gather[axis = 0](%3899, %3898)\n",
      "  %3920 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3921 = Shape(%3919)\n",
      "  %3922 = Expand(%3920, %3921)\n",
      "  %3923 = Constant[value = <Tensor>]()\n",
      "  %3924 = Unsqueeze(%3898, %3923)\n",
      "  %3925 = Shape(%3899)\n",
      "  %3926 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3927 = Gather[axis = 0](%3925, %3926)\n",
      "  %3928 = Cast[to = 7](%3927)\n",
      "  %3929 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3930 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3931 = Range(%3929, %3928, %3930)\n",
      "  %3932 = Constant[value = <Tensor>]()\n",
      "  %3933 = Reshape[allowzero = 0](%3924, %3932)\n",
      "  %3934 = Add(%3933, %3931)\n",
      "  %3935 = Shape(%3934)\n",
      "  %3936 = Shape(%3935)\n",
      "  %3937 = ConstantOfShape[value = <Tensor>](%3936)\n",
      "  %3938 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3939 = Mul(%3937, %3938)\n",
      "  %3940 = Equal(%3935, %3939)\n",
      "  %3941 = Where(%3940, %3937, %3935)\n",
      "  %3942 = Expand(%3933, %3941)\n",
      "  %3943 = Constant[value = <Tensor>]()\n",
      "  %3944 = Unsqueeze(%3942, %3943)\n",
      "  %3945 = Shape(%3935)\n",
      "  %3946 = ConstantOfShape[value = <Tensor>](%3945)\n",
      "  %3947 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3948 = Mul(%3946, %3947)\n",
      "  %3949 = Equal(%3935, %3948)\n",
      "  %3950 = Where(%3949, %3946, %3935)\n",
      "  %3951 = Expand(%3931, %3950)\n",
      "  %3952 = Constant[value = <Tensor>]()\n",
      "  %3953 = Unsqueeze(%3951, %3952)\n",
      "  %3954 = Concat[axis = -1](%3944, %3953)\n",
      "  %3955 = Shape(%3899)\n",
      "  %3956 = Constant[value = <Tensor>]()\n",
      "  %3957 = Constant[value = <Tensor>]()\n",
      "  %3958 = Constant[value = <Tensor>]()\n",
      "  %3959 = Slice(%3955, %3957, %3958, %3956)\n",
      "  %3960 = Concat[axis = 0](%3935, %3959)\n",
      "  %3961 = Reshape[allowzero = 0](%3922, %3960)\n",
      "  %3962 = ScatterND(%3899, %3954, %3961)\n",
      "  %3963 = Gather[axis = 0](%3900, %3898)\n",
      "  %3964 = Cast[to = 7](%pad_token_id.34)\n",
      "  %3965 = Shape(%3963)\n",
      "  %3966 = Expand(%3964, %3965)\n",
      "  %3967 = Constant[value = <Tensor>]()\n",
      "  %3968 = Unsqueeze(%3898, %3967)\n",
      "  %3969 = Shape(%3900)\n",
      "  %3970 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3971 = Gather[axis = 0](%3969, %3970)\n",
      "  %3972 = Cast[to = 7](%3971)\n",
      "  %3973 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3974 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3975 = Range(%3973, %3972, %3974)\n",
      "  %3976 = Constant[value = <Tensor>]()\n",
      "  %3977 = Reshape[allowzero = 0](%3968, %3976)\n",
      "  %3978 = Add(%3977, %3975)\n",
      "  %3979 = Shape(%3978)\n",
      "  %3980 = Shape(%3979)\n",
      "  %3981 = ConstantOfShape[value = <Tensor>](%3980)\n",
      "  %3982 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3983 = Mul(%3981, %3982)\n",
      "  %3984 = Equal(%3979, %3983)\n",
      "  %3985 = Where(%3984, %3981, %3979)\n",
      "  %3986 = Expand(%3977, %3985)\n",
      "  %3987 = Constant[value = <Tensor>]()\n",
      "  %3988 = Unsqueeze(%3986, %3987)\n",
      "  %3989 = Shape(%3979)\n",
      "  %3990 = ConstantOfShape[value = <Tensor>](%3989)\n",
      "  %3991 = Constant[value = <Scalar Tensor []>]()\n",
      "  %3992 = Mul(%3990, %3991)\n",
      "  %3993 = Equal(%3979, %3992)\n",
      "  %3994 = Where(%3993, %3990, %3979)\n",
      "  %3995 = Expand(%3975, %3994)\n",
      "  %3996 = Constant[value = <Tensor>]()\n",
      "  %3997 = Unsqueeze(%3995, %3996)\n",
      "  %3998 = Concat[axis = -1](%3988, %3997)\n",
      "  %3999 = Shape(%3900)\n",
      "  %4000 = Constant[value = <Tensor>]()\n",
      "  %4001 = Constant[value = <Tensor>]()\n",
      "  %4002 = Constant[value = <Tensor>]()\n",
      "  %4003 = Slice(%3999, %4001, %4002, %4000)\n",
      "  %4004 = Concat[axis = 0](%3979, %4003)\n",
      "  %4005 = Reshape[allowzero = 0](%3966, %4004)\n",
      "  %4006 = ScatterND(%3900, %3998, %4005)\n",
      "  %4007 = Gather[axis = 0](%3901, %3898)\n",
      "  %4008 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4009 = Shape(%4007)\n",
      "  %4010 = Expand(%4008, %4009)\n",
      "  %4011 = Constant[value = <Tensor>]()\n",
      "  %4012 = Unsqueeze(%3898, %4011)\n",
      "  %4013 = Shape(%3901)\n",
      "  %4014 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4015 = Gather[axis = 0](%4013, %4014)\n",
      "  %4016 = Cast[to = 7](%4015)\n",
      "  %4017 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4018 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4019 = Range(%4017, %4016, %4018)\n",
      "  %4020 = Constant[value = <Tensor>]()\n",
      "  %4021 = Reshape[allowzero = 0](%4012, %4020)\n",
      "  %4022 = Add(%4021, %4019)\n",
      "  %4023 = Shape(%4022)\n",
      "  %4024 = Shape(%4023)\n",
      "  %4025 = ConstantOfShape[value = <Tensor>](%4024)\n",
      "  %4026 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4027 = Mul(%4025, %4026)\n",
      "  %4028 = Equal(%4023, %4027)\n",
      "  %4029 = Where(%4028, %4025, %4023)\n",
      "  %4030 = Expand(%4021, %4029)\n",
      "  %4031 = Constant[value = <Tensor>]()\n",
      "  %4032 = Unsqueeze(%4030, %4031)\n",
      "  %4033 = Shape(%4023)\n",
      "  %4034 = ConstantOfShape[value = <Tensor>](%4033)\n",
      "  %4035 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4036 = Mul(%4034, %4035)\n",
      "  %4037 = Equal(%4023, %4036)\n",
      "  %4038 = Where(%4037, %4034, %4023)\n",
      "  %4039 = Expand(%4019, %4038)\n",
      "  %4040 = Constant[value = <Tensor>]()\n",
      "  %4041 = Unsqueeze(%4039, %4040)\n",
      "  %4042 = Concat[axis = -1](%4032, %4041)\n",
      "  %4043 = Shape(%3901)\n",
      "  %4044 = Constant[value = <Tensor>]()\n",
      "  %4045 = Constant[value = <Tensor>]()\n",
      "  %4046 = Constant[value = <Tensor>]()\n",
      "  %4047 = Slice(%4043, %4045, %4046, %4044)\n",
      "  %4048 = Concat[axis = 0](%4023, %4047)\n",
      "  %4049 = Reshape[allowzero = 0](%4010, %4048)\n",
      "  %4050 = ScatterND(%3901, %4042, %4049)\n",
      "  %eos_token_id.71 = Identity(%eos_token_id.74)\n",
      "  %pad_token_id.31 = Identity(%pad_token_id.34)\n",
      "  %4053 = Identity(%3902)\n",
      "  %4054 = Identity(%3903)\n",
      "  %4055 = Identity(%3904)\n",
      "  %4056 = Identity(%3905)\n",
      "  %4057 = Identity(%3906)\n",
      "  return %eos_token_id.71, %pad_token_id.31, %3962, %4006, %4050, %4053, %4054, %4055, %4056, %4057\n",
      "}\n",
      "\n",
      "graph torch-jit-export8 {\n",
      "  %4058 = Gather[axis = 0](%3857, %3898)\n",
      "  %4059 = Gather[axis = 0](%3849, %3898)\n",
      "  %4060 = Gather[axis = 0](%3854, %3898)\n",
      "  %4061 = Constant[value = <Tensor>]()\n",
      "  %4062 = Shape(%4058)\n",
      "  %4063 = Gather[axis = 0](%4062, %4061)\n",
      "  %4064 = Constant[value = <Tensor>]()\n",
      "  %4065 = Squeeze(%4063, %4064)\n",
      "  %4066 = Constant[value = <Tensor>]()\n",
      "  %4067 = Shape(%4059)\n",
      "  %4068 = Gather[axis = 0](%4067, %4066)\n",
      "  %4069 = Constant[value = <Tensor>]()\n",
      "  %4070 = Squeeze(%4068, %4069)\n",
      "  %4071 = Constant[value = <Tensor>]()\n",
      "  %4072 = Shape(%4060)\n",
      "  %4073 = Gather[axis = 0](%4072, %4071)\n",
      "  %4074 = Constant[value = <Tensor>]()\n",
      "  %4075 = Squeeze(%4073, %4074)\n",
      "  %4076 = Constant[value = <Tensor>]()\n",
      "  %4077 = Unsqueeze(%184, %4076)\n",
      "  %4078 = Constant[value = <Tensor>]()\n",
      "  %4079 = Unsqueeze(%4065, %4078)\n",
      "  %4080 = Constant[value = <Tensor>]()\n",
      "  %4081 = Unsqueeze(%4070, %4080)\n",
      "  %4082 = Constant[value = <Tensor>]()\n",
      "  %4083 = Unsqueeze(%4075, %4082)\n",
      "  %4084 = Concat[axis = 0](%4077, %4079, %4081, %4083)\n",
      "  %4085 = ReduceMin[keepdims = 0](%4084)\n",
      "  %4086 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4087 = Greater(%4085, %4086)\n",
      "  %4088, %4089, %4090, %4091, %4092, %4093, %4094, %4095, %4096, %4097 = Loop[body = <graph torch-jit-export9>](%184, %4087, %191, %eos_token_id.74, %191, %3902, %3903, %3904, %3905, %3899, %3900, %3901)\n",
      "  %4508 = Gather[axis = 0](%3906, %3898)\n",
      "  %4509 = Cast[to = 9](%4508)\n",
      "  %4510 = If[else_branch = <graph torch-jit-export29>, then_branch = <graph torch-jit-export28>](%4509)\n",
      "  %4518 = Gather[axis = 0](%3906, %3898)\n",
      "  %4519 = Cast[to = 9](%4510)\n",
      "  %4520 = Shape(%4518)\n",
      "  %4521 = Expand(%4519, %4520)\n",
      "  %4522 = Constant[value = <Tensor>]()\n",
      "  %4523 = Unsqueeze(%3898, %4522)\n",
      "  %4524 = Shape(%4523)\n",
      "  %4525 = Constant[value = <Tensor>]()\n",
      "  %4526 = Unsqueeze(%4523, %4525)\n",
      "  %4527 = Shape(%3906)\n",
      "  %4528 = Constant[value = <Tensor>]()\n",
      "  %4529 = Constant[value = <Tensor>]()\n",
      "  %4530 = Constant[value = <Tensor>]()\n",
      "  %4531 = Slice(%4527, %4529, %4530, %4528)\n",
      "  %4532 = Concat[axis = 0](%4524, %4531)\n",
      "  %4533 = Shape(%4532)\n",
      "  %4534 = ConstantOfShape[value = <Tensor>](%4533)\n",
      "  %4535 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4536 = Mul(%4534, %4535)\n",
      "  %4537 = Equal(%4532, %4536)\n",
      "  %4538 = Where(%4537, %4534, %4532)\n",
      "  %4539 = Expand(%4521, %4538)\n",
      "  %4540 = Reshape[allowzero = 0](%4539, %4532)\n",
      "  %4541 = ScatterND(%3906, %4526, %4540)\n",
      "  %pad_token_id.32 = Identity(%pad_token_id.34)\n",
      "  return %4089, %pad_token_id.32, %4095, %4096, %4097, %4091, %4092, %4093, %4094, %4541\n",
      "}\n",
      "\n",
      "graph torch-jit-export9 (\n",
      "  %4098[INT64, scalar]\n",
      "  %cond.1[BOOL, scalar]\n",
      "  %beam_idx.36[INT64, scalar]\n",
      "  %eos_token_id.72[INT64, scalar]\n",
      "  %4102[INT64, scalar]\n",
      "  %4103[Unknown type sequence_type]\n",
      "  %4104[Unknown type sequence_type]\n",
      "  %4105[FLOAT, 335_dim_0]\n",
      "  %4106[INT64, 336_dim_0]\n",
      "  %4107[FLOAT, 3899_dim_0x3899_dim_1]\n",
      "  %4108[INT64, 3900_dim_0x3900_dim_1]\n",
      "  %4109[INT64, 3901_dim_0x3901_dim_1]\n",
      ") {\n",
      "  %4110 = Gather[axis = 0](%4058, %4102)\n",
      "  %4111 = Gather[axis = 0](%4059, %4102)\n",
      "  %4112 = Gather[axis = 0](%4060, %4102)\n",
      "  %4113 = Mul(%3898, %200)\n",
      "  %4114 = Add(%4112, %4113)\n",
      "  %4115 = Equal(%4110, %eos_token_id.72)\n",
      "  %4116 = Cast[to = 9](%4115)\n",
      "  %4117, %4118, %4119, %4120, %4121, %4122, %4123, %4124, %4125, %4126, %4127, %4128, %4129 = If[else_branch = <graph torch-jit-export21>, then_branch = <graph torch-jit-export10>](%4116)\n",
      "  %4462 = Cast[to = 9](%4117)\n",
      "  %4463, %4464, %4465, %4466, %4467, %4468, %4469 = If[else_branch = <graph torch-jit-export23>, then_branch = <graph torch-jit-export22>](%4462)\n",
      "  %4491 = Cast[to = 9](%4463)\n",
      "  %4492, %4493, %4494 = If[else_branch = <graph torch-jit-export27>, then_branch = <graph torch-jit-export26>](%4491)\n",
      "  %4501 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4502 = Add(%4102, %4501)\n",
      "  %4503 = Less(%4502, %4085)\n",
      "  %4504 = Cast[to = 9](%4503)\n",
      "  %4505 = Cast[to = 9](%4492)\n",
      "  %4506 = And(%4504, %4505)\n",
      "  %4507 = Cast[to = 9](%4506)\n",
      "  return %4507, %4493, %4494, %4502, %4123, %4124, %4125, %4126, %4127, %4128, %4129\n",
      "}\n",
      "\n",
      "graph torch-jit-export10 {\n",
      "  %4130 = GreaterOrEqual(%4102, %200)\n",
      "  %4131 = Cast[to = 9](%4130)\n",
      "  %4132, %4133, %4134, %4135, %4136, %4137, %4138, %4139, %4140 = If[else_branch = <graph torch-jit-export12>, then_branch = <graph torch-jit-export11>](%4131)\n",
      "  %4311 = Identity(%4107)\n",
      "  %4312 = Identity(%4108)\n",
      "  %4313 = Identity(%4109)\n",
      "  return %4130, %4132, %4133, %4134, %4135, %4136, %4137, %4138, %4139, %4140, %4311, %4312, %4313\n",
      "}\n",
      "\n",
      "graph torch-jit-export11 {\n",
      "  %4141 = Identity(%187)\n",
      "  %beam_idx.38 = Identity(%beam_idx.36)\n",
      "  %eos_token_id.67 = Identity(%eos_token_id.72)\n",
      "  %4144 = Identity(%4103)\n",
      "  %4145 = Identity(%4104)\n",
      "  %4146 = Identity(%4105)\n",
      "  %4147 = Identity(%4106)\n",
      "  %beam_idx.34 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4141, %beam_idx.38, %eos_token_id.67, %beam_idx.34, %beam_idx.34, %4144, %4145, %4146, %4147\n",
      "}\n",
      "\n",
      "graph torch-jit-export12 {\n",
      "  %4149 = Gather[axis = 0](%input_ids.25, %4114)\n",
      "  %4150 = Shape(%4149)\n",
      "  %4151 = Constant[value = <Tensor>]()\n",
      "  %4152 = Constant[value = <Tensor>]()\n",
      "  %4153 = Constant[value = <Tensor>]()\n",
      "  %4154 = Slice(%4150, %4152, %4153, %4151)\n",
      "  %4155 = Constant[value = <Tensor>]()\n",
      "  %4156 = Squeeze(%4154, %4155)\n",
      "  %4157 = Cast[to = 1](%4156)\n",
      "  %4158 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4159 = Pow(%4157, %4158)\n",
      "  %4160 = Div(%4111, %4159)\n",
      "  %4161 = Gather[axis = 0](%4106, %3898)\n",
      "  %4162 = Less(%4161, %num_beams)\n",
      "  %4163 = Cast[to = 9](%4162)\n",
      "  %4164 = If[else_branch = <graph torch-jit-export14>, then_branch = <graph torch-jit-export13>](%4163)\n",
      "  %4168 = Cast[to = 9](%4164)\n",
      "  %4169, %4170, %4171, %4172 = If[else_branch = <graph torch-jit-export20>, then_branch = <graph torch-jit-export15>](%4168)\n",
      "  %beam_idx.40 = Identity(%beam_idx.36)\n",
      "  %eos_token_id.68 = Identity(%eos_token_id.72)\n",
      "  %4309 = Constant[value = <Scalar Tensor []>]()\n",
      "  %beam_idx.33 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4309, %beam_idx.33, %beam_idx.33, %beam_idx.40, %eos_token_id.68, %4169, %4170, %4171, %4172\n",
      "}\n",
      "\n",
      "graph torch-jit-export13 {\n",
      "  %4165 = Identity(%187)\n",
      "  return %4165\n",
      "}\n",
      "\n",
      "graph torch-jit-export14 {\n",
      "  %4166 = Gather[axis = 0](%4105, %3898)\n",
      "  %4167 = Less(%4166, %4160)\n",
      "  return %4167\n",
      "}\n",
      "\n",
      "graph torch-jit-export15 {\n",
      "  %4173 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4174 = Equal(%3898, %4173)\n",
      "  %4175 = Not(%4174)\n",
      "  %4176 = Cast[to = 9](%4175)\n",
      "  %4177 = If[else_branch = <graph torch-jit-export17>, then_branch = <graph torch-jit-export16>](%4176)\n",
      "  %4189 = Constant[value = <Tensor>]()\n",
      "  %4190 = Reshape[allowzero = 0](%4160, %4189)\n",
      "  %4191 = Cast[to = 1](%4190)\n",
      "  %4192 = Concat[axis = 0](%4191)\n",
      "  %4193 = SequenceInsert(%4103, %4192, %4177)\n",
      "  %4194 = SequenceInsert(%4104, %4149, %4177)\n",
      "  %4195 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4196 = Add(%4161, %4195)\n",
      "  %4197 = Greater(%4196, %num_beams)\n",
      "  %4198 = Cast[to = 9](%4197)\n",
      "  %4199, %4200, %4201, %4202 = If[else_branch = <graph torch-jit-export19>, then_branch = <graph torch-jit-export18>](%4198)\n",
      "  return %4200, %4199, %4201, %4202\n",
      "}\n",
      "\n",
      "graph torch-jit-export16 {\n",
      "  %4178 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4179 = Constant[value = <Tensor>]()\n",
      "  %4180 = Unsqueeze(%4178, %4179)\n",
      "  %4181 = Constant[value = <Tensor>]()\n",
      "  %4182 = Unsqueeze(%3898, %4181)\n",
      "  %4183 = Constant[value = <Tensor>]()\n",
      "  %4184 = Unsqueeze(%191, %4183)\n",
      "  %4185 = Constant[value = <Tensor>]()\n",
      "  %4186 = Slice(%4106, %4180, %4182, %4184, %4185)\n",
      "  %4187 = ReduceSum[keepdims = 0](%4186)\n",
      "  return %4187\n",
      "}\n",
      "\n",
      "graph torch-jit-export17 {\n",
      "  %4188 = Identity(%178)\n",
      "  return %4188\n",
      "}\n",
      "\n",
      "graph torch-jit-export18 {\n",
      "  %4203 = ConcatFromSequence[axis = 0](%4193)\n",
      "  %4204 = Add(%4177, %4161)\n",
      "  %4205 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4206 = Add(%4204, %4205)\n",
      "  %4207 = Constant[value = <Tensor>]()\n",
      "  %4208 = Unsqueeze(%4177, %4207)\n",
      "  %4209 = Constant[value = <Tensor>]()\n",
      "  %4210 = Unsqueeze(%4206, %4209)\n",
      "  %4211 = Constant[value = <Tensor>]()\n",
      "  %4212 = Unsqueeze(%191, %4211)\n",
      "  %4213 = Constant[value = <Tensor>]()\n",
      "  %4214 = Slice(%4203, %4208, %4210, %4212, %4213)\n",
      "  %4215 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4216 = Add(%4161, %4215)\n",
      "  %4217 = Constant[value = <Tensor>]()\n",
      "  %4218 = Reshape[allowzero = 0](%4216, %4217)\n",
      "  %4219, %4220 = TopK[axis = -1, largest = 0, sorted = 1](%4214, %4218)\n",
      "  %4221 = Gather[axis = 0](%4220, %191)\n",
      "  %4222 = Add(%4221, %4177)\n",
      "  %4223 = SequenceErase(%4194, %4222)\n",
      "  %4224 = SequenceErase(%4193, %4222)\n",
      "  %4225 = Gather[axis = 0](%4219, %189)\n",
      "  %4226 = Gather[axis = 0](%4105, %3898)\n",
      "  %4227 = Shape(%4226)\n",
      "  %4228 = Expand(%4225, %4227)\n",
      "  %4229 = Constant[value = <Tensor>]()\n",
      "  %4230 = Unsqueeze(%3898, %4229)\n",
      "  %4231 = Shape(%4230)\n",
      "  %4232 = Constant[value = <Tensor>]()\n",
      "  %4233 = Unsqueeze(%4230, %4232)\n",
      "  %4234 = Shape(%4105)\n",
      "  %4235 = Constant[value = <Tensor>]()\n",
      "  %4236 = Constant[value = <Tensor>]()\n",
      "  %4237 = Constant[value = <Tensor>]()\n",
      "  %4238 = Slice(%4234, %4236, %4237, %4235)\n",
      "  %4239 = Concat[axis = 0](%4231, %4238)\n",
      "  %4240 = Shape(%4239)\n",
      "  %4241 = ConstantOfShape[value = <Tensor>](%4240)\n",
      "  %4242 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4243 = Mul(%4241, %4242)\n",
      "  %4244 = Equal(%4239, %4243)\n",
      "  %4245 = Where(%4244, %4241, %4239)\n",
      "  %4246 = Expand(%4228, %4245)\n",
      "  %4247 = Reshape[allowzero = 0](%4246, %4239)\n",
      "  %4248 = ScatterND(%4105, %4233, %4247)\n",
      "  %4249 = Identity(%4106)\n",
      "  return %4223, %4224, %4248, %4249\n",
      "}\n",
      "\n",
      "graph torch-jit-export19 {\n",
      "  %4250 = Gather[axis = 0](%4105, %3898)\n",
      "  %4251 = Min(%4160, %4250)\n",
      "  %4252 = Gather[axis = 0](%4105, %3898)\n",
      "  %4253 = Cast[to = 1](%4251)\n",
      "  %4254 = Shape(%4252)\n",
      "  %4255 = Expand(%4253, %4254)\n",
      "  %4256 = Constant[value = <Tensor>]()\n",
      "  %4257 = Unsqueeze(%3898, %4256)\n",
      "  %4258 = Shape(%4257)\n",
      "  %4259 = Constant[value = <Tensor>]()\n",
      "  %4260 = Unsqueeze(%4257, %4259)\n",
      "  %4261 = Shape(%4105)\n",
      "  %4262 = Constant[value = <Tensor>]()\n",
      "  %4263 = Constant[value = <Tensor>]()\n",
      "  %4264 = Constant[value = <Tensor>]()\n",
      "  %4265 = Slice(%4261, %4263, %4264, %4262)\n",
      "  %4266 = Concat[axis = 0](%4258, %4265)\n",
      "  %4267 = Shape(%4266)\n",
      "  %4268 = ConstantOfShape[value = <Tensor>](%4267)\n",
      "  %4269 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4270 = Mul(%4268, %4269)\n",
      "  %4271 = Equal(%4266, %4270)\n",
      "  %4272 = Where(%4271, %4268, %4266)\n",
      "  %4273 = Expand(%4255, %4272)\n",
      "  %4274 = Reshape[allowzero = 0](%4273, %4266)\n",
      "  %4275 = ScatterND(%4105, %4260, %4274)\n",
      "  %4276 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4277 = Add(%4161, %4276)\n",
      "  %4278 = Gather[axis = 0](%4106, %3898)\n",
      "  %4279 = Shape(%4278)\n",
      "  %4280 = Expand(%4277, %4279)\n",
      "  %4281 = Constant[value = <Tensor>]()\n",
      "  %4282 = Unsqueeze(%3898, %4281)\n",
      "  %4283 = Shape(%4282)\n",
      "  %4284 = Constant[value = <Tensor>]()\n",
      "  %4285 = Unsqueeze(%4282, %4284)\n",
      "  %4286 = Shape(%4106)\n",
      "  %4287 = Constant[value = <Tensor>]()\n",
      "  %4288 = Constant[value = <Tensor>]()\n",
      "  %4289 = Constant[value = <Tensor>]()\n",
      "  %4290 = Slice(%4286, %4288, %4289, %4287)\n",
      "  %4291 = Concat[axis = 0](%4283, %4290)\n",
      "  %4292 = Shape(%4291)\n",
      "  %4293 = ConstantOfShape[value = <Tensor>](%4292)\n",
      "  %4294 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4295 = Mul(%4293, %4294)\n",
      "  %4296 = Equal(%4291, %4295)\n",
      "  %4297 = Where(%4296, %4293, %4291)\n",
      "  %4298 = Expand(%4280, %4297)\n",
      "  %4299 = Reshape[allowzero = 0](%4298, %4291)\n",
      "  %4300 = ScatterND(%4106, %4285, %4299)\n",
      "  %4301 = Identity(%4194)\n",
      "  %4302 = Identity(%4193)\n",
      "  return %4301, %4302, %4275, %4300\n",
      "}\n",
      "\n",
      "graph torch-jit-export20 {\n",
      "  %4303 = Identity(%4103)\n",
      "  %4304 = Identity(%4104)\n",
      "  %4305 = Identity(%4105)\n",
      "  %4306 = Identity(%4106)\n",
      "  return %4303, %4304, %4305, %4306\n",
      "}\n",
      "\n",
      "graph torch-jit-export21 {\n",
      "  %4314 = Gather[axis = 0](%4107, %3898)\n",
      "  %4315 = Gather[axis = 0](%4314, %beam_idx.36)\n",
      "  %4316 = Shape(%4315)\n",
      "  %4317 = Expand(%4111, %4316)\n",
      "  %4318 = Constant[value = <Tensor>]()\n",
      "  %4319 = Unsqueeze(%3898, %4318)\n",
      "  %4320 = Constant[value = <Tensor>]()\n",
      "  %4321 = Unsqueeze(%beam_idx.36, %4320)\n",
      "  %4322 = Constant[value = <Tensor>]()\n",
      "  %4323 = Reshape[allowzero = 0](%4319, %4322)\n",
      "  %4324 = Add(%4323, %4321)\n",
      "  %4325 = Shape(%4324)\n",
      "  %4326 = Shape(%4325)\n",
      "  %4327 = ConstantOfShape[value = <Tensor>](%4326)\n",
      "  %4328 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4329 = Mul(%4327, %4328)\n",
      "  %4330 = Equal(%4325, %4329)\n",
      "  %4331 = Where(%4330, %4327, %4325)\n",
      "  %4332 = Expand(%4323, %4331)\n",
      "  %4333 = Constant[value = <Tensor>]()\n",
      "  %4334 = Unsqueeze(%4332, %4333)\n",
      "  %4335 = Shape(%4325)\n",
      "  %4336 = ConstantOfShape[value = <Tensor>](%4335)\n",
      "  %4337 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4338 = Mul(%4336, %4337)\n",
      "  %4339 = Equal(%4325, %4338)\n",
      "  %4340 = Where(%4339, %4336, %4325)\n",
      "  %4341 = Expand(%4321, %4340)\n",
      "  %4342 = Constant[value = <Tensor>]()\n",
      "  %4343 = Unsqueeze(%4341, %4342)\n",
      "  %4344 = Concat[axis = -1](%4334, %4343)\n",
      "  %4345 = Shape(%4107)\n",
      "  %4346 = Constant[value = <Tensor>]()\n",
      "  %4347 = Constant[value = <Tensor>]()\n",
      "  %4348 = Constant[value = <Tensor>]()\n",
      "  %4349 = Slice(%4345, %4347, %4348, %4346)\n",
      "  %4350 = Concat[axis = 0](%4325, %4349)\n",
      "  %4351 = Shape(%4350)\n",
      "  %4352 = ConstantOfShape[value = <Tensor>](%4351)\n",
      "  %4353 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4354 = Mul(%4352, %4353)\n",
      "  %4355 = Equal(%4350, %4354)\n",
      "  %4356 = Where(%4355, %4352, %4350)\n",
      "  %4357 = Expand(%4317, %4356)\n",
      "  %4358 = Reshape[allowzero = 0](%4357, %4350)\n",
      "  %4359 = ScatterND(%4107, %4344, %4358)\n",
      "  %4360 = Gather[axis = 0](%4108, %3898)\n",
      "  %4361 = Gather[axis = 0](%4360, %beam_idx.36)\n",
      "  %4362 = Shape(%4361)\n",
      "  %4363 = Expand(%4110, %4362)\n",
      "  %4364 = Constant[value = <Tensor>]()\n",
      "  %4365 = Unsqueeze(%3898, %4364)\n",
      "  %4366 = Constant[value = <Tensor>]()\n",
      "  %4367 = Unsqueeze(%beam_idx.36, %4366)\n",
      "  %4368 = Constant[value = <Tensor>]()\n",
      "  %4369 = Reshape[allowzero = 0](%4365, %4368)\n",
      "  %4370 = Add(%4369, %4367)\n",
      "  %4371 = Shape(%4370)\n",
      "  %4372 = Shape(%4371)\n",
      "  %4373 = ConstantOfShape[value = <Tensor>](%4372)\n",
      "  %4374 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4375 = Mul(%4373, %4374)\n",
      "  %4376 = Equal(%4371, %4375)\n",
      "  %4377 = Where(%4376, %4373, %4371)\n",
      "  %4378 = Expand(%4369, %4377)\n",
      "  %4379 = Constant[value = <Tensor>]()\n",
      "  %4380 = Unsqueeze(%4378, %4379)\n",
      "  %4381 = Shape(%4371)\n",
      "  %4382 = ConstantOfShape[value = <Tensor>](%4381)\n",
      "  %4383 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4384 = Mul(%4382, %4383)\n",
      "  %4385 = Equal(%4371, %4384)\n",
      "  %4386 = Where(%4385, %4382, %4371)\n",
      "  %4387 = Expand(%4367, %4386)\n",
      "  %4388 = Constant[value = <Tensor>]()\n",
      "  %4389 = Unsqueeze(%4387, %4388)\n",
      "  %4390 = Concat[axis = -1](%4380, %4389)\n",
      "  %4391 = Shape(%4108)\n",
      "  %4392 = Constant[value = <Tensor>]()\n",
      "  %4393 = Constant[value = <Tensor>]()\n",
      "  %4394 = Constant[value = <Tensor>]()\n",
      "  %4395 = Slice(%4391, %4393, %4394, %4392)\n",
      "  %4396 = Concat[axis = 0](%4371, %4395)\n",
      "  %4397 = Shape(%4396)\n",
      "  %4398 = ConstantOfShape[value = <Tensor>](%4397)\n",
      "  %4399 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4400 = Mul(%4398, %4399)\n",
      "  %4401 = Equal(%4396, %4400)\n",
      "  %4402 = Where(%4401, %4398, %4396)\n",
      "  %4403 = Expand(%4363, %4402)\n",
      "  %4404 = Reshape[allowzero = 0](%4403, %4396)\n",
      "  %4405 = ScatterND(%4108, %4390, %4404)\n",
      "  %4406 = Gather[axis = 0](%4109, %3898)\n",
      "  %4407 = Gather[axis = 0](%4406, %beam_idx.36)\n",
      "  %4408 = Shape(%4407)\n",
      "  %4409 = Expand(%4114, %4408)\n",
      "  %4410 = Constant[value = <Tensor>]()\n",
      "  %4411 = Unsqueeze(%3898, %4410)\n",
      "  %4412 = Constant[value = <Tensor>]()\n",
      "  %4413 = Unsqueeze(%beam_idx.36, %4412)\n",
      "  %4414 = Constant[value = <Tensor>]()\n",
      "  %4415 = Reshape[allowzero = 0](%4411, %4414)\n",
      "  %4416 = Add(%4415, %4413)\n",
      "  %4417 = Shape(%4416)\n",
      "  %4418 = Shape(%4417)\n",
      "  %4419 = ConstantOfShape[value = <Tensor>](%4418)\n",
      "  %4420 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4421 = Mul(%4419, %4420)\n",
      "  %4422 = Equal(%4417, %4421)\n",
      "  %4423 = Where(%4422, %4419, %4417)\n",
      "  %4424 = Expand(%4415, %4423)\n",
      "  %4425 = Constant[value = <Tensor>]()\n",
      "  %4426 = Unsqueeze(%4424, %4425)\n",
      "  %4427 = Shape(%4417)\n",
      "  %4428 = ConstantOfShape[value = <Tensor>](%4427)\n",
      "  %4429 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4430 = Mul(%4428, %4429)\n",
      "  %4431 = Equal(%4417, %4430)\n",
      "  %4432 = Where(%4431, %4428, %4417)\n",
      "  %4433 = Expand(%4413, %4432)\n",
      "  %4434 = Constant[value = <Tensor>]()\n",
      "  %4435 = Unsqueeze(%4433, %4434)\n",
      "  %4436 = Concat[axis = -1](%4426, %4435)\n",
      "  %4437 = Shape(%4109)\n",
      "  %4438 = Constant[value = <Tensor>]()\n",
      "  %4439 = Constant[value = <Tensor>]()\n",
      "  %4440 = Constant[value = <Tensor>]()\n",
      "  %4441 = Slice(%4437, %4439, %4440, %4438)\n",
      "  %4442 = Concat[axis = 0](%4417, %4441)\n",
      "  %4443 = Shape(%4442)\n",
      "  %4444 = ConstantOfShape[value = <Tensor>](%4443)\n",
      "  %4445 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4446 = Mul(%4444, %4445)\n",
      "  %4447 = Equal(%4442, %4446)\n",
      "  %4448 = Where(%4447, %4444, %4442)\n",
      "  %4449 = Expand(%4409, %4448)\n",
      "  %4450 = Reshape[allowzero = 0](%4449, %4442)\n",
      "  %4451 = ScatterND(%4109, %4436, %4450)\n",
      "  %4452 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4453 = Add(%beam_idx.36, %4452)\n",
      "  %4454 = Identity(%188)\n",
      "  %eos_token_id.70 = Identity(%eos_token_id.72)\n",
      "  %4456 = Identity(%4103)\n",
      "  %4457 = Identity(%4104)\n",
      "  %4458 = Identity(%4105)\n",
      "  %4459 = Identity(%4106)\n",
      "  %4460 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4461 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4454, %4460, %4461, %4461, %4453, %eos_token_id.70, %4456, %4457, %4458, %4459, %4359, %4405, %4451\n",
      "}\n",
      "\n",
      "graph torch-jit-export22 {\n",
      "  %4470 = Identity(%187)\n",
      "  %4471 = Identity(%4118)\n",
      "  %4472 = Identity(%4119)\n",
      "  %4473 = Identity(%4120)\n",
      "  %4474 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4475 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4476 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4470, %4471, %4472, %4473, %4474, %4475, %4476\n",
      "}\n",
      "\n",
      "graph torch-jit-export23 {\n",
      "  %4477 = Equal(%4121, %200)\n",
      "  %4478 = Cast[to = 9](%4477)\n",
      "  %4479, %4480, %4481 = If[else_branch = <graph torch-jit-export25>, then_branch = <graph torch-jit-export24>](%4478)\n",
      "  %4488 = Identity(%187)\n",
      "  %4489 = Identity(%4121)\n",
      "  %4490 = Identity(%4122)\n",
      "  return %4477, %4479, %4480, %4481, %4488, %4489, %4490\n",
      "}\n",
      "\n",
      "graph torch-jit-export24 {\n",
      "  %4482 = Identity(%188)\n",
      "  %4483 = Identity(%4121)\n",
      "  %4484 = Identity(%4122)\n",
      "  return %4482, %4483, %4484\n",
      "}\n",
      "\n",
      "graph torch-jit-export25 {\n",
      "  %4485 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4486 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4487 = Constant[value = <Scalar Tensor []>]()\n",
      "  return %4485, %4486, %4487\n",
      "}\n",
      "\n",
      "graph torch-jit-export26 {\n",
      "  %4495 = Identity(%4464)\n",
      "  %4496 = Identity(%4465)\n",
      "  %4497 = Identity(%4466)\n",
      "  return %4495, %4496, %4497\n",
      "}\n",
      "\n",
      "graph torch-jit-export27 {\n",
      "  %4498 = Identity(%4467)\n",
      "  %4499 = Identity(%4468)\n",
      "  %4500 = Identity(%4469)\n",
      "  return %4498, %4499, %4500\n",
      "}\n",
      "\n",
      "graph torch-jit-export28 {\n",
      "  %4511 = Identity(%187)\n",
      "  return %4511\n",
      "}\n",
      "\n",
      "graph torch-jit-export29 {\n",
      "  %4512 = Gather[axis = 0](%4094, %3898)\n",
      "  %4513 = Less(%4512, %num_beams)\n",
      "  %4514 = Cast[to = 9](%4513)\n",
      "  %4515 = If[else_branch = <graph torch-jit-export31>, then_branch = <graph torch-jit-export30>](%4514)\n",
      "  return %4515\n",
      "}\n",
      "\n",
      "graph torch-jit-export30 {\n",
      "  %4516 = Identity(%188)\n",
      "  return %4516\n",
      "}\n",
      "\n",
      "graph torch-jit-export31 {\n",
      "  %4517 = Identity(%187)\n",
      "  return %4517\n",
      "}\n",
      "\n",
      "graph torch-jit-export32 {\n",
      "  %4581 = Identity(%188)\n",
      "  return %4581\n",
      "}\n",
      "\n",
      "graph torch-jit-export33 {\n",
      "  %4582 = Greater(%max_length, %4572)\n",
      "  return %4582\n",
      "}\n",
      "\n",
      "graph torch-jit-export34 (\n",
      "  %4595[INT64, scalar]\n",
      "  %cond.9[BOOL, scalar]\n",
      "  %4597[INT64, scalar]\n",
      "  %4598[Unknown type sequence_type]\n",
      "  %4599[Unknown type sequence_type]\n",
      "  %4600[FLOAT, Loop3891_dim_0]\n",
      "  %4601[INT64, Loop3892_dim_0]\n",
      ") {\n",
      "  %4602 = Gather[axis = 0](%326, %4597)\n",
      "  %4603 = Cast[to = 9](%4602)\n",
      "  %4604, %4605, %4606, %4607 = If[else_branch = <graph torch-jit-export36>, then_branch = <graph torch-jit-export35>](%4603)\n",
      "  %4784 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4785 = Add(%4597, %4784)\n",
      "  %4786 = Less(%4785, %4587)\n",
      "  %4787 = Cast[to = 9](%4786)\n",
      "  %4788 = Cast[to = 9](%187)\n",
      "  %4789 = And(%4787, %4788)\n",
      "  %4790 = Cast[to = 9](%4789)\n",
      "  return %4790, %4785, %4604, %4605, %4606, %4607\n",
      "}\n",
      "\n",
      "graph torch-jit-export35 {\n",
      "  %4608 = Identity(%4598)\n",
      "  %4609 = Identity(%4599)\n",
      "  %4610 = Identity(%4600)\n",
      "  %4611 = Identity(%4601)\n",
      "  return %4608, %4609, %4610, %4611\n",
      "}\n",
      "\n",
      "graph torch-jit-export36 {\n",
      "  %4612, %4613, %4614, %4615 = Loop[body = <graph torch-jit-export37>](%num_beams, %187, %4598, %4599, %4600, %4601)\n",
      "  return %4612, %4613, %4614, %4615\n",
      "}\n",
      "\n",
      "graph torch-jit-export37 (\n",
      "  %beam_id.1[INT64, scalar]\n",
      "  %cond.7[BOOL, scalar]\n",
      "  %4618[Unknown type sequence_type]\n",
      "  %4619[Unknown type sequence_type]\n",
      "  %4620[FLOAT, Loop3891_dim_0]\n",
      "  %4621[INT64, Loop3892_dim_0]\n",
      ") {\n",
      "  %4622 = Mul(%4597, %num_beams)\n",
      "  %4623 = Add(%4622, %beam_id.1)\n",
      "  %4624 = Gather[axis = 0](%319, %4623)\n",
      "  %4625 = Gather[axis = 0](%318, %4623)\n",
      "  %4626 = Shape(%4625)\n",
      "  %4627 = Constant[value = <Tensor>]()\n",
      "  %4628 = Constant[value = <Tensor>]()\n",
      "  %4629 = Constant[value = <Tensor>]()\n",
      "  %4630 = Slice(%4626, %4628, %4629, %4627)\n",
      "  %4631 = Constant[value = <Tensor>]()\n",
      "  %4632 = Squeeze(%4630, %4631)\n",
      "  %4633 = Cast[to = 1](%4632)\n",
      "  %4634 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4635 = Pow(%4633, %4634)\n",
      "  %4636 = Div(%4624, %4635)\n",
      "  %4637 = Gather[axis = 0](%4621, %4597)\n",
      "  %4638 = Less(%4637, %num_beams)\n",
      "  %4639 = Cast[to = 9](%4638)\n",
      "  %4640 = If[else_branch = <graph torch-jit-export39>, then_branch = <graph torch-jit-export38>](%4639)\n",
      "  %4644 = Cast[to = 9](%4640)\n",
      "  %4645, %4646, %4647, %4648 = If[else_branch = <graph torch-jit-export45>, then_branch = <graph torch-jit-export40>](%4644)\n",
      "  %4783 = Identity(%187)\n",
      "  return %4783, %4645, %4646, %4647, %4648\n",
      "}\n",
      "\n",
      "graph torch-jit-export38 {\n",
      "  %4641 = Identity(%187)\n",
      "  return %4641\n",
      "}\n",
      "\n",
      "graph torch-jit-export39 {\n",
      "  %4642 = Gather[axis = 0](%4620, %4597)\n",
      "  %4643 = Less(%4642, %4636)\n",
      "  return %4643\n",
      "}\n",
      "\n",
      "graph torch-jit-export40 {\n",
      "  %4649 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4650 = Equal(%4597, %4649)\n",
      "  %4651 = Not(%4650)\n",
      "  %4652 = Cast[to = 9](%4651)\n",
      "  %4653 = If[else_branch = <graph torch-jit-export42>, then_branch = <graph torch-jit-export41>](%4652)\n",
      "  %4665 = Constant[value = <Tensor>]()\n",
      "  %4666 = Reshape[allowzero = 0](%4636, %4665)\n",
      "  %4667 = Cast[to = 1](%4666)\n",
      "  %4668 = Concat[axis = 0](%4667)\n",
      "  %4669 = SequenceInsert(%4618, %4668, %4653)\n",
      "  %4670 = SequenceInsert(%4619, %4625, %4653)\n",
      "  %4671 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4672 = Add(%4637, %4671)\n",
      "  %4673 = Greater(%4672, %num_beams)\n",
      "  %4674 = Cast[to = 9](%4673)\n",
      "  %4675, %4676, %4677, %4678 = If[else_branch = <graph torch-jit-export44>, then_branch = <graph torch-jit-export43>](%4674)\n",
      "  return %4676, %4675, %4677, %4678\n",
      "}\n",
      "\n",
      "graph torch-jit-export41 {\n",
      "  %4654 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4655 = Constant[value = <Tensor>]()\n",
      "  %4656 = Unsqueeze(%4654, %4655)\n",
      "  %4657 = Constant[value = <Tensor>]()\n",
      "  %4658 = Unsqueeze(%4597, %4657)\n",
      "  %4659 = Constant[value = <Tensor>]()\n",
      "  %4660 = Unsqueeze(%191, %4659)\n",
      "  %4661 = Constant[value = <Tensor>]()\n",
      "  %4662 = Slice(%4621, %4656, %4658, %4660, %4661)\n",
      "  %4663 = ReduceSum[keepdims = 0](%4662)\n",
      "  return %4663\n",
      "}\n",
      "\n",
      "graph torch-jit-export42 {\n",
      "  %4664 = Identity(%178)\n",
      "  return %4664\n",
      "}\n",
      "\n",
      "graph torch-jit-export43 {\n",
      "  %4679 = ConcatFromSequence[axis = 0](%4669)\n",
      "  %4680 = Add(%4653, %4637)\n",
      "  %4681 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4682 = Add(%4680, %4681)\n",
      "  %4683 = Constant[value = <Tensor>]()\n",
      "  %4684 = Unsqueeze(%4653, %4683)\n",
      "  %4685 = Constant[value = <Tensor>]()\n",
      "  %4686 = Unsqueeze(%4682, %4685)\n",
      "  %4687 = Constant[value = <Tensor>]()\n",
      "  %4688 = Unsqueeze(%191, %4687)\n",
      "  %4689 = Constant[value = <Tensor>]()\n",
      "  %4690 = Slice(%4679, %4684, %4686, %4688, %4689)\n",
      "  %4691 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4692 = Add(%4637, %4691)\n",
      "  %4693 = Constant[value = <Tensor>]()\n",
      "  %4694 = Reshape[allowzero = 0](%4692, %4693)\n",
      "  %4695, %4696 = TopK[axis = -1, largest = 0, sorted = 1](%4690, %4694)\n",
      "  %4697 = Gather[axis = 0](%4696, %191)\n",
      "  %4698 = Add(%4697, %4653)\n",
      "  %4699 = SequenceErase(%4670, %4698)\n",
      "  %4700 = SequenceErase(%4669, %4698)\n",
      "  %4701 = Gather[axis = 0](%4695, %189)\n",
      "  %4702 = Gather[axis = 0](%4620, %4597)\n",
      "  %4703 = Shape(%4702)\n",
      "  %4704 = Expand(%4701, %4703)\n",
      "  %4705 = Constant[value = <Tensor>]()\n",
      "  %4706 = Unsqueeze(%4597, %4705)\n",
      "  %4707 = Shape(%4706)\n",
      "  %4708 = Constant[value = <Tensor>]()\n",
      "  %4709 = Unsqueeze(%4706, %4708)\n",
      "  %4710 = Shape(%4620)\n",
      "  %4711 = Constant[value = <Tensor>]()\n",
      "  %4712 = Constant[value = <Tensor>]()\n",
      "  %4713 = Constant[value = <Tensor>]()\n",
      "  %4714 = Slice(%4710, %4712, %4713, %4711)\n",
      "  %4715 = Concat[axis = 0](%4707, %4714)\n",
      "  %4716 = Shape(%4715)\n",
      "  %4717 = ConstantOfShape[value = <Tensor>](%4716)\n",
      "  %4718 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4719 = Mul(%4717, %4718)\n",
      "  %4720 = Equal(%4715, %4719)\n",
      "  %4721 = Where(%4720, %4717, %4715)\n",
      "  %4722 = Expand(%4704, %4721)\n",
      "  %4723 = Reshape[allowzero = 0](%4722, %4715)\n",
      "  %4724 = ScatterND(%4620, %4709, %4723)\n",
      "  %4725 = Identity(%4621)\n",
      "  return %4699, %4700, %4724, %4725\n",
      "}\n",
      "\n",
      "graph torch-jit-export44 {\n",
      "  %4726 = Gather[axis = 0](%4620, %4597)\n",
      "  %4727 = Min(%4636, %4726)\n",
      "  %4728 = Gather[axis = 0](%4620, %4597)\n",
      "  %4729 = Cast[to = 1](%4727)\n",
      "  %4730 = Shape(%4728)\n",
      "  %4731 = Expand(%4729, %4730)\n",
      "  %4732 = Constant[value = <Tensor>]()\n",
      "  %4733 = Unsqueeze(%4597, %4732)\n",
      "  %4734 = Shape(%4733)\n",
      "  %4735 = Constant[value = <Tensor>]()\n",
      "  %4736 = Unsqueeze(%4733, %4735)\n",
      "  %4737 = Shape(%4620)\n",
      "  %4738 = Constant[value = <Tensor>]()\n",
      "  %4739 = Constant[value = <Tensor>]()\n",
      "  %4740 = Constant[value = <Tensor>]()\n",
      "  %4741 = Slice(%4737, %4739, %4740, %4738)\n",
      "  %4742 = Concat[axis = 0](%4734, %4741)\n",
      "  %4743 = Shape(%4742)\n",
      "  %4744 = ConstantOfShape[value = <Tensor>](%4743)\n",
      "  %4745 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4746 = Mul(%4744, %4745)\n",
      "  %4747 = Equal(%4742, %4746)\n",
      "  %4748 = Where(%4747, %4744, %4742)\n",
      "  %4749 = Expand(%4731, %4748)\n",
      "  %4750 = Reshape[allowzero = 0](%4749, %4742)\n",
      "  %4751 = ScatterND(%4620, %4736, %4750)\n",
      "  %4752 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4753 = Add(%4637, %4752)\n",
      "  %4754 = Gather[axis = 0](%4621, %4597)\n",
      "  %4755 = Shape(%4754)\n",
      "  %4756 = Expand(%4753, %4755)\n",
      "  %4757 = Constant[value = <Tensor>]()\n",
      "  %4758 = Unsqueeze(%4597, %4757)\n",
      "  %4759 = Shape(%4758)\n",
      "  %4760 = Constant[value = <Tensor>]()\n",
      "  %4761 = Unsqueeze(%4758, %4760)\n",
      "  %4762 = Shape(%4621)\n",
      "  %4763 = Constant[value = <Tensor>]()\n",
      "  %4764 = Constant[value = <Tensor>]()\n",
      "  %4765 = Constant[value = <Tensor>]()\n",
      "  %4766 = Slice(%4762, %4764, %4765, %4763)\n",
      "  %4767 = Concat[axis = 0](%4759, %4766)\n",
      "  %4768 = Shape(%4767)\n",
      "  %4769 = ConstantOfShape[value = <Tensor>](%4768)\n",
      "  %4770 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4771 = Mul(%4769, %4770)\n",
      "  %4772 = Equal(%4767, %4771)\n",
      "  %4773 = Where(%4772, %4769, %4767)\n",
      "  %4774 = Expand(%4756, %4773)\n",
      "  %4775 = Reshape[allowzero = 0](%4774, %4767)\n",
      "  %4776 = ScatterND(%4621, %4761, %4775)\n",
      "  %4777 = Identity(%4670)\n",
      "  %4778 = Identity(%4669)\n",
      "  return %4777, %4778, %4751, %4776\n",
      "}\n",
      "\n",
      "graph torch-jit-export45 {\n",
      "  %4779 = Identity(%4618)\n",
      "  %4780 = Identity(%4619)\n",
      "  %4781 = Identity(%4620)\n",
      "  %4782 = Identity(%4621)\n",
      "  return %4779, %4780, %4781, %4782\n",
      "}\n",
      "\n",
      "graph torch-jit-export46 (\n",
      "  %i.1[INT64, scalar]\n",
      "  %cond.13[BOOL, scalar]\n",
      "  %4802[INT64, 4802_dim_0]\n",
      "  %4803[Unknown type sequence_type]\n",
      ") {\n",
      "  %4804 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4805 = Greater(%i.1, %4804)\n",
      "  %4806 = Cast[to = 9](%4805)\n",
      "  %4807 = If[else_branch = <graph torch-jit-export48>, then_branch = <graph torch-jit-export47>](%4806)\n",
      "  %4819 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4820 = Add(%i.1, %4819)\n",
      "  %4821 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4822 = Constant[value = <Tensor>]()\n",
      "  %4823 = Unsqueeze(%4821, %4822)\n",
      "  %4824 = Constant[value = <Tensor>]()\n",
      "  %4825 = Unsqueeze(%4820, %4824)\n",
      "  %4826 = Constant[value = <Tensor>]()\n",
      "  %4827 = Unsqueeze(%191, %4826)\n",
      "  %4828 = Constant[value = <Tensor>]()\n",
      "  %4829 = Slice(%4594, %4823, %4825, %4827, %4828)\n",
      "  %4830 = ReduceSum[keepdims = 0](%4829)\n",
      "  %4831 = ConcatFromSequence[axis = 0](%4591)\n",
      "  %4832 = Constant[value = <Tensor>]()\n",
      "  %4833 = Unsqueeze(%4807, %4832)\n",
      "  %4834 = Constant[value = <Tensor>]()\n",
      "  %4835 = Unsqueeze(%4830, %4834)\n",
      "  %4836 = Constant[value = <Tensor>]()\n",
      "  %4837 = Unsqueeze(%191, %4836)\n",
      "  %4838 = Constant[value = <Tensor>]()\n",
      "  %4839 = Slice(%4831, %4833, %4835, %4837, %4838)\n",
      "  %4840 = Constant[value = <Tensor>]()\n",
      "  %4841 = Shape(%4839)\n",
      "  %4842 = Gather[axis = 0](%4841, %4840)\n",
      "  %4843 = Constant[value = <Tensor>]()\n",
      "  %4844 = Squeeze(%4842, %4843)\n",
      "  %4845 = Constant[value = <Tensor>]()\n",
      "  %4846 = Reshape[allowzero = 0](%4844, %4845)\n",
      "  %4847, %4848 = TopK[axis = -1, largest = 1, sorted = 1](%4839, %4846)\n",
      "  %4849, %4850 = Loop[body = <graph torch-jit-export49>](%189, %187, %4802, %4803)\n",
      "  %4892 = Identity(%187)\n",
      "  return %4892, %4849, %4850\n",
      "}\n",
      "\n",
      "graph torch-jit-export47 {\n",
      "  %4808 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4809 = Constant[value = <Tensor>]()\n",
      "  %4810 = Unsqueeze(%4808, %4809)\n",
      "  %4811 = Constant[value = <Tensor>]()\n",
      "  %4812 = Unsqueeze(%i.1, %4811)\n",
      "  %4813 = Constant[value = <Tensor>]()\n",
      "  %4814 = Unsqueeze(%191, %4813)\n",
      "  %4815 = Constant[value = <Tensor>]()\n",
      "  %4816 = Slice(%4594, %4810, %4812, %4814, %4815)\n",
      "  %4817 = ReduceSum[keepdims = 0](%4816)\n",
      "  return %4817\n",
      "}\n",
      "\n",
      "graph torch-jit-export48 {\n",
      "  %4818 = Identity(%178)\n",
      "  return %4818\n",
      "}\n",
      "\n",
      "graph torch-jit-export49 (\n",
      "  %j.1[INT64, scalar]\n",
      "  %cond.11[BOOL, scalar]\n",
      "  %4853[INT64, 4802_dim_0]\n",
      "  %4854[Unknown type sequence_type]\n",
      ") {\n",
      "  %4855 = Gather[axis = 0](%4848, %j.1)\n",
      "  %4856 = Add(%4807, %4855)\n",
      "  %4857 = SequenceAt(%4592, %4856)\n",
      "  %4858 = Constant[value = <Tensor>]()\n",
      "  %4859 = Shape(%4857)\n",
      "  %4860 = Gather[axis = 0](%4859, %4858)\n",
      "  %4861 = Constant[value = <Tensor>]()\n",
      "  %4862 = Squeeze(%4860, %4861)\n",
      "  %4863 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4864 = Mul(%4863, %i.1)\n",
      "  %4865 = Add(%4864, %j.1)\n",
      "  %4866 = Gather[axis = 0](%4853, %4865)\n",
      "  %4867 = Cast[to = 7](%4862)\n",
      "  %4868 = Shape(%4866)\n",
      "  %4869 = Expand(%4867, %4868)\n",
      "  %4870 = Constant[value = <Tensor>]()\n",
      "  %4871 = Unsqueeze(%4865, %4870)\n",
      "  %4872 = Shape(%4871)\n",
      "  %4873 = Constant[value = <Tensor>]()\n",
      "  %4874 = Unsqueeze(%4871, %4873)\n",
      "  %4875 = Shape(%4853)\n",
      "  %4876 = Constant[value = <Tensor>]()\n",
      "  %4877 = Constant[value = <Tensor>]()\n",
      "  %4878 = Constant[value = <Tensor>]()\n",
      "  %4879 = Slice(%4875, %4877, %4878, %4876)\n",
      "  %4880 = Concat[axis = 0](%4872, %4879)\n",
      "  %4881 = Shape(%4880)\n",
      "  %4882 = ConstantOfShape[value = <Tensor>](%4881)\n",
      "  %4883 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4884 = Mul(%4882, %4883)\n",
      "  %4885 = Equal(%4880, %4884)\n",
      "  %4886 = Where(%4885, %4882, %4880)\n",
      "  %4887 = Expand(%4869, %4886)\n",
      "  %4888 = Reshape[allowzero = 0](%4887, %4880)\n",
      "  %4889 = ScatterND(%4853, %4874, %4888)\n",
      "  %4890 = SequenceInsert(%4854, %4857)\n",
      "  %4891 = Identity(%187)\n",
      "  return %4891, %4889, %4890\n",
      "}\n",
      "\n",
      "graph torch-jit-export50 {\n",
      "  %4911 = Shape(%4904)\n",
      "  %4912 = ConstantOfShape[value = <Tensor>](%4911)\n",
      "  return %4912\n",
      "}\n",
      "\n",
      "graph torch-jit-export51 {\n",
      "  %4913 = Identity(%4904)\n",
      "  return %4913\n",
      "}\n",
      "\n",
      "graph torch-jit-export52 (\n",
      "  %i.17[INT64, scalar]\n",
      "  %cond[BOOL, scalar]\n",
      "  %4924[INT64, ConstantOfShape4912_dim_0xConstantOfShape4912_dim_1]\n",
      ") {\n",
      "  %4925 = SequenceAt(%4799, %i.17)\n",
      "  %4926 = Gather[axis = 0](%4924, %i.17)\n",
      "  %4927 = Gather[axis = 0](%4798, %i.17)\n",
      "  %4928 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4929 = Constant[value = <Tensor>]()\n",
      "  %4930 = Unsqueeze(%4928, %4929)\n",
      "  %4931 = Constant[value = <Tensor>]()\n",
      "  %4932 = Unsqueeze(%4927, %4931)\n",
      "  %4933 = Constant[value = <Tensor>]()\n",
      "  %4934 = Unsqueeze(%191, %4933)\n",
      "  %4935 = Constant[value = <Tensor>]()\n",
      "  %4936 = Slice(%4926, %4930, %4932, %4934, %4935)\n",
      "  %4937 = Shape(%4936)\n",
      "  %4938 = Expand(%4925, %4937)\n",
      "  %4939 = Constant[value = <Tensor>]()\n",
      "  %4940 = Unsqueeze(%i.17, %4939)\n",
      "  %4941 = Shape(%4924)\n",
      "  %4942 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4943 = Gather[axis = 0](%4941, %4942)\n",
      "  %4944 = Cast[to = 7](%4943)\n",
      "  %4945 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4946 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4947 = Range(%4945, %4944, %4946)\n",
      "  %4948 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4949 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4950 = Constant[value = <Tensor>]()\n",
      "  %4951 = Unsqueeze(%4949, %4950)\n",
      "  %4952 = Constant[value = <Tensor>]()\n",
      "  %4953 = Unsqueeze(%4927, %4952)\n",
      "  %4954 = Constant[value = <Tensor>]()\n",
      "  %4955 = Unsqueeze(%4948, %4954)\n",
      "  %4956 = Constant[value = <Tensor>]()\n",
      "  %4957 = Slice(%4947, %4951, %4953, %4955, %4956)\n",
      "  %4958 = Constant[value = <Tensor>]()\n",
      "  %4959 = Reshape[allowzero = 0](%4940, %4958)\n",
      "  %4960 = Add(%4959, %4957)\n",
      "  %4961 = Shape(%4960)\n",
      "  %4962 = Shape(%4961)\n",
      "  %4963 = ConstantOfShape[value = <Tensor>](%4962)\n",
      "  %4964 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4965 = Mul(%4963, %4964)\n",
      "  %4966 = Equal(%4961, %4965)\n",
      "  %4967 = Where(%4966, %4963, %4961)\n",
      "  %4968 = Expand(%4959, %4967)\n",
      "  %4969 = Constant[value = <Tensor>]()\n",
      "  %4970 = Unsqueeze(%4968, %4969)\n",
      "  %4971 = Shape(%4961)\n",
      "  %4972 = ConstantOfShape[value = <Tensor>](%4971)\n",
      "  %4973 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4974 = Mul(%4972, %4973)\n",
      "  %4975 = Equal(%4961, %4974)\n",
      "  %4976 = Where(%4975, %4972, %4961)\n",
      "  %4977 = Expand(%4957, %4976)\n",
      "  %4978 = Constant[value = <Tensor>]()\n",
      "  %4979 = Unsqueeze(%4977, %4978)\n",
      "  %4980 = Concat[axis = -1](%4970, %4979)\n",
      "  %4981 = Shape(%4924)\n",
      "  %4982 = Constant[value = <Tensor>]()\n",
      "  %4983 = Constant[value = <Tensor>]()\n",
      "  %4984 = Constant[value = <Tensor>]()\n",
      "  %4985 = Slice(%4981, %4983, %4984, %4982)\n",
      "  %4986 = Concat[axis = 0](%4961, %4985)\n",
      "  %4987 = Reshape[allowzero = 0](%4938, %4986)\n",
      "  %4988 = Cast[to = 7](%4987)\n",
      "  %4989 = ScatterND(%4924, %4980, %4988)\n",
      "  %4990 = Gather[axis = 0](%4798, %i.17)\n",
      "  %4991 = Less(%4990, %max_length)\n",
      "  %4992 = Cast[to = 9](%4991)\n",
      "  %4993 = If[else_branch = <graph torch-jit-export54>, then_branch = <graph torch-jit-export53>](%4992)\n",
      "  %5037 = Identity(%187)\n",
      "  return %5037, %4993\n",
      "}\n",
      "\n",
      "graph torch-jit-export53 {\n",
      "  %4994 = Gather[axis = 0](%4798, %i.17)\n",
      "  %4995 = Constant[value = <Scalar Tensor []>]()\n",
      "  %4996 = Constant[value = <Tensor>]()\n",
      "  %4997 = Unsqueeze(%i.17, %4996)\n",
      "  %4998 = Constant[value = <Tensor>]()\n",
      "  %4999 = Reshape[allowzero = 0](%4997, %4998)\n",
      "  %5000 = Add(%4999, %4994)\n",
      "  %5001 = Shape(%5000)\n",
      "  %5002 = Shape(%5001)\n",
      "  %5003 = ConstantOfShape[value = <Tensor>](%5002)\n",
      "  %5004 = Constant[value = <Scalar Tensor []>]()\n",
      "  %5005 = Mul(%5003, %5004)\n",
      "  %5006 = Equal(%5001, %5005)\n",
      "  %5007 = Where(%5006, %5003, %5001)\n",
      "  %5008 = Expand(%4999, %5007)\n",
      "  %5009 = Constant[value = <Tensor>]()\n",
      "  %5010 = Unsqueeze(%5008, %5009)\n",
      "  %5011 = Shape(%5001)\n",
      "  %5012 = ConstantOfShape[value = <Tensor>](%5011)\n",
      "  %5013 = Constant[value = <Scalar Tensor []>]()\n",
      "  %5014 = Mul(%5012, %5013)\n",
      "  %5015 = Equal(%5001, %5014)\n",
      "  %5016 = Where(%5015, %5012, %5001)\n",
      "  %5017 = Expand(%4994, %5016)\n",
      "  %5018 = Constant[value = <Tensor>]()\n",
      "  %5019 = Unsqueeze(%5017, %5018)\n",
      "  %5020 = Concat[axis = -1](%5010, %5019)\n",
      "  %5021 = Shape(%4989)\n",
      "  %5022 = Constant[value = <Tensor>]()\n",
      "  %5023 = Constant[value = <Tensor>]()\n",
      "  %5024 = Constant[value = <Tensor>]()\n",
      "  %5025 = Slice(%5021, %5023, %5024, %5022)\n",
      "  %5026 = Concat[axis = 0](%5001, %5025)\n",
      "  %5027 = Shape(%5026)\n",
      "  %5028 = ConstantOfShape[value = <Tensor>](%5027)\n",
      "  %5029 = Constant[value = <Scalar Tensor []>]()\n",
      "  %5030 = Mul(%5028, %5029)\n",
      "  %5031 = Equal(%5026, %5030)\n",
      "  %5032 = Where(%5031, %5028, %5026)\n",
      "  %5033 = Expand(%4995, %5032)\n",
      "  %5034 = Reshape[allowzero = 0](%5033, %5026)\n",
      "  %5035 = ScatterND(%4989, %5020, %5034)\n",
      "  return %5035\n",
      "}\n",
      "\n",
      "graph torch-jit-export54 {\n",
      "  %5036 = Identity(%4989)\n",
      "  return %5036\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model_onnx_sample.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = onnxruntime.SessionOptions()\n",
    "\n",
    "ort_sess = onnxruntime.InferenceSession(onnx_file_path, sess_options=options )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].cpu().numpy(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].cpu().numpy(),\n",
    "        \"num_beams\": np.array(num_beams, dtype=np.int64),\n",
    "        \"max_length\": np.array(max_length, dtype=np.int64),\n",
    "        \"temperature\": np.array(temperature, dtype=np.float64),\n",
    "        \"top_p\": np.array(top_p, dtype=np.float64),\n",
    "    }\n",
    "\n",
    "ort_out = ort_sess.run(\n",
    "    None,\n",
    "    ort_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,   365, 28715,\n",
      "          3638,  1207,    16,   282, 28715, 23940,  3942,    17, 18047,     2]])\n",
      "tensor([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,   365, 28715,\n",
      "          3638,  1207,    16,   282, 28715, 23940,  3942,    17, 18047,     2]])\n",
      "[array([[    1,   419,  2611, 50258, 18989,  2909, 50259, 50257,  1681,\n",
      "          808,   417,  1300,   945,   811,   329,   417,   418,  3209,\n",
      "          411,     2]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "print(summary_ids)\n",
    "print(summary_ids_temp)\n",
    "print(ort_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg: <s>старик _kw_ Кощей _endkw_ [SEP]  В некотором царстве, в некотором государстве жил-был</s>\n",
      "onnx: <s>старик _kw_ Кощей _endkw_ [SEP]  Под время я запрудился у явочек из</s>\n"
     ]
    }
   ],
   "source": [
    "print(\"hg:\", tokenizer.decode(summary_ids_temp[0], skip_special_tokens=False, clean_up_tokenization_spaces=False))\n",
    "print(\"onnx:\",tokenizer.decode(ort_out[0][0], skip_special_tokens=False, clean_up_tokenization_spaces=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(summary_ids.cpu().numpy(), ort_out[0], rtol=1e-3, atol=1e-3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d3a13fa35461c6d7f441fbb3d93fc4f14860aa527e8f914775d5e57b8364c02"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
