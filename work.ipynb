{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import rouge\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model.logger import Logger\n",
    "from src.model.data_full import RawFilesDataset\n",
    "from src.model.loss import ParagraphLoss\n",
    "from src.model.generate_utils import toks_to_str\n",
    "\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "\n",
    "# from src.model.generate_utils  import generate_paragraph\n",
    "# from src.model.eval_utils import evaluate_doc_model\n",
    "# from src.model.model import GPT2BaseModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.decoders import ByteLevel\n",
    "decoder = ByteLevel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_rep = []\n",
    "end_tok = encoder.convert_tokens_to_ids('_end_')\n",
    "\n",
    "for token in sample_output[0]:\n",
    "    print(token.item(), repr(decoder.decode([ encoder.convert_ids_to_tokens(token.item(), skip_special_tokens=True)])))\n",
    "    if token.item() == end_tok : #or token.item() == 0:# or x.item() == end_idx:\n",
    "        break        \n",
    "    str_rep.append(encoder.convert_ids_to_tokens(token.item()))\n",
    "\n",
    "str_rep = encoder.convert_tokens_to_string(str_rep)\n",
    "\n",
    "# This makes sure rouge scorers doesn't complain about no sentences\n",
    "if not str_rep:\n",
    "    str_rep = \"unk.\"\n",
    "elif \".\" not in str_rep:\n",
    "    str_rep += \".\"\n",
    "\n",
    "print(encoder.decode(sample_output[0], skip_special_tokens=False, clean_up_tokenization_spaces=False))\n",
    "print(\"-\"*50)\n",
    "print(str_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    repeattheta = 1.5\n",
    "    output_attentions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model = GPT2BaseModel(args, vocab=vocab, n_ctx=config['n_ctx'], gen_len=401, lastidx=encoder.eos_token_id, includeprev=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_doc_model(model=doc_model, val_loader=val_loader, text_encoder=encoder, device='cpu', beam=0, gen_len=401, k=0, p=90, save_file='out', max_len=512, gen_dir=None, tgt_dir=None, min_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w', encoding='utf-8') as f:\n",
    "    json.dump(\"Моя строка\", f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('generated/test.gens.tsv', sep='\\t', header=None, names=['id', 'plot', 'context', 'part', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* для токенизаторов в исходном коде не применяется язык\n",
    "* англ токенизатор предложений лучше делит, к примеру русский не смог разделить 'Король дал за дочкой богатое приданое, наградил зятя большим чином и задал пир на весь мир.\\nЖивут молодые месяц, и два, и три.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Metric, Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = '111 Волшебное кольцо.txt'\n",
    "path = 'dataset/raw'\n",
    "with open(os.path.join(path, story), 'r', encoding='utf-8') as f:\n",
    "    text =  f.read()\n",
    "    text = re.sub('\\.\\.\\.', '.', text)\n",
    "    text = re.sub('—', '-', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_scores(hyps, refs):       \n",
    "    rouge_scorer = rouge.Rouge()\n",
    "    averaged_scores = rouge_scorer.get_scores(hyps, refs, avg=True)\n",
    "    return averaged_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\", add_prefix_space=True)\n",
    "text_encoder.add_special_tokens({'bos_token': '<s>',                                     \n",
    "                                    'eos_token': '</s>',\n",
    "                                    'additional_special_tokens': ['[SEP]', '_kw_', '_endkw_']\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('savedir/s_all_nodiscourse_kw/checkpoints/checkpoint.pt', 'rb') as f:\n",
    "    model = torch.load(f, map_location=torch.device('cpu'))\n",
    "\n",
    "with open('savedir/s_all_nodiscourse_kw/test_dataset', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RawFilesDataset(test, text_encoder, 2048, n_ctx=70)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_batch(batch: dict, text_encoder: GPT2Tokenizer)-> tuple:\n",
    "    septok = text_encoder.convert_tokens_to_ids('[SEP]')\n",
    "    endtok = text_encoder.eos_token_id\n",
    "    input_ids, mask = batch['sample'], batch['mask']\n",
    "\n",
    "    sep_idx = torch.where(input_ids[0] == septok)[0].item()\n",
    "    eos_idx = torch.where(input_ids[0] == endtok)[0].item()\n",
    "    context = input_ids[:, :sep_idx+1]\n",
    "    target_txt = input_ids[:, sep_idx+1:eos_idx+1]\n",
    "\n",
    "    context_txt = text_encoder.decode(context[0], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    refs = text_encoder.decode(target_txt[0], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    sample_output = model.generate(\n",
    "                                    context, \n",
    "                                    # attention_mask=mask,\n",
    "                                    max_length=512, \n",
    "                                    do_sample=True,\n",
    "                                    num_beams = 20,  # https://arxiv.org/pdf/2108.03502.pdf \n",
    "                                    top_p=0.95, # https://arxiv.org/pdf/2108.03502.pdf \n",
    "                                    top_k=3, # https://arxiv.org/pdf/2108.03502.pdf\n",
    "                                    eos_token_id=endtok,\n",
    "                                    bos_token_id=text_encoder.bos_token_id,\n",
    "                                    decoder_start_token_id = septok,\n",
    "                                    min_length = 100,\n",
    "                                    num_return_sequences=1, \n",
    "                                    temperature=1.0, # https://arxiv.org/pdf/2108.03502.pdf\n",
    "                                    repetition_penalty=2.0,  # https://arxiv.org/pdf/2108.03502.pdf\n",
    "                                    no_repeat_ngram_size=3, # https://arxiv.org/pdf/2108.03502.pdf\n",
    "                                    forced_eos_token_id = endtok,\n",
    "                                    early_stopping=True  # https://arxiv.org/pdf/2108.03502.pdf\n",
    "                                )\n",
    "    hyps = text_encoder.decode(sample_output[0][sep_idx+1:], skip_special_tokens=False, clean_up_tokenization_spaces=False)\n",
    "    rouge_score = rouge_scores(hyps, refs)\n",
    "    return context_txt, refs, hyps, rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_text(text: str=\"\") -> str:\n",
    "    return text.replace('\\r\\n',' ').replace('\\n',' ').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_evaluate_result(data: tuple, path: str=''):\n",
    "    columns = ['context', 'refs', 'hyps', 'ROUGE-1 F1', 'ROUGE-2 F1', 'ROUGE-L F1']\n",
    "    assert len(columns) == len(data[0])    \n",
    "    with open(os.path.join(path, 'evaluate_results.csv'), 'w', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f, delimiter='|', lineterminator='\\n')\n",
    "        writer.writerow(columns)\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'savedir/s_all_nodiscourse_kw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "context, refs, hyps, score = evaluate_batch(batch, text_encoder)\n",
    "data.append( (context, flat_text(refs), flat_text(hyps), score['rouge-1']['f'], score['rouge-2']['f'], score['rouge-l']['f']) )\n",
    "write_evaluate_result(data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'evaluate_results.csv'), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72.000000\n",
       "mean      0.121379\n",
       "std       0.043786\n",
       "min       0.048593\n",
       "25%       0.088740\n",
       "50%       0.117673\n",
       "75%       0.153257\n",
       "max       0.225455\n",
       "Name: ROUGE-L F1, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ROUGE-L F1'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'generated_stories.csv'), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В некотором царстве, в некотором государстве жил да был старик со старухой, и был у них сын Мартынка. Всю жизнь свою занимался старик охотой, бил зверя и птицу, тем и сам кормился и семью кормил. Пришло время - заболел старик и помер. Остался Мартынка с матерью, потужили-поплакали, да делать-то нечего: мертвого назад не воротишь. Пожили с неделю и приели весь хлеб, что в запасе был. Видит старуха, что больше есть нечего, надо за денежки приниматься, а старик-то оставил им двести рублей. Больно не хотелось ей начинать кубышку, однако сколько ни крепилась, а начинать нужно - не с голоду же умирать! Отсчитала сто рублей и говорит сыну: - Ну, Мартынка, вот тебе сто целковиков, пойди попроси у соседей лошадь, поезжай в город да закупи хлеба. Авось как-нибудь зиму промаячим, а весной станем работу искать. Мартынка выпросил телегу с лошадью и поехал в город. Едет он мимо мясных лавок - шум, брань, толпа народу. Что такое? А то мясники изловили охотничью собаку, привязали к столбу и бьют ее палками - собака рвется, визжит, огрызается. Мартынка подбежал к тем мясникам и спрашивает: - Братцы, за что вы бедного пса так бьете немилостиво? - Да как его не бить, - отвечают мясники, - когда он целую тушу говядины испортил! - Полно, братцы! Не бейте его, лучше продайте мне. - Пожалуйста, купи, - говорит один мужик шутя. - Давай сто рублей. Мартынка вытащил из-за пазухи сотню, отдал мясникам, а собаку отвязал и взял с собой. Пес начал к нему ласкаться, хвостом так и вертит: понимает, значит, кто его от смерти спас. Вот приезжает Мартынка домой, мать тотчас стала спрашивать: - Что купил, сынок? - Купил себе первое счастье. - Что ты завираешься! Какое там счастье? - А вот он, Журка! - и показывает ей собаку. - А больше ничего не купил? - Коли б деньги остались, может, и купил бы, только вся сотня за собаку пошла. Старуха заругалась. - Нам, - говорит, - самим есть нечего, нынче последние поскребушки по закромам собрала да лепешку испекла, а завтра и того не будет! На другой день вытащила старуха еще сто рублей, отдает Мартынке и наказывает: - На, сынок! Поезжай в город, купи хлеба, а задаром денег не бросай. Приехал Мартынка в город, стал ходить по улицам да присматриваться, и попался ему на глаза злой мальчишка: поймал кота, зацепил веревкой за шею и давай тащить на реку. - Постой! - закричал Мартынка. - Куда Ваську тащишь? - Хочу его утопить, проклятого! - За какую провинность? - Со стола пирог стянул. - Не топи его, лучше продай мне. - Пожалуй, купи. Давай сто рублей. Мартынка не стал долго раздумывать, полез за пазуху, вытащил деньги и отдал мальчику, а кота посадил в мешок и повез домой. - Что купил сынок? - спрашивает его старуха. - Кота Ваську. - А больше ничего не купил? - Коли б деньги остались, может, и купил бы еще что-нибудь. - Ах ты дурак этакой! - закричала на него старуха. - Ступай же из дому вон, ищи себе хлеба по чужим людям! Пошел Мартынка в соседнее село искать работу. Идет дорогою, а следом за ним Журка с Васькой бегут. Навстречу ему поп: - Куда, свет, идешь? - Иду в батраки наниматься. - Ступай ко мне. Только я работников без ряды беру: кто у меня прослужил три года, того и так не обижу. Мартынка согласился и без устали три лета и три зимы на попа работал. Пришел срок к расплате, зовет его хозяин: - Ну, Мартынка, иди - получай за свою службу. Привел его в амбар, показывает два полных мешка и говорит: - Какой хочешь, тот и бери. - Смотрит Мартынка - в одном мешке серебро, а в другом песок, и задумался: Эта шутка неспроста приготовлена! Пусть лучше мои труды пропадут, а уж я попытаю, возьму песок - что из того будет? Говорит он хозяину: - Я, батюшка, выбираю себе мешок с мелким песочком. - Ну, свет, твоя добрая воля. Бери, коли серебром брезгаешь. Мартынка взвалил мешок на спину и пошел искать другого места. Шел, шел и забрел в темный, дремучий лес. Среди леса поляна, на поляне огонь горит, в огне девица сидит, да такая красавица, что ни вздумать, ни взгадать, только в сказке сказать. Говорит красна девица: - Мартын, вдовьин сын! Если хочешь добыть себе счастья, избавь меня: засыпь это пламя песком, за который ты три года служил. И впрямь, - подумал Мартынка, - чем таскать с собою этакую тяжесть, лучше человеку пособить. Невелико богатство - песок, этого добра везде много! Снял мешок, развязал и давай сыпать. Огонь тотчас погас, красная девица ударилась оземь, обернулась змеею, вскочила доброму молодцу на грудь и обвилась кольцом вокруг его шеи. Мартынка испугался. - Не бойся! - сказала ему змея. - Иди теперь за тридевять земель, в тридесятое государство, в подземное царство, там мой батюшка царствует. Как придешь к нему на двор, будет он давать тебе много злата, и серебра, и самоцветных камней - ты ничего не бери, а проси у него с мизинного перста колечко. То кольцо не простое: если перекинуть его с руки на руку - тотчас двенадцать молодцев явятся, и что им ни будет приказано, всё за единую ночь сделают. Отправился добрый молодец в путь-дорогу. Близко ли, далеко ли, скоро ли, коротко ли - подходит к тридесятому царству и видит огромный камень. Тут соскочила с его шеи змея, ударилась о сырую землю и сделалась по-прежнему красною девицей. - Ступай за мной! - говорит красная девица и повела его под тот камень. Долго шли они подземным ходом, вдруг забрезжил свет - все светлей да светлей, и вышли они на широкое поле, под ясное небо. На том поле великолепный дворец выстроен, а во дворце живет отец красной девицы, царь той подземной стороны. Входят путники в палаты белокаменные, встречает их царь ласково. - Здравствуй, - говорит, - дочь моя милая! Где ты столько лет скрывалась? - Свет ты мой батюшка! Я бы совсем пропала, если бы не этот человек: он меня от злой, неминуемой смерти освободил и сюда, в родные места, привел. - Спасибо тебе, добрый молодец! - сказал царь. - За твою добродетель наградить тебя надо. Бери себе и злата, и серебра, и камней самоцветных, сколько твоей душе хочется. Отвечает ему Мартын, вдовьин сын: - Ваше царское величество! Не требуется мне ни злата, ни серебра, ни камней самоцветных. Коли хочешь жаловать, дай мне колечко со своей царской руки - с мизинного перста. Я человек холостой, стану на колечко почаще посматривать, стану про невесту раздумывать, тем свою скуку разгонять. Царь тотчас снял кольцо, отдал Мартыну: - На, владей на здоровье! Да смотри никому про кольцо не рассказывай, не то сам себя в большую беду втянешь! Мартын, вдовьин сын, поблагодарил царя, взял кольцо да малую толику денег на дорогу и пустился обратно тем же путем, каким прежде шел. Близко ли, далеко ли, скоро ли, коротко ли - воротился на родину, разыскал свою мать-старуху, и стали они вместе жить-поживать без всякой нужды и печали. Захотелось Мартынке жениться; пристал он к матери, посылает ее свахою. - Ступай, - говорит, - к самому королю, высватай за меня прекрасную королевну. - Эй, сынок, - отвечает старуха, - рубил бы ты дерево по себе, лучше бы вышло! А то вишь что выдумал! Ну зачем я к королю пойду? Известное дело, он осердится и меня и тебя велит казни предать. - Ничего, матушка! Небось, коли я посылаю, значит, смело иди. Какой будет ответ от короля, про то мне скажи, а без ответу и домой не возвращайся. С</s>\n"
     ]
    }
   ],
   "source": [
    "print(df.refs.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d3a13fa35461c6d7f441fbb3d93fc4f14860aa527e8f914775d5e57b8364c02"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
