{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import rouge\n",
    "import codecs\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.model.logger import Logger\n",
    "from src.model.data_full import RawFilesDataset\n",
    "from src.model.loss import ParagraphLoss\n",
    "from src.model.generate_utils import toks_to_str\n",
    "\n",
    "from rake_nltk import Rake\n",
    "from nltk.corpus import stopwords\n",
    "import csv\n",
    "\n",
    "# from src.model.generate_utils  import generate_paragraph\n",
    "# from src.model.eval_utils import evaluate_doc_model\n",
    "# from src.model.model import GPT2BaseModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers.decoders import ByteLevel\n",
    "decoder = ByteLevel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_rep = []\n",
    "end_tok = encoder.convert_tokens_to_ids('_end_')\n",
    "\n",
    "for token in sample_output[0]:\n",
    "    print(token.item(), repr(decoder.decode([ encoder.convert_ids_to_tokens(token.item(), skip_special_tokens=True)])))\n",
    "    if token.item() == end_tok : #or token.item() == 0:# or x.item() == end_idx:\n",
    "        break        \n",
    "    str_rep.append(encoder.convert_ids_to_tokens(token.item()))\n",
    "\n",
    "str_rep = encoder.convert_tokens_to_string(str_rep)\n",
    "\n",
    "# This makes sure rouge scorers doesn't complain about no sentences\n",
    "if not str_rep:\n",
    "    str_rep = \"unk.\"\n",
    "elif \".\" not in str_rep:\n",
    "    str_rep += \".\"\n",
    "\n",
    "print(encoder.decode(sample_output[0], skip_special_tokens=False, clean_up_tokenization_spaces=False))\n",
    "print(\"-\"*50)\n",
    "print(str_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    repeattheta = 1.5\n",
    "    output_attentions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_model = GPT2BaseModel(args, vocab=vocab, n_ctx=config['n_ctx'], gen_len=401, lastidx=encoder.eos_token_id, includeprev=False, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_doc_model(model=doc_model, val_loader=val_loader, text_encoder=encoder, device='cpu', beam=0, gen_len=401, k=0, p=90, save_file='out', max_len=512, gen_dir=None, tgt_dir=None, min_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w', encoding='utf-8') as f:\n",
    "    json.dump(\"Моя строка\", f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('generated/test.gens.tsv', sep='\\t', header=None, names=['id', 'plot', 'context', 'part', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* для токенизаторов в исходном коде не применяется язык\n",
    "* англ токенизатор предложений лучше делит, к примеру русский не смог разделить 'Король дал за дочкой богатое приданое, наградил зятя большим чином и задал пир на весь мир.\\nЖивут молодые месяц, и два, и три.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Metric, Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = '111 Волшебное кольцо.txt'\n",
    "path = 'dataset/raw'\n",
    "with open(os.path.join(path, story), 'r', encoding='utf-8') as f:\n",
    "    text =  f.read()\n",
    "    text = re.sub('\\.\\.\\.', '.', text)\n",
    "    text = re.sub('—', '-', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_scores(hyps, refs):       \n",
    "    rouge_scorer = rouge.Rouge()\n",
    "    averaged_scores = rouge_scorer.get_scores(hyps, refs, avg=True)\n",
    "    return averaged_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_encoder = GPT2Tokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\", add_prefix_space=True)\n",
    "text_encoder.add_special_tokens({'bos_token': '<s>',                                     \n",
    "                                    'eos_token': '</s>',\n",
    "                                    'additional_special_tokens': ['[SEP]', '_kw_', '_endkw_']\n",
    "                                })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('savedir/s_all_nodiscourse_kw/checkpoints/checkpoint.pt', 'rb') as f:\n",
    "    model = torch.load(f, map_location=torch.device('cpu'))\n",
    "\n",
    "with open('savedir/s_all_nodiscourse_kw/test_dataset', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = RawFilesDataset(test, text_encoder, 2048, n_ctx=70)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "batch = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, mask = batch['sample'], batch['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = input_ids[:, 70:]\n",
    "mask_tgt = mask[:, 70:]\n",
    "new = target[mask_tgt==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_encoder.batch_decode(batch['sample'], clean_up_tokenization_spaces=False, skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder.additional_special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(batch['mask'][0,0:70].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'savedir/s_all_nodiscourse_kw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(path, 'generated_stories.csv'), sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Помер старик со старухою, оставался у них сын сирота. Взял его к себе дядя и заставил овец пасти. Ни много, ни мало прошло времени, призывает дядя племянника, хочет попытать у него ума-разума и говорит ему: - Вот тебе сотни баранов, гони их на ярмонку да продай с барышом, чтобы и бараны были целы, и деньги сполна выручены. Что тут делать! Заплакал бедняга и погнал баранов в чистое поле: выгнал, сел на дороге и задумался о своем горе. Идет мимо девица: - О чем слезы льешь, добрый молодец? - Как же мне не плакать? Нет у меня ни отца, ни матери; один дядя, и тот обижает! - Какую ж обиду он тебе делает? - Да вот послал на ярмонку, велел баранами торговать, да так, чтобы и бараны были целы, и деньги сполна выручены. - Ну, это хитрость не великая! Найми-ка ты баб да остриги баранов, а шерсть отнеси на ярмонку и продай; вот у тебя и деньги, и бараны в целости! Парень так и сделал; продал шерсть, пригнал стадо домой и отдает дяде вырученные деньги. - Хорошо, - говорит дядя племяннику, - только ведь ты не своим разумом вздумал это? Чай, тебя научил кто-нибудь? Парень признался. - Шла, - говорит, - мимо девица, она научила. Дядя тотчас приказал закладывать лошадь: - Поедем, станем сватать ту девицу. Вот и поехали. Приезжают прямо на двор, спрашивают: куда лошадь девать? - Привяжите до зимы аль до лета! - говорит им девица. Дядя с племянником думали, думали, не знают, за что привязать; стали у ней спрашивать: до какой зимы, до какого лета? - Эх вы, недогадливые! Привяжите к саням, а не то к телеге. Привязали они лошадь, вошли в избу и сели на лавочку. Спрашивает ее дядя: - Ты с кем живешь, девица? - С батюшкой. - Где ж твой отец? - Уехал сто рублей на пятнадцать копеек менять. - А когда назад воротится? - Если кругом поедет - к вечеру будет, а если прямо поедет - и через три дня не бывать! - Что ж это за диво такое? - спрашивает дядя. - Неужто и вправду отец твой поехал сто рублей на пятнадцать копеек менять! - А то нет? Он поехал зайцев травить; зайца-то затравит - всего пятнадцать копеек заработает, а лошадь загонит - сто рублей потеряет. - А что значит: ежели он прямо поедет - и в три дня не прибудет, а ежели кругом - к вечеру будет? - А то значит, что прямо болотом ехать, а кругом дорогою! Удивился дядя уму-разуму девицы и сосватал ее за своего племянника.\n"
     ]
    }
   ],
   "source": [
    "print(df.refs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "царь тотчас снял кольцокот васька говориткот взял кольцоднем королевна носит кольцо\n"
     ]
    }
   ],
   "source": [
    "text = '<s> царь тотчас снял кольцо _kw_ кот васька говорит _kw_ кот взял кольцо _kw_ днем королевна носит кольцо _kw_'\n",
    "\n",
    "tokens = text_encoder.encode(text)\n",
    "hyps = text_encoder.decode(tokens, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "print(hyps)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2d3a13fa35461c6d7f441fbb3d93fc4f14860aa527e8f914775d5e57b8364c02"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
