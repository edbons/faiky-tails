# Описание задачи

## Наименование разработки

Наименование: "Система генерации русских народных сказок" (далее -- СГС)

## Цель и назначение разработки

Цель: снижение себестоимости контента, предоставляемого конечному потребителю, за счет использование уникальных произведений, не требующих отчислений правообладателям.

Назначение: создание уникальных текстовых и/или аудио произведений на тематику народных сказаний.

## Описание применения

СГС может применяться в качестве источника контента для следующих служб:

* голосовые помощники (пример, Алиса (Яндекс), Маруся (Mail.ru Group));
* службы потокового аудио (пример, Яндекс Музыка, Spotify).

Потребителями (пользователями) контента генерируемого СГС могут выступать:

* дети дошкольного возраста, для которых форма произведения превалирует над возможной не логичностью содержания.
* родители детей, приобретающие подписки для служб потокового аудио.

## Описание существующих решений

Для генерации сказок в русскоязычном сегменте сети Интернет присутствуют различные ресурсы, среди которых для анализа были отобраны следующие:

1. Навык "Сказки" для голосового помощника Алиса (источник -- https://alice.voice-ui.ru/skills/ec1176f1-skazki)
2. Мобильное приложение "Сказаврия" (источник -- https://skazavria.ru/)
4. Сайт http://generatorskazok.ru/
5. Модель генерации сказок с озвучкой и картинками от Sber AI (источник -- https://github.com/sberbank-ai/DigiTeller/blob/main/Readme_Rus.md)
6. Сервис "Балабоба" от Яндекс (источник -- https://yandex.ru/lab/yalm?style=0).

Для генерации сказок в существующих решениях используются следующие подходы:

1. Подстановка в шаблон текста ключевых слов (фраз). Например, имена главных героев, сказочных артефактов. Подход используется в мобильном приложении "Сказаврия", на сайте http://generatorskazok.ru/.
2. Поиск существующей сказки по ключевым фразам пользователя. Не является генератором уникального контента, например навык "Сказки" для голосового помощника Алиса.
3. Генерация уникального текста большими моделями (пример, BERT, GPT, YAML) дообученными на специализированной доменной области (к примеру, на корпусе текстов художественной литературы), пример модели от Sber AI и сервис "Балабоба" от Яндекс.

Пример сгенерированного текста для фразы  "сказка про царя" в сервисе "Балабоба" от Яндекс:
"сказка про царя, который в шутку женился на лягушке.
Только вот потом он обнаружил, что женился на крокодиле, и лягушачьи лапки оказались как раз кстати, чтобы заменить ему ужин.
А уж после того как царь обнаружил, что женится на утке, которая летает, а гнездо свила на вершине башни, он вообще чуть не ослеп и вынужден был бежать, потому как не смог отличить, где небо, а где земля."

## Описание задачи

Задача генерации текста может решаться алгоритмами машинного обучения без учителя:

1. Генеративно-состязательные сети (Generative adversarial network, сокращённо GAN).
2. Модели предсказывающие следующее слово по его частотности вхождения в N-грамму, например в зависимости от имеющейся выборки в 2-грамму "Мама мыла", входит слово "мыла" (хвост 2-граммы), а для 2-граммы где  слово "мыла" является ведущим (головой 2-граммы), наиболее вероятным (чаще встречается в выборке) может быть слово "раму". Один из примеров таких моделей "жадный поиск" ("greedy search", источник - https://towardsdatascience.com/foundations-of-nlp-explained-visually-beam-search-how-it-works-1586b9849a24)

## Выбор методики определения эффективности решения

Существуют следующие подходы к оценке сгенерированного текста (источник -- https://arxiv.org/pdf/2006.14799.pdf):

1. Ручная оценка, выполняется человеком, который сравнивает эталонный текст (reference) и сгенерированный (candidate) на похожесть, либо только сгенерированный текст на синтаксические и смысловые ошибки (например, тест Тьюринга). Недостатки: ручная оценка затратна по времени; может требовать затрат на привлечение оценщиков (экспертов) на краудсорсинговых платформах (например, Яндекс.Толока https://toloka.yandex.ru/)
2. Автоматическая проверка (автоматические метрики), которая сравнивает статистическими методами эталонный текст (reference) и сгенерированный (candidate) на похожесть (например, расстояние Левенштейна). Недостатки: сложность подбора методов, т.к. сгенерированный текст может сильно отличаться от эталонного, но по смыслу, стилю изложения соответствовать контексту эталона. 
3. Предобученные метрики. Используются специальные модели машинного обучения способные оценивать похожесть двух сгенерированных текстов, или эталонного  (reference) и сгенерированного (candidate) текстов. Недостатки: оценивающие модели необходимо дообучать для оцениваемого контекста.

Для сгенерированных историй, например сказок, наиболее интересным являются оценки:

1. Согласованности (coherence) или последовательности (consistency) содержания (например, что главные герои не меняются по ходу изложения).
2. Грамматических ошибок.
3. Соответствие стилю (тону) произведения ("Жили-были...").

